// Generated from /home/runner/work/ms-spark-formatter/ms-spark-formatter/grammar/SqlBaseParser.g4 by ANTLR 4.8
#![allow(dead_code)]
#![allow(non_snake_case)]
#![allow(non_upper_case_globals)]
#![allow(nonstandard_style)]
#![allow(unused_imports)]
#![allow(unused_mut)]
#![allow(unused_braces)]
use antlr_rust::PredictionContextCache;
use antlr_rust::parser::{Parser, BaseParser, ParserRecog, ParserNodeType};
use antlr_rust::token_stream::TokenStream;
use antlr_rust::TokenSource;
use antlr_rust::parser_atn_simulator::ParserATNSimulator;
use antlr_rust::errors::*;
use antlr_rust::rule_context::{BaseRuleContext, CustomRuleContext, RuleContext};
use antlr_rust::recognizer::{Recognizer,Actions};
use antlr_rust::atn_deserializer::ATNDeserializer;
use antlr_rust::dfa::DFA;
use antlr_rust::atn::{ATN, INVALID_ALT};
use antlr_rust::error_strategy::{ErrorStrategy, DefaultErrorStrategy};
use antlr_rust::parser_rule_context::{BaseParserRuleContext, ParserRuleContext,cast,cast_mut};
use antlr_rust::tree::*;
use antlr_rust::token::{TOKEN_EOF,OwningToken,Token};
use antlr_rust::int_stream::EOF;
use antlr_rust::vocabulary::{Vocabulary,VocabularyImpl};
use antlr_rust::token_factory::{CommonTokenFactory,TokenFactory, TokenAware};
use super::sqlbaseparserlistener::*;
use super::sqlbaseparservisitor::*;

use antlr_rust::lazy_static;
use antlr_rust::{TidAble,TidExt};

use std::marker::PhantomData;
use std::sync::Arc;
use std::rc::Rc;
use std::convert::TryFrom;
use std::cell::RefCell;
use std::ops::{DerefMut, Deref};
use std::borrow::{Borrow,BorrowMut};
use std::any::{Any,TypeId};

		pub const SEMICOLON:isize=1; 
		pub const LEFT_PAREN:isize=2; 
		pub const RIGHT_PAREN:isize=3; 
		pub const COMMA:isize=4; 
		pub const DOT:isize=5; 
		pub const LEFT_BRACKET:isize=6; 
		pub const RIGHT_BRACKET:isize=7; 
		pub const BANG:isize=8; 
		pub const ADD:isize=9; 
		pub const AFTER:isize=10; 
		pub const AGGREGATE:isize=11; 
		pub const ALL:isize=12; 
		pub const ALTER:isize=13; 
		pub const ALWAYS:isize=14; 
		pub const ANALYZE:isize=15; 
		pub const AND:isize=16; 
		pub const ANTI:isize=17; 
		pub const ANY:isize=18; 
		pub const ANY_VALUE:isize=19; 
		pub const ARCHIVE:isize=20; 
		pub const ARRAY:isize=21; 
		pub const AS:isize=22; 
		pub const ASC:isize=23; 
		pub const AT:isize=24; 
		pub const ATOMIC:isize=25; 
		pub const AUTHORIZATION:isize=26; 
		pub const BEGIN:isize=27; 
		pub const BETWEEN:isize=28; 
		pub const BIGINT:isize=29; 
		pub const BINARY:isize=30; 
		pub const BINDING:isize=31; 
		pub const BOOLEAN:isize=32; 
		pub const BOTH:isize=33; 
		pub const BUCKET:isize=34; 
		pub const BUCKETS:isize=35; 
		pub const BY:isize=36; 
		pub const BYTE:isize=37; 
		pub const CACHE:isize=38; 
		pub const CALL:isize=39; 
		pub const CALLED:isize=40; 
		pub const CASCADE:isize=41; 
		pub const CASE:isize=42; 
		pub const CAST:isize=43; 
		pub const CATALOG:isize=44; 
		pub const CATALOGS:isize=45; 
		pub const CHANGE:isize=46; 
		pub const CHAR:isize=47; 
		pub const CHARACTER:isize=48; 
		pub const CHECK:isize=49; 
		pub const CLEAR:isize=50; 
		pub const CLUSTER:isize=51; 
		pub const CLUSTERED:isize=52; 
		pub const CODEGEN:isize=53; 
		pub const COLLATE:isize=54; 
		pub const COLLATION:isize=55; 
		pub const COLLECTION:isize=56; 
		pub const COLUMN:isize=57; 
		pub const COLUMNS:isize=58; 
		pub const COMMENT:isize=59; 
		pub const COMMIT:isize=60; 
		pub const COMPACT:isize=61; 
		pub const COMPACTIONS:isize=62; 
		pub const COMPENSATION:isize=63; 
		pub const COMPUTE:isize=64; 
		pub const CONCATENATE:isize=65; 
		pub const CONDITION:isize=66; 
		pub const CONSTRAINT:isize=67; 
		pub const CONTAINS:isize=68; 
		pub const CONTINUE:isize=69; 
		pub const COST:isize=70; 
		pub const CREATE:isize=71; 
		pub const CROSS:isize=72; 
		pub const CUBE:isize=73; 
		pub const CURRENT:isize=74; 
		pub const CURRENT_DATE:isize=75; 
		pub const CURRENT_TIME:isize=76; 
		pub const CURRENT_TIMESTAMP:isize=77; 
		pub const CURRENT_USER:isize=78; 
		pub const DAY:isize=79; 
		pub const DAYS:isize=80; 
		pub const DAYOFYEAR:isize=81; 
		pub const DATA:isize=82; 
		pub const DATE:isize=83; 
		pub const DATABASE:isize=84; 
		pub const DATABASES:isize=85; 
		pub const DATEADD:isize=86; 
		pub const DATE_ADD:isize=87; 
		pub const DATEDIFF:isize=88; 
		pub const DATE_DIFF:isize=89; 
		pub const DBPROPERTIES:isize=90; 
		pub const DEC:isize=91; 
		pub const DECIMAL:isize=92; 
		pub const DECLARE:isize=93; 
		pub const DEFAULT:isize=94; 
		pub const DEFINED:isize=95; 
		pub const DEFINER:isize=96; 
		pub const DELAY:isize=97; 
		pub const DELETE:isize=98; 
		pub const DELIMITED:isize=99; 
		pub const DESC:isize=100; 
		pub const DESCRIBE:isize=101; 
		pub const DETERMINISTIC:isize=102; 
		pub const DFS:isize=103; 
		pub const DIRECTORIES:isize=104; 
		pub const DIRECTORY:isize=105; 
		pub const DISTINCT:isize=106; 
		pub const DISTRIBUTE:isize=107; 
		pub const DIV:isize=108; 
		pub const DO:isize=109; 
		pub const DOUBLE:isize=110; 
		pub const DROP:isize=111; 
		pub const ELSE:isize=112; 
		pub const ELSEIF:isize=113; 
		pub const END:isize=114; 
		pub const ENFORCED:isize=115; 
		pub const ESCAPE:isize=116; 
		pub const ESCAPED:isize=117; 
		pub const EVOLUTION:isize=118; 
		pub const EXCEPT:isize=119; 
		pub const EXCHANGE:isize=120; 
		pub const EXCLUDE:isize=121; 
		pub const EXISTS:isize=122; 
		pub const EXIT:isize=123; 
		pub const EXPLAIN:isize=124; 
		pub const EXPORT:isize=125; 
		pub const EXTEND:isize=126; 
		pub const EXTENDED:isize=127; 
		pub const EXTERNAL:isize=128; 
		pub const EXTRACT:isize=129; 
		pub const FALSE:isize=130; 
		pub const FETCH:isize=131; 
		pub const FIELDS:isize=132; 
		pub const FILTER:isize=133; 
		pub const FILEFORMAT:isize=134; 
		pub const FIRST:isize=135; 
		pub const FLOAT:isize=136; 
		pub const FLOW:isize=137; 
		pub const FOLLOWING:isize=138; 
		pub const FOR:isize=139; 
		pub const FOREIGN:isize=140; 
		pub const FORMAT:isize=141; 
		pub const FORMATTED:isize=142; 
		pub const FOUND:isize=143; 
		pub const FROM:isize=144; 
		pub const FULL:isize=145; 
		pub const FUNCTION:isize=146; 
		pub const FUNCTIONS:isize=147; 
		pub const GENERATED:isize=148; 
		pub const GEOGRAPHY:isize=149; 
		pub const GEOMETRY:isize=150; 
		pub const GLOBAL:isize=151; 
		pub const GRANT:isize=152; 
		pub const GROUP:isize=153; 
		pub const GROUPING:isize=154; 
		pub const HANDLER:isize=155; 
		pub const HAVING:isize=156; 
		pub const BINARY_HEX:isize=157; 
		pub const HOUR:isize=158; 
		pub const HOURS:isize=159; 
		pub const IDENTIFIER_KW:isize=160; 
		pub const IDENTITY:isize=161; 
		pub const IF:isize=162; 
		pub const IGNORE:isize=163; 
		pub const IMMEDIATE:isize=164; 
		pub const IMPORT:isize=165; 
		pub const IN:isize=166; 
		pub const INCLUDE:isize=167; 
		pub const INCREMENT:isize=168; 
		pub const INDEX:isize=169; 
		pub const INDEXES:isize=170; 
		pub const INNER:isize=171; 
		pub const INPATH:isize=172; 
		pub const INPUT:isize=173; 
		pub const INPUTFORMAT:isize=174; 
		pub const INSERT:isize=175; 
		pub const INTERSECT:isize=176; 
		pub const INTERVAL:isize=177; 
		pub const INT:isize=178; 
		pub const INTEGER:isize=179; 
		pub const INTO:isize=180; 
		pub const INVOKER:isize=181; 
		pub const IS:isize=182; 
		pub const ITEMS:isize=183; 
		pub const ITERATE:isize=184; 
		pub const JOIN:isize=185; 
		pub const JSON:isize=186; 
		pub const KEY:isize=187; 
		pub const KEYS:isize=188; 
		pub const LANGUAGE:isize=189; 
		pub const LAST:isize=190; 
		pub const LATERAL:isize=191; 
		pub const LAZY:isize=192; 
		pub const LEADING:isize=193; 
		pub const LEAVE:isize=194; 
		pub const LEFT:isize=195; 
		pub const LEVEL:isize=196; 
		pub const LIKE:isize=197; 
		pub const ILIKE:isize=198; 
		pub const LIMIT:isize=199; 
		pub const LINES:isize=200; 
		pub const LIST:isize=201; 
		pub const LOAD:isize=202; 
		pub const LOCAL:isize=203; 
		pub const LOCATION:isize=204; 
		pub const LOCK:isize=205; 
		pub const LOCKS:isize=206; 
		pub const LOGICAL:isize=207; 
		pub const LONG:isize=208; 
		pub const LOOP:isize=209; 
		pub const MACRO:isize=210; 
		pub const MAP:isize=211; 
		pub const MATCHED:isize=212; 
		pub const MATERIALIZED:isize=213; 
		pub const MAX:isize=214; 
		pub const MEASURE:isize=215; 
		pub const MERGE:isize=216; 
		pub const METRICS:isize=217; 
		pub const MICROSECOND:isize=218; 
		pub const MICROSECONDS:isize=219; 
		pub const MILLISECOND:isize=220; 
		pub const MILLISECONDS:isize=221; 
		pub const MINUTE:isize=222; 
		pub const MINUTES:isize=223; 
		pub const MODIFIES:isize=224; 
		pub const MONTH:isize=225; 
		pub const MONTHS:isize=226; 
		pub const MSCK:isize=227; 
		pub const NAME:isize=228; 
		pub const NAMESPACE:isize=229; 
		pub const NAMESPACES:isize=230; 
		pub const NANOSECOND:isize=231; 
		pub const NANOSECONDS:isize=232; 
		pub const NATURAL:isize=233; 
		pub const NO:isize=234; 
		pub const NONE:isize=235; 
		pub const NOT:isize=236; 
		pub const NULL:isize=237; 
		pub const NULLS:isize=238; 
		pub const NUMERIC:isize=239; 
		pub const NORELY:isize=240; 
		pub const OF:isize=241; 
		pub const OFFSET:isize=242; 
		pub const ON:isize=243; 
		pub const ONLY:isize=244; 
		pub const OPTION:isize=245; 
		pub const OPTIONS:isize=246; 
		pub const OR:isize=247; 
		pub const ORDER:isize=248; 
		pub const OUT:isize=249; 
		pub const OUTER:isize=250; 
		pub const OUTPUTFORMAT:isize=251; 
		pub const OVER:isize=252; 
		pub const OVERLAPS:isize=253; 
		pub const OVERLAY:isize=254; 
		pub const OVERWRITE:isize=255; 
		pub const PARTITION:isize=256; 
		pub const PARTITIONED:isize=257; 
		pub const PARTITIONS:isize=258; 
		pub const PERCENTLIT:isize=259; 
		pub const PIVOT:isize=260; 
		pub const PLACING:isize=261; 
		pub const POSITION:isize=262; 
		pub const PRECEDING:isize=263; 
		pub const PRIMARY:isize=264; 
		pub const PRINCIPALS:isize=265; 
		pub const PROCEDURE:isize=266; 
		pub const PROCEDURES:isize=267; 
		pub const PROPERTIES:isize=268; 
		pub const PURGE:isize=269; 
		pub const QUARTER:isize=270; 
		pub const QUERY:isize=271; 
		pub const RANGE:isize=272; 
		pub const READS:isize=273; 
		pub const REAL:isize=274; 
		pub const RECORDREADER:isize=275; 
		pub const RECORDWRITER:isize=276; 
		pub const RECOVER:isize=277; 
		pub const RECURSION:isize=278; 
		pub const RECURSIVE:isize=279; 
		pub const REDUCE:isize=280; 
		pub const REFERENCES:isize=281; 
		pub const REFRESH:isize=282; 
		pub const RELY:isize=283; 
		pub const RENAME:isize=284; 
		pub const REPAIR:isize=285; 
		pub const REPEAT:isize=286; 
		pub const REPEATABLE:isize=287; 
		pub const REPLACE:isize=288; 
		pub const RESET:isize=289; 
		pub const RESPECT:isize=290; 
		pub const RESTRICT:isize=291; 
		pub const RETURN:isize=292; 
		pub const RETURNS:isize=293; 
		pub const REVOKE:isize=294; 
		pub const RIGHT:isize=295; 
		pub const RLIKE:isize=296; 
		pub const ROLE:isize=297; 
		pub const ROLES:isize=298; 
		pub const ROLLBACK:isize=299; 
		pub const ROLLUP:isize=300; 
		pub const ROW:isize=301; 
		pub const ROWS:isize=302; 
		pub const SECOND:isize=303; 
		pub const SECONDS:isize=304; 
		pub const SCHEMA:isize=305; 
		pub const SCHEMAS:isize=306; 
		pub const SECURITY:isize=307; 
		pub const SELECT:isize=308; 
		pub const SEMI:isize=309; 
		pub const SEPARATED:isize=310; 
		pub const SERDE:isize=311; 
		pub const SERDEPROPERTIES:isize=312; 
		pub const SESSION_USER:isize=313; 
		pub const SET:isize=314; 
		pub const SETMINUS:isize=315; 
		pub const SETS:isize=316; 
		pub const SHORT:isize=317; 
		pub const SHOW:isize=318; 
		pub const SINGLE:isize=319; 
		pub const SKEWED:isize=320; 
		pub const SMALLINT:isize=321; 
		pub const SOME:isize=322; 
		pub const SORT:isize=323; 
		pub const SORTED:isize=324; 
		pub const SOURCE:isize=325; 
		pub const SPECIFIC:isize=326; 
		pub const SQL:isize=327; 
		pub const SQLEXCEPTION:isize=328; 
		pub const SQLSTATE:isize=329; 
		pub const START:isize=330; 
		pub const STATISTICS:isize=331; 
		pub const STORED:isize=332; 
		pub const STRATIFY:isize=333; 
		pub const STREAM:isize=334; 
		pub const STREAMING:isize=335; 
		pub const STRING:isize=336; 
		pub const STRUCT:isize=337; 
		pub const SUBSTR:isize=338; 
		pub const SUBSTRING:isize=339; 
		pub const SYNC:isize=340; 
		pub const SYSTEM_TIME:isize=341; 
		pub const SYSTEM_VERSION:isize=342; 
		pub const TABLE:isize=343; 
		pub const TABLES:isize=344; 
		pub const TABLESAMPLE:isize=345; 
		pub const TARGET:isize=346; 
		pub const TBLPROPERTIES:isize=347; 
		pub const TEMPORARY:isize=348; 
		pub const TERMINATED:isize=349; 
		pub const THEN:isize=350; 
		pub const TIME:isize=351; 
		pub const TIMEDIFF:isize=352; 
		pub const TIMESTAMP:isize=353; 
		pub const TIMESTAMP_LTZ:isize=354; 
		pub const TIMESTAMP_NTZ:isize=355; 
		pub const TIMESTAMPADD:isize=356; 
		pub const TIMESTAMPDIFF:isize=357; 
		pub const TINYINT:isize=358; 
		pub const TO:isize=359; 
		pub const EXECUTE:isize=360; 
		pub const TOUCH:isize=361; 
		pub const TRAILING:isize=362; 
		pub const TRANSACTION:isize=363; 
		pub const TRANSACTIONS:isize=364; 
		pub const TRANSFORM:isize=365; 
		pub const TRIM:isize=366; 
		pub const TRUE:isize=367; 
		pub const TRUNCATE:isize=368; 
		pub const TRY_CAST:isize=369; 
		pub const TYPE:isize=370; 
		pub const UNARCHIVE:isize=371; 
		pub const UNBOUNDED:isize=372; 
		pub const UNCACHE:isize=373; 
		pub const UNION:isize=374; 
		pub const UNIQUE:isize=375; 
		pub const UNKNOWN:isize=376; 
		pub const UNLOCK:isize=377; 
		pub const UNPIVOT:isize=378; 
		pub const UNSET:isize=379; 
		pub const UNTIL:isize=380; 
		pub const UPDATE:isize=381; 
		pub const USE:isize=382; 
		pub const USER:isize=383; 
		pub const USING:isize=384; 
		pub const VALUE:isize=385; 
		pub const VALUES:isize=386; 
		pub const VARCHAR:isize=387; 
		pub const VAR:isize=388; 
		pub const VARIABLE:isize=389; 
		pub const VARIANT:isize=390; 
		pub const VERSION:isize=391; 
		pub const VIEW:isize=392; 
		pub const VIEWS:isize=393; 
		pub const VOID:isize=394; 
		pub const WATERMARK:isize=395; 
		pub const WEEK:isize=396; 
		pub const WEEKS:isize=397; 
		pub const WHEN:isize=398; 
		pub const WHERE:isize=399; 
		pub const WHILE:isize=400; 
		pub const WINDOW:isize=401; 
		pub const WITH:isize=402; 
		pub const WITHIN:isize=403; 
		pub const WITHOUT:isize=404; 
		pub const YEAR:isize=405; 
		pub const YEARS:isize=406; 
		pub const ZONE:isize=407; 
		pub const EQ:isize=408; 
		pub const NSEQ:isize=409; 
		pub const NEQ:isize=410; 
		pub const NEQJ:isize=411; 
		pub const LT:isize=412; 
		pub const LTE:isize=413; 
		pub const GT:isize=414; 
		pub const GTE:isize=415; 
		pub const SHIFT_LEFT:isize=416; 
		pub const SHIFT_RIGHT:isize=417; 
		pub const SHIFT_RIGHT_UNSIGNED:isize=418; 
		pub const PLUS:isize=419; 
		pub const MINUS:isize=420; 
		pub const ASTERISK:isize=421; 
		pub const SLASH:isize=422; 
		pub const PERCENT:isize=423; 
		pub const TILDE:isize=424; 
		pub const AMPERSAND:isize=425; 
		pub const PIPE:isize=426; 
		pub const CONCAT_PIPE:isize=427; 
		pub const OPERATOR_PIPE:isize=428; 
		pub const HAT:isize=429; 
		pub const COLON:isize=430; 
		pub const DOUBLE_COLON:isize=431; 
		pub const ARROW:isize=432; 
		pub const FAT_ARROW:isize=433; 
		pub const HENT_START:isize=434; 
		pub const HENT_END:isize=435; 
		pub const QUESTION:isize=436; 
		pub const STRING_LITERAL:isize=437; 
		pub const BEGIN_DOLLAR_QUOTED_STRING:isize=438; 
		pub const DOUBLEQUOTED_STRING:isize=439; 
		pub const BIGINT_LITERAL:isize=440; 
		pub const SMALLINT_LITERAL:isize=441; 
		pub const TINYINT_LITERAL:isize=442; 
		pub const INTEGER_VALUE:isize=443; 
		pub const EXPONENT_VALUE:isize=444; 
		pub const DECIMAL_VALUE:isize=445; 
		pub const FLOAT_LITERAL:isize=446; 
		pub const DOUBLE_LITERAL:isize=447; 
		pub const BIGDECIMAL_LITERAL:isize=448; 
		pub const IDENTIFIER:isize=449; 
		pub const BACKQUOTED_IDENTIFIER:isize=450; 
		pub const SIMPLE_COMMENT:isize=451; 
		pub const BRACKETED_COMMENT:isize=452; 
		pub const WS:isize=453; 
		pub const UNRECOGNIZED:isize=454; 
		pub const DOLLAR_QUOTED_STRING_BODY:isize=455; 
		pub const END_DOLLAR_QUOTED_STRING:isize=456;
	pub const RULE_compoundOrSingleStatement:usize = 0; 
	pub const RULE_singleCompoundStatement:usize = 1; 
	pub const RULE_beginEndCompoundBlock:usize = 2; 
	pub const RULE_compoundBody:usize = 3; 
	pub const RULE_compoundStatement:usize = 4; 
	pub const RULE_setStatementInsideSqlScript:usize = 5; 
	pub const RULE_sqlStateValue:usize = 6; 
	pub const RULE_declareConditionStatement:usize = 7; 
	pub const RULE_conditionValue:usize = 8; 
	pub const RULE_conditionValues:usize = 9; 
	pub const RULE_declareHandlerStatement:usize = 10; 
	pub const RULE_whileStatement:usize = 11; 
	pub const RULE_ifElseStatement:usize = 12; 
	pub const RULE_repeatStatement:usize = 13; 
	pub const RULE_leaveStatement:usize = 14; 
	pub const RULE_iterateStatement:usize = 15; 
	pub const RULE_caseStatement:usize = 16; 
	pub const RULE_loopStatement:usize = 17; 
	pub const RULE_forStatement:usize = 18; 
	pub const RULE_singleStatement:usize = 19; 
	pub const RULE_beginLabel:usize = 20; 
	pub const RULE_endLabel:usize = 21; 
	pub const RULE_singleExpression:usize = 22; 
	pub const RULE_singleTableIdentifier:usize = 23; 
	pub const RULE_singleMultipartIdentifier:usize = 24; 
	pub const RULE_singleFunctionIdentifier:usize = 25; 
	pub const RULE_singleDataType:usize = 26; 
	pub const RULE_singleTableSchema:usize = 27; 
	pub const RULE_singleRoutineParamList:usize = 28; 
	pub const RULE_statement:usize = 29; 
	pub const RULE_materializedView:usize = 30; 
	pub const RULE_streamingTable:usize = 31; 
	pub const RULE_createPipelineDatasetHeader:usize = 32; 
	pub const RULE_streamRelationPrimary:usize = 33; 
	pub const RULE_setResetStatement:usize = 34; 
	pub const RULE_executeImmediate:usize = 35; 
	pub const RULE_executeImmediateUsing:usize = 36; 
	pub const RULE_timezone:usize = 37; 
	pub const RULE_configKey:usize = 38; 
	pub const RULE_configValue:usize = 39; 
	pub const RULE_unsupportedHiveNativeCommands:usize = 40; 
	pub const RULE_createTableHeader:usize = 41; 
	pub const RULE_replaceTableHeader:usize = 42; 
	pub const RULE_clusterBySpec:usize = 43; 
	pub const RULE_bucketSpec:usize = 44; 
	pub const RULE_skewSpec:usize = 45; 
	pub const RULE_locationSpec:usize = 46; 
	pub const RULE_schemaBinding:usize = 47; 
	pub const RULE_commentSpec:usize = 48; 
	pub const RULE_singleQuery:usize = 49; 
	pub const RULE_query:usize = 50; 
	pub const RULE_insertInto:usize = 51; 
	pub const RULE_partitionSpecLocation:usize = 52; 
	pub const RULE_partitionSpec:usize = 53; 
	pub const RULE_partitionVal:usize = 54; 
	pub const RULE_createPipelineFlowHeader:usize = 55; 
	pub const RULE_namespace:usize = 56; 
	pub const RULE_namespaces:usize = 57; 
	pub const RULE_variable:usize = 58; 
	pub const RULE_describeFuncName:usize = 59; 
	pub const RULE_describeColName:usize = 60; 
	pub const RULE_ctes:usize = 61; 
	pub const RULE_namedQuery:usize = 62; 
	pub const RULE_tableProvider:usize = 63; 
	pub const RULE_createTableClauses:usize = 64; 
	pub const RULE_propertyList:usize = 65; 
	pub const RULE_property:usize = 66; 
	pub const RULE_propertyKey:usize = 67; 
	pub const RULE_propertyKeyOrStringLit:usize = 68; 
	pub const RULE_propertyKeyOrStringLitNoCoalesce:usize = 69; 
	pub const RULE_propertyValue:usize = 70; 
	pub const RULE_expressionPropertyList:usize = 71; 
	pub const RULE_expressionProperty:usize = 72; 
	pub const RULE_constantList:usize = 73; 
	pub const RULE_nestedConstantList:usize = 74; 
	pub const RULE_createFileFormat:usize = 75; 
	pub const RULE_fileFormat:usize = 76; 
	pub const RULE_storageHandler:usize = 77; 
	pub const RULE_resource:usize = 78; 
	pub const RULE_dmlStatementNoWith:usize = 79; 
	pub const RULE_identifierReference:usize = 80; 
	pub const RULE_catalogIdentifierReference:usize = 81; 
	pub const RULE_queryOrganization:usize = 82; 
	pub const RULE_multiInsertQueryBody:usize = 83; 
	pub const RULE_queryTerm:usize = 84; 
	pub const RULE_queryPrimary:usize = 85; 
	pub const RULE_sortItem:usize = 86; 
	pub const RULE_fromStatement:usize = 87; 
	pub const RULE_fromStatementBody:usize = 88; 
	pub const RULE_querySpecification:usize = 89; 
	pub const RULE_transformClause:usize = 90; 
	pub const RULE_selectClause:usize = 91; 
	pub const RULE_setClause:usize = 92; 
	pub const RULE_matchedClause:usize = 93; 
	pub const RULE_notMatchedClause:usize = 94; 
	pub const RULE_notMatchedBySourceClause:usize = 95; 
	pub const RULE_matchedAction:usize = 96; 
	pub const RULE_notMatchedAction:usize = 97; 
	pub const RULE_notMatchedBySourceAction:usize = 98; 
	pub const RULE_exceptClause:usize = 99; 
	pub const RULE_assignmentList:usize = 100; 
	pub const RULE_assignment:usize = 101; 
	pub const RULE_whereClause:usize = 102; 
	pub const RULE_havingClause:usize = 103; 
	pub const RULE_hint:usize = 104; 
	pub const RULE_hintStatement:usize = 105; 
	pub const RULE_fromClause:usize = 106; 
	pub const RULE_temporalClause:usize = 107; 
	pub const RULE_aggregationClause:usize = 108; 
	pub const RULE_groupByClause:usize = 109; 
	pub const RULE_groupingAnalytics:usize = 110; 
	pub const RULE_groupingElement:usize = 111; 
	pub const RULE_groupingSet:usize = 112; 
	pub const RULE_pivotClause:usize = 113; 
	pub const RULE_pivotColumn:usize = 114; 
	pub const RULE_pivotValue:usize = 115; 
	pub const RULE_unpivotClause:usize = 116; 
	pub const RULE_unpivotNullClause:usize = 117; 
	pub const RULE_unpivotOperator:usize = 118; 
	pub const RULE_unpivotSingleValueColumnClause:usize = 119; 
	pub const RULE_unpivotMultiValueColumnClause:usize = 120; 
	pub const RULE_unpivotColumnSet:usize = 121; 
	pub const RULE_unpivotValueColumn:usize = 122; 
	pub const RULE_unpivotNameColumn:usize = 123; 
	pub const RULE_unpivotColumnAndAlias:usize = 124; 
	pub const RULE_unpivotColumn:usize = 125; 
	pub const RULE_unpivotAlias:usize = 126; 
	pub const RULE_lateralView:usize = 127; 
	pub const RULE_watermarkClause:usize = 128; 
	pub const RULE_setQuantifier:usize = 129; 
	pub const RULE_relation:usize = 130; 
	pub const RULE_relationExtension:usize = 131; 
	pub const RULE_joinRelation:usize = 132; 
	pub const RULE_joinType:usize = 133; 
	pub const RULE_joinCriteria:usize = 134; 
	pub const RULE_sample:usize = 135; 
	pub const RULE_sampleMethod:usize = 136; 
	pub const RULE_identifierList:usize = 137; 
	pub const RULE_identifierSeq:usize = 138; 
	pub const RULE_orderedIdentifierList:usize = 139; 
	pub const RULE_orderedIdentifier:usize = 140; 
	pub const RULE_identifierCommentList:usize = 141; 
	pub const RULE_identifierComment:usize = 142; 
	pub const RULE_relationPrimary:usize = 143; 
	pub const RULE_optionsClause:usize = 144; 
	pub const RULE_inlineTable:usize = 145; 
	pub const RULE_functionTableSubqueryArgument:usize = 146; 
	pub const RULE_tableArgumentPartitioning:usize = 147; 
	pub const RULE_functionTableNamedArgumentExpression:usize = 148; 
	pub const RULE_functionTableReferenceArgument:usize = 149; 
	pub const RULE_functionTableArgument:usize = 150; 
	pub const RULE_functionTable:usize = 151; 
	pub const RULE_tableAlias:usize = 152; 
	pub const RULE_rowFormat:usize = 153; 
	pub const RULE_multipartIdentifierList:usize = 154; 
	pub const RULE_multipartIdentifier:usize = 155; 
	pub const RULE_multipartIdentifierPropertyList:usize = 156; 
	pub const RULE_multipartIdentifierProperty:usize = 157; 
	pub const RULE_tableIdentifier:usize = 158; 
	pub const RULE_functionIdentifier:usize = 159; 
	pub const RULE_namedExpression:usize = 160; 
	pub const RULE_namedExpressionSeq:usize = 161; 
	pub const RULE_partitionFieldList:usize = 162; 
	pub const RULE_partitionField:usize = 163; 
	pub const RULE_transform:usize = 164; 
	pub const RULE_transformArgument:usize = 165; 
	pub const RULE_expression:usize = 166; 
	pub const RULE_namedArgumentExpression:usize = 167; 
	pub const RULE_functionArgument:usize = 168; 
	pub const RULE_expressionSeq:usize = 169; 
	pub const RULE_booleanExpression:usize = 170; 
	pub const RULE_predicate:usize = 171; 
	pub const RULE_errorCapturingNot:usize = 172; 
	pub const RULE_valueExpression:usize = 173; 
	pub const RULE_shiftOperator:usize = 174; 
	pub const RULE_datetimeUnit:usize = 175; 
	pub const RULE_primaryExpression:usize = 176; 
	pub const RULE_semiStructuredExtractionPath:usize = 177; 
	pub const RULE_jsonPathIdentifier:usize = 178; 
	pub const RULE_jsonPathBracketedIdentifier:usize = 179; 
	pub const RULE_jsonPathFirstPart:usize = 180; 
	pub const RULE_jsonPathParts:usize = 181; 
	pub const RULE_literalType:usize = 182; 
	pub const RULE_constant:usize = 183; 
	pub const RULE_namedParameterMarker:usize = 184; 
	pub const RULE_comparisonOperator:usize = 185; 
	pub const RULE_arithmeticOperator:usize = 186; 
	pub const RULE_predicateOperator:usize = 187; 
	pub const RULE_booleanValue:usize = 188; 
	pub const RULE_interval:usize = 189; 
	pub const RULE_errorCapturingMultiUnitsInterval:usize = 190; 
	pub const RULE_multiUnitsInterval:usize = 191; 
	pub const RULE_errorCapturingUnitToUnitInterval:usize = 192; 
	pub const RULE_unitToUnitInterval:usize = 193; 
	pub const RULE_intervalValue:usize = 194; 
	pub const RULE_unitInMultiUnits:usize = 195; 
	pub const RULE_unitInUnitToUnit:usize = 196; 
	pub const RULE_colPosition:usize = 197; 
	pub const RULE_collationSpec:usize = 198; 
	pub const RULE_collateClause:usize = 199; 
	pub const RULE_nonTrivialPrimitiveType:usize = 200; 
	pub const RULE_trivialPrimitiveType:usize = 201; 
	pub const RULE_primitiveType:usize = 202; 
	pub const RULE_dataType:usize = 203; 
	pub const RULE_qualifiedColTypeWithPositionList:usize = 204; 
	pub const RULE_qualifiedColTypeWithPosition:usize = 205; 
	pub const RULE_colDefinitionDescriptorWithPosition:usize = 206; 
	pub const RULE_defaultExpression:usize = 207; 
	pub const RULE_variableDefaultExpression:usize = 208; 
	pub const RULE_colTypeList:usize = 209; 
	pub const RULE_colType:usize = 210; 
	pub const RULE_tableElementList:usize = 211; 
	pub const RULE_tableElement:usize = 212; 
	pub const RULE_colDefinitionList:usize = 213; 
	pub const RULE_colDefinition:usize = 214; 
	pub const RULE_colDefinitionOption:usize = 215; 
	pub const RULE_generationExpression:usize = 216; 
	pub const RULE_identityColSpec:usize = 217; 
	pub const RULE_sequenceGeneratorOption:usize = 218; 
	pub const RULE_sequenceGeneratorStartOrStep:usize = 219; 
	pub const RULE_complexColTypeList:usize = 220; 
	pub const RULE_complexColType:usize = 221; 
	pub const RULE_codeLiteral:usize = 222; 
	pub const RULE_routineCharacteristics:usize = 223; 
	pub const RULE_routineLanguage:usize = 224; 
	pub const RULE_specificName:usize = 225; 
	pub const RULE_deterministic:usize = 226; 
	pub const RULE_sqlDataAccess:usize = 227; 
	pub const RULE_nullCall:usize = 228; 
	pub const RULE_rightsClause:usize = 229; 
	pub const RULE_whenClause:usize = 230; 
	pub const RULE_windowClause:usize = 231; 
	pub const RULE_namedWindow:usize = 232; 
	pub const RULE_windowSpec:usize = 233; 
	pub const RULE_windowFrame:usize = 234; 
	pub const RULE_frameBound:usize = 235; 
	pub const RULE_qualifiedNameList:usize = 236; 
	pub const RULE_functionName:usize = 237; 
	pub const RULE_qualifiedName:usize = 238; 
	pub const RULE_errorCapturingIdentifier:usize = 239; 
	pub const RULE_errorCapturingIdentifierExtra:usize = 240; 
	pub const RULE_identifier:usize = 241; 
	pub const RULE_simpleIdentifier:usize = 242; 
	pub const RULE_strictIdentifier:usize = 243; 
	pub const RULE_simpleStrictIdentifier:usize = 244; 
	pub const RULE_quotedIdentifier:usize = 245; 
	pub const RULE_backQuotedIdentifier:usize = 246; 
	pub const RULE_number:usize = 247; 
	pub const RULE_integerValue:usize = 248; 
	pub const RULE_columnConstraintDefinition:usize = 249; 
	pub const RULE_columnConstraint:usize = 250; 
	pub const RULE_tableConstraintDefinition:usize = 251; 
	pub const RULE_tableConstraint:usize = 252; 
	pub const RULE_checkConstraint:usize = 253; 
	pub const RULE_uniqueSpec:usize = 254; 
	pub const RULE_uniqueConstraint:usize = 255; 
	pub const RULE_referenceSpec:usize = 256; 
	pub const RULE_foreignKeyConstraint:usize = 257; 
	pub const RULE_constraintCharacteristic:usize = 258; 
	pub const RULE_enforcedCharacteristic:usize = 259; 
	pub const RULE_relyCharacteristic:usize = 260; 
	pub const RULE_alterColumnSpecList:usize = 261; 
	pub const RULE_alterColumnSpec:usize = 262; 
	pub const RULE_alterColumnAction:usize = 263; 
	pub const RULE_singleStringLitWithoutMarker:usize = 264; 
	pub const RULE_singleStringLit:usize = 265; 
	pub const RULE_parameterMarker:usize = 266; 
	pub const RULE_stringLit:usize = 267; 
	pub const RULE_comment:usize = 268; 
	pub const RULE_version:usize = 269; 
	pub const RULE_operatorPipeRightSide:usize = 270; 
	pub const RULE_operatorPipeSetAssignmentSeq:usize = 271; 
	pub const RULE_ansiNonReserved:usize = 272; 
	pub const RULE_strictNonReserved:usize = 273; 
	pub const RULE_nonReserved:usize = 274;
	pub const ruleNames: [&'static str; 275] =  [
		"compoundOrSingleStatement", "singleCompoundStatement", "beginEndCompoundBlock", 
		"compoundBody", "compoundStatement", "setStatementInsideSqlScript", "sqlStateValue", 
		"declareConditionStatement", "conditionValue", "conditionValues", "declareHandlerStatement", 
		"whileStatement", "ifElseStatement", "repeatStatement", "leaveStatement", 
		"iterateStatement", "caseStatement", "loopStatement", "forStatement", 
		"singleStatement", "beginLabel", "endLabel", "singleExpression", "singleTableIdentifier", 
		"singleMultipartIdentifier", "singleFunctionIdentifier", "singleDataType", 
		"singleTableSchema", "singleRoutineParamList", "statement", "materializedView", 
		"streamingTable", "createPipelineDatasetHeader", "streamRelationPrimary", 
		"setResetStatement", "executeImmediate", "executeImmediateUsing", "timezone", 
		"configKey", "configValue", "unsupportedHiveNativeCommands", "createTableHeader", 
		"replaceTableHeader", "clusterBySpec", "bucketSpec", "skewSpec", "locationSpec", 
		"schemaBinding", "commentSpec", "singleQuery", "query", "insertInto", 
		"partitionSpecLocation", "partitionSpec", "partitionVal", "createPipelineFlowHeader", 
		"namespace", "namespaces", "variable", "describeFuncName", "describeColName", 
		"ctes", "namedQuery", "tableProvider", "createTableClauses", "propertyList", 
		"property", "propertyKey", "propertyKeyOrStringLit", "propertyKeyOrStringLitNoCoalesce", 
		"propertyValue", "expressionPropertyList", "expressionProperty", "constantList", 
		"nestedConstantList", "createFileFormat", "fileFormat", "storageHandler", 
		"resource", "dmlStatementNoWith", "identifierReference", "catalogIdentifierReference", 
		"queryOrganization", "multiInsertQueryBody", "queryTerm", "queryPrimary", 
		"sortItem", "fromStatement", "fromStatementBody", "querySpecification", 
		"transformClause", "selectClause", "setClause", "matchedClause", "notMatchedClause", 
		"notMatchedBySourceClause", "matchedAction", "notMatchedAction", "notMatchedBySourceAction", 
		"exceptClause", "assignmentList", "assignment", "whereClause", "havingClause", 
		"hint", "hintStatement", "fromClause", "temporalClause", "aggregationClause", 
		"groupByClause", "groupingAnalytics", "groupingElement", "groupingSet", 
		"pivotClause", "pivotColumn", "pivotValue", "unpivotClause", "unpivotNullClause", 
		"unpivotOperator", "unpivotSingleValueColumnClause", "unpivotMultiValueColumnClause", 
		"unpivotColumnSet", "unpivotValueColumn", "unpivotNameColumn", "unpivotColumnAndAlias", 
		"unpivotColumn", "unpivotAlias", "lateralView", "watermarkClause", "setQuantifier", 
		"relation", "relationExtension", "joinRelation", "joinType", "joinCriteria", 
		"sample", "sampleMethod", "identifierList", "identifierSeq", "orderedIdentifierList", 
		"orderedIdentifier", "identifierCommentList", "identifierComment", "relationPrimary", 
		"optionsClause", "inlineTable", "functionTableSubqueryArgument", "tableArgumentPartitioning", 
		"functionTableNamedArgumentExpression", "functionTableReferenceArgument", 
		"functionTableArgument", "functionTable", "tableAlias", "rowFormat", "multipartIdentifierList", 
		"multipartIdentifier", "multipartIdentifierPropertyList", "multipartIdentifierProperty", 
		"tableIdentifier", "functionIdentifier", "namedExpression", "namedExpressionSeq", 
		"partitionFieldList", "partitionField", "transform", "transformArgument", 
		"expression", "namedArgumentExpression", "functionArgument", "expressionSeq", 
		"booleanExpression", "predicate", "errorCapturingNot", "valueExpression", 
		"shiftOperator", "datetimeUnit", "primaryExpression", "semiStructuredExtractionPath", 
		"jsonPathIdentifier", "jsonPathBracketedIdentifier", "jsonPathFirstPart", 
		"jsonPathParts", "literalType", "constant", "namedParameterMarker", "comparisonOperator", 
		"arithmeticOperator", "predicateOperator", "booleanValue", "interval", 
		"errorCapturingMultiUnitsInterval", "multiUnitsInterval", "errorCapturingUnitToUnitInterval", 
		"unitToUnitInterval", "intervalValue", "unitInMultiUnits", "unitInUnitToUnit", 
		"colPosition", "collationSpec", "collateClause", "nonTrivialPrimitiveType", 
		"trivialPrimitiveType", "primitiveType", "dataType", "qualifiedColTypeWithPositionList", 
		"qualifiedColTypeWithPosition", "colDefinitionDescriptorWithPosition", 
		"defaultExpression", "variableDefaultExpression", "colTypeList", "colType", 
		"tableElementList", "tableElement", "colDefinitionList", "colDefinition", 
		"colDefinitionOption", "generationExpression", "identityColSpec", "sequenceGeneratorOption", 
		"sequenceGeneratorStartOrStep", "complexColTypeList", "complexColType", 
		"codeLiteral", "routineCharacteristics", "routineLanguage", "specificName", 
		"deterministic", "sqlDataAccess", "nullCall", "rightsClause", "whenClause", 
		"windowClause", "namedWindow", "windowSpec", "windowFrame", "frameBound", 
		"qualifiedNameList", "functionName", "qualifiedName", "errorCapturingIdentifier", 
		"errorCapturingIdentifierExtra", "identifier", "simpleIdentifier", "strictIdentifier", 
		"simpleStrictIdentifier", "quotedIdentifier", "backQuotedIdentifier", 
		"number", "integerValue", "columnConstraintDefinition", "columnConstraint", 
		"tableConstraintDefinition", "tableConstraint", "checkConstraint", "uniqueSpec", 
		"uniqueConstraint", "referenceSpec", "foreignKeyConstraint", "constraintCharacteristic", 
		"enforcedCharacteristic", "relyCharacteristic", "alterColumnSpecList", 
		"alterColumnSpec", "alterColumnAction", "singleStringLitWithoutMarker", 
		"singleStringLit", "parameterMarker", "stringLit", "comment", "version", 
		"operatorPipeRightSide", "operatorPipeSetAssignmentSeq", "ansiNonReserved", 
		"strictNonReserved", "nonReserved"
	];


	pub const _LITERAL_NAMES: [Option<&'static str>;437] = [
		None, Some("';'"), Some("'('"), Some("')'"), Some("','"), Some("'.'"), 
		Some("'['"), Some("']'"), Some("'!'"), Some("'ADD'"), Some("'AFTER'"), 
		Some("'AGGREGATE'"), Some("'ALL'"), Some("'ALTER'"), Some("'ALWAYS'"), 
		Some("'ANALYZE'"), Some("'AND'"), Some("'ANTI'"), Some("'ANY'"), Some("'ANY_VALUE'"), 
		Some("'ARCHIVE'"), Some("'ARRAY'"), Some("'AS'"), Some("'ASC'"), Some("'AT'"), 
		Some("'ATOMIC'"), Some("'AUTHORIZATION'"), Some("'BEGIN'"), Some("'BETWEEN'"), 
		Some("'BIGINT'"), Some("'BINARY'"), Some("'BINDING'"), Some("'BOOLEAN'"), 
		Some("'BOTH'"), Some("'BUCKET'"), Some("'BUCKETS'"), Some("'BY'"), Some("'BYTE'"), 
		Some("'CACHE'"), Some("'CALL'"), Some("'CALLED'"), Some("'CASCADE'"), 
		Some("'CASE'"), Some("'CAST'"), Some("'CATALOG'"), Some("'CATALOGS'"), 
		Some("'CHANGE'"), Some("'CHAR'"), Some("'CHARACTER'"), Some("'CHECK'"), 
		Some("'CLEAR'"), Some("'CLUSTER'"), Some("'CLUSTERED'"), Some("'CODEGEN'"), 
		Some("'COLLATE'"), Some("'COLLATION'"), Some("'COLLECTION'"), Some("'COLUMN'"), 
		Some("'COLUMNS'"), Some("'COMMENT'"), Some("'COMMIT'"), Some("'COMPACT'"), 
		Some("'COMPACTIONS'"), Some("'COMPENSATION'"), Some("'COMPUTE'"), Some("'CONCATENATE'"), 
		Some("'CONDITION'"), Some("'CONSTRAINT'"), Some("'CONTAINS'"), Some("'CONTINUE'"), 
		Some("'COST'"), Some("'CREATE'"), Some("'CROSS'"), Some("'CUBE'"), Some("'CURRENT'"), 
		Some("'CURRENT_DATE'"), Some("'CURRENT_TIME'"), Some("'CURRENT_TIMESTAMP'"), 
		Some("'CURRENT_USER'"), Some("'DAY'"), Some("'DAYS'"), Some("'DAYOFYEAR'"), 
		Some("'DATA'"), Some("'DATE'"), Some("'DATABASE'"), Some("'DATABASES'"), 
		Some("'DATEADD'"), Some("'DATE_ADD'"), Some("'DATEDIFF'"), Some("'DATE_DIFF'"), 
		Some("'DBPROPERTIES'"), Some("'DEC'"), Some("'DECIMAL'"), Some("'DECLARE'"), 
		Some("'DEFAULT'"), Some("'DEFINED'"), Some("'DEFINER'"), Some("'DELAY'"), 
		Some("'DELETE'"), Some("'DELIMITED'"), Some("'DESC'"), Some("'DESCRIBE'"), 
		Some("'DETERMINISTIC'"), Some("'DFS'"), Some("'DIRECTORIES'"), Some("'DIRECTORY'"), 
		Some("'DISTINCT'"), Some("'DISTRIBUTE'"), Some("'DIV'"), Some("'DO'"), 
		Some("'DOUBLE'"), Some("'DROP'"), Some("'ELSE'"), Some("'ELSEIF'"), Some("'END'"), 
		Some("'ENFORCED'"), Some("'ESCAPE'"), Some("'ESCAPED'"), Some("'EVOLUTION'"), 
		Some("'EXCEPT'"), Some("'EXCHANGE'"), Some("'EXCLUDE'"), Some("'EXISTS'"), 
		Some("'EXIT'"), Some("'EXPLAIN'"), Some("'EXPORT'"), Some("'EXTEND'"), 
		Some("'EXTENDED'"), Some("'EXTERNAL'"), Some("'EXTRACT'"), Some("'FALSE'"), 
		Some("'FETCH'"), Some("'FIELDS'"), Some("'FILTER'"), Some("'FILEFORMAT'"), 
		Some("'FIRST'"), Some("'FLOAT'"), Some("'FLOW'"), Some("'FOLLOWING'"), 
		Some("'FOR'"), Some("'FOREIGN'"), Some("'FORMAT'"), Some("'FORMATTED'"), 
		Some("'FOUND'"), Some("'FROM'"), Some("'FULL'"), Some("'FUNCTION'"), Some("'FUNCTIONS'"), 
		Some("'GENERATED'"), Some("'GEOGRAPHY'"), Some("'GEOMETRY'"), Some("'GLOBAL'"), 
		Some("'GRANT'"), Some("'GROUP'"), Some("'GROUPING'"), Some("'HANDLER'"), 
		Some("'HAVING'"), Some("'X'"), Some("'HOUR'"), Some("'HOURS'"), Some("'IDENTIFIER'"), 
		Some("'IDENTITY'"), Some("'IF'"), Some("'IGNORE'"), Some("'IMMEDIATE'"), 
		Some("'IMPORT'"), Some("'IN'"), Some("'INCLUDE'"), Some("'INCREMENT'"), 
		Some("'INDEX'"), Some("'INDEXES'"), Some("'INNER'"), Some("'INPATH'"), 
		Some("'INPUT'"), Some("'INPUTFORMAT'"), Some("'INSERT'"), Some("'INTERSECT'"), 
		Some("'INTERVAL'"), Some("'INT'"), Some("'INTEGER'"), Some("'INTO'"), 
		Some("'INVOKER'"), Some("'IS'"), Some("'ITEMS'"), Some("'ITERATE'"), Some("'JOIN'"), 
		Some("'JSON'"), Some("'KEY'"), Some("'KEYS'"), Some("'LANGUAGE'"), Some("'LAST'"), 
		Some("'LATERAL'"), Some("'LAZY'"), Some("'LEADING'"), Some("'LEAVE'"), 
		Some("'LEFT'"), Some("'LEVEL'"), Some("'LIKE'"), Some("'ILIKE'"), Some("'LIMIT'"), 
		Some("'LINES'"), Some("'LIST'"), Some("'LOAD'"), Some("'LOCAL'"), Some("'LOCATION'"), 
		Some("'LOCK'"), Some("'LOCKS'"), Some("'LOGICAL'"), Some("'LONG'"), Some("'LOOP'"), 
		Some("'MACRO'"), Some("'MAP'"), Some("'MATCHED'"), Some("'MATERIALIZED'"), 
		Some("'MAX'"), Some("'MEASURE'"), Some("'MERGE'"), Some("'METRICS'"), 
		Some("'MICROSECOND'"), Some("'MICROSECONDS'"), Some("'MILLISECOND'"), 
		Some("'MILLISECONDS'"), Some("'MINUTE'"), Some("'MINUTES'"), Some("'MODIFIES'"), 
		Some("'MONTH'"), Some("'MONTHS'"), Some("'MSCK'"), Some("'NAME'"), Some("'NAMESPACE'"), 
		Some("'NAMESPACES'"), Some("'NANOSECOND'"), Some("'NANOSECONDS'"), Some("'NATURAL'"), 
		Some("'NO'"), Some("'NONE'"), Some("'NOT'"), Some("'NULL'"), Some("'NULLS'"), 
		Some("'NUMERIC'"), Some("'NORELY'"), Some("'OF'"), Some("'OFFSET'"), Some("'ON'"), 
		Some("'ONLY'"), Some("'OPTION'"), Some("'OPTIONS'"), Some("'OR'"), Some("'ORDER'"), 
		Some("'OUT'"), Some("'OUTER'"), Some("'OUTPUTFORMAT'"), Some("'OVER'"), 
		Some("'OVERLAPS'"), Some("'OVERLAY'"), Some("'OVERWRITE'"), Some("'PARTITION'"), 
		Some("'PARTITIONED'"), Some("'PARTITIONS'"), Some("'PERCENT'"), Some("'PIVOT'"), 
		Some("'PLACING'"), Some("'POSITION'"), Some("'PRECEDING'"), Some("'PRIMARY'"), 
		Some("'PRINCIPALS'"), Some("'PROCEDURE'"), Some("'PROCEDURES'"), Some("'PROPERTIES'"), 
		Some("'PURGE'"), Some("'QUARTER'"), Some("'QUERY'"), Some("'RANGE'"), 
		Some("'READS'"), Some("'REAL'"), Some("'RECORDREADER'"), Some("'RECORDWRITER'"), 
		Some("'RECOVER'"), Some("'RECURSION'"), Some("'RECURSIVE'"), Some("'REDUCE'"), 
		Some("'REFERENCES'"), Some("'REFRESH'"), Some("'RELY'"), Some("'RENAME'"), 
		Some("'REPAIR'"), Some("'REPEAT'"), Some("'REPEATABLE'"), Some("'REPLACE'"), 
		Some("'RESET'"), Some("'RESPECT'"), Some("'RESTRICT'"), Some("'RETURN'"), 
		Some("'RETURNS'"), Some("'REVOKE'"), Some("'RIGHT'"), None, Some("'ROLE'"), 
		Some("'ROLES'"), Some("'ROLLBACK'"), Some("'ROLLUP'"), Some("'ROW'"), 
		Some("'ROWS'"), Some("'SECOND'"), Some("'SECONDS'"), Some("'SCHEMA'"), 
		Some("'SCHEMAS'"), Some("'SECURITY'"), Some("'SELECT'"), Some("'SEMI'"), 
		Some("'SEPARATED'"), Some("'SERDE'"), Some("'SERDEPROPERTIES'"), Some("'SESSION_USER'"), 
		Some("'SET'"), Some("'MINUS'"), Some("'SETS'"), Some("'SHORT'"), Some("'SHOW'"), 
		Some("'SINGLE'"), Some("'SKEWED'"), Some("'SMALLINT'"), Some("'SOME'"), 
		Some("'SORT'"), Some("'SORTED'"), Some("'SOURCE'"), Some("'SPECIFIC'"), 
		Some("'SQL'"), Some("'SQLEXCEPTION'"), Some("'SQLSTATE'"), Some("'START'"), 
		Some("'STATISTICS'"), Some("'STORED'"), Some("'STRATIFY'"), Some("'STREAM'"), 
		Some("'STREAMING'"), Some("'STRING'"), Some("'STRUCT'"), Some("'SUBSTR'"), 
		Some("'SUBSTRING'"), Some("'SYNC'"), Some("'SYSTEM_TIME'"), Some("'SYSTEM_VERSION'"), 
		Some("'TABLE'"), Some("'TABLES'"), Some("'TABLESAMPLE'"), Some("'TARGET'"), 
		Some("'TBLPROPERTIES'"), None, Some("'TERMINATED'"), Some("'THEN'"), Some("'TIME'"), 
		Some("'TIMEDIFF'"), Some("'TIMESTAMP'"), Some("'TIMESTAMP_LTZ'"), Some("'TIMESTAMP_NTZ'"), 
		Some("'TIMESTAMPADD'"), Some("'TIMESTAMPDIFF'"), Some("'TINYINT'"), Some("'TO'"), 
		Some("'EXECUTE'"), Some("'TOUCH'"), Some("'TRAILING'"), Some("'TRANSACTION'"), 
		Some("'TRANSACTIONS'"), Some("'TRANSFORM'"), Some("'TRIM'"), Some("'TRUE'"), 
		Some("'TRUNCATE'"), Some("'TRY_CAST'"), Some("'TYPE'"), Some("'UNARCHIVE'"), 
		Some("'UNBOUNDED'"), Some("'UNCACHE'"), Some("'UNION'"), Some("'UNIQUE'"), 
		Some("'UNKNOWN'"), Some("'UNLOCK'"), Some("'UNPIVOT'"), Some("'UNSET'"), 
		Some("'UNTIL'"), Some("'UPDATE'"), Some("'USE'"), Some("'USER'"), Some("'USING'"), 
		Some("'VALUE'"), Some("'VALUES'"), Some("'VARCHAR'"), Some("'VAR'"), Some("'VARIABLE'"), 
		Some("'VARIANT'"), Some("'VERSION'"), Some("'VIEW'"), Some("'VIEWS'"), 
		Some("'VOID'"), Some("'WATERMARK'"), Some("'WEEK'"), Some("'WEEKS'"), 
		Some("'WHEN'"), Some("'WHERE'"), Some("'WHILE'"), Some("'WINDOW'"), Some("'WITH'"), 
		Some("'WITHIN'"), Some("'WITHOUT'"), Some("'YEAR'"), Some("'YEARS'"), 
		Some("'ZONE'"), None, Some("'<=>'"), Some("'<>'"), Some("'!='"), Some("'<'"), 
		None, Some("'>'"), None, Some("'<<'"), Some("'>>'"), Some("'>>>'"), Some("'+'"), 
		Some("'-'"), Some("'*'"), Some("'/'"), Some("'%'"), Some("'~'"), Some("'&'"), 
		Some("'|'"), Some("'||'"), Some("'|>'"), Some("'^'"), Some("':'"), Some("'::'"), 
		Some("'->'"), Some("'=>'"), Some("'/*+'"), Some("'*/'"), Some("'?'")
	];
	pub const _SYMBOLIC_NAMES: [Option<&'static str>;457]  = [
		None, Some("SEMICOLON"), Some("LEFT_PAREN"), Some("RIGHT_PAREN"), Some("COMMA"), 
		Some("DOT"), Some("LEFT_BRACKET"), Some("RIGHT_BRACKET"), Some("BANG"), 
		Some("ADD"), Some("AFTER"), Some("AGGREGATE"), Some("ALL"), Some("ALTER"), 
		Some("ALWAYS"), Some("ANALYZE"), Some("AND"), Some("ANTI"), Some("ANY"), 
		Some("ANY_VALUE"), Some("ARCHIVE"), Some("ARRAY"), Some("AS"), Some("ASC"), 
		Some("AT"), Some("ATOMIC"), Some("AUTHORIZATION"), Some("BEGIN"), Some("BETWEEN"), 
		Some("BIGINT"), Some("BINARY"), Some("BINDING"), Some("BOOLEAN"), Some("BOTH"), 
		Some("BUCKET"), Some("BUCKETS"), Some("BY"), Some("BYTE"), Some("CACHE"), 
		Some("CALL"), Some("CALLED"), Some("CASCADE"), Some("CASE"), Some("CAST"), 
		Some("CATALOG"), Some("CATALOGS"), Some("CHANGE"), Some("CHAR"), Some("CHARACTER"), 
		Some("CHECK"), Some("CLEAR"), Some("CLUSTER"), Some("CLUSTERED"), Some("CODEGEN"), 
		Some("COLLATE"), Some("COLLATION"), Some("COLLECTION"), Some("COLUMN"), 
		Some("COLUMNS"), Some("COMMENT"), Some("COMMIT"), Some("COMPACT"), Some("COMPACTIONS"), 
		Some("COMPENSATION"), Some("COMPUTE"), Some("CONCATENATE"), Some("CONDITION"), 
		Some("CONSTRAINT"), Some("CONTAINS"), Some("CONTINUE"), Some("COST"), 
		Some("CREATE"), Some("CROSS"), Some("CUBE"), Some("CURRENT"), Some("CURRENT_DATE"), 
		Some("CURRENT_TIME"), Some("CURRENT_TIMESTAMP"), Some("CURRENT_USER"), 
		Some("DAY"), Some("DAYS"), Some("DAYOFYEAR"), Some("DATA"), Some("DATE"), 
		Some("DATABASE"), Some("DATABASES"), Some("DATEADD"), Some("DATE_ADD"), 
		Some("DATEDIFF"), Some("DATE_DIFF"), Some("DBPROPERTIES"), Some("DEC"), 
		Some("DECIMAL"), Some("DECLARE"), Some("DEFAULT"), Some("DEFINED"), Some("DEFINER"), 
		Some("DELAY"), Some("DELETE"), Some("DELIMITED"), Some("DESC"), Some("DESCRIBE"), 
		Some("DETERMINISTIC"), Some("DFS"), Some("DIRECTORIES"), Some("DIRECTORY"), 
		Some("DISTINCT"), Some("DISTRIBUTE"), Some("DIV"), Some("DO"), Some("DOUBLE"), 
		Some("DROP"), Some("ELSE"), Some("ELSEIF"), Some("END"), Some("ENFORCED"), 
		Some("ESCAPE"), Some("ESCAPED"), Some("EVOLUTION"), Some("EXCEPT"), Some("EXCHANGE"), 
		Some("EXCLUDE"), Some("EXISTS"), Some("EXIT"), Some("EXPLAIN"), Some("EXPORT"), 
		Some("EXTEND"), Some("EXTENDED"), Some("EXTERNAL"), Some("EXTRACT"), Some("FALSE"), 
		Some("FETCH"), Some("FIELDS"), Some("FILTER"), Some("FILEFORMAT"), Some("FIRST"), 
		Some("FLOAT"), Some("FLOW"), Some("FOLLOWING"), Some("FOR"), Some("FOREIGN"), 
		Some("FORMAT"), Some("FORMATTED"), Some("FOUND"), Some("FROM"), Some("FULL"), 
		Some("FUNCTION"), Some("FUNCTIONS"), Some("GENERATED"), Some("GEOGRAPHY"), 
		Some("GEOMETRY"), Some("GLOBAL"), Some("GRANT"), Some("GROUP"), Some("GROUPING"), 
		Some("HANDLER"), Some("HAVING"), Some("BINARY_HEX"), Some("HOUR"), Some("HOURS"), 
		Some("IDENTIFIER_KW"), Some("IDENTITY"), Some("IF"), Some("IGNORE"), Some("IMMEDIATE"), 
		Some("IMPORT"), Some("IN"), Some("INCLUDE"), Some("INCREMENT"), Some("INDEX"), 
		Some("INDEXES"), Some("INNER"), Some("INPATH"), Some("INPUT"), Some("INPUTFORMAT"), 
		Some("INSERT"), Some("INTERSECT"), Some("INTERVAL"), Some("INT"), Some("INTEGER"), 
		Some("INTO"), Some("INVOKER"), Some("IS"), Some("ITEMS"), Some("ITERATE"), 
		Some("JOIN"), Some("JSON"), Some("KEY"), Some("KEYS"), Some("LANGUAGE"), 
		Some("LAST"), Some("LATERAL"), Some("LAZY"), Some("LEADING"), Some("LEAVE"), 
		Some("LEFT"), Some("LEVEL"), Some("LIKE"), Some("ILIKE"), Some("LIMIT"), 
		Some("LINES"), Some("LIST"), Some("LOAD"), Some("LOCAL"), Some("LOCATION"), 
		Some("LOCK"), Some("LOCKS"), Some("LOGICAL"), Some("LONG"), Some("LOOP"), 
		Some("MACRO"), Some("MAP"), Some("MATCHED"), Some("MATERIALIZED"), Some("MAX"), 
		Some("MEASURE"), Some("MERGE"), Some("METRICS"), Some("MICROSECOND"), 
		Some("MICROSECONDS"), Some("MILLISECOND"), Some("MILLISECONDS"), Some("MINUTE"), 
		Some("MINUTES"), Some("MODIFIES"), Some("MONTH"), Some("MONTHS"), Some("MSCK"), 
		Some("NAME"), Some("NAMESPACE"), Some("NAMESPACES"), Some("NANOSECOND"), 
		Some("NANOSECONDS"), Some("NATURAL"), Some("NO"), Some("NONE"), Some("NOT"), 
		Some("NULL"), Some("NULLS"), Some("NUMERIC"), Some("NORELY"), Some("OF"), 
		Some("OFFSET"), Some("ON"), Some("ONLY"), Some("OPTION"), Some("OPTIONS"), 
		Some("OR"), Some("ORDER"), Some("OUT"), Some("OUTER"), Some("OUTPUTFORMAT"), 
		Some("OVER"), Some("OVERLAPS"), Some("OVERLAY"), Some("OVERWRITE"), Some("PARTITION"), 
		Some("PARTITIONED"), Some("PARTITIONS"), Some("PERCENTLIT"), Some("PIVOT"), 
		Some("PLACING"), Some("POSITION"), Some("PRECEDING"), Some("PRIMARY"), 
		Some("PRINCIPALS"), Some("PROCEDURE"), Some("PROCEDURES"), Some("PROPERTIES"), 
		Some("PURGE"), Some("QUARTER"), Some("QUERY"), Some("RANGE"), Some("READS"), 
		Some("REAL"), Some("RECORDREADER"), Some("RECORDWRITER"), Some("RECOVER"), 
		Some("RECURSION"), Some("RECURSIVE"), Some("REDUCE"), Some("REFERENCES"), 
		Some("REFRESH"), Some("RELY"), Some("RENAME"), Some("REPAIR"), Some("REPEAT"), 
		Some("REPEATABLE"), Some("REPLACE"), Some("RESET"), Some("RESPECT"), Some("RESTRICT"), 
		Some("RETURN"), Some("RETURNS"), Some("REVOKE"), Some("RIGHT"), Some("RLIKE"), 
		Some("ROLE"), Some("ROLES"), Some("ROLLBACK"), Some("ROLLUP"), Some("ROW"), 
		Some("ROWS"), Some("SECOND"), Some("SECONDS"), Some("SCHEMA"), Some("SCHEMAS"), 
		Some("SECURITY"), Some("SELECT"), Some("SEMI"), Some("SEPARATED"), Some("SERDE"), 
		Some("SERDEPROPERTIES"), Some("SESSION_USER"), Some("SET"), Some("SETMINUS"), 
		Some("SETS"), Some("SHORT"), Some("SHOW"), Some("SINGLE"), Some("SKEWED"), 
		Some("SMALLINT"), Some("SOME"), Some("SORT"), Some("SORTED"), Some("SOURCE"), 
		Some("SPECIFIC"), Some("SQL"), Some("SQLEXCEPTION"), Some("SQLSTATE"), 
		Some("START"), Some("STATISTICS"), Some("STORED"), Some("STRATIFY"), Some("STREAM"), 
		Some("STREAMING"), Some("STRING"), Some("STRUCT"), Some("SUBSTR"), Some("SUBSTRING"), 
		Some("SYNC"), Some("SYSTEM_TIME"), Some("SYSTEM_VERSION"), Some("TABLE"), 
		Some("TABLES"), Some("TABLESAMPLE"), Some("TARGET"), Some("TBLPROPERTIES"), 
		Some("TEMPORARY"), Some("TERMINATED"), Some("THEN"), Some("TIME"), Some("TIMEDIFF"), 
		Some("TIMESTAMP"), Some("TIMESTAMP_LTZ"), Some("TIMESTAMP_NTZ"), Some("TIMESTAMPADD"), 
		Some("TIMESTAMPDIFF"), Some("TINYINT"), Some("TO"), Some("EXECUTE"), Some("TOUCH"), 
		Some("TRAILING"), Some("TRANSACTION"), Some("TRANSACTIONS"), Some("TRANSFORM"), 
		Some("TRIM"), Some("TRUE"), Some("TRUNCATE"), Some("TRY_CAST"), Some("TYPE"), 
		Some("UNARCHIVE"), Some("UNBOUNDED"), Some("UNCACHE"), Some("UNION"), 
		Some("UNIQUE"), Some("UNKNOWN"), Some("UNLOCK"), Some("UNPIVOT"), Some("UNSET"), 
		Some("UNTIL"), Some("UPDATE"), Some("USE"), Some("USER"), Some("USING"), 
		Some("VALUE"), Some("VALUES"), Some("VARCHAR"), Some("VAR"), Some("VARIABLE"), 
		Some("VARIANT"), Some("VERSION"), Some("VIEW"), Some("VIEWS"), Some("VOID"), 
		Some("WATERMARK"), Some("WEEK"), Some("WEEKS"), Some("WHEN"), Some("WHERE"), 
		Some("WHILE"), Some("WINDOW"), Some("WITH"), Some("WITHIN"), Some("WITHOUT"), 
		Some("YEAR"), Some("YEARS"), Some("ZONE"), Some("EQ"), Some("NSEQ"), Some("NEQ"), 
		Some("NEQJ"), Some("LT"), Some("LTE"), Some("GT"), Some("GTE"), Some("SHIFT_LEFT"), 
		Some("SHIFT_RIGHT"), Some("SHIFT_RIGHT_UNSIGNED"), Some("PLUS"), Some("MINUS"), 
		Some("ASTERISK"), Some("SLASH"), Some("PERCENT"), Some("TILDE"), Some("AMPERSAND"), 
		Some("PIPE"), Some("CONCAT_PIPE"), Some("OPERATOR_PIPE"), Some("HAT"), 
		Some("COLON"), Some("DOUBLE_COLON"), Some("ARROW"), Some("FAT_ARROW"), 
		Some("HENT_START"), Some("HENT_END"), Some("QUESTION"), Some("STRING_LITERAL"), 
		Some("BEGIN_DOLLAR_QUOTED_STRING"), Some("DOUBLEQUOTED_STRING"), Some("BIGINT_LITERAL"), 
		Some("SMALLINT_LITERAL"), Some("TINYINT_LITERAL"), Some("INTEGER_VALUE"), 
		Some("EXPONENT_VALUE"), Some("DECIMAL_VALUE"), Some("FLOAT_LITERAL"), 
		Some("DOUBLE_LITERAL"), Some("BIGDECIMAL_LITERAL"), Some("IDENTIFIER"), 
		Some("BACKQUOTED_IDENTIFIER"), Some("SIMPLE_COMMENT"), Some("BRACKETED_COMMENT"), 
		Some("WS"), Some("UNRECOGNIZED"), Some("DOLLAR_QUOTED_STRING_BODY"), Some("END_DOLLAR_QUOTED_STRING")
	];
	lazy_static!{
	    static ref _shared_context_cache: Arc<PredictionContextCache> = Arc::new(PredictionContextCache::new());
		static ref VOCABULARY: Box<dyn Vocabulary> = Box::new(VocabularyImpl::new(_LITERAL_NAMES.iter(), _SYMBOLIC_NAMES.iter(), None));
	}


type BaseParserType<'input, I> =
	BaseParser<'input,SqlBaseParserExt<'input>, I, SqlBaseParserContextType , dyn SqlBaseParserListener<'input> + 'input >;

type TokenType<'input> = <LocalTokenFactory<'input> as TokenFactory<'input>>::Tok;
pub type LocalTokenFactory<'input> = CommonTokenFactory;

pub type SqlBaseParserTreeWalker<'input,'a> =
	ParseTreeWalker<'input, 'a, SqlBaseParserContextType , dyn SqlBaseParserListener<'input> + 'a>;

/// Parser for SqlBaseParser grammar
pub struct SqlBaseParser<'input,I,H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	base:BaseParserType<'input,I>,
	interpreter:Arc<ParserATNSimulator>,
	_shared_context_cache: Box<PredictionContextCache>,
    pub err_handler: H,
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn get_serialized_atn() -> &'static str { _serializedATN }

    pub fn set_error_strategy(&mut self, strategy: H) {
        self.err_handler = strategy
    }

    pub fn with_strategy(input: I, strategy: H) -> Self {
		antlr_rust::recognizer::check_version("0","3");
		let interpreter = Arc::new(ParserATNSimulator::new(
			_ATN.clone(),
			_decision_to_DFA.clone(),
			_shared_context_cache.clone(),
		));
		Self {
			base: BaseParser::new_base_parser(
				input,
				Arc::clone(&interpreter),
				SqlBaseParserExt{
					_pd: Default::default(),
				}
			),
			interpreter,
            _shared_context_cache: Box::new(PredictionContextCache::new()),
            err_handler: strategy,
        }
    }

}

type DynStrategy<'input,I> = Box<dyn ErrorStrategy<'input,BaseParserType<'input,I>> + 'input>;

impl<'input, I> SqlBaseParser<'input, I, DynStrategy<'input,I>>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
{
    pub fn with_dyn_strategy(input: I) -> Self{
    	Self::with_strategy(input,Box::new(DefaultErrorStrategy::new()))
    }
}

impl<'input, I> SqlBaseParser<'input, I, DefaultErrorStrategy<'input,SqlBaseParserContextType>>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
{
    pub fn new(input: I) -> Self{
    	Self::with_strategy(input,DefaultErrorStrategy::new())
    }
}

/// Trait for monomorphized trait object that corresponds to the nodes of parse tree generated for SqlBaseParser
pub trait SqlBaseParserContext<'input>:
	for<'x> Listenable<dyn SqlBaseParserListener<'input> + 'x > + 
	for<'x> Visitable<dyn SqlBaseParserVisitor<'input> + 'x > + 
	ParserRuleContext<'input, TF=LocalTokenFactory<'input>, Ctx=SqlBaseParserContextType>
{}

antlr_rust::coerce_from!{ 'input : SqlBaseParserContext<'input> }

impl<'input, 'x, T> VisitableDyn<T> for dyn SqlBaseParserContext<'input> + 'input
where
    T: SqlBaseParserVisitor<'input> + 'x,
{
    fn accept_dyn(&self, visitor: &mut T) {
        self.accept(visitor as &mut (dyn SqlBaseParserVisitor<'input> + 'x))
    }
}

impl<'input> SqlBaseParserContext<'input> for TerminalNode<'input,SqlBaseParserContextType> {}
impl<'input> SqlBaseParserContext<'input> for ErrorNode<'input,SqlBaseParserContextType> {}

antlr_rust::tid! { impl<'input> TidAble<'input> for dyn SqlBaseParserContext<'input> + 'input }

antlr_rust::tid! { impl<'input> TidAble<'input> for dyn SqlBaseParserListener<'input> + 'input }

pub struct SqlBaseParserContextType;
antlr_rust::tid!{SqlBaseParserContextType}

impl<'input> ParserNodeType<'input> for SqlBaseParserContextType{
	type TF = LocalTokenFactory<'input>;
	type Type = dyn SqlBaseParserContext<'input> + 'input;
}

impl<'input, I, H> Deref for SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
    type Target = BaseParserType<'input,I>;

    fn deref(&self) -> &Self::Target {
        &self.base
    }
}

impl<'input, I, H> DerefMut for SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
    fn deref_mut(&mut self) -> &mut Self::Target {
        &mut self.base
    }
}

pub struct SqlBaseParserExt<'input>{
	_pd: PhantomData<&'input str>,
}

impl<'input> SqlBaseParserExt<'input>{

	  /**
	   * When false, INTERSECT is given the greater precedence over the other set
	   * operations (UNION, EXCEPT and MINUS) as per the SQL standard.
	   */
	  public boolean legacy_setops_precedence_enabled = false;

	  /**
	   * When false, a literal with an exponent would be converted into
	   * double type rather than decimal type.
	   */
	  public boolean legacy_exponent_literal_as_decimal_enabled = false;

	  /**
	   * When true, the behavior of keywords follows ANSI SQL standard.
	   */
	  public boolean SQL_standard_keyword_behavior = false;

	  /**
	   * When true, double quoted literals are identifiers rather than STRINGs.
	   */
	  public boolean double_quoted_identifiers = false;

	  /**
	   * When false, parameter markers (? and :param) are only allowed in constant contexts.
	   * When true, parameter markers are allowed everywhere a literal is supported.
	   */
	  public boolean parameter_substitution_enabled = true;

	  /**
	   * When false (default), IDENTIFIER('literal') is resolved to an identifier at parse time (identifier-lite).
	   * When true, only the legacy IDENTIFIER(expression) function syntax is allowed.
	   * Controlled by spark.sql.legacy.identifierClause configuration.
	   */
	  public boolean legacy_identifier_clause_only = false;

	  /**
	   * When true, the single character pipe token '|' can be used as an alternative to '|>' for
	   * SQL pipe operators. When false, only '|>' is recognized as a pipe operator.
	   */
	  public boolean single_character_pipe_operator_enabled = true;

	  /**
	   * Checks if the next token after PIPE can start an operator pipe right side.
	   * This disambiguates between bitwise OR (|) in expressions and pipe operator (|) in queries.
	   * Used to maintain backwards compatibility when allowing both | and |> as pipe operators.
	   * Only applies when single_character_pipe_operator_enabled is true.
	   */
	  public boolean isOperatorPipeStart() {
	    if (!single_character_pipe_operator_enabled) {
	      return false;
	    }
	    int la = _input.LA(2); // Look ahead 2 tokens (current is PIPE, check what follows)
	    return la == SELECT || la == EXTEND || la == SET || la == DROP || 
	           la == AS || la == WHERE || la == PIVOT || la == UNPIVOT ||
	           la == TABLESAMPLE || la == INNER || la == CROSS || la == LEFT ||
	           la == RIGHT || la == FULL || la == NATURAL || la == SEMI || 
	           la == ANTI || la == JOIN || la == UNION || la == EXCEPT || 
	           la == SETMINUS || la == INTERSECT || la == ORDER || la == CLUSTER ||
	           la == DISTRIBUTE || la == SORT || la == LIMIT || la == OFFSET ||
	           la == AGGREGATE || la == WINDOW || la == LATERAL;
	  }

}
antlr_rust::tid! { SqlBaseParserExt<'a> }

impl<'input> TokenAware<'input> for SqlBaseParserExt<'input>{
	type TF = LocalTokenFactory<'input>;
}

impl<'input,I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>> ParserRecog<'input, BaseParserType<'input,I>> for SqlBaseParserExt<'input>{}

impl<'input,I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>> Actions<'input, BaseParserType<'input,I>> for SqlBaseParserExt<'input>{
	fn get_grammar_file_name(&self) -> & str{ "SqlBaseParser.g4"}

   	fn get_rule_names(&self) -> &[& str] {&ruleNames}

   	fn get_vocabulary(&self) -> &dyn Vocabulary { &**VOCABULARY }
	fn sempred(_localctx: Option<&(dyn SqlBaseParserContext<'input> + 'input)>, rule_index: isize, pred_index: isize,
			   recog:&mut BaseParserType<'input,I>
	)->bool{
		match rule_index {
					84 => SqlBaseParser::<'input,I,_>::queryTerm_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
					170 => SqlBaseParser::<'input,I,_>::booleanExpression_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
					173 => SqlBaseParser::<'input,I,_>::valueExpression_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
					176 => SqlBaseParser::<'input,I,_>::primaryExpression_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
					241 => SqlBaseParser::<'input,I,_>::identifier_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
					242 => SqlBaseParser::<'input,I,_>::simpleIdentifier_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
					243 => SqlBaseParser::<'input,I,_>::strictIdentifier_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
					244 => SqlBaseParser::<'input,I,_>::simpleStrictIdentifier_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
					245 => SqlBaseParser::<'input,I,_>::quotedIdentifier_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
					247 => SqlBaseParser::<'input,I,_>::number_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
					264 => SqlBaseParser::<'input,I,_>::singleStringLitWithoutMarker_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
					266 => SqlBaseParser::<'input,I,_>::parameterMarker_sempred(_localctx.and_then(|x|x.downcast_ref()), pred_index, recog),
			_ => true
		}
	}
}

impl<'input, I> SqlBaseParser<'input, I, DefaultErrorStrategy<'input,SqlBaseParserContextType>>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
{
	fn queryTerm_sempred(_localctx: Option<&QueryTermContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				0=>{
					recog.precpred(None, 5)
				}
				1=>{
					legacy_setops_precedence_enabled
				}
				2=>{
					recog.precpred(None, 4)
				}
				3=>{
					!legacy_setops_precedence_enabled
				}
				4=>{
					recog.precpred(None, 3)
				}
				5=>{
					!legacy_setops_precedence_enabled
				}
				6=>{
					recog.precpred(None, 2)
				}
				7=>{
					recog.precpred(None, 1)
				}
				8=>{
					isOperatorPipeStart()
				}
			_ => true
		}
	}
	fn booleanExpression_sempred(_localctx: Option<&BooleanExpressionContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				9=>{
					recog.precpred(None, 2)
				}
				10=>{
					recog.precpred(None, 1)
				}
			_ => true
		}
	}
	fn valueExpression_sempred(_localctx: Option<&ValueExpressionContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				11=>{
					recog.precpred(None, 7)
				}
				12=>{
					recog.precpred(None, 6)
				}
				13=>{
					recog.precpred(None, 5)
				}
				14=>{
					recog.precpred(None, 4)
				}
				15=>{
					recog.precpred(None, 3)
				}
				16=>{
					recog.precpred(None, 2)
				}
				17=>{
					!isOperatorPipeStart()
				}
				18=>{
					recog.precpred(None, 1)
				}
			_ => true
		}
	}
	fn primaryExpression_sempred(_localctx: Option<&PrimaryExpressionContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				19=>{
					recog.precpred(None, 24)
				}
				20=>{
					recog.precpred(None, 23)
				}
				21=>{
					recog.precpred(None, 14)
				}
				22=>{
					recog.precpred(None, 8)
				}
				23=>{
					recog.precpred(None, 6)
				}
			_ => true
		}
	}
	fn identifier_sempred(_localctx: Option<&IdentifierContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				24=>{
					!SQL_standard_keyword_behavior
				}
			_ => true
		}
	}
	fn simpleIdentifier_sempred(_localctx: Option<&SimpleIdentifierContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				25=>{
					!SQL_standard_keyword_behavior
				}
			_ => true
		}
	}
	fn strictIdentifier_sempred(_localctx: Option<&StrictIdentifierContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				26=>{
					!legacy_identifier_clause_only
				}
				27=>{
					SQL_standard_keyword_behavior
				}
				28=>{
					!SQL_standard_keyword_behavior
				}
			_ => true
		}
	}
	fn simpleStrictIdentifier_sempred(_localctx: Option<&SimpleStrictIdentifierContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				29=>{
					SQL_standard_keyword_behavior
				}
				30=>{
					!SQL_standard_keyword_behavior
				}
			_ => true
		}
	}
	fn quotedIdentifier_sempred(_localctx: Option<&QuotedIdentifierContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				31=>{
					double_quoted_identifiers
				}
			_ => true
		}
	}
	fn number_sempred(_localctx: Option<&NumberContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				32=>{
					!legacy_exponent_literal_as_decimal_enabled
				}
				33=>{
					!legacy_exponent_literal_as_decimal_enabled
				}
				34=>{
					legacy_exponent_literal_as_decimal_enabled
				}
			_ => true
		}
	}
	fn singleStringLitWithoutMarker_sempred(_localctx: Option<&SingleStringLitWithoutMarkerContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				35=>{
					!double_quoted_identifiers
				}
			_ => true
		}
	}
	fn parameterMarker_sempred(_localctx: Option<&ParameterMarkerContext<'input>>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				36=>{
					parameter_substitution_enabled
				}
				37=>{
					parameter_substitution_enabled
				}
			_ => true
		}
	}
}
//------------------- compoundOrSingleStatement ----------------
pub type CompoundOrSingleStatementContextAll<'input> = CompoundOrSingleStatementContext<'input>;


pub type CompoundOrSingleStatementContext<'input> = BaseParserRuleContext<'input,CompoundOrSingleStatementContextExt<'input>>;

#[derive(Clone)]
pub struct CompoundOrSingleStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for CompoundOrSingleStatementContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CompoundOrSingleStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_compoundOrSingleStatement(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_compoundOrSingleStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CompoundOrSingleStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_compoundOrSingleStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for CompoundOrSingleStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_compoundOrSingleStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_compoundOrSingleStatement }
}
antlr_rust::tid!{CompoundOrSingleStatementContextExt<'a>}

impl<'input> CompoundOrSingleStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CompoundOrSingleStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CompoundOrSingleStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait CompoundOrSingleStatementContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<CompoundOrSingleStatementContextExt<'input>>{

fn singleStatement(&self) -> Option<Rc<SingleStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn singleCompoundStatement(&self) -> Option<Rc<SingleCompoundStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CompoundOrSingleStatementContextAttrs<'input> for CompoundOrSingleStatementContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn compoundOrSingleStatement(&mut self,)
	-> Result<Rc<CompoundOrSingleStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CompoundOrSingleStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 0, RULE_compoundOrSingleStatement);
        let mut _localctx: Rc<CompoundOrSingleStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(552);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 LEFT_PAREN | ADD | ALTER | ANALYZE | CACHE | CALL | CLEAR | COMMENT |
			 COMMIT | CREATE | DECLARE | DELETE | DESC | DESCRIBE | DFS | DROP | EXPLAIN |
			 EXPORT | FROM | GRANT | IMPORT | INSERT | LIST | LOAD | LOCK | MAP |
			 MERGE | MSCK | REDUCE | REFRESH | REPAIR | REPLACE | RESET | REVOKE |
			 ROLLBACK | SELECT | SET | SHOW | START | TABLE | EXECUTE | TRUNCATE |
			 UNCACHE | UNLOCK | UPDATE | USE | VALUES | WITH 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule singleStatement*/
					recog.base.set_state(550);
					recog.singleStatement()?;

					}
				}

			 BEGIN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule singleCompoundStatement*/
					recog.base.set_state(551);
					recog.singleCompoundStatement()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- singleCompoundStatement ----------------
pub type SingleCompoundStatementContextAll<'input> = SingleCompoundStatementContext<'input>;


pub type SingleCompoundStatementContext<'input> = BaseParserRuleContext<'input,SingleCompoundStatementContextExt<'input>>;

#[derive(Clone)]
pub struct SingleCompoundStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SingleCompoundStatementContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SingleCompoundStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_singleCompoundStatement(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_singleCompoundStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SingleCompoundStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_singleCompoundStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for SingleCompoundStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_singleCompoundStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_singleCompoundStatement }
}
antlr_rust::tid!{SingleCompoundStatementContextExt<'a>}

impl<'input> SingleCompoundStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SingleCompoundStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SingleCompoundStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SingleCompoundStatementContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SingleCompoundStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token BEGIN
/// Returns `None` if there is no child corresponding to token BEGIN
fn BEGIN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BEGIN, 0)
}
/// Retrieves first TerminalNode corresponding to token END
/// Returns `None` if there is no child corresponding to token END
fn END(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(END, 0)
}
/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}
/// Retrieves first TerminalNode corresponding to token NOT
/// Returns `None` if there is no child corresponding to token NOT
fn NOT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NOT, 0)
}
/// Retrieves first TerminalNode corresponding to token ATOMIC
/// Returns `None` if there is no child corresponding to token ATOMIC
fn ATOMIC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ATOMIC, 0)
}
fn compoundBody(&self) -> Option<Rc<CompoundBodyContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token SEMICOLON
/// Returns `None` if there is no child corresponding to token SEMICOLON
fn SEMICOLON(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SEMICOLON, 0)
}

}

impl<'input> SingleCompoundStatementContextAttrs<'input> for SingleCompoundStatementContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn singleCompoundStatement(&mut self,)
	-> Result<Rc<SingleCompoundStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SingleCompoundStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 2, RULE_singleCompoundStatement);
        let mut _localctx: Rc<SingleCompoundStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(554);
			recog.base.match_token(BEGIN,&mut recog.err_handler)?;

			recog.base.set_state(557);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(1,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(555);
					recog.base.match_token(NOT,&mut recog.err_handler)?;

					recog.base.set_state(556);
					recog.base.match_token(ATOMIC,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			recog.base.set_state(560);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(2,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule compoundBody*/
					recog.base.set_state(559);
					recog.compoundBody()?;

					}
				}

				_ => {}
			}
			recog.base.set_state(562);
			recog.base.match_token(END,&mut recog.err_handler)?;

			recog.base.set_state(564);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==SEMICOLON {
				{
				recog.base.set_state(563);
				recog.base.match_token(SEMICOLON,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(566);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- beginEndCompoundBlock ----------------
pub type BeginEndCompoundBlockContextAll<'input> = BeginEndCompoundBlockContext<'input>;


pub type BeginEndCompoundBlockContext<'input> = BaseParserRuleContext<'input,BeginEndCompoundBlockContextExt<'input>>;

#[derive(Clone)]
pub struct BeginEndCompoundBlockContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for BeginEndCompoundBlockContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for BeginEndCompoundBlockContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_beginEndCompoundBlock(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_beginEndCompoundBlock(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for BeginEndCompoundBlockContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_beginEndCompoundBlock(self);
	}
}

impl<'input> CustomRuleContext<'input> for BeginEndCompoundBlockContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_beginEndCompoundBlock }
	//fn type_rule_index() -> usize where Self: Sized { RULE_beginEndCompoundBlock }
}
antlr_rust::tid!{BeginEndCompoundBlockContextExt<'a>}

impl<'input> BeginEndCompoundBlockContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<BeginEndCompoundBlockContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,BeginEndCompoundBlockContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait BeginEndCompoundBlockContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<BeginEndCompoundBlockContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token BEGIN
/// Returns `None` if there is no child corresponding to token BEGIN
fn BEGIN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BEGIN, 0)
}
/// Retrieves first TerminalNode corresponding to token END
/// Returns `None` if there is no child corresponding to token END
fn END(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(END, 0)
}
fn beginLabel(&self) -> Option<Rc<BeginLabelContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token NOT
/// Returns `None` if there is no child corresponding to token NOT
fn NOT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NOT, 0)
}
/// Retrieves first TerminalNode corresponding to token ATOMIC
/// Returns `None` if there is no child corresponding to token ATOMIC
fn ATOMIC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ATOMIC, 0)
}
fn compoundBody(&self) -> Option<Rc<CompoundBodyContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn endLabel(&self) -> Option<Rc<EndLabelContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> BeginEndCompoundBlockContextAttrs<'input> for BeginEndCompoundBlockContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn beginEndCompoundBlock(&mut self,)
	-> Result<Rc<BeginEndCompoundBlockContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = BeginEndCompoundBlockContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 4, RULE_beginEndCompoundBlock);
        let mut _localctx: Rc<BeginEndCompoundBlockContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(569);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(4,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule beginLabel*/
					recog.base.set_state(568);
					recog.beginLabel()?;

					}
				}

				_ => {}
			}
			recog.base.set_state(571);
			recog.base.match_token(BEGIN,&mut recog.err_handler)?;

			recog.base.set_state(574);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(5,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(572);
					recog.base.match_token(NOT,&mut recog.err_handler)?;

					recog.base.set_state(573);
					recog.base.match_token(ATOMIC,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			recog.base.set_state(577);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(6,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule compoundBody*/
					recog.base.set_state(576);
					recog.compoundBody()?;

					}
				}

				_ => {}
			}
			recog.base.set_state(579);
			recog.base.match_token(END,&mut recog.err_handler)?;

			recog.base.set_state(581);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(7,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule endLabel*/
					recog.base.set_state(580);
					recog.endLabel()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- compoundBody ----------------
pub type CompoundBodyContextAll<'input> = CompoundBodyContext<'input>;


pub type CompoundBodyContext<'input> = BaseParserRuleContext<'input,CompoundBodyContextExt<'input>>;

#[derive(Clone)]
pub struct CompoundBodyContextExt<'input>{
	pub compoundStatement: Option<Rc<CompoundStatementContextAll<'input>>>,
	pub compoundStatements:Vec<Rc<CompoundStatementContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for CompoundBodyContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CompoundBodyContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_compoundBody(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_compoundBody(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CompoundBodyContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_compoundBody(self);
	}
}

impl<'input> CustomRuleContext<'input> for CompoundBodyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_compoundBody }
	//fn type_rule_index() -> usize where Self: Sized { RULE_compoundBody }
}
antlr_rust::tid!{CompoundBodyContextExt<'a>}

impl<'input> CompoundBodyContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CompoundBodyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CompoundBodyContextExt{
				compoundStatement: None, 
				compoundStatements: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait CompoundBodyContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<CompoundBodyContextExt<'input>>{

/// Retrieves all `TerminalNode`s corresponding to token SEMICOLON in current rule
fn SEMICOLON_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token SEMICOLON, starting from 0.
/// Returns `None` if number of children corresponding to token SEMICOLON is less or equal than `i`.
fn SEMICOLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SEMICOLON, i)
}
fn compoundStatement_all(&self) ->  Vec<Rc<CompoundStatementContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn compoundStatement(&self, i: usize) -> Option<Rc<CompoundStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> CompoundBodyContextAttrs<'input> for CompoundBodyContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn compoundBody(&mut self,)
	-> Result<Rc<CompoundBodyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CompoundBodyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 6, RULE_compoundBody);
        let mut _localctx: Rc<CompoundBodyContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(586); 
			recog.err_handler.sync(&mut recog.base)?;
			_alt = 1;
			loop {
				match _alt {
				    x if x == 1=>
					{
					{
					/*InvokeRule compoundStatement*/
					recog.base.set_state(583);
					let tmp = recog.compoundStatement()?;
					 cast_mut::<_,CompoundBodyContext >(&mut _localctx).compoundStatement = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,CompoundBodyContext >(&mut _localctx).compoundStatement.clone().unwrap()
					 ;
					 cast_mut::<_,CompoundBodyContext >(&mut _localctx).compoundStatements.push(temp);
					  
					recog.base.set_state(584);
					recog.base.match_token(SEMICOLON,&mut recog.err_handler)?;

					}
					}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
				}
				recog.base.set_state(588); 
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(8,&mut recog.base)?;
				if _alt==2 || _alt==INVALID_ALT { break }
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- compoundStatement ----------------
pub type CompoundStatementContextAll<'input> = CompoundStatementContext<'input>;


pub type CompoundStatementContext<'input> = BaseParserRuleContext<'input,CompoundStatementContextExt<'input>>;

#[derive(Clone)]
pub struct CompoundStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for CompoundStatementContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CompoundStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_compoundStatement(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_compoundStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CompoundStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_compoundStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for CompoundStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_compoundStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_compoundStatement }
}
antlr_rust::tid!{CompoundStatementContextExt<'a>}

impl<'input> CompoundStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CompoundStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CompoundStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait CompoundStatementContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<CompoundStatementContextExt<'input>>{

fn declareConditionStatement(&self) -> Option<Rc<DeclareConditionStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn statement(&self) -> Option<Rc<StatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn setStatementInsideSqlScript(&self) -> Option<Rc<SetStatementInsideSqlScriptContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn beginEndCompoundBlock(&self) -> Option<Rc<BeginEndCompoundBlockContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn declareHandlerStatement(&self) -> Option<Rc<DeclareHandlerStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn ifElseStatement(&self) -> Option<Rc<IfElseStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn caseStatement(&self) -> Option<Rc<CaseStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn whileStatement(&self) -> Option<Rc<WhileStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn repeatStatement(&self) -> Option<Rc<RepeatStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn leaveStatement(&self) -> Option<Rc<LeaveStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn iterateStatement(&self) -> Option<Rc<IterateStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn loopStatement(&self) -> Option<Rc<LoopStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn forStatement(&self) -> Option<Rc<ForStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CompoundStatementContextAttrs<'input> for CompoundStatementContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn compoundStatement(&mut self,)
	-> Result<Rc<CompoundStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CompoundStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 8, RULE_compoundStatement);
        let mut _localctx: Rc<CompoundStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(603);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(9,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule declareConditionStatement*/
					recog.base.set_state(590);
					recog.declareConditionStatement()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule statement*/
					recog.base.set_state(591);
					recog.statement()?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule setStatementInsideSqlScript*/
					recog.base.set_state(592);
					recog.setStatementInsideSqlScript()?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule beginEndCompoundBlock*/
					recog.base.set_state(593);
					recog.beginEndCompoundBlock()?;

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					/*InvokeRule declareHandlerStatement*/
					recog.base.set_state(594);
					recog.declareHandlerStatement()?;

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					/*InvokeRule ifElseStatement*/
					recog.base.set_state(595);
					recog.ifElseStatement()?;

					}
				}
			,
				7 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					/*InvokeRule caseStatement*/
					recog.base.set_state(596);
					recog.caseStatement()?;

					}
				}
			,
				8 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 8);
					recog.base.enter_outer_alt(None, 8);
					{
					/*InvokeRule whileStatement*/
					recog.base.set_state(597);
					recog.whileStatement()?;

					}
				}
			,
				9 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 9);
					recog.base.enter_outer_alt(None, 9);
					{
					/*InvokeRule repeatStatement*/
					recog.base.set_state(598);
					recog.repeatStatement()?;

					}
				}
			,
				10 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 10);
					recog.base.enter_outer_alt(None, 10);
					{
					/*InvokeRule leaveStatement*/
					recog.base.set_state(599);
					recog.leaveStatement()?;

					}
				}
			,
				11 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 11);
					recog.base.enter_outer_alt(None, 11);
					{
					/*InvokeRule iterateStatement*/
					recog.base.set_state(600);
					recog.iterateStatement()?;

					}
				}
			,
				12 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 12);
					recog.base.enter_outer_alt(None, 12);
					{
					/*InvokeRule loopStatement*/
					recog.base.set_state(601);
					recog.loopStatement()?;

					}
				}
			,
				13 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 13);
					recog.base.enter_outer_alt(None, 13);
					{
					/*InvokeRule forStatement*/
					recog.base.set_state(602);
					recog.forStatement()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- setStatementInsideSqlScript ----------------
#[derive(Debug)]
pub enum SetStatementInsideSqlScriptContextAll<'input>{
	SetVariableInsideSqlScriptContext(SetVariableInsideSqlScriptContext<'input>),
Error(SetStatementInsideSqlScriptContext<'input>)
}
antlr_rust::tid!{SetStatementInsideSqlScriptContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for SetStatementInsideSqlScriptContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for SetStatementInsideSqlScriptContextAll<'input>{}

impl<'input> Deref for SetStatementInsideSqlScriptContextAll<'input>{
	type Target = dyn SetStatementInsideSqlScriptContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use SetStatementInsideSqlScriptContextAll::*;
		match self{
			SetVariableInsideSqlScriptContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SetStatementInsideSqlScriptContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SetStatementInsideSqlScriptContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type SetStatementInsideSqlScriptContext<'input> = BaseParserRuleContext<'input,SetStatementInsideSqlScriptContextExt<'input>>;

#[derive(Clone)]
pub struct SetStatementInsideSqlScriptContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SetStatementInsideSqlScriptContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SetStatementInsideSqlScriptContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SetStatementInsideSqlScriptContext<'input>{
}

impl<'input> CustomRuleContext<'input> for SetStatementInsideSqlScriptContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setStatementInsideSqlScript }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setStatementInsideSqlScript }
}
antlr_rust::tid!{SetStatementInsideSqlScriptContextExt<'a>}

impl<'input> SetStatementInsideSqlScriptContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SetStatementInsideSqlScriptContextAll<'input>> {
		Rc::new(
		SetStatementInsideSqlScriptContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SetStatementInsideSqlScriptContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait SetStatementInsideSqlScriptContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SetStatementInsideSqlScriptContextExt<'input>>{


}

impl<'input> SetStatementInsideSqlScriptContextAttrs<'input> for SetStatementInsideSqlScriptContext<'input>{}

pub type SetVariableInsideSqlScriptContext<'input> = BaseParserRuleContext<'input,SetVariableInsideSqlScriptContextExt<'input>>;

pub trait SetVariableInsideSqlScriptContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	fn assignmentList(&self) -> Option<Rc<AssignmentListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token LEFT_PAREN in current rule
	fn LEFT_PAREN_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token LEFT_PAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token LEFT_PAREN is less or equal than `i`.
	fn LEFT_PAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, i)
	}
	fn multipartIdentifierList(&self) -> Option<Rc<MultipartIdentifierListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token RIGHT_PAREN in current rule
	fn RIGHT_PAREN_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token RIGHT_PAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token RIGHT_PAREN is less or equal than `i`.
	fn RIGHT_PAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, i)
	}
	/// Retrieves first TerminalNode corresponding to token EQ
	/// Returns `None` if there is no child corresponding to token EQ
	fn EQ(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EQ, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SetVariableInsideSqlScriptContextAttrs<'input> for SetVariableInsideSqlScriptContext<'input>{}

pub struct SetVariableInsideSqlScriptContextExt<'input>{
	base:SetStatementInsideSqlScriptContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetVariableInsideSqlScriptContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SetVariableInsideSqlScriptContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SetVariableInsideSqlScriptContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setVariableInsideSqlScript(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_setVariableInsideSqlScript(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SetVariableInsideSqlScriptContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_setVariableInsideSqlScript(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetVariableInsideSqlScriptContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setStatementInsideSqlScript }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setStatementInsideSqlScript }
}

impl<'input> Borrow<SetStatementInsideSqlScriptContextExt<'input>> for SetVariableInsideSqlScriptContext<'input>{
	fn borrow(&self) -> &SetStatementInsideSqlScriptContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<SetStatementInsideSqlScriptContextExt<'input>> for SetVariableInsideSqlScriptContext<'input>{
	fn borrow_mut(&mut self) -> &mut SetStatementInsideSqlScriptContextExt<'input> { &mut self.base }
}

impl<'input> SetStatementInsideSqlScriptContextAttrs<'input> for SetVariableInsideSqlScriptContext<'input> {}

impl<'input> SetVariableInsideSqlScriptContextExt<'input>{
	fn new(ctx: &dyn SetStatementInsideSqlScriptContextAttrs<'input>) -> Rc<SetStatementInsideSqlScriptContextAll<'input>>  {
		Rc::new(
			SetStatementInsideSqlScriptContextAll::SetVariableInsideSqlScriptContext(
				BaseParserRuleContext::copy_from(ctx,SetVariableInsideSqlScriptContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn setStatementInsideSqlScript(&mut self,)
	-> Result<Rc<SetStatementInsideSqlScriptContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SetStatementInsideSqlScriptContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 10, RULE_setStatementInsideSqlScript);
        let mut _localctx: Rc<SetStatementInsideSqlScriptContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(616);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(10,&mut recog.base)? {
				1 =>{
					let tmp = SetVariableInsideSqlScriptContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(605);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					/*InvokeRule assignmentList*/
					recog.base.set_state(606);
					recog.assignmentList()?;

					}
				}
			,
				2 =>{
					let tmp = SetVariableInsideSqlScriptContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(607);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(608);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule multipartIdentifierList*/
					recog.base.set_state(609);
					recog.multipartIdentifierList()?;

					recog.base.set_state(610);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					recog.base.set_state(611);
					recog.base.match_token(EQ,&mut recog.err_handler)?;

					recog.base.set_state(612);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(613);
					recog.query()?;

					recog.base.set_state(614);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- sqlStateValue ----------------
pub type SqlStateValueContextAll<'input> = SqlStateValueContext<'input>;


pub type SqlStateValueContext<'input> = BaseParserRuleContext<'input,SqlStateValueContextExt<'input>>;

#[derive(Clone)]
pub struct SqlStateValueContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SqlStateValueContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SqlStateValueContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_sqlStateValue(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_sqlStateValue(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SqlStateValueContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_sqlStateValue(self);
	}
}

impl<'input> CustomRuleContext<'input> for SqlStateValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sqlStateValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sqlStateValue }
}
antlr_rust::tid!{SqlStateValueContextExt<'a>}

impl<'input> SqlStateValueContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SqlStateValueContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SqlStateValueContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SqlStateValueContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SqlStateValueContextExt<'input>>{

fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SqlStateValueContextAttrs<'input> for SqlStateValueContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn sqlStateValue(&mut self,)
	-> Result<Rc<SqlStateValueContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SqlStateValueContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 12, RULE_sqlStateValue);
        let mut _localctx: Rc<SqlStateValueContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule stringLit*/
			recog.base.set_state(618);
			recog.stringLit()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- declareConditionStatement ----------------
pub type DeclareConditionStatementContextAll<'input> = DeclareConditionStatementContext<'input>;


pub type DeclareConditionStatementContext<'input> = BaseParserRuleContext<'input,DeclareConditionStatementContextExt<'input>>;

#[derive(Clone)]
pub struct DeclareConditionStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for DeclareConditionStatementContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DeclareConditionStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_declareConditionStatement(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_declareConditionStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DeclareConditionStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_declareConditionStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for DeclareConditionStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_declareConditionStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_declareConditionStatement }
}
antlr_rust::tid!{DeclareConditionStatementContextExt<'a>}

impl<'input> DeclareConditionStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DeclareConditionStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DeclareConditionStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DeclareConditionStatementContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<DeclareConditionStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DECLARE
/// Returns `None` if there is no child corresponding to token DECLARE
fn DECLARE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DECLARE, 0)
}
fn strictIdentifier(&self) -> Option<Rc<StrictIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token CONDITION
/// Returns `None` if there is no child corresponding to token CONDITION
fn CONDITION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CONDITION, 0)
}
/// Retrieves first TerminalNode corresponding to token FOR
/// Returns `None` if there is no child corresponding to token FOR
fn FOR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FOR, 0)
}
/// Retrieves first TerminalNode corresponding to token SQLSTATE
/// Returns `None` if there is no child corresponding to token SQLSTATE
fn SQLSTATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SQLSTATE, 0)
}
fn sqlStateValue(&self) -> Option<Rc<SqlStateValueContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token VALUE
/// Returns `None` if there is no child corresponding to token VALUE
fn VALUE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VALUE, 0)
}

}

impl<'input> DeclareConditionStatementContextAttrs<'input> for DeclareConditionStatementContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn declareConditionStatement(&mut self,)
	-> Result<Rc<DeclareConditionStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DeclareConditionStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 14, RULE_declareConditionStatement);
        let mut _localctx: Rc<DeclareConditionStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(620);
			recog.base.match_token(DECLARE,&mut recog.err_handler)?;

			/*InvokeRule strictIdentifier*/
			recog.base.set_state(621);
			recog.strictIdentifier()?;

			recog.base.set_state(622);
			recog.base.match_token(CONDITION,&mut recog.err_handler)?;

			recog.base.set_state(629);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==FOR {
				{
				recog.base.set_state(623);
				recog.base.match_token(FOR,&mut recog.err_handler)?;

				recog.base.set_state(624);
				recog.base.match_token(SQLSTATE,&mut recog.err_handler)?;

				recog.base.set_state(626);
				recog.err_handler.sync(&mut recog.base)?;
				match  recog.interpreter.adaptive_predict(11,&mut recog.base)? {
					x if x == 1=>{
						{
						recog.base.set_state(625);
						recog.base.match_token(VALUE,&mut recog.err_handler)?;

						}
					}

					_ => {}
				}
				/*InvokeRule sqlStateValue*/
				recog.base.set_state(628);
				recog.sqlStateValue()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- conditionValue ----------------
pub type ConditionValueContextAll<'input> = ConditionValueContext<'input>;


pub type ConditionValueContext<'input> = BaseParserRuleContext<'input,ConditionValueContextExt<'input>>;

#[derive(Clone)]
pub struct ConditionValueContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ConditionValueContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ConditionValueContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_conditionValue(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_conditionValue(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ConditionValueContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_conditionValue(self);
	}
}

impl<'input> CustomRuleContext<'input> for ConditionValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_conditionValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_conditionValue }
}
antlr_rust::tid!{ConditionValueContextExt<'a>}

impl<'input> ConditionValueContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ConditionValueContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ConditionValueContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ConditionValueContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ConditionValueContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token SQLSTATE
/// Returns `None` if there is no child corresponding to token SQLSTATE
fn SQLSTATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SQLSTATE, 0)
}
fn sqlStateValue(&self) -> Option<Rc<SqlStateValueContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token VALUE
/// Returns `None` if there is no child corresponding to token VALUE
fn VALUE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VALUE, 0)
}
/// Retrieves first TerminalNode corresponding to token SQLEXCEPTION
/// Returns `None` if there is no child corresponding to token SQLEXCEPTION
fn SQLEXCEPTION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SQLEXCEPTION, 0)
}
/// Retrieves first TerminalNode corresponding to token NOT
/// Returns `None` if there is no child corresponding to token NOT
fn NOT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NOT, 0)
}
/// Retrieves first TerminalNode corresponding to token FOUND
/// Returns `None` if there is no child corresponding to token FOUND
fn FOUND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FOUND, 0)
}
fn multipartIdentifier(&self) -> Option<Rc<MultipartIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ConditionValueContextAttrs<'input> for ConditionValueContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn conditionValue(&mut self,)
	-> Result<Rc<ConditionValueContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ConditionValueContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 16, RULE_conditionValue);
        let mut _localctx: Rc<ConditionValueContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(640);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(14,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(631);
					recog.base.match_token(SQLSTATE,&mut recog.err_handler)?;

					recog.base.set_state(633);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(13,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(632);
							recog.base.match_token(VALUE,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule sqlStateValue*/
					recog.base.set_state(635);
					recog.sqlStateValue()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(636);
					recog.base.match_token(SQLEXCEPTION,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(637);
					recog.base.match_token(NOT,&mut recog.err_handler)?;

					recog.base.set_state(638);
					recog.base.match_token(FOUND,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule multipartIdentifier*/
					recog.base.set_state(639);
					recog.multipartIdentifier()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- conditionValues ----------------
pub type ConditionValuesContextAll<'input> = ConditionValuesContext<'input>;


pub type ConditionValuesContext<'input> = BaseParserRuleContext<'input,ConditionValuesContextExt<'input>>;

#[derive(Clone)]
pub struct ConditionValuesContextExt<'input>{
	pub conditionValue: Option<Rc<ConditionValueContextAll<'input>>>,
	pub cvList:Vec<Rc<ConditionValueContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ConditionValuesContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ConditionValuesContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_conditionValues(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_conditionValues(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ConditionValuesContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_conditionValues(self);
	}
}

impl<'input> CustomRuleContext<'input> for ConditionValuesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_conditionValues }
	//fn type_rule_index() -> usize where Self: Sized { RULE_conditionValues }
}
antlr_rust::tid!{ConditionValuesContextExt<'a>}

impl<'input> ConditionValuesContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ConditionValuesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ConditionValuesContextExt{
				conditionValue: None, 
				cvList: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait ConditionValuesContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ConditionValuesContextExt<'input>>{

fn conditionValue_all(&self) ->  Vec<Rc<ConditionValueContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn conditionValue(&self, i: usize) -> Option<Rc<ConditionValueContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ConditionValuesContextAttrs<'input> for ConditionValuesContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn conditionValues(&mut self,)
	-> Result<Rc<ConditionValuesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ConditionValuesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 18, RULE_conditionValues);
        let mut _localctx: Rc<ConditionValuesContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule conditionValue*/
			recog.base.set_state(642);
			let tmp = recog.conditionValue()?;
			 cast_mut::<_,ConditionValuesContext >(&mut _localctx).conditionValue = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,ConditionValuesContext >(&mut _localctx).conditionValue.clone().unwrap()
			 ;
			 cast_mut::<_,ConditionValuesContext >(&mut _localctx).cvList.push(temp);
			  
			recog.base.set_state(647);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(15,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(643);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule conditionValue*/
					recog.base.set_state(644);
					let tmp = recog.conditionValue()?;
					 cast_mut::<_,ConditionValuesContext >(&mut _localctx).conditionValue = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,ConditionValuesContext >(&mut _localctx).conditionValue.clone().unwrap()
					 ;
					 cast_mut::<_,ConditionValuesContext >(&mut _localctx).cvList.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(649);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(15,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- declareHandlerStatement ----------------
pub type DeclareHandlerStatementContextAll<'input> = DeclareHandlerStatementContext<'input>;


pub type DeclareHandlerStatementContext<'input> = BaseParserRuleContext<'input,DeclareHandlerStatementContextExt<'input>>;

#[derive(Clone)]
pub struct DeclareHandlerStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for DeclareHandlerStatementContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DeclareHandlerStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_declareHandlerStatement(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_declareHandlerStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DeclareHandlerStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_declareHandlerStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for DeclareHandlerStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_declareHandlerStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_declareHandlerStatement }
}
antlr_rust::tid!{DeclareHandlerStatementContextExt<'a>}

impl<'input> DeclareHandlerStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DeclareHandlerStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DeclareHandlerStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DeclareHandlerStatementContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<DeclareHandlerStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DECLARE
/// Returns `None` if there is no child corresponding to token DECLARE
fn DECLARE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DECLARE, 0)
}
/// Retrieves first TerminalNode corresponding to token HANDLER
/// Returns `None` if there is no child corresponding to token HANDLER
fn HANDLER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(HANDLER, 0)
}
/// Retrieves first TerminalNode corresponding to token FOR
/// Returns `None` if there is no child corresponding to token FOR
fn FOR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FOR, 0)
}
fn conditionValues(&self) -> Option<Rc<ConditionValuesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token CONTINUE
/// Returns `None` if there is no child corresponding to token CONTINUE
fn CONTINUE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CONTINUE, 0)
}
/// Retrieves first TerminalNode corresponding to token EXIT
/// Returns `None` if there is no child corresponding to token EXIT
fn EXIT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXIT, 0)
}
fn beginEndCompoundBlock(&self) -> Option<Rc<BeginEndCompoundBlockContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn statement(&self) -> Option<Rc<StatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn setStatementInsideSqlScript(&self) -> Option<Rc<SetStatementInsideSqlScriptContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DeclareHandlerStatementContextAttrs<'input> for DeclareHandlerStatementContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn declareHandlerStatement(&mut self,)
	-> Result<Rc<DeclareHandlerStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DeclareHandlerStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 20, RULE_declareHandlerStatement);
        let mut _localctx: Rc<DeclareHandlerStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(650);
			recog.base.match_token(DECLARE,&mut recog.err_handler)?;

			recog.base.set_state(651);
			_la = recog.base.input.la(1);
			if { !(_la==CONTINUE || _la==EXIT) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(652);
			recog.base.match_token(HANDLER,&mut recog.err_handler)?;

			recog.base.set_state(653);
			recog.base.match_token(FOR,&mut recog.err_handler)?;

			/*InvokeRule conditionValues*/
			recog.base.set_state(654);
			recog.conditionValues()?;

			recog.base.set_state(658);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(16,&mut recog.base)? {
				1 =>{
					{
					/*InvokeRule beginEndCompoundBlock*/
					recog.base.set_state(655);
					recog.beginEndCompoundBlock()?;

					}
				}
			,
				2 =>{
					{
					/*InvokeRule statement*/
					recog.base.set_state(656);
					recog.statement()?;

					}
				}
			,
				3 =>{
					{
					/*InvokeRule setStatementInsideSqlScript*/
					recog.base.set_state(657);
					recog.setStatementInsideSqlScript()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- whileStatement ----------------
pub type WhileStatementContextAll<'input> = WhileStatementContext<'input>;


pub type WhileStatementContext<'input> = BaseParserRuleContext<'input,WhileStatementContextExt<'input>>;

#[derive(Clone)]
pub struct WhileStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for WhileStatementContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for WhileStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_whileStatement(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_whileStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for WhileStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_whileStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for WhileStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_whileStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_whileStatement }
}
antlr_rust::tid!{WhileStatementContextExt<'a>}

impl<'input> WhileStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WhileStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WhileStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait WhileStatementContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<WhileStatementContextExt<'input>>{

/// Retrieves all `TerminalNode`s corresponding to token WHILE in current rule
fn WHILE_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token WHILE, starting from 0.
/// Returns `None` if number of children corresponding to token WHILE is less or equal than `i`.
fn WHILE(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WHILE, i)
}
fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token DO
/// Returns `None` if there is no child corresponding to token DO
fn DO(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DO, 0)
}
fn compoundBody(&self) -> Option<Rc<CompoundBodyContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token END
/// Returns `None` if there is no child corresponding to token END
fn END(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(END, 0)
}
fn beginLabel(&self) -> Option<Rc<BeginLabelContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn endLabel(&self) -> Option<Rc<EndLabelContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> WhileStatementContextAttrs<'input> for WhileStatementContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn whileStatement(&mut self,)
	-> Result<Rc<WhileStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WhileStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 22, RULE_whileStatement);
        let mut _localctx: Rc<WhileStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(661);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(17,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule beginLabel*/
					recog.base.set_state(660);
					recog.beginLabel()?;

					}
				}

				_ => {}
			}
			recog.base.set_state(663);
			recog.base.match_token(WHILE,&mut recog.err_handler)?;

			/*InvokeRule booleanExpression*/
			recog.base.set_state(664);
			recog.booleanExpression_rec(0)?;

			recog.base.set_state(665);
			recog.base.match_token(DO,&mut recog.err_handler)?;

			/*InvokeRule compoundBody*/
			recog.base.set_state(666);
			recog.compoundBody()?;

			recog.base.set_state(667);
			recog.base.match_token(END,&mut recog.err_handler)?;

			recog.base.set_state(668);
			recog.base.match_token(WHILE,&mut recog.err_handler)?;

			recog.base.set_state(670);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(18,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule endLabel*/
					recog.base.set_state(669);
					recog.endLabel()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- ifElseStatement ----------------
pub type IfElseStatementContextAll<'input> = IfElseStatementContext<'input>;


pub type IfElseStatementContext<'input> = BaseParserRuleContext<'input,IfElseStatementContextExt<'input>>;

#[derive(Clone)]
pub struct IfElseStatementContextExt<'input>{
	pub compoundBody: Option<Rc<CompoundBodyContextAll<'input>>>,
	pub conditionalBodies:Vec<Rc<CompoundBodyContextAll<'input>>>,
	pub elseBody: Option<Rc<CompoundBodyContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for IfElseStatementContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for IfElseStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_ifElseStatement(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_ifElseStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for IfElseStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_ifElseStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for IfElseStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_ifElseStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_ifElseStatement }
}
antlr_rust::tid!{IfElseStatementContextExt<'a>}

impl<'input> IfElseStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IfElseStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IfElseStatementContextExt{
				compoundBody: None, elseBody: None, 
				conditionalBodies: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait IfElseStatementContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<IfElseStatementContextExt<'input>>{

/// Retrieves all `TerminalNode`s corresponding to token IF in current rule
fn IF_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token IF, starting from 0.
/// Returns `None` if number of children corresponding to token IF is less or equal than `i`.
fn IF(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IF, i)
}
fn booleanExpression_all(&self) ->  Vec<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn booleanExpression(&self, i: usize) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token THEN in current rule
fn THEN_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token THEN, starting from 0.
/// Returns `None` if number of children corresponding to token THEN is less or equal than `i`.
fn THEN(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(THEN, i)
}
/// Retrieves first TerminalNode corresponding to token END
/// Returns `None` if there is no child corresponding to token END
fn END(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(END, 0)
}
fn compoundBody_all(&self) ->  Vec<Rc<CompoundBodyContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn compoundBody(&self, i: usize) -> Option<Rc<CompoundBodyContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token ELSEIF in current rule
fn ELSEIF_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token ELSEIF, starting from 0.
/// Returns `None` if number of children corresponding to token ELSEIF is less or equal than `i`.
fn ELSEIF(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ELSEIF, i)
}
/// Retrieves first TerminalNode corresponding to token ELSE
/// Returns `None` if there is no child corresponding to token ELSE
fn ELSE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ELSE, 0)
}

}

impl<'input> IfElseStatementContextAttrs<'input> for IfElseStatementContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn ifElseStatement(&mut self,)
	-> Result<Rc<IfElseStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IfElseStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 24, RULE_ifElseStatement);
        let mut _localctx: Rc<IfElseStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(672);
			recog.base.match_token(IF,&mut recog.err_handler)?;

			/*InvokeRule booleanExpression*/
			recog.base.set_state(673);
			recog.booleanExpression_rec(0)?;

			recog.base.set_state(674);
			recog.base.match_token(THEN,&mut recog.err_handler)?;

			/*InvokeRule compoundBody*/
			recog.base.set_state(675);
			let tmp = recog.compoundBody()?;
			 cast_mut::<_,IfElseStatementContext >(&mut _localctx).compoundBody = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,IfElseStatementContext >(&mut _localctx).compoundBody.clone().unwrap()
			 ;
			 cast_mut::<_,IfElseStatementContext >(&mut _localctx).conditionalBodies.push(temp);
			  
			recog.base.set_state(683);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==ELSEIF {
				{
				{
				recog.base.set_state(676);
				recog.base.match_token(ELSEIF,&mut recog.err_handler)?;

				/*InvokeRule booleanExpression*/
				recog.base.set_state(677);
				recog.booleanExpression_rec(0)?;

				recog.base.set_state(678);
				recog.base.match_token(THEN,&mut recog.err_handler)?;

				/*InvokeRule compoundBody*/
				recog.base.set_state(679);
				let tmp = recog.compoundBody()?;
				 cast_mut::<_,IfElseStatementContext >(&mut _localctx).compoundBody = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,IfElseStatementContext >(&mut _localctx).compoundBody.clone().unwrap()
				 ;
				 cast_mut::<_,IfElseStatementContext >(&mut _localctx).conditionalBodies.push(temp);
				  
				}
				}
				recog.base.set_state(685);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(688);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ELSE {
				{
				recog.base.set_state(686);
				recog.base.match_token(ELSE,&mut recog.err_handler)?;

				/*InvokeRule compoundBody*/
				recog.base.set_state(687);
				let tmp = recog.compoundBody()?;
				 cast_mut::<_,IfElseStatementContext >(&mut _localctx).elseBody = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(690);
			recog.base.match_token(END,&mut recog.err_handler)?;

			recog.base.set_state(691);
			recog.base.match_token(IF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- repeatStatement ----------------
pub type RepeatStatementContextAll<'input> = RepeatStatementContext<'input>;


pub type RepeatStatementContext<'input> = BaseParserRuleContext<'input,RepeatStatementContextExt<'input>>;

#[derive(Clone)]
pub struct RepeatStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for RepeatStatementContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for RepeatStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_repeatStatement(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_repeatStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for RepeatStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_repeatStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for RepeatStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_repeatStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_repeatStatement }
}
antlr_rust::tid!{RepeatStatementContextExt<'a>}

impl<'input> RepeatStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RepeatStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RepeatStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RepeatStatementContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<RepeatStatementContextExt<'input>>{

/// Retrieves all `TerminalNode`s corresponding to token REPEAT in current rule
fn REPEAT_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token REPEAT, starting from 0.
/// Returns `None` if number of children corresponding to token REPEAT is less or equal than `i`.
fn REPEAT(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(REPEAT, i)
}
fn compoundBody(&self) -> Option<Rc<CompoundBodyContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token UNTIL
/// Returns `None` if there is no child corresponding to token UNTIL
fn UNTIL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UNTIL, 0)
}
fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token END
/// Returns `None` if there is no child corresponding to token END
fn END(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(END, 0)
}
fn beginLabel(&self) -> Option<Rc<BeginLabelContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn endLabel(&self) -> Option<Rc<EndLabelContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> RepeatStatementContextAttrs<'input> for RepeatStatementContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn repeatStatement(&mut self,)
	-> Result<Rc<RepeatStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RepeatStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 26, RULE_repeatStatement);
        let mut _localctx: Rc<RepeatStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(694);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(21,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule beginLabel*/
					recog.base.set_state(693);
					recog.beginLabel()?;

					}
				}

				_ => {}
			}
			recog.base.set_state(696);
			recog.base.match_token(REPEAT,&mut recog.err_handler)?;

			/*InvokeRule compoundBody*/
			recog.base.set_state(697);
			recog.compoundBody()?;

			recog.base.set_state(698);
			recog.base.match_token(UNTIL,&mut recog.err_handler)?;

			/*InvokeRule booleanExpression*/
			recog.base.set_state(699);
			recog.booleanExpression_rec(0)?;

			recog.base.set_state(700);
			recog.base.match_token(END,&mut recog.err_handler)?;

			recog.base.set_state(701);
			recog.base.match_token(REPEAT,&mut recog.err_handler)?;

			recog.base.set_state(703);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(22,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule endLabel*/
					recog.base.set_state(702);
					recog.endLabel()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- leaveStatement ----------------
pub type LeaveStatementContextAll<'input> = LeaveStatementContext<'input>;


pub type LeaveStatementContext<'input> = BaseParserRuleContext<'input,LeaveStatementContextExt<'input>>;

#[derive(Clone)]
pub struct LeaveStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for LeaveStatementContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for LeaveStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_leaveStatement(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_leaveStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for LeaveStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_leaveStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for LeaveStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_leaveStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_leaveStatement }
}
antlr_rust::tid!{LeaveStatementContextExt<'a>}

impl<'input> LeaveStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LeaveStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LeaveStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait LeaveStatementContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<LeaveStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LEAVE
/// Returns `None` if there is no child corresponding to token LEAVE
fn LEAVE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEAVE, 0)
}
fn strictIdentifier(&self) -> Option<Rc<StrictIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LeaveStatementContextAttrs<'input> for LeaveStatementContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn leaveStatement(&mut self,)
	-> Result<Rc<LeaveStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LeaveStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 28, RULE_leaveStatement);
        let mut _localctx: Rc<LeaveStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(705);
			recog.base.match_token(LEAVE,&mut recog.err_handler)?;

			/*InvokeRule strictIdentifier*/
			recog.base.set_state(706);
			recog.strictIdentifier()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- iterateStatement ----------------
pub type IterateStatementContextAll<'input> = IterateStatementContext<'input>;


pub type IterateStatementContext<'input> = BaseParserRuleContext<'input,IterateStatementContextExt<'input>>;

#[derive(Clone)]
pub struct IterateStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for IterateStatementContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for IterateStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_iterateStatement(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_iterateStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for IterateStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_iterateStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for IterateStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_iterateStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_iterateStatement }
}
antlr_rust::tid!{IterateStatementContextExt<'a>}

impl<'input> IterateStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IterateStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IterateStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait IterateStatementContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<IterateStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ITERATE
/// Returns `None` if there is no child corresponding to token ITERATE
fn ITERATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ITERATE, 0)
}
fn strictIdentifier(&self) -> Option<Rc<StrictIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> IterateStatementContextAttrs<'input> for IterateStatementContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn iterateStatement(&mut self,)
	-> Result<Rc<IterateStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IterateStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 30, RULE_iterateStatement);
        let mut _localctx: Rc<IterateStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(708);
			recog.base.match_token(ITERATE,&mut recog.err_handler)?;

			/*InvokeRule strictIdentifier*/
			recog.base.set_state(709);
			recog.strictIdentifier()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- caseStatement ----------------
#[derive(Debug)]
pub enum CaseStatementContextAll<'input>{
	SimpleCaseStatementContext(SimpleCaseStatementContext<'input>),
	SearchedCaseStatementContext(SearchedCaseStatementContext<'input>),
Error(CaseStatementContext<'input>)
}
antlr_rust::tid!{CaseStatementContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for CaseStatementContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for CaseStatementContextAll<'input>{}

impl<'input> Deref for CaseStatementContextAll<'input>{
	type Target = dyn CaseStatementContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use CaseStatementContextAll::*;
		match self{
			SimpleCaseStatementContext(inner) => inner,
			SearchedCaseStatementContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CaseStatementContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CaseStatementContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type CaseStatementContext<'input> = BaseParserRuleContext<'input,CaseStatementContextExt<'input>>;

#[derive(Clone)]
pub struct CaseStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for CaseStatementContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CaseStatementContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CaseStatementContext<'input>{
}

impl<'input> CustomRuleContext<'input> for CaseStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_caseStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_caseStatement }
}
antlr_rust::tid!{CaseStatementContextExt<'a>}

impl<'input> CaseStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CaseStatementContextAll<'input>> {
		Rc::new(
		CaseStatementContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CaseStatementContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait CaseStatementContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<CaseStatementContextExt<'input>>{


}

impl<'input> CaseStatementContextAttrs<'input> for CaseStatementContext<'input>{}

pub type SimpleCaseStatementContext<'input> = BaseParserRuleContext<'input,SimpleCaseStatementContextExt<'input>>;

pub trait SimpleCaseStatementContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves all `TerminalNode`s corresponding to token CASE in current rule
	fn CASE_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token CASE, starting from 0.
	/// Returns `None` if number of children corresponding to token CASE is less or equal than `i`.
	fn CASE(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CASE, i)
	}
	/// Retrieves first TerminalNode corresponding to token END
	/// Returns `None` if there is no child corresponding to token END
	fn END(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(END, 0)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token WHEN in current rule
	fn WHEN_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token WHEN, starting from 0.
	/// Returns `None` if number of children corresponding to token WHEN is less or equal than `i`.
	fn WHEN(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(WHEN, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token THEN in current rule
	fn THEN_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token THEN, starting from 0.
	/// Returns `None` if number of children corresponding to token THEN is less or equal than `i`.
	fn THEN(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(THEN, i)
	}
	/// Retrieves first TerminalNode corresponding to token ELSE
	/// Returns `None` if there is no child corresponding to token ELSE
	fn ELSE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ELSE, 0)
	}
	fn compoundBody_all(&self) ->  Vec<Rc<CompoundBodyContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn compoundBody(&self, i: usize) -> Option<Rc<CompoundBodyContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> SimpleCaseStatementContextAttrs<'input> for SimpleCaseStatementContext<'input>{}

pub struct SimpleCaseStatementContextExt<'input>{
	base:CaseStatementContextExt<'input>,
	pub caseVariable: Option<Rc<ExpressionContextAll<'input>>>,
	pub expression: Option<Rc<ExpressionContextAll<'input>>>,
	pub conditionExpressions:Vec<Rc<ExpressionContextAll<'input>>>,
	pub compoundBody: Option<Rc<CompoundBodyContextAll<'input>>>,
	pub conditionalBodies:Vec<Rc<CompoundBodyContextAll<'input>>>,
	pub elseBody: Option<Rc<CompoundBodyContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SimpleCaseStatementContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SimpleCaseStatementContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SimpleCaseStatementContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_simpleCaseStatement(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_simpleCaseStatement(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SimpleCaseStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_simpleCaseStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for SimpleCaseStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_caseStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_caseStatement }
}

impl<'input> Borrow<CaseStatementContextExt<'input>> for SimpleCaseStatementContext<'input>{
	fn borrow(&self) -> &CaseStatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<CaseStatementContextExt<'input>> for SimpleCaseStatementContext<'input>{
	fn borrow_mut(&mut self) -> &mut CaseStatementContextExt<'input> { &mut self.base }
}

impl<'input> CaseStatementContextAttrs<'input> for SimpleCaseStatementContext<'input> {}

impl<'input> SimpleCaseStatementContextExt<'input>{
	fn new(ctx: &dyn CaseStatementContextAttrs<'input>) -> Rc<CaseStatementContextAll<'input>>  {
		Rc::new(
			CaseStatementContextAll::SimpleCaseStatementContext(
				BaseParserRuleContext::copy_from(ctx,SimpleCaseStatementContextExt{
        			caseVariable:None, expression:None, compoundBody:None, elseBody:None, 
        			conditionExpressions:Vec::new(), conditionalBodies:Vec::new(), 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SearchedCaseStatementContext<'input> = BaseParserRuleContext<'input,SearchedCaseStatementContextExt<'input>>;

pub trait SearchedCaseStatementContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves all `TerminalNode`s corresponding to token CASE in current rule
	fn CASE_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token CASE, starting from 0.
	/// Returns `None` if number of children corresponding to token CASE is less or equal than `i`.
	fn CASE(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CASE, i)
	}
	/// Retrieves first TerminalNode corresponding to token END
	/// Returns `None` if there is no child corresponding to token END
	fn END(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(END, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token WHEN in current rule
	fn WHEN_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token WHEN, starting from 0.
	/// Returns `None` if number of children corresponding to token WHEN is less or equal than `i`.
	fn WHEN(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(WHEN, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token THEN in current rule
	fn THEN_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token THEN, starting from 0.
	/// Returns `None` if number of children corresponding to token THEN is less or equal than `i`.
	fn THEN(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(THEN, i)
	}
	/// Retrieves first TerminalNode corresponding to token ELSE
	/// Returns `None` if there is no child corresponding to token ELSE
	fn ELSE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ELSE, 0)
	}
	fn booleanExpression_all(&self) ->  Vec<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn booleanExpression(&self, i: usize) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn compoundBody_all(&self) ->  Vec<Rc<CompoundBodyContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn compoundBody(&self, i: usize) -> Option<Rc<CompoundBodyContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> SearchedCaseStatementContextAttrs<'input> for SearchedCaseStatementContext<'input>{}

pub struct SearchedCaseStatementContextExt<'input>{
	base:CaseStatementContextExt<'input>,
	pub booleanExpression: Option<Rc<BooleanExpressionContextAll<'input>>>,
	pub conditions:Vec<Rc<BooleanExpressionContextAll<'input>>>,
	pub compoundBody: Option<Rc<CompoundBodyContextAll<'input>>>,
	pub conditionalBodies:Vec<Rc<CompoundBodyContextAll<'input>>>,
	pub elseBody: Option<Rc<CompoundBodyContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SearchedCaseStatementContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SearchedCaseStatementContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SearchedCaseStatementContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_searchedCaseStatement(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_searchedCaseStatement(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SearchedCaseStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_searchedCaseStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for SearchedCaseStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_caseStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_caseStatement }
}

impl<'input> Borrow<CaseStatementContextExt<'input>> for SearchedCaseStatementContext<'input>{
	fn borrow(&self) -> &CaseStatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<CaseStatementContextExt<'input>> for SearchedCaseStatementContext<'input>{
	fn borrow_mut(&mut self) -> &mut CaseStatementContextExt<'input> { &mut self.base }
}

impl<'input> CaseStatementContextAttrs<'input> for SearchedCaseStatementContext<'input> {}

impl<'input> SearchedCaseStatementContextExt<'input>{
	fn new(ctx: &dyn CaseStatementContextAttrs<'input>) -> Rc<CaseStatementContextAll<'input>>  {
		Rc::new(
			CaseStatementContextAll::SearchedCaseStatementContext(
				BaseParserRuleContext::copy_from(ctx,SearchedCaseStatementContextExt{
        			booleanExpression:None, compoundBody:None, elseBody:None, 
        			conditions:Vec::new(), conditionalBodies:Vec::new(), 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn caseStatement(&mut self,)
	-> Result<Rc<CaseStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CaseStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 32, RULE_caseStatement);
        let mut _localctx: Rc<CaseStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(746);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(27,&mut recog.base)? {
				1 =>{
					let tmp = SearchedCaseStatementContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(711);
					recog.base.match_token(CASE,&mut recog.err_handler)?;

					recog.base.set_state(717); 
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					loop {
						{
						{
						recog.base.set_state(712);
						recog.base.match_token(WHEN,&mut recog.err_handler)?;

						/*InvokeRule booleanExpression*/
						recog.base.set_state(713);
						let tmp = recog.booleanExpression_rec(0)?;
						if let CaseStatementContextAll::SearchedCaseStatementContext(ctx) = cast_mut::<_,CaseStatementContextAll >(&mut _localctx){
						ctx.booleanExpression = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						let temp = if let CaseStatementContextAll::SearchedCaseStatementContext(ctx) = cast_mut::<_,CaseStatementContextAll >(&mut _localctx){
						ctx.booleanExpression.clone().unwrap() } else {unreachable!("cant cast");} ;
						if let CaseStatementContextAll::SearchedCaseStatementContext(ctx) = cast_mut::<_,CaseStatementContextAll >(&mut _localctx){
						ctx.conditions.push(temp); } else {unreachable!("cant cast");}  
						recog.base.set_state(714);
						recog.base.match_token(THEN,&mut recog.err_handler)?;

						/*InvokeRule compoundBody*/
						recog.base.set_state(715);
						let tmp = recog.compoundBody()?;
						if let CaseStatementContextAll::SearchedCaseStatementContext(ctx) = cast_mut::<_,CaseStatementContextAll >(&mut _localctx){
						ctx.compoundBody = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						let temp = if let CaseStatementContextAll::SearchedCaseStatementContext(ctx) = cast_mut::<_,CaseStatementContextAll >(&mut _localctx){
						ctx.compoundBody.clone().unwrap() } else {unreachable!("cant cast");} ;
						if let CaseStatementContextAll::SearchedCaseStatementContext(ctx) = cast_mut::<_,CaseStatementContextAll >(&mut _localctx){
						ctx.conditionalBodies.push(temp); } else {unreachable!("cant cast");}  
						}
						}
						recog.base.set_state(719); 
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if !(_la==WHEN) {break}
					}
					recog.base.set_state(723);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ELSE {
						{
						recog.base.set_state(721);
						recog.base.match_token(ELSE,&mut recog.err_handler)?;

						/*InvokeRule compoundBody*/
						recog.base.set_state(722);
						let tmp = recog.compoundBody()?;
						if let CaseStatementContextAll::SearchedCaseStatementContext(ctx) = cast_mut::<_,CaseStatementContextAll >(&mut _localctx){
						ctx.elseBody = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(725);
					recog.base.match_token(END,&mut recog.err_handler)?;

					recog.base.set_state(726);
					recog.base.match_token(CASE,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = SimpleCaseStatementContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(728);
					recog.base.match_token(CASE,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(729);
					let tmp = recog.expression()?;
					if let CaseStatementContextAll::SimpleCaseStatementContext(ctx) = cast_mut::<_,CaseStatementContextAll >(&mut _localctx){
					ctx.caseVariable = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(735); 
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					loop {
						{
						{
						recog.base.set_state(730);
						recog.base.match_token(WHEN,&mut recog.err_handler)?;

						/*InvokeRule expression*/
						recog.base.set_state(731);
						let tmp = recog.expression()?;
						if let CaseStatementContextAll::SimpleCaseStatementContext(ctx) = cast_mut::<_,CaseStatementContextAll >(&mut _localctx){
						ctx.expression = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						let temp = if let CaseStatementContextAll::SimpleCaseStatementContext(ctx) = cast_mut::<_,CaseStatementContextAll >(&mut _localctx){
						ctx.expression.clone().unwrap() } else {unreachable!("cant cast");} ;
						if let CaseStatementContextAll::SimpleCaseStatementContext(ctx) = cast_mut::<_,CaseStatementContextAll >(&mut _localctx){
						ctx.conditionExpressions.push(temp); } else {unreachable!("cant cast");}  
						recog.base.set_state(732);
						recog.base.match_token(THEN,&mut recog.err_handler)?;

						/*InvokeRule compoundBody*/
						recog.base.set_state(733);
						let tmp = recog.compoundBody()?;
						if let CaseStatementContextAll::SimpleCaseStatementContext(ctx) = cast_mut::<_,CaseStatementContextAll >(&mut _localctx){
						ctx.compoundBody = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						let temp = if let CaseStatementContextAll::SimpleCaseStatementContext(ctx) = cast_mut::<_,CaseStatementContextAll >(&mut _localctx){
						ctx.compoundBody.clone().unwrap() } else {unreachable!("cant cast");} ;
						if let CaseStatementContextAll::SimpleCaseStatementContext(ctx) = cast_mut::<_,CaseStatementContextAll >(&mut _localctx){
						ctx.conditionalBodies.push(temp); } else {unreachable!("cant cast");}  
						}
						}
						recog.base.set_state(737); 
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if !(_la==WHEN) {break}
					}
					recog.base.set_state(741);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ELSE {
						{
						recog.base.set_state(739);
						recog.base.match_token(ELSE,&mut recog.err_handler)?;

						/*InvokeRule compoundBody*/
						recog.base.set_state(740);
						let tmp = recog.compoundBody()?;
						if let CaseStatementContextAll::SimpleCaseStatementContext(ctx) = cast_mut::<_,CaseStatementContextAll >(&mut _localctx){
						ctx.elseBody = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(743);
					recog.base.match_token(END,&mut recog.err_handler)?;

					recog.base.set_state(744);
					recog.base.match_token(CASE,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- loopStatement ----------------
pub type LoopStatementContextAll<'input> = LoopStatementContext<'input>;


pub type LoopStatementContext<'input> = BaseParserRuleContext<'input,LoopStatementContextExt<'input>>;

#[derive(Clone)]
pub struct LoopStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for LoopStatementContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for LoopStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_loopStatement(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_loopStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for LoopStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_loopStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for LoopStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_loopStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_loopStatement }
}
antlr_rust::tid!{LoopStatementContextExt<'a>}

impl<'input> LoopStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LoopStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LoopStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait LoopStatementContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<LoopStatementContextExt<'input>>{

/// Retrieves all `TerminalNode`s corresponding to token LOOP in current rule
fn LOOP_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LOOP, starting from 0.
/// Returns `None` if number of children corresponding to token LOOP is less or equal than `i`.
fn LOOP(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LOOP, i)
}
fn compoundBody(&self) -> Option<Rc<CompoundBodyContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token END
/// Returns `None` if there is no child corresponding to token END
fn END(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(END, 0)
}
fn beginLabel(&self) -> Option<Rc<BeginLabelContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn endLabel(&self) -> Option<Rc<EndLabelContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LoopStatementContextAttrs<'input> for LoopStatementContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn loopStatement(&mut self,)
	-> Result<Rc<LoopStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LoopStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 34, RULE_loopStatement);
        let mut _localctx: Rc<LoopStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(749);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(28,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule beginLabel*/
					recog.base.set_state(748);
					recog.beginLabel()?;

					}
				}

				_ => {}
			}
			recog.base.set_state(751);
			recog.base.match_token(LOOP,&mut recog.err_handler)?;

			/*InvokeRule compoundBody*/
			recog.base.set_state(752);
			recog.compoundBody()?;

			recog.base.set_state(753);
			recog.base.match_token(END,&mut recog.err_handler)?;

			recog.base.set_state(754);
			recog.base.match_token(LOOP,&mut recog.err_handler)?;

			recog.base.set_state(756);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(29,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule endLabel*/
					recog.base.set_state(755);
					recog.endLabel()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- forStatement ----------------
pub type ForStatementContextAll<'input> = ForStatementContext<'input>;


pub type ForStatementContext<'input> = BaseParserRuleContext<'input,ForStatementContextExt<'input>>;

#[derive(Clone)]
pub struct ForStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ForStatementContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ForStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_forStatement(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_forStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ForStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_forStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for ForStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_forStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_forStatement }
}
antlr_rust::tid!{ForStatementContextExt<'a>}

impl<'input> ForStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ForStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ForStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ForStatementContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ForStatementContextExt<'input>>{

/// Retrieves all `TerminalNode`s corresponding to token FOR in current rule
fn FOR_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token FOR, starting from 0.
/// Returns `None` if number of children corresponding to token FOR is less or equal than `i`.
fn FOR(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FOR, i)
}
fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token DO
/// Returns `None` if there is no child corresponding to token DO
fn DO(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DO, 0)
}
fn compoundBody(&self) -> Option<Rc<CompoundBodyContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token END
/// Returns `None` if there is no child corresponding to token END
fn END(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(END, 0)
}
fn beginLabel(&self) -> Option<Rc<BeginLabelContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn strictIdentifier(&self) -> Option<Rc<StrictIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
fn endLabel(&self) -> Option<Rc<EndLabelContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ForStatementContextAttrs<'input> for ForStatementContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn forStatement(&mut self,)
	-> Result<Rc<ForStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ForStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 36, RULE_forStatement);
        let mut _localctx: Rc<ForStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(759);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(30,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule beginLabel*/
					recog.base.set_state(758);
					recog.beginLabel()?;

					}
				}

				_ => {}
			}
			recog.base.set_state(761);
			recog.base.match_token(FOR,&mut recog.err_handler)?;

			recog.base.set_state(765);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(31,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule strictIdentifier*/
					recog.base.set_state(762);
					recog.strictIdentifier()?;

					recog.base.set_state(763);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			/*InvokeRule query*/
			recog.base.set_state(767);
			recog.query()?;

			recog.base.set_state(768);
			recog.base.match_token(DO,&mut recog.err_handler)?;

			/*InvokeRule compoundBody*/
			recog.base.set_state(769);
			recog.compoundBody()?;

			recog.base.set_state(770);
			recog.base.match_token(END,&mut recog.err_handler)?;

			recog.base.set_state(771);
			recog.base.match_token(FOR,&mut recog.err_handler)?;

			recog.base.set_state(773);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(32,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule endLabel*/
					recog.base.set_state(772);
					recog.endLabel()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- singleStatement ----------------
pub type SingleStatementContextAll<'input> = SingleStatementContext<'input>;


pub type SingleStatementContext<'input> = BaseParserRuleContext<'input,SingleStatementContextExt<'input>>;

#[derive(Clone)]
pub struct SingleStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SingleStatementContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SingleStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_singleStatement(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_singleStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SingleStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_singleStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for SingleStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_singleStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_singleStatement }
}
antlr_rust::tid!{SingleStatementContextExt<'a>}

impl<'input> SingleStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SingleStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SingleStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SingleStatementContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SingleStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}
fn statement(&self) -> Option<Rc<StatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn setResetStatement(&self) -> Option<Rc<SetResetStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves all `TerminalNode`s corresponding to token SEMICOLON in current rule
fn SEMICOLON_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token SEMICOLON, starting from 0.
/// Returns `None` if number of children corresponding to token SEMICOLON is less or equal than `i`.
fn SEMICOLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SEMICOLON, i)
}

}

impl<'input> SingleStatementContextAttrs<'input> for SingleStatementContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn singleStatement(&mut self,)
	-> Result<Rc<SingleStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SingleStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 38, RULE_singleStatement);
        let mut _localctx: Rc<SingleStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(777);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(33,&mut recog.base)? {
				1 =>{
					{
					/*InvokeRule statement*/
					recog.base.set_state(775);
					recog.statement()?;

					}
				}
			,
				2 =>{
					{
					/*InvokeRule setResetStatement*/
					recog.base.set_state(776);
					recog.setResetStatement()?;

					}
				}

				_ => {}
			}
			recog.base.set_state(782);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==SEMICOLON {
				{
				{
				recog.base.set_state(779);
				recog.base.match_token(SEMICOLON,&mut recog.err_handler)?;

				}
				}
				recog.base.set_state(784);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(785);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- beginLabel ----------------
pub type BeginLabelContextAll<'input> = BeginLabelContext<'input>;


pub type BeginLabelContext<'input> = BaseParserRuleContext<'input,BeginLabelContextExt<'input>>;

#[derive(Clone)]
pub struct BeginLabelContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for BeginLabelContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for BeginLabelContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_beginLabel(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_beginLabel(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for BeginLabelContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_beginLabel(self);
	}
}

impl<'input> CustomRuleContext<'input> for BeginLabelContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_beginLabel }
	//fn type_rule_index() -> usize where Self: Sized { RULE_beginLabel }
}
antlr_rust::tid!{BeginLabelContextExt<'a>}

impl<'input> BeginLabelContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<BeginLabelContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,BeginLabelContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait BeginLabelContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<BeginLabelContextExt<'input>>{

fn strictIdentifier(&self) -> Option<Rc<StrictIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token COLON
/// Returns `None` if there is no child corresponding to token COLON
fn COLON(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COLON, 0)
}

}

impl<'input> BeginLabelContextAttrs<'input> for BeginLabelContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn beginLabel(&mut self,)
	-> Result<Rc<BeginLabelContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = BeginLabelContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 40, RULE_beginLabel);
        let mut _localctx: Rc<BeginLabelContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule strictIdentifier*/
			recog.base.set_state(787);
			recog.strictIdentifier()?;

			recog.base.set_state(788);
			recog.base.match_token(COLON,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- endLabel ----------------
pub type EndLabelContextAll<'input> = EndLabelContext<'input>;


pub type EndLabelContext<'input> = BaseParserRuleContext<'input,EndLabelContextExt<'input>>;

#[derive(Clone)]
pub struct EndLabelContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for EndLabelContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for EndLabelContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_endLabel(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_endLabel(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for EndLabelContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_endLabel(self);
	}
}

impl<'input> CustomRuleContext<'input> for EndLabelContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_endLabel }
	//fn type_rule_index() -> usize where Self: Sized { RULE_endLabel }
}
antlr_rust::tid!{EndLabelContextExt<'a>}

impl<'input> EndLabelContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<EndLabelContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,EndLabelContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait EndLabelContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<EndLabelContextExt<'input>>{

fn strictIdentifier(&self) -> Option<Rc<StrictIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> EndLabelContextAttrs<'input> for EndLabelContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn endLabel(&mut self,)
	-> Result<Rc<EndLabelContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = EndLabelContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 42, RULE_endLabel);
        let mut _localctx: Rc<EndLabelContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule strictIdentifier*/
			recog.base.set_state(790);
			recog.strictIdentifier()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- singleExpression ----------------
pub type SingleExpressionContextAll<'input> = SingleExpressionContext<'input>;


pub type SingleExpressionContext<'input> = BaseParserRuleContext<'input,SingleExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct SingleExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SingleExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SingleExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_singleExpression(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_singleExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SingleExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_singleExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for SingleExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_singleExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_singleExpression }
}
antlr_rust::tid!{SingleExpressionContextExt<'a>}

impl<'input> SingleExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SingleExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SingleExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SingleExpressionContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SingleExpressionContextExt<'input>>{

fn namedExpression(&self) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}

}

impl<'input> SingleExpressionContextAttrs<'input> for SingleExpressionContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn singleExpression(&mut self,)
	-> Result<Rc<SingleExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SingleExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 44, RULE_singleExpression);
        let mut _localctx: Rc<SingleExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule namedExpression*/
			recog.base.set_state(792);
			recog.namedExpression()?;

			recog.base.set_state(793);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- singleTableIdentifier ----------------
pub type SingleTableIdentifierContextAll<'input> = SingleTableIdentifierContext<'input>;


pub type SingleTableIdentifierContext<'input> = BaseParserRuleContext<'input,SingleTableIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct SingleTableIdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SingleTableIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SingleTableIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_singleTableIdentifier(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_singleTableIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SingleTableIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_singleTableIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for SingleTableIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_singleTableIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_singleTableIdentifier }
}
antlr_rust::tid!{SingleTableIdentifierContextExt<'a>}

impl<'input> SingleTableIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SingleTableIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SingleTableIdentifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SingleTableIdentifierContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SingleTableIdentifierContextExt<'input>>{

fn tableIdentifier(&self) -> Option<Rc<TableIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}

}

impl<'input> SingleTableIdentifierContextAttrs<'input> for SingleTableIdentifierContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn singleTableIdentifier(&mut self,)
	-> Result<Rc<SingleTableIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SingleTableIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 46, RULE_singleTableIdentifier);
        let mut _localctx: Rc<SingleTableIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule tableIdentifier*/
			recog.base.set_state(795);
			recog.tableIdentifier()?;

			recog.base.set_state(796);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- singleMultipartIdentifier ----------------
pub type SingleMultipartIdentifierContextAll<'input> = SingleMultipartIdentifierContext<'input>;


pub type SingleMultipartIdentifierContext<'input> = BaseParserRuleContext<'input,SingleMultipartIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct SingleMultipartIdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SingleMultipartIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SingleMultipartIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_singleMultipartIdentifier(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_singleMultipartIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SingleMultipartIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_singleMultipartIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for SingleMultipartIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_singleMultipartIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_singleMultipartIdentifier }
}
antlr_rust::tid!{SingleMultipartIdentifierContextExt<'a>}

impl<'input> SingleMultipartIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SingleMultipartIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SingleMultipartIdentifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SingleMultipartIdentifierContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SingleMultipartIdentifierContextExt<'input>>{

fn multipartIdentifier(&self) -> Option<Rc<MultipartIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}

}

impl<'input> SingleMultipartIdentifierContextAttrs<'input> for SingleMultipartIdentifierContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn singleMultipartIdentifier(&mut self,)
	-> Result<Rc<SingleMultipartIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SingleMultipartIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 48, RULE_singleMultipartIdentifier);
        let mut _localctx: Rc<SingleMultipartIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule multipartIdentifier*/
			recog.base.set_state(798);
			recog.multipartIdentifier()?;

			recog.base.set_state(799);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- singleFunctionIdentifier ----------------
pub type SingleFunctionIdentifierContextAll<'input> = SingleFunctionIdentifierContext<'input>;


pub type SingleFunctionIdentifierContext<'input> = BaseParserRuleContext<'input,SingleFunctionIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct SingleFunctionIdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SingleFunctionIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SingleFunctionIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_singleFunctionIdentifier(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_singleFunctionIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SingleFunctionIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_singleFunctionIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for SingleFunctionIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_singleFunctionIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_singleFunctionIdentifier }
}
antlr_rust::tid!{SingleFunctionIdentifierContextExt<'a>}

impl<'input> SingleFunctionIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SingleFunctionIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SingleFunctionIdentifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SingleFunctionIdentifierContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SingleFunctionIdentifierContextExt<'input>>{

fn functionIdentifier(&self) -> Option<Rc<FunctionIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}

}

impl<'input> SingleFunctionIdentifierContextAttrs<'input> for SingleFunctionIdentifierContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn singleFunctionIdentifier(&mut self,)
	-> Result<Rc<SingleFunctionIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SingleFunctionIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 50, RULE_singleFunctionIdentifier);
        let mut _localctx: Rc<SingleFunctionIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule functionIdentifier*/
			recog.base.set_state(801);
			recog.functionIdentifier()?;

			recog.base.set_state(802);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- singleDataType ----------------
pub type SingleDataTypeContextAll<'input> = SingleDataTypeContext<'input>;


pub type SingleDataTypeContext<'input> = BaseParserRuleContext<'input,SingleDataTypeContextExt<'input>>;

#[derive(Clone)]
pub struct SingleDataTypeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SingleDataTypeContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SingleDataTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_singleDataType(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_singleDataType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SingleDataTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_singleDataType(self);
	}
}

impl<'input> CustomRuleContext<'input> for SingleDataTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_singleDataType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_singleDataType }
}
antlr_rust::tid!{SingleDataTypeContextExt<'a>}

impl<'input> SingleDataTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SingleDataTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SingleDataTypeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SingleDataTypeContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SingleDataTypeContextExt<'input>>{

fn dataType(&self) -> Option<Rc<DataTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}

}

impl<'input> SingleDataTypeContextAttrs<'input> for SingleDataTypeContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn singleDataType(&mut self,)
	-> Result<Rc<SingleDataTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SingleDataTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 52, RULE_singleDataType);
        let mut _localctx: Rc<SingleDataTypeContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule dataType*/
			recog.base.set_state(804);
			recog.dataType()?;

			recog.base.set_state(805);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- singleTableSchema ----------------
pub type SingleTableSchemaContextAll<'input> = SingleTableSchemaContext<'input>;


pub type SingleTableSchemaContext<'input> = BaseParserRuleContext<'input,SingleTableSchemaContextExt<'input>>;

#[derive(Clone)]
pub struct SingleTableSchemaContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SingleTableSchemaContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SingleTableSchemaContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_singleTableSchema(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_singleTableSchema(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SingleTableSchemaContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_singleTableSchema(self);
	}
}

impl<'input> CustomRuleContext<'input> for SingleTableSchemaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_singleTableSchema }
	//fn type_rule_index() -> usize where Self: Sized { RULE_singleTableSchema }
}
antlr_rust::tid!{SingleTableSchemaContextExt<'a>}

impl<'input> SingleTableSchemaContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SingleTableSchemaContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SingleTableSchemaContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SingleTableSchemaContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SingleTableSchemaContextExt<'input>>{

fn colTypeList(&self) -> Option<Rc<ColTypeListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}

}

impl<'input> SingleTableSchemaContextAttrs<'input> for SingleTableSchemaContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn singleTableSchema(&mut self,)
	-> Result<Rc<SingleTableSchemaContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SingleTableSchemaContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 54, RULE_singleTableSchema);
        let mut _localctx: Rc<SingleTableSchemaContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule colTypeList*/
			recog.base.set_state(807);
			recog.colTypeList()?;

			recog.base.set_state(808);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- singleRoutineParamList ----------------
pub type SingleRoutineParamListContextAll<'input> = SingleRoutineParamListContext<'input>;


pub type SingleRoutineParamListContext<'input> = BaseParserRuleContext<'input,SingleRoutineParamListContextExt<'input>>;

#[derive(Clone)]
pub struct SingleRoutineParamListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SingleRoutineParamListContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SingleRoutineParamListContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_singleRoutineParamList(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_singleRoutineParamList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SingleRoutineParamListContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_singleRoutineParamList(self);
	}
}

impl<'input> CustomRuleContext<'input> for SingleRoutineParamListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_singleRoutineParamList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_singleRoutineParamList }
}
antlr_rust::tid!{SingleRoutineParamListContextExt<'a>}

impl<'input> SingleRoutineParamListContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SingleRoutineParamListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SingleRoutineParamListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SingleRoutineParamListContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SingleRoutineParamListContextExt<'input>>{

fn colDefinitionList(&self) -> Option<Rc<ColDefinitionListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}

}

impl<'input> SingleRoutineParamListContextAttrs<'input> for SingleRoutineParamListContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn singleRoutineParamList(&mut self,)
	-> Result<Rc<SingleRoutineParamListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SingleRoutineParamListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 56, RULE_singleRoutineParamList);
        let mut _localctx: Rc<SingleRoutineParamListContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule colDefinitionList*/
			recog.base.set_state(810);
			recog.colDefinitionList()?;

			recog.base.set_state(811);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- statement ----------------
#[derive(Debug)]
pub enum StatementContextAll<'input>{
	ExplainContext(ExplainContext<'input>),
	SetNamespaceCollationContext(SetNamespaceCollationContext<'input>),
	AlterViewQueryContext(AlterViewQueryContext<'input>),
	CreatePipelineInsertIntoFlowContext(CreatePipelineInsertIntoFlowContext<'input>),
	UseContext(UseContext<'input>),
	DropNamespaceContext(DropNamespaceContext<'input>),
	CreateTempViewUsingContext(CreateTempViewUsingContext<'input>),
	ShowProceduresContext(ShowProceduresContext<'input>),
	RenameTableContext(RenameTableContext<'input>),
	FailNativeCommandContext(FailNativeCommandContext<'input>),
	SetCatalogContext(SetCatalogContext<'input>),
	ClearCacheContext(ClearCacheContext<'input>),
	DropViewContext(DropViewContext<'input>),
	ShowTablesContext(ShowTablesContext<'input>),
	RecoverPartitionsContext(RecoverPartitionsContext<'input>),
	DropTableConstraintContext(DropTableConstraintContext<'input>),
	DropIndexContext(DropIndexContext<'input>),
	ShowCatalogsContext(ShowCatalogsContext<'input>),
	ShowCurrentNamespaceContext(ShowCurrentNamespaceContext<'input>),
	RenameTablePartitionContext(RenameTablePartitionContext<'input>),
	RepairTableContext(RepairTableContext<'input>),
	AddTableConstraintContext(AddTableConstraintContext<'input>),
	RefreshResourceContext(RefreshResourceContext<'input>),
	AlterViewSchemaBindingContext(AlterViewSchemaBindingContext<'input>),
	CreateVariableContext(CreateVariableContext<'input>),
	CreatePipelineDatasetContext(CreatePipelineDatasetContext<'input>),
	ShowCreateTableContext(ShowCreateTableContext<'input>),
	ShowNamespacesContext(ShowNamespacesContext<'input>),
	ShowColumnsContext(ShowColumnsContext<'input>),
	ReplaceTableContext(ReplaceTableContext<'input>),
	AnalyzeTablesContext(AnalyzeTablesContext<'input>),
	UnsetNamespacePropertiesContext(UnsetNamespacePropertiesContext<'input>),
	AddTablePartitionContext(AddTablePartitionContext<'input>),
	SetNamespaceLocationContext(SetNamespaceLocationContext<'input>),
	RefreshTableContext(RefreshTableContext<'input>),
	AlterTableCollationContext(AlterTableCollationContext<'input>),
	SetNamespacePropertiesContext(SetNamespacePropertiesContext<'input>),
	ManageResourceContext(ManageResourceContext<'input>),
	AnalyzeContext(AnalyzeContext<'input>),
	CreateFunctionContext(CreateFunctionContext<'input>),
	HiveReplaceColumnsContext(HiveReplaceColumnsContext<'input>),
	CommentNamespaceContext(CommentNamespaceContext<'input>),
	CreateTableContext(CreateTableContext<'input>),
	DmlStatementContext(DmlStatementContext<'input>),
	CreateTableLikeContext(CreateTableLikeContext<'input>),
	UncacheTableContext(UncacheTableContext<'input>),
	DropFunctionContext(DropFunctionContext<'input>),
	DescribeRelationContext(DescribeRelationContext<'input>),
	LoadDataContext(LoadDataContext<'input>),
	ShowPartitionsContext(ShowPartitionsContext<'input>),
	DescribeFunctionContext(DescribeFunctionContext<'input>),
	RenameTableColumnContext(RenameTableColumnContext<'input>),
	CreateUserDefinedFunctionContext(CreateUserDefinedFunctionContext<'input>),
	StatementDefaultContext(StatementDefaultContext<'input>),
	AlterClusterByContext(AlterClusterByContext<'input>),
	HiveChangeColumnContext(HiveChangeColumnContext<'input>),
	DescribeQueryContext(DescribeQueryContext<'input>),
	TruncateTableContext(TruncateTableContext<'input>),
	SetTableSerDeContext(SetTableSerDeContext<'input>),
	CreateViewContext(CreateViewContext<'input>),
	DropTablePartitionsContext(DropTablePartitionsContext<'input>),
	DropTableContext(DropTableContext<'input>),
	ShowTableExtendedContext(ShowTableExtendedContext<'input>),
	DescribeNamespaceContext(DescribeNamespaceContext<'input>),
	AlterTableAlterColumnContext(AlterTableAlterColumnContext<'input>),
	RefreshFunctionContext(RefreshFunctionContext<'input>),
	CommentTableContext(CommentTableContext<'input>),
	DescribeProcedureContext(DescribeProcedureContext<'input>),
	CreateIndexContext(CreateIndexContext<'input>),
	UseNamespaceContext(UseNamespaceContext<'input>),
	DropVariableContext(DropVariableContext<'input>),
	CreateNamespaceContext(CreateNamespaceContext<'input>),
	CallContext(CallContext<'input>),
	ShowTblPropertiesContext(ShowTblPropertiesContext<'input>),
	VisitExecuteImmediateContext(VisitExecuteImmediateContext<'input>),
	UnsetTablePropertiesContext(UnsetTablePropertiesContext<'input>),
	SetTableLocationContext(SetTableLocationContext<'input>),
	DropTableColumnsContext(DropTableColumnsContext<'input>),
	ShowViewsContext(ShowViewsContext<'input>),
	CreateMetricViewContext(CreateMetricViewContext<'input>),
	ShowFunctionsContext(ShowFunctionsContext<'input>),
	CacheTableContext(CacheTableContext<'input>),
	AddTableColumnsContext(AddTableColumnsContext<'input>),
	SetTablePropertiesContext(SetTablePropertiesContext<'input>),
Error(StatementContext<'input>)
}
antlr_rust::tid!{StatementContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for StatementContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for StatementContextAll<'input>{}

impl<'input> Deref for StatementContextAll<'input>{
	type Target = dyn StatementContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use StatementContextAll::*;
		match self{
			ExplainContext(inner) => inner,
			SetNamespaceCollationContext(inner) => inner,
			AlterViewQueryContext(inner) => inner,
			CreatePipelineInsertIntoFlowContext(inner) => inner,
			UseContext(inner) => inner,
			DropNamespaceContext(inner) => inner,
			CreateTempViewUsingContext(inner) => inner,
			ShowProceduresContext(inner) => inner,
			RenameTableContext(inner) => inner,
			FailNativeCommandContext(inner) => inner,
			SetCatalogContext(inner) => inner,
			ClearCacheContext(inner) => inner,
			DropViewContext(inner) => inner,
			ShowTablesContext(inner) => inner,
			RecoverPartitionsContext(inner) => inner,
			DropTableConstraintContext(inner) => inner,
			DropIndexContext(inner) => inner,
			ShowCatalogsContext(inner) => inner,
			ShowCurrentNamespaceContext(inner) => inner,
			RenameTablePartitionContext(inner) => inner,
			RepairTableContext(inner) => inner,
			AddTableConstraintContext(inner) => inner,
			RefreshResourceContext(inner) => inner,
			AlterViewSchemaBindingContext(inner) => inner,
			CreateVariableContext(inner) => inner,
			CreatePipelineDatasetContext(inner) => inner,
			ShowCreateTableContext(inner) => inner,
			ShowNamespacesContext(inner) => inner,
			ShowColumnsContext(inner) => inner,
			ReplaceTableContext(inner) => inner,
			AnalyzeTablesContext(inner) => inner,
			UnsetNamespacePropertiesContext(inner) => inner,
			AddTablePartitionContext(inner) => inner,
			SetNamespaceLocationContext(inner) => inner,
			RefreshTableContext(inner) => inner,
			AlterTableCollationContext(inner) => inner,
			SetNamespacePropertiesContext(inner) => inner,
			ManageResourceContext(inner) => inner,
			AnalyzeContext(inner) => inner,
			CreateFunctionContext(inner) => inner,
			HiveReplaceColumnsContext(inner) => inner,
			CommentNamespaceContext(inner) => inner,
			CreateTableContext(inner) => inner,
			DmlStatementContext(inner) => inner,
			CreateTableLikeContext(inner) => inner,
			UncacheTableContext(inner) => inner,
			DropFunctionContext(inner) => inner,
			DescribeRelationContext(inner) => inner,
			LoadDataContext(inner) => inner,
			ShowPartitionsContext(inner) => inner,
			DescribeFunctionContext(inner) => inner,
			RenameTableColumnContext(inner) => inner,
			CreateUserDefinedFunctionContext(inner) => inner,
			StatementDefaultContext(inner) => inner,
			AlterClusterByContext(inner) => inner,
			HiveChangeColumnContext(inner) => inner,
			DescribeQueryContext(inner) => inner,
			TruncateTableContext(inner) => inner,
			SetTableSerDeContext(inner) => inner,
			CreateViewContext(inner) => inner,
			DropTablePartitionsContext(inner) => inner,
			DropTableContext(inner) => inner,
			ShowTableExtendedContext(inner) => inner,
			DescribeNamespaceContext(inner) => inner,
			AlterTableAlterColumnContext(inner) => inner,
			RefreshFunctionContext(inner) => inner,
			CommentTableContext(inner) => inner,
			DescribeProcedureContext(inner) => inner,
			CreateIndexContext(inner) => inner,
			UseNamespaceContext(inner) => inner,
			DropVariableContext(inner) => inner,
			CreateNamespaceContext(inner) => inner,
			CallContext(inner) => inner,
			ShowTblPropertiesContext(inner) => inner,
			VisitExecuteImmediateContext(inner) => inner,
			UnsetTablePropertiesContext(inner) => inner,
			SetTableLocationContext(inner) => inner,
			DropTableColumnsContext(inner) => inner,
			ShowViewsContext(inner) => inner,
			CreateMetricViewContext(inner) => inner,
			ShowFunctionsContext(inner) => inner,
			CacheTableContext(inner) => inner,
			AddTableColumnsContext(inner) => inner,
			SetTablePropertiesContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for StatementContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for StatementContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type StatementContext<'input> = BaseParserRuleContext<'input,StatementContextExt<'input>>;

#[derive(Clone)]
pub struct StatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for StatementContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for StatementContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for StatementContext<'input>{
}

impl<'input> CustomRuleContext<'input> for StatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}
antlr_rust::tid!{StatementContextExt<'a>}

impl<'input> StatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StatementContextAll<'input>> {
		Rc::new(
		StatementContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StatementContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait StatementContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<StatementContextExt<'input>>{


}

impl<'input> StatementContextAttrs<'input> for StatementContext<'input>{}

pub type ExplainContext<'input> = BaseParserRuleContext<'input,ExplainContextExt<'input>>;

pub trait ExplainContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token EXPLAIN
	/// Returns `None` if there is no child corresponding to token EXPLAIN
	fn EXPLAIN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXPLAIN, 0)
	}
	fn statement(&self) -> Option<Rc<StatementContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn setResetStatement(&self) -> Option<Rc<SetResetStatementContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LOGICAL
	/// Returns `None` if there is no child corresponding to token LOGICAL
	fn LOGICAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LOGICAL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FORMATTED
	/// Returns `None` if there is no child corresponding to token FORMATTED
	fn FORMATTED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FORMATTED, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXTENDED
	/// Returns `None` if there is no child corresponding to token EXTENDED
	fn EXTENDED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXTENDED, 0)
	}
	/// Retrieves first TerminalNode corresponding to token CODEGEN
	/// Returns `None` if there is no child corresponding to token CODEGEN
	fn CODEGEN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CODEGEN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COST
	/// Returns `None` if there is no child corresponding to token COST
	fn COST(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COST, 0)
	}
}

impl<'input> ExplainContextAttrs<'input> for ExplainContext<'input>{}

pub struct ExplainContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ExplainContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ExplainContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ExplainContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_explain(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_explain(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ExplainContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_explain(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExplainContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ExplainContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ExplainContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ExplainContext<'input> {}

impl<'input> ExplainContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ExplainContext(
				BaseParserRuleContext::copy_from(ctx,ExplainContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetNamespaceCollationContext<'input> = BaseParserRuleContext<'input,SetNamespaceCollationContextExt<'input>>;

pub trait SetNamespaceCollationContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	fn namespace(&self) -> Option<Rc<NamespaceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn collationSpec(&self) -> Option<Rc<CollationSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SetNamespaceCollationContextAttrs<'input> for SetNamespaceCollationContext<'input>{}

pub struct SetNamespaceCollationContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetNamespaceCollationContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SetNamespaceCollationContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SetNamespaceCollationContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setNamespaceCollation(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_setNamespaceCollation(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SetNamespaceCollationContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_setNamespaceCollation(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetNamespaceCollationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for SetNamespaceCollationContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for SetNamespaceCollationContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for SetNamespaceCollationContext<'input> {}

impl<'input> SetNamespaceCollationContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::SetNamespaceCollationContext(
				BaseParserRuleContext::copy_from(ctx,SetNamespaceCollationContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AlterViewQueryContext<'input> = BaseParserRuleContext<'input,AlterViewQueryContextExt<'input>>;

pub trait AlterViewQueryContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
}

impl<'input> AlterViewQueryContextAttrs<'input> for AlterViewQueryContext<'input>{}

pub struct AlterViewQueryContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AlterViewQueryContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for AlterViewQueryContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for AlterViewQueryContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_alterViewQuery(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_alterViewQuery(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for AlterViewQueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_alterViewQuery(self);
	}
}

impl<'input> CustomRuleContext<'input> for AlterViewQueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for AlterViewQueryContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for AlterViewQueryContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for AlterViewQueryContext<'input> {}

impl<'input> AlterViewQueryContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::AlterViewQueryContext(
				BaseParserRuleContext::copy_from(ctx,AlterViewQueryContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreatePipelineInsertIntoFlowContext<'input> = BaseParserRuleContext<'input,CreatePipelineInsertIntoFlowContextExt<'input>>;

pub trait CreatePipelineInsertIntoFlowContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn createPipelineFlowHeader(&self) -> Option<Rc<CreatePipelineFlowHeaderContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn insertInto(&self) -> Option<Rc<InsertIntoContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> CreatePipelineInsertIntoFlowContextAttrs<'input> for CreatePipelineInsertIntoFlowContext<'input>{}

pub struct CreatePipelineInsertIntoFlowContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreatePipelineInsertIntoFlowContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for CreatePipelineInsertIntoFlowContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CreatePipelineInsertIntoFlowContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createPipelineInsertIntoFlow(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_createPipelineInsertIntoFlow(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CreatePipelineInsertIntoFlowContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_createPipelineInsertIntoFlow(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreatePipelineInsertIntoFlowContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreatePipelineInsertIntoFlowContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreatePipelineInsertIntoFlowContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreatePipelineInsertIntoFlowContext<'input> {}

impl<'input> CreatePipelineInsertIntoFlowContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreatePipelineInsertIntoFlowContext(
				BaseParserRuleContext::copy_from(ctx,CreatePipelineInsertIntoFlowContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type UseContext<'input> = BaseParserRuleContext<'input,UseContextExt<'input>>;

pub trait UseContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token USE
	/// Returns `None` if there is no child corresponding to token USE
	fn USE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(USE, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> UseContextAttrs<'input> for UseContext<'input>{}

pub struct UseContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UseContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for UseContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for UseContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_use(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_use(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for UseContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_use(self);
	}
}

impl<'input> CustomRuleContext<'input> for UseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for UseContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for UseContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for UseContext<'input> {}

impl<'input> UseContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::UseContext(
				BaseParserRuleContext::copy_from(ctx,UseContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DropNamespaceContext<'input> = BaseParserRuleContext<'input,DropNamespaceContextExt<'input>>;

pub trait DropNamespaceContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DROP
	/// Returns `None` if there is no child corresponding to token DROP
	fn DROP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DROP, 0)
	}
	fn namespace(&self) -> Option<Rc<NamespaceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RESTRICT
	/// Returns `None` if there is no child corresponding to token RESTRICT
	fn RESTRICT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RESTRICT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token CASCADE
	/// Returns `None` if there is no child corresponding to token CASCADE
	fn CASCADE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CASCADE, 0)
	}
}

impl<'input> DropNamespaceContextAttrs<'input> for DropNamespaceContext<'input>{}

pub struct DropNamespaceContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DropNamespaceContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for DropNamespaceContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DropNamespaceContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dropNamespace(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_dropNamespace(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DropNamespaceContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_dropNamespace(self);
	}
}

impl<'input> CustomRuleContext<'input> for DropNamespaceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DropNamespaceContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DropNamespaceContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DropNamespaceContext<'input> {}

impl<'input> DropNamespaceContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DropNamespaceContext(
				BaseParserRuleContext::copy_from(ctx,DropNamespaceContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateTempViewUsingContext<'input> = BaseParserRuleContext<'input,CreateTempViewUsingContextExt<'input>>;

pub trait CreateTempViewUsingContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TEMPORARY
	/// Returns `None` if there is no child corresponding to token TEMPORARY
	fn TEMPORARY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TEMPORARY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	fn tableIdentifier(&self) -> Option<Rc<TableIdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn tableProvider(&self) -> Option<Rc<TableProviderContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token GLOBAL
	/// Returns `None` if there is no child corresponding to token GLOBAL
	fn GLOBAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(GLOBAL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	fn colTypeList(&self) -> Option<Rc<ColTypeListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OPTIONS
	/// Returns `None` if there is no child corresponding to token OPTIONS
	fn OPTIONS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(OPTIONS, 0)
	}
	fn propertyList(&self) -> Option<Rc<PropertyListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> CreateTempViewUsingContextAttrs<'input> for CreateTempViewUsingContext<'input>{}

pub struct CreateTempViewUsingContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateTempViewUsingContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for CreateTempViewUsingContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CreateTempViewUsingContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createTempViewUsing(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_createTempViewUsing(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CreateTempViewUsingContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_createTempViewUsing(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateTempViewUsingContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateTempViewUsingContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateTempViewUsingContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateTempViewUsingContext<'input> {}

impl<'input> CreateTempViewUsingContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateTempViewUsingContext(
				BaseParserRuleContext::copy_from(ctx,CreateTempViewUsingContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ShowProceduresContext<'input> = BaseParserRuleContext<'input,ShowProceduresContextExt<'input>>;

pub trait ShowProceduresContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SHOW
	/// Returns `None` if there is no child corresponding to token SHOW
	fn SHOW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SHOW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PROCEDURES
	/// Returns `None` if there is no child corresponding to token PROCEDURES
	fn PROCEDURES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(PROCEDURES, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IN
	/// Returns `None` if there is no child corresponding to token IN
	fn IN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IN, 0)
	}
}

impl<'input> ShowProceduresContextAttrs<'input> for ShowProceduresContext<'input>{}

pub struct ShowProceduresContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ShowProceduresContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ShowProceduresContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ShowProceduresContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_showProcedures(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_showProcedures(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ShowProceduresContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_showProcedures(self);
	}
}

impl<'input> CustomRuleContext<'input> for ShowProceduresContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ShowProceduresContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ShowProceduresContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ShowProceduresContext<'input> {}

impl<'input> ShowProceduresContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ShowProceduresContext(
				BaseParserRuleContext::copy_from(ctx,ShowProceduresContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RenameTableContext<'input> = BaseParserRuleContext<'input,RenameTableContextExt<'input>>;

pub trait RenameTableContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RENAME
	/// Returns `None` if there is no child corresponding to token RENAME
	fn RENAME(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RENAME, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TO
	/// Returns `None` if there is no child corresponding to token TO
	fn TO(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TO, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn multipartIdentifier(&self) -> Option<Rc<MultipartIdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> RenameTableContextAttrs<'input> for RenameTableContext<'input>{}

pub struct RenameTableContextExt<'input>{
	base:StatementContextExt<'input>,
	pub from: Option<Rc<IdentifierReferenceContextAll<'input>>>,
	pub to: Option<Rc<MultipartIdentifierContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RenameTableContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for RenameTableContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for RenameTableContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_renameTable(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_renameTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for RenameTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_renameTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for RenameTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RenameTableContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RenameTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RenameTableContext<'input> {}

impl<'input> RenameTableContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RenameTableContext(
				BaseParserRuleContext::copy_from(ctx,RenameTableContextExt{
        			from:None, to:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type FailNativeCommandContext<'input> = BaseParserRuleContext<'input,FailNativeCommandContextExt<'input>>;

pub trait FailNativeCommandContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn unsupportedHiveNativeCommands(&self) -> Option<Rc<UnsupportedHiveNativeCommandsContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> FailNativeCommandContextAttrs<'input> for FailNativeCommandContext<'input>{}

pub struct FailNativeCommandContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FailNativeCommandContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for FailNativeCommandContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for FailNativeCommandContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_failNativeCommand(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_failNativeCommand(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for FailNativeCommandContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_failNativeCommand(self);
	}
}

impl<'input> CustomRuleContext<'input> for FailNativeCommandContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for FailNativeCommandContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for FailNativeCommandContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for FailNativeCommandContext<'input> {}

impl<'input> FailNativeCommandContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::FailNativeCommandContext(
				BaseParserRuleContext::copy_from(ctx,FailNativeCommandContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetCatalogContext<'input> = BaseParserRuleContext<'input,SetCatalogContextExt<'input>>;

pub trait SetCatalogContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token CATALOG
	/// Returns `None` if there is no child corresponding to token CATALOG
	fn CATALOG(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CATALOG, 0)
	}
	fn catalogIdentifierReference(&self) -> Option<Rc<CatalogIdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SetCatalogContextAttrs<'input> for SetCatalogContext<'input>{}

pub struct SetCatalogContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetCatalogContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SetCatalogContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SetCatalogContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setCatalog(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_setCatalog(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SetCatalogContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_setCatalog(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetCatalogContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for SetCatalogContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for SetCatalogContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for SetCatalogContext<'input> {}

impl<'input> SetCatalogContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::SetCatalogContext(
				BaseParserRuleContext::copy_from(ctx,SetCatalogContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ClearCacheContext<'input> = BaseParserRuleContext<'input,ClearCacheContextExt<'input>>;

pub trait ClearCacheContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CLEAR
	/// Returns `None` if there is no child corresponding to token CLEAR
	fn CLEAR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CLEAR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token CACHE
	/// Returns `None` if there is no child corresponding to token CACHE
	fn CACHE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CACHE, 0)
	}
}

impl<'input> ClearCacheContextAttrs<'input> for ClearCacheContext<'input>{}

pub struct ClearCacheContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ClearCacheContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ClearCacheContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ClearCacheContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_clearCache(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_clearCache(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ClearCacheContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_clearCache(self);
	}
}

impl<'input> CustomRuleContext<'input> for ClearCacheContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ClearCacheContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ClearCacheContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ClearCacheContext<'input> {}

impl<'input> ClearCacheContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ClearCacheContext(
				BaseParserRuleContext::copy_from(ctx,ClearCacheContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DropViewContext<'input> = BaseParserRuleContext<'input,DropViewContextExt<'input>>;

pub trait DropViewContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DROP
	/// Returns `None` if there is no child corresponding to token DROP
	fn DROP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DROP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
}

impl<'input> DropViewContextAttrs<'input> for DropViewContext<'input>{}

pub struct DropViewContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DropViewContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for DropViewContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DropViewContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dropView(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_dropView(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DropViewContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_dropView(self);
	}
}

impl<'input> CustomRuleContext<'input> for DropViewContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DropViewContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DropViewContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DropViewContext<'input> {}

impl<'input> DropViewContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DropViewContext(
				BaseParserRuleContext::copy_from(ctx,DropViewContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ShowTablesContext<'input> = BaseParserRuleContext<'input,ShowTablesContextExt<'input>>;

pub trait ShowTablesContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SHOW
	/// Returns `None` if there is no child corresponding to token SHOW
	fn SHOW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SHOW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLES
	/// Returns `None` if there is no child corresponding to token TABLES
	fn TABLES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLES, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IN
	/// Returns `None` if there is no child corresponding to token IN
	fn IN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IN, 0)
	}
	fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LIKE
	/// Returns `None` if there is no child corresponding to token LIKE
	fn LIKE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LIKE, 0)
	}
}

impl<'input> ShowTablesContextAttrs<'input> for ShowTablesContext<'input>{}

pub struct ShowTablesContextExt<'input>{
	base:StatementContextExt<'input>,
	pub pattern: Option<Rc<StringLitContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ShowTablesContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ShowTablesContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ShowTablesContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_showTables(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_showTables(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ShowTablesContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_showTables(self);
	}
}

impl<'input> CustomRuleContext<'input> for ShowTablesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ShowTablesContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ShowTablesContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ShowTablesContext<'input> {}

impl<'input> ShowTablesContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ShowTablesContext(
				BaseParserRuleContext::copy_from(ctx,ShowTablesContextExt{
        			pattern:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RecoverPartitionsContext<'input> = BaseParserRuleContext<'input,RecoverPartitionsContextExt<'input>>;

pub trait RecoverPartitionsContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RECOVER
	/// Returns `None` if there is no child corresponding to token RECOVER
	fn RECOVER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RECOVER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PARTITIONS
	/// Returns `None` if there is no child corresponding to token PARTITIONS
	fn PARTITIONS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(PARTITIONS, 0)
	}
}

impl<'input> RecoverPartitionsContextAttrs<'input> for RecoverPartitionsContext<'input>{}

pub struct RecoverPartitionsContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RecoverPartitionsContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for RecoverPartitionsContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for RecoverPartitionsContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_recoverPartitions(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_recoverPartitions(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for RecoverPartitionsContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_recoverPartitions(self);
	}
}

impl<'input> CustomRuleContext<'input> for RecoverPartitionsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RecoverPartitionsContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RecoverPartitionsContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RecoverPartitionsContext<'input> {}

impl<'input> RecoverPartitionsContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RecoverPartitionsContext(
				BaseParserRuleContext::copy_from(ctx,RecoverPartitionsContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DropTableConstraintContext<'input> = BaseParserRuleContext<'input,DropTableConstraintContextExt<'input>>;

pub trait DropTableConstraintContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token DROP
	/// Returns `None` if there is no child corresponding to token DROP
	fn DROP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DROP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token CONSTRAINT
	/// Returns `None` if there is no child corresponding to token CONSTRAINT
	fn CONSTRAINT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CONSTRAINT, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RESTRICT
	/// Returns `None` if there is no child corresponding to token RESTRICT
	fn RESTRICT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RESTRICT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token CASCADE
	/// Returns `None` if there is no child corresponding to token CASCADE
	fn CASCADE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CASCADE, 0)
	}
}

impl<'input> DropTableConstraintContextAttrs<'input> for DropTableConstraintContext<'input>{}

pub struct DropTableConstraintContextExt<'input>{
	base:StatementContextExt<'input>,
	pub name: Option<Rc<IdentifierContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DropTableConstraintContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for DropTableConstraintContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DropTableConstraintContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dropTableConstraint(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_dropTableConstraint(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DropTableConstraintContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_dropTableConstraint(self);
	}
}

impl<'input> CustomRuleContext<'input> for DropTableConstraintContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DropTableConstraintContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DropTableConstraintContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DropTableConstraintContext<'input> {}

impl<'input> DropTableConstraintContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DropTableConstraintContext(
				BaseParserRuleContext::copy_from(ctx,DropTableConstraintContextExt{
        			name:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DropIndexContext<'input> = BaseParserRuleContext<'input,DropIndexContextExt<'input>>;

pub trait DropIndexContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DROP
	/// Returns `None` if there is no child corresponding to token DROP
	fn DROP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DROP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token INDEX
	/// Returns `None` if there is no child corresponding to token INDEX
	fn INDEX(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(INDEX, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token ON
	/// Returns `None` if there is no child corresponding to token ON
	fn ON(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ON, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
}

impl<'input> DropIndexContextAttrs<'input> for DropIndexContext<'input>{}

pub struct DropIndexContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DropIndexContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for DropIndexContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DropIndexContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dropIndex(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_dropIndex(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DropIndexContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_dropIndex(self);
	}
}

impl<'input> CustomRuleContext<'input> for DropIndexContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DropIndexContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DropIndexContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DropIndexContext<'input> {}

impl<'input> DropIndexContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DropIndexContext(
				BaseParserRuleContext::copy_from(ctx,DropIndexContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ShowCatalogsContext<'input> = BaseParserRuleContext<'input,ShowCatalogsContextExt<'input>>;

pub trait ShowCatalogsContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SHOW
	/// Returns `None` if there is no child corresponding to token SHOW
	fn SHOW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SHOW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token CATALOGS
	/// Returns `None` if there is no child corresponding to token CATALOGS
	fn CATALOGS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CATALOGS, 0)
	}
	fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LIKE
	/// Returns `None` if there is no child corresponding to token LIKE
	fn LIKE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LIKE, 0)
	}
}

impl<'input> ShowCatalogsContextAttrs<'input> for ShowCatalogsContext<'input>{}

pub struct ShowCatalogsContextExt<'input>{
	base:StatementContextExt<'input>,
	pub pattern: Option<Rc<StringLitContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ShowCatalogsContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ShowCatalogsContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ShowCatalogsContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_showCatalogs(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_showCatalogs(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ShowCatalogsContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_showCatalogs(self);
	}
}

impl<'input> CustomRuleContext<'input> for ShowCatalogsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ShowCatalogsContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ShowCatalogsContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ShowCatalogsContext<'input> {}

impl<'input> ShowCatalogsContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ShowCatalogsContext(
				BaseParserRuleContext::copy_from(ctx,ShowCatalogsContextExt{
        			pattern:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ShowCurrentNamespaceContext<'input> = BaseParserRuleContext<'input,ShowCurrentNamespaceContextExt<'input>>;

pub trait ShowCurrentNamespaceContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SHOW
	/// Returns `None` if there is no child corresponding to token SHOW
	fn SHOW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SHOW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token CURRENT
	/// Returns `None` if there is no child corresponding to token CURRENT
	fn CURRENT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CURRENT, 0)
	}
	fn namespace(&self) -> Option<Rc<NamespaceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ShowCurrentNamespaceContextAttrs<'input> for ShowCurrentNamespaceContext<'input>{}

pub struct ShowCurrentNamespaceContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ShowCurrentNamespaceContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ShowCurrentNamespaceContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ShowCurrentNamespaceContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_showCurrentNamespace(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_showCurrentNamespace(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ShowCurrentNamespaceContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_showCurrentNamespace(self);
	}
}

impl<'input> CustomRuleContext<'input> for ShowCurrentNamespaceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ShowCurrentNamespaceContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ShowCurrentNamespaceContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ShowCurrentNamespaceContext<'input> {}

impl<'input> ShowCurrentNamespaceContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ShowCurrentNamespaceContext(
				BaseParserRuleContext::copy_from(ctx,ShowCurrentNamespaceContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RenameTablePartitionContext<'input> = BaseParserRuleContext<'input,RenameTablePartitionContextExt<'input>>;

pub trait RenameTablePartitionContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RENAME
	/// Returns `None` if there is no child corresponding to token RENAME
	fn RENAME(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RENAME, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TO
	/// Returns `None` if there is no child corresponding to token TO
	fn TO(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TO, 0)
	}
	fn partitionSpec_all(&self) ->  Vec<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn partitionSpec(&self, i: usize) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> RenameTablePartitionContextAttrs<'input> for RenameTablePartitionContext<'input>{}

pub struct RenameTablePartitionContextExt<'input>{
	base:StatementContextExt<'input>,
	pub from: Option<Rc<PartitionSpecContextAll<'input>>>,
	pub to: Option<Rc<PartitionSpecContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RenameTablePartitionContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for RenameTablePartitionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for RenameTablePartitionContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_renameTablePartition(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_renameTablePartition(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for RenameTablePartitionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_renameTablePartition(self);
	}
}

impl<'input> CustomRuleContext<'input> for RenameTablePartitionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RenameTablePartitionContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RenameTablePartitionContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RenameTablePartitionContext<'input> {}

impl<'input> RenameTablePartitionContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RenameTablePartitionContext(
				BaseParserRuleContext::copy_from(ctx,RenameTablePartitionContextExt{
        			from:None, to:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RepairTableContext<'input> = BaseParserRuleContext<'input,RepairTableContextExt<'input>>;

pub trait RepairTableContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token REPAIR
	/// Returns `None` if there is no child corresponding to token REPAIR
	fn REPAIR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(REPAIR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token MSCK
	/// Returns `None` if there is no child corresponding to token MSCK
	fn MSCK(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(MSCK, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PARTITIONS
	/// Returns `None` if there is no child corresponding to token PARTITIONS
	fn PARTITIONS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(PARTITIONS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ADD
	/// Returns `None` if there is no child corresponding to token ADD
	fn ADD(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ADD, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DROP
	/// Returns `None` if there is no child corresponding to token DROP
	fn DROP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DROP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SYNC
	/// Returns `None` if there is no child corresponding to token SYNC
	fn SYNC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SYNC, 0)
	}
}

impl<'input> RepairTableContextAttrs<'input> for RepairTableContext<'input>{}

pub struct RepairTableContextExt<'input>{
	base:StatementContextExt<'input>,
	pub option: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RepairTableContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for RepairTableContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for RepairTableContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_repairTable(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_repairTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for RepairTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_repairTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for RepairTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RepairTableContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RepairTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RepairTableContext<'input> {}

impl<'input> RepairTableContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RepairTableContext(
				BaseParserRuleContext::copy_from(ctx,RepairTableContextExt{
					option:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AddTableConstraintContext<'input> = BaseParserRuleContext<'input,AddTableConstraintContextExt<'input>>;

pub trait AddTableConstraintContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token ADD
	/// Returns `None` if there is no child corresponding to token ADD
	fn ADD(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ADD, 0)
	}
	fn tableConstraintDefinition(&self) -> Option<Rc<TableConstraintDefinitionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> AddTableConstraintContextAttrs<'input> for AddTableConstraintContext<'input>{}

pub struct AddTableConstraintContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AddTableConstraintContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for AddTableConstraintContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for AddTableConstraintContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_addTableConstraint(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_addTableConstraint(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for AddTableConstraintContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_addTableConstraint(self);
	}
}

impl<'input> CustomRuleContext<'input> for AddTableConstraintContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for AddTableConstraintContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for AddTableConstraintContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for AddTableConstraintContext<'input> {}

impl<'input> AddTableConstraintContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::AddTableConstraintContext(
				BaseParserRuleContext::copy_from(ctx,AddTableConstraintContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RefreshResourceContext<'input> = BaseParserRuleContext<'input,RefreshResourceContextExt<'input>>;

pub trait RefreshResourceContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token REFRESH
	/// Returns `None` if there is no child corresponding to token REFRESH
	fn REFRESH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(REFRESH, 0)
	}
	fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> RefreshResourceContextAttrs<'input> for RefreshResourceContext<'input>{}

pub struct RefreshResourceContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RefreshResourceContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for RefreshResourceContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for RefreshResourceContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_refreshResource(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_refreshResource(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for RefreshResourceContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_refreshResource(self);
	}
}

impl<'input> CustomRuleContext<'input> for RefreshResourceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RefreshResourceContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RefreshResourceContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RefreshResourceContext<'input> {}

impl<'input> RefreshResourceContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RefreshResourceContext(
				BaseParserRuleContext::copy_from(ctx,RefreshResourceContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AlterViewSchemaBindingContext<'input> = BaseParserRuleContext<'input,AlterViewSchemaBindingContextExt<'input>>;

pub trait AlterViewSchemaBindingContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn schemaBinding(&self) -> Option<Rc<SchemaBindingContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> AlterViewSchemaBindingContextAttrs<'input> for AlterViewSchemaBindingContext<'input>{}

pub struct AlterViewSchemaBindingContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AlterViewSchemaBindingContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for AlterViewSchemaBindingContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for AlterViewSchemaBindingContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_alterViewSchemaBinding(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_alterViewSchemaBinding(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for AlterViewSchemaBindingContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_alterViewSchemaBinding(self);
	}
}

impl<'input> CustomRuleContext<'input> for AlterViewSchemaBindingContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for AlterViewSchemaBindingContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for AlterViewSchemaBindingContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for AlterViewSchemaBindingContext<'input> {}

impl<'input> AlterViewSchemaBindingContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::AlterViewSchemaBindingContext(
				BaseParserRuleContext::copy_from(ctx,AlterViewSchemaBindingContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateVariableContext<'input> = BaseParserRuleContext<'input,CreateVariableContextExt<'input>>;

pub trait CreateVariableContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DECLARE
	/// Returns `None` if there is no child corresponding to token DECLARE
	fn DECLARE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DECLARE, 0)
	}
	fn identifierReference_all(&self) ->  Vec<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn identifierReference(&self, i: usize) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	fn variable(&self) -> Option<Rc<VariableContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
	fn dataType(&self) -> Option<Rc<DataTypeContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn variableDefaultExpression(&self) -> Option<Rc<VariableDefaultExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> CreateVariableContextAttrs<'input> for CreateVariableContext<'input>{}

pub struct CreateVariableContextExt<'input>{
	base:StatementContextExt<'input>,
	pub identifierReference: Option<Rc<IdentifierReferenceContextAll<'input>>>,
	pub identifierReferences:Vec<Rc<IdentifierReferenceContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateVariableContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for CreateVariableContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CreateVariableContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createVariable(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_createVariable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CreateVariableContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_createVariable(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateVariableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateVariableContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateVariableContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateVariableContext<'input> {}

impl<'input> CreateVariableContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateVariableContext(
				BaseParserRuleContext::copy_from(ctx,CreateVariableContextExt{
        			identifierReference:None, 
        			identifierReferences:Vec::new(), 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreatePipelineDatasetContext<'input> = BaseParserRuleContext<'input,CreatePipelineDatasetContextExt<'input>>;

pub trait CreatePipelineDatasetContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn createPipelineDatasetHeader(&self) -> Option<Rc<CreatePipelineDatasetHeaderContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn createTableClauses(&self) -> Option<Rc<CreateTableClausesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
	fn tableProvider(&self) -> Option<Rc<TableProviderContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn tableElementList(&self) -> Option<Rc<TableElementListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> CreatePipelineDatasetContextAttrs<'input> for CreatePipelineDatasetContext<'input>{}

pub struct CreatePipelineDatasetContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreatePipelineDatasetContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for CreatePipelineDatasetContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CreatePipelineDatasetContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createPipelineDataset(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_createPipelineDataset(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CreatePipelineDatasetContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_createPipelineDataset(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreatePipelineDatasetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreatePipelineDatasetContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreatePipelineDatasetContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreatePipelineDatasetContext<'input> {}

impl<'input> CreatePipelineDatasetContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreatePipelineDatasetContext(
				BaseParserRuleContext::copy_from(ctx,CreatePipelineDatasetContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ShowCreateTableContext<'input> = BaseParserRuleContext<'input,ShowCreateTableContextExt<'input>>;

pub trait ShowCreateTableContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SHOW
	/// Returns `None` if there is no child corresponding to token SHOW
	fn SHOW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SHOW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SERDE
	/// Returns `None` if there is no child corresponding to token SERDE
	fn SERDE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SERDE, 0)
	}
}

impl<'input> ShowCreateTableContextAttrs<'input> for ShowCreateTableContext<'input>{}

pub struct ShowCreateTableContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ShowCreateTableContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ShowCreateTableContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ShowCreateTableContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_showCreateTable(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_showCreateTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ShowCreateTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_showCreateTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for ShowCreateTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ShowCreateTableContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ShowCreateTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ShowCreateTableContext<'input> {}

impl<'input> ShowCreateTableContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ShowCreateTableContext(
				BaseParserRuleContext::copy_from(ctx,ShowCreateTableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ShowNamespacesContext<'input> = BaseParserRuleContext<'input,ShowNamespacesContextExt<'input>>;

pub trait ShowNamespacesContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SHOW
	/// Returns `None` if there is no child corresponding to token SHOW
	fn SHOW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SHOW, 0)
	}
	fn namespaces(&self) -> Option<Rc<NamespacesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn multipartIdentifier(&self) -> Option<Rc<MultipartIdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IN
	/// Returns `None` if there is no child corresponding to token IN
	fn IN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IN, 0)
	}
	fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LIKE
	/// Returns `None` if there is no child corresponding to token LIKE
	fn LIKE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LIKE, 0)
	}
}

impl<'input> ShowNamespacesContextAttrs<'input> for ShowNamespacesContext<'input>{}

pub struct ShowNamespacesContextExt<'input>{
	base:StatementContextExt<'input>,
	pub pattern: Option<Rc<StringLitContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ShowNamespacesContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ShowNamespacesContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ShowNamespacesContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_showNamespaces(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_showNamespaces(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ShowNamespacesContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_showNamespaces(self);
	}
}

impl<'input> CustomRuleContext<'input> for ShowNamespacesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ShowNamespacesContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ShowNamespacesContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ShowNamespacesContext<'input> {}

impl<'input> ShowNamespacesContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ShowNamespacesContext(
				BaseParserRuleContext::copy_from(ctx,ShowNamespacesContextExt{
        			pattern:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ShowColumnsContext<'input> = BaseParserRuleContext<'input,ShowColumnsContextExt<'input>>;

pub trait ShowColumnsContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SHOW
	/// Returns `None` if there is no child corresponding to token SHOW
	fn SHOW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SHOW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COLUMNS
	/// Returns `None` if there is no child corresponding to token COLUMNS
	fn COLUMNS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COLUMNS, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token FROM in current rule
	fn FROM_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token FROM, starting from 0.
	/// Returns `None` if number of children corresponding to token FROM is less or equal than `i`.
	fn FROM(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FROM, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token IN in current rule
	fn IN_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token IN, starting from 0.
	/// Returns `None` if number of children corresponding to token IN is less or equal than `i`.
	fn IN(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IN, i)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn multipartIdentifier(&self) -> Option<Rc<MultipartIdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ShowColumnsContextAttrs<'input> for ShowColumnsContext<'input>{}

pub struct ShowColumnsContextExt<'input>{
	base:StatementContextExt<'input>,
	pub table: Option<Rc<IdentifierReferenceContextAll<'input>>>,
	pub ns: Option<Rc<MultipartIdentifierContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ShowColumnsContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ShowColumnsContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ShowColumnsContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_showColumns(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_showColumns(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ShowColumnsContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_showColumns(self);
	}
}

impl<'input> CustomRuleContext<'input> for ShowColumnsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ShowColumnsContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ShowColumnsContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ShowColumnsContext<'input> {}

impl<'input> ShowColumnsContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ShowColumnsContext(
				BaseParserRuleContext::copy_from(ctx,ShowColumnsContextExt{
        			table:None, ns:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ReplaceTableContext<'input> = BaseParserRuleContext<'input,ReplaceTableContextExt<'input>>;

pub trait ReplaceTableContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn replaceTableHeader(&self) -> Option<Rc<ReplaceTableHeaderContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn createTableClauses(&self) -> Option<Rc<CreateTableClausesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	fn tableElementList(&self) -> Option<Rc<TableElementListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
	fn tableProvider(&self) -> Option<Rc<TableProviderContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
}

impl<'input> ReplaceTableContextAttrs<'input> for ReplaceTableContext<'input>{}

pub struct ReplaceTableContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ReplaceTableContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ReplaceTableContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ReplaceTableContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_replaceTable(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_replaceTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ReplaceTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_replaceTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for ReplaceTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ReplaceTableContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ReplaceTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ReplaceTableContext<'input> {}

impl<'input> ReplaceTableContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ReplaceTableContext(
				BaseParserRuleContext::copy_from(ctx,ReplaceTableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AnalyzeTablesContext<'input> = BaseParserRuleContext<'input,AnalyzeTablesContextExt<'input>>;

pub trait AnalyzeTablesContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ANALYZE
	/// Returns `None` if there is no child corresponding to token ANALYZE
	fn ANALYZE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ANALYZE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLES
	/// Returns `None` if there is no child corresponding to token TABLES
	fn TABLES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLES, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COMPUTE
	/// Returns `None` if there is no child corresponding to token COMPUTE
	fn COMPUTE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COMPUTE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token STATISTICS
	/// Returns `None` if there is no child corresponding to token STATISTICS
	fn STATISTICS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(STATISTICS, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn simpleIdentifier(&self) -> Option<Rc<SimpleIdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IN
	/// Returns `None` if there is no child corresponding to token IN
	fn IN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IN, 0)
	}
}

impl<'input> AnalyzeTablesContextAttrs<'input> for AnalyzeTablesContext<'input>{}

pub struct AnalyzeTablesContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AnalyzeTablesContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for AnalyzeTablesContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for AnalyzeTablesContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_analyzeTables(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_analyzeTables(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for AnalyzeTablesContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_analyzeTables(self);
	}
}

impl<'input> CustomRuleContext<'input> for AnalyzeTablesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for AnalyzeTablesContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for AnalyzeTablesContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for AnalyzeTablesContext<'input> {}

impl<'input> AnalyzeTablesContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::AnalyzeTablesContext(
				BaseParserRuleContext::copy_from(ctx,AnalyzeTablesContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type UnsetNamespacePropertiesContext<'input> = BaseParserRuleContext<'input,UnsetNamespacePropertiesContextExt<'input>>;

pub trait UnsetNamespacePropertiesContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	fn namespace(&self) -> Option<Rc<NamespaceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token UNSET
	/// Returns `None` if there is no child corresponding to token UNSET
	fn UNSET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(UNSET, 0)
	}
	fn propertyList(&self) -> Option<Rc<PropertyListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token DBPROPERTIES
	/// Returns `None` if there is no child corresponding to token DBPROPERTIES
	fn DBPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DBPROPERTIES, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PROPERTIES
	/// Returns `None` if there is no child corresponding to token PROPERTIES
	fn PROPERTIES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(PROPERTIES, 0)
	}
}

impl<'input> UnsetNamespacePropertiesContextAttrs<'input> for UnsetNamespacePropertiesContext<'input>{}

pub struct UnsetNamespacePropertiesContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UnsetNamespacePropertiesContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for UnsetNamespacePropertiesContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for UnsetNamespacePropertiesContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_unsetNamespaceProperties(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_unsetNamespaceProperties(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for UnsetNamespacePropertiesContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_unsetNamespaceProperties(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnsetNamespacePropertiesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for UnsetNamespacePropertiesContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for UnsetNamespacePropertiesContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for UnsetNamespacePropertiesContext<'input> {}

impl<'input> UnsetNamespacePropertiesContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::UnsetNamespacePropertiesContext(
				BaseParserRuleContext::copy_from(ctx,UnsetNamespacePropertiesContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AddTablePartitionContext<'input> = BaseParserRuleContext<'input,AddTablePartitionContextExt<'input>>;

pub trait AddTablePartitionContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token ADD
	/// Returns `None` if there is no child corresponding to token ADD
	fn ADD(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ADD, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	fn errorCapturingNot(&self) -> Option<Rc<ErrorCapturingNotContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	fn partitionSpecLocation_all(&self) ->  Vec<Rc<PartitionSpecLocationContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn partitionSpecLocation(&self, i: usize) -> Option<Rc<PartitionSpecLocationContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> AddTablePartitionContextAttrs<'input> for AddTablePartitionContext<'input>{}

pub struct AddTablePartitionContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AddTablePartitionContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for AddTablePartitionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for AddTablePartitionContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_addTablePartition(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_addTablePartition(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for AddTablePartitionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_addTablePartition(self);
	}
}

impl<'input> CustomRuleContext<'input> for AddTablePartitionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for AddTablePartitionContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for AddTablePartitionContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for AddTablePartitionContext<'input> {}

impl<'input> AddTablePartitionContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::AddTablePartitionContext(
				BaseParserRuleContext::copy_from(ctx,AddTablePartitionContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetNamespaceLocationContext<'input> = BaseParserRuleContext<'input,SetNamespaceLocationContextExt<'input>>;

pub trait SetNamespaceLocationContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	fn namespace(&self) -> Option<Rc<NamespaceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	fn locationSpec(&self) -> Option<Rc<LocationSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SetNamespaceLocationContextAttrs<'input> for SetNamespaceLocationContext<'input>{}

pub struct SetNamespaceLocationContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetNamespaceLocationContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SetNamespaceLocationContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SetNamespaceLocationContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setNamespaceLocation(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_setNamespaceLocation(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SetNamespaceLocationContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_setNamespaceLocation(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetNamespaceLocationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for SetNamespaceLocationContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for SetNamespaceLocationContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for SetNamespaceLocationContext<'input> {}

impl<'input> SetNamespaceLocationContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::SetNamespaceLocationContext(
				BaseParserRuleContext::copy_from(ctx,SetNamespaceLocationContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RefreshTableContext<'input> = BaseParserRuleContext<'input,RefreshTableContextExt<'input>>;

pub trait RefreshTableContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token REFRESH
	/// Returns `None` if there is no child corresponding to token REFRESH
	fn REFRESH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(REFRESH, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> RefreshTableContextAttrs<'input> for RefreshTableContext<'input>{}

pub struct RefreshTableContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RefreshTableContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for RefreshTableContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for RefreshTableContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_refreshTable(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_refreshTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for RefreshTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_refreshTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for RefreshTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RefreshTableContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RefreshTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RefreshTableContext<'input> {}

impl<'input> RefreshTableContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RefreshTableContext(
				BaseParserRuleContext::copy_from(ctx,RefreshTableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AlterTableCollationContext<'input> = BaseParserRuleContext<'input,AlterTableCollationContextExt<'input>>;

pub trait AlterTableCollationContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn collationSpec(&self) -> Option<Rc<CollationSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> AlterTableCollationContextAttrs<'input> for AlterTableCollationContext<'input>{}

pub struct AlterTableCollationContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AlterTableCollationContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for AlterTableCollationContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for AlterTableCollationContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_alterTableCollation(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_alterTableCollation(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for AlterTableCollationContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_alterTableCollation(self);
	}
}

impl<'input> CustomRuleContext<'input> for AlterTableCollationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for AlterTableCollationContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for AlterTableCollationContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for AlterTableCollationContext<'input> {}

impl<'input> AlterTableCollationContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::AlterTableCollationContext(
				BaseParserRuleContext::copy_from(ctx,AlterTableCollationContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetNamespacePropertiesContext<'input> = BaseParserRuleContext<'input,SetNamespacePropertiesContextExt<'input>>;

pub trait SetNamespacePropertiesContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	fn namespace(&self) -> Option<Rc<NamespaceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	fn propertyList(&self) -> Option<Rc<PropertyListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token DBPROPERTIES
	/// Returns `None` if there is no child corresponding to token DBPROPERTIES
	fn DBPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DBPROPERTIES, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PROPERTIES
	/// Returns `None` if there is no child corresponding to token PROPERTIES
	fn PROPERTIES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(PROPERTIES, 0)
	}
}

impl<'input> SetNamespacePropertiesContextAttrs<'input> for SetNamespacePropertiesContext<'input>{}

pub struct SetNamespacePropertiesContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetNamespacePropertiesContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SetNamespacePropertiesContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SetNamespacePropertiesContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setNamespaceProperties(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_setNamespaceProperties(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SetNamespacePropertiesContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_setNamespaceProperties(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetNamespacePropertiesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for SetNamespacePropertiesContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for SetNamespacePropertiesContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for SetNamespacePropertiesContext<'input> {}

impl<'input> SetNamespacePropertiesContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::SetNamespacePropertiesContext(
				BaseParserRuleContext::copy_from(ctx,SetNamespacePropertiesContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ManageResourceContext<'input> = BaseParserRuleContext<'input,ManageResourceContextExt<'input>>;

pub trait ManageResourceContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn simpleIdentifier(&self) -> Option<Rc<SimpleIdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token ADD
	/// Returns `None` if there is no child corresponding to token ADD
	fn ADD(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ADD, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LIST
	/// Returns `None` if there is no child corresponding to token LIST
	fn LIST(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LIST, 0)
	}
}

impl<'input> ManageResourceContextAttrs<'input> for ManageResourceContext<'input>{}

pub struct ManageResourceContextExt<'input>{
	base:StatementContextExt<'input>,
	pub op: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ManageResourceContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ManageResourceContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ManageResourceContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_manageResource(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_manageResource(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ManageResourceContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_manageResource(self);
	}
}

impl<'input> CustomRuleContext<'input> for ManageResourceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ManageResourceContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ManageResourceContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ManageResourceContext<'input> {}

impl<'input> ManageResourceContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ManageResourceContext(
				BaseParserRuleContext::copy_from(ctx,ManageResourceContextExt{
					op:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AnalyzeContext<'input> = BaseParserRuleContext<'input,AnalyzeContextExt<'input>>;

pub trait AnalyzeContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ANALYZE
	/// Returns `None` if there is no child corresponding to token ANALYZE
	fn ANALYZE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ANALYZE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token COMPUTE
	/// Returns `None` if there is no child corresponding to token COMPUTE
	fn COMPUTE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COMPUTE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token STATISTICS
	/// Returns `None` if there is no child corresponding to token STATISTICS
	fn STATISTICS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(STATISTICS, 0)
	}
	fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn simpleIdentifier(&self) -> Option<Rc<SimpleIdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token FOR
	/// Returns `None` if there is no child corresponding to token FOR
	fn FOR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FOR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COLUMNS
	/// Returns `None` if there is no child corresponding to token COLUMNS
	fn COLUMNS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COLUMNS, 0)
	}
	fn identifierSeq(&self) -> Option<Rc<IdentifierSeqContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token ALL
	/// Returns `None` if there is no child corresponding to token ALL
	fn ALL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ALL, 0)
	}
}

impl<'input> AnalyzeContextAttrs<'input> for AnalyzeContext<'input>{}

pub struct AnalyzeContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AnalyzeContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for AnalyzeContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for AnalyzeContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_analyze(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_analyze(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for AnalyzeContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_analyze(self);
	}
}

impl<'input> CustomRuleContext<'input> for AnalyzeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for AnalyzeContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for AnalyzeContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for AnalyzeContext<'input> {}

impl<'input> AnalyzeContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::AnalyzeContext(
				BaseParserRuleContext::copy_from(ctx,AnalyzeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateFunctionContext<'input> = BaseParserRuleContext<'input,CreateFunctionContextExt<'input>>;

pub trait CreateFunctionContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FUNCTION
	/// Returns `None` if there is no child corresponding to token FUNCTION
	fn FUNCTION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FUNCTION, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TEMPORARY
	/// Returns `None` if there is no child corresponding to token TEMPORARY
	fn TEMPORARY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TEMPORARY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	fn errorCapturingNot(&self) -> Option<Rc<ErrorCapturingNotContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token USING
	/// Returns `None` if there is no child corresponding to token USING
	fn USING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(USING, 0)
	}
	fn resource_all(&self) ->  Vec<Rc<ResourceContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn resource(&self, i: usize) -> Option<Rc<ResourceContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> CreateFunctionContextAttrs<'input> for CreateFunctionContext<'input>{}

pub struct CreateFunctionContextExt<'input>{
	base:StatementContextExt<'input>,
	pub className: Option<Rc<StringLitContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateFunctionContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for CreateFunctionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CreateFunctionContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createFunction(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_createFunction(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CreateFunctionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_createFunction(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateFunctionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateFunctionContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateFunctionContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateFunctionContext<'input> {}

impl<'input> CreateFunctionContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateFunctionContext(
				BaseParserRuleContext::copy_from(ctx,CreateFunctionContextExt{
        			className:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type HiveReplaceColumnsContext<'input> = BaseParserRuleContext<'input,HiveReplaceColumnsContextExt<'input>>;

pub trait HiveReplaceColumnsContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COLUMNS
	/// Returns `None` if there is no child corresponding to token COLUMNS
	fn COLUMNS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COLUMNS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn qualifiedColTypeWithPositionList(&self) -> Option<Rc<QualifiedColTypeWithPositionListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> HiveReplaceColumnsContextAttrs<'input> for HiveReplaceColumnsContext<'input>{}

pub struct HiveReplaceColumnsContextExt<'input>{
	base:StatementContextExt<'input>,
	pub table: Option<Rc<IdentifierReferenceContextAll<'input>>>,
	pub columns: Option<Rc<QualifiedColTypeWithPositionListContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{HiveReplaceColumnsContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for HiveReplaceColumnsContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for HiveReplaceColumnsContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_hiveReplaceColumns(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_hiveReplaceColumns(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for HiveReplaceColumnsContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_hiveReplaceColumns(self);
	}
}

impl<'input> CustomRuleContext<'input> for HiveReplaceColumnsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for HiveReplaceColumnsContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for HiveReplaceColumnsContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for HiveReplaceColumnsContext<'input> {}

impl<'input> HiveReplaceColumnsContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::HiveReplaceColumnsContext(
				BaseParserRuleContext::copy_from(ctx,HiveReplaceColumnsContextExt{
        			table:None, columns:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CommentNamespaceContext<'input> = BaseParserRuleContext<'input,CommentNamespaceContextExt<'input>>;

pub trait CommentNamespaceContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token COMMENT
	/// Returns `None` if there is no child corresponding to token COMMENT
	fn COMMENT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COMMENT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ON
	/// Returns `None` if there is no child corresponding to token ON
	fn ON(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ON, 0)
	}
	fn namespace(&self) -> Option<Rc<NamespaceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token IS
	/// Returns `None` if there is no child corresponding to token IS
	fn IS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IS, 0)
	}
	fn comment(&self) -> Option<Rc<CommentContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> CommentNamespaceContextAttrs<'input> for CommentNamespaceContext<'input>{}

pub struct CommentNamespaceContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CommentNamespaceContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for CommentNamespaceContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CommentNamespaceContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_commentNamespace(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_commentNamespace(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CommentNamespaceContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_commentNamespace(self);
	}
}

impl<'input> CustomRuleContext<'input> for CommentNamespaceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CommentNamespaceContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CommentNamespaceContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CommentNamespaceContext<'input> {}

impl<'input> CommentNamespaceContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CommentNamespaceContext(
				BaseParserRuleContext::copy_from(ctx,CommentNamespaceContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateTableContext<'input> = BaseParserRuleContext<'input,CreateTableContextExt<'input>>;

pub trait CreateTableContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn createTableHeader(&self) -> Option<Rc<CreateTableHeaderContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn createTableClauses(&self) -> Option<Rc<CreateTableClausesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	fn tableElementList(&self) -> Option<Rc<TableElementListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
	fn tableProvider(&self) -> Option<Rc<TableProviderContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
}

impl<'input> CreateTableContextAttrs<'input> for CreateTableContext<'input>{}

pub struct CreateTableContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateTableContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for CreateTableContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CreateTableContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createTable(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_createTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CreateTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_createTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateTableContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateTableContext<'input> {}

impl<'input> CreateTableContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateTableContext(
				BaseParserRuleContext::copy_from(ctx,CreateTableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DmlStatementContext<'input> = BaseParserRuleContext<'input,DmlStatementContextExt<'input>>;

pub trait DmlStatementContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn dmlStatementNoWith(&self) -> Option<Rc<DmlStatementNoWithContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn ctes(&self) -> Option<Rc<CtesContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> DmlStatementContextAttrs<'input> for DmlStatementContext<'input>{}

pub struct DmlStatementContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DmlStatementContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for DmlStatementContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DmlStatementContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dmlStatement(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_dmlStatement(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DmlStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_dmlStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for DmlStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DmlStatementContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DmlStatementContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DmlStatementContext<'input> {}

impl<'input> DmlStatementContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DmlStatementContext(
				BaseParserRuleContext::copy_from(ctx,DmlStatementContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateTableLikeContext<'input> = BaseParserRuleContext<'input,CreateTableLikeContextExt<'input>>;

pub trait CreateTableLikeContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LIKE
	/// Returns `None` if there is no child corresponding to token LIKE
	fn LIKE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LIKE, 0)
	}
	fn tableIdentifier_all(&self) ->  Vec<Rc<TableIdentifierContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn tableIdentifier(&self, i: usize) -> Option<Rc<TableIdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	fn errorCapturingNot(&self) -> Option<Rc<ErrorCapturingNotContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	fn tableProvider_all(&self) ->  Vec<Rc<TableProviderContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn tableProvider(&self, i: usize) -> Option<Rc<TableProviderContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn rowFormat_all(&self) ->  Vec<Rc<RowFormatContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn rowFormat(&self, i: usize) -> Option<Rc<RowFormatContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn createFileFormat_all(&self) ->  Vec<Rc<CreateFileFormatContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn createFileFormat(&self, i: usize) -> Option<Rc<CreateFileFormatContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn locationSpec_all(&self) ->  Vec<Rc<LocationSpecContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn locationSpec(&self, i: usize) -> Option<Rc<LocationSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token TBLPROPERTIES in current rule
	fn TBLPROPERTIES_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token TBLPROPERTIES, starting from 0.
	/// Returns `None` if number of children corresponding to token TBLPROPERTIES is less or equal than `i`.
	fn TBLPROPERTIES(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TBLPROPERTIES, i)
	}
	fn propertyList_all(&self) ->  Vec<Rc<PropertyListContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn propertyList(&self, i: usize) -> Option<Rc<PropertyListContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> CreateTableLikeContextAttrs<'input> for CreateTableLikeContext<'input>{}

pub struct CreateTableLikeContextExt<'input>{
	base:StatementContextExt<'input>,
	pub target: Option<Rc<TableIdentifierContextAll<'input>>>,
	pub source: Option<Rc<TableIdentifierContextAll<'input>>>,
	pub tableProps: Option<Rc<PropertyListContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateTableLikeContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for CreateTableLikeContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CreateTableLikeContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createTableLike(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_createTableLike(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CreateTableLikeContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_createTableLike(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateTableLikeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateTableLikeContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateTableLikeContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateTableLikeContext<'input> {}

impl<'input> CreateTableLikeContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateTableLikeContext(
				BaseParserRuleContext::copy_from(ctx,CreateTableLikeContextExt{
        			target:None, source:None, tableProps:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type UncacheTableContext<'input> = BaseParserRuleContext<'input,UncacheTableContextExt<'input>>;

pub trait UncacheTableContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token UNCACHE
	/// Returns `None` if there is no child corresponding to token UNCACHE
	fn UNCACHE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(UNCACHE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
}

impl<'input> UncacheTableContextAttrs<'input> for UncacheTableContext<'input>{}

pub struct UncacheTableContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UncacheTableContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for UncacheTableContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for UncacheTableContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_uncacheTable(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_uncacheTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for UncacheTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_uncacheTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for UncacheTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for UncacheTableContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for UncacheTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for UncacheTableContext<'input> {}

impl<'input> UncacheTableContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::UncacheTableContext(
				BaseParserRuleContext::copy_from(ctx,UncacheTableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DropFunctionContext<'input> = BaseParserRuleContext<'input,DropFunctionContextExt<'input>>;

pub trait DropFunctionContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DROP
	/// Returns `None` if there is no child corresponding to token DROP
	fn DROP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DROP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FUNCTION
	/// Returns `None` if there is no child corresponding to token FUNCTION
	fn FUNCTION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FUNCTION, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token TEMPORARY
	/// Returns `None` if there is no child corresponding to token TEMPORARY
	fn TEMPORARY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TEMPORARY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
}

impl<'input> DropFunctionContextAttrs<'input> for DropFunctionContext<'input>{}

pub struct DropFunctionContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DropFunctionContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for DropFunctionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DropFunctionContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dropFunction(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_dropFunction(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DropFunctionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_dropFunction(self);
	}
}

impl<'input> CustomRuleContext<'input> for DropFunctionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DropFunctionContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DropFunctionContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DropFunctionContext<'input> {}

impl<'input> DropFunctionContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DropFunctionContext(
				BaseParserRuleContext::copy_from(ctx,DropFunctionContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DescribeRelationContext<'input> = BaseParserRuleContext<'input,DescribeRelationContextExt<'input>>;

pub trait DescribeRelationContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token DESC
	/// Returns `None` if there is no child corresponding to token DESC
	fn DESC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DESC, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DESCRIBE
	/// Returns `None` if there is no child corresponding to token DESCRIBE
	fn DESCRIBE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DESCRIBE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn describeColName(&self) -> Option<Rc<DescribeColNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token JSON
	/// Returns `None` if there is no child corresponding to token JSON
	fn JSON(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(JSON, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXTENDED
	/// Returns `None` if there is no child corresponding to token EXTENDED
	fn EXTENDED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXTENDED, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FORMATTED
	/// Returns `None` if there is no child corresponding to token FORMATTED
	fn FORMATTED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FORMATTED, 0)
	}
}

impl<'input> DescribeRelationContextAttrs<'input> for DescribeRelationContext<'input>{}

pub struct DescribeRelationContextExt<'input>{
	base:StatementContextExt<'input>,
	pub option: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DescribeRelationContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for DescribeRelationContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DescribeRelationContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_describeRelation(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_describeRelation(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DescribeRelationContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_describeRelation(self);
	}
}

impl<'input> CustomRuleContext<'input> for DescribeRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DescribeRelationContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DescribeRelationContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DescribeRelationContext<'input> {}

impl<'input> DescribeRelationContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DescribeRelationContext(
				BaseParserRuleContext::copy_from(ctx,DescribeRelationContextExt{
					option:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type LoadDataContext<'input> = BaseParserRuleContext<'input,LoadDataContextExt<'input>>;

pub trait LoadDataContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LOAD
	/// Returns `None` if there is no child corresponding to token LOAD
	fn LOAD(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LOAD, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DATA
	/// Returns `None` if there is no child corresponding to token DATA
	fn DATA(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DATA, 0)
	}
	/// Retrieves first TerminalNode corresponding to token INPATH
	/// Returns `None` if there is no child corresponding to token INPATH
	fn INPATH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(INPATH, 0)
	}
	/// Retrieves first TerminalNode corresponding to token INTO
	/// Returns `None` if there is no child corresponding to token INTO
	fn INTO(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(INTO, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LOCAL
	/// Returns `None` if there is no child corresponding to token LOCAL
	fn LOCAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LOCAL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OVERWRITE
	/// Returns `None` if there is no child corresponding to token OVERWRITE
	fn OVERWRITE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(OVERWRITE, 0)
	}
	fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> LoadDataContextAttrs<'input> for LoadDataContext<'input>{}

pub struct LoadDataContextExt<'input>{
	base:StatementContextExt<'input>,
	pub path: Option<Rc<StringLitContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{LoadDataContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for LoadDataContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for LoadDataContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_loadData(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_loadData(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for LoadDataContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_loadData(self);
	}
}

impl<'input> CustomRuleContext<'input> for LoadDataContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for LoadDataContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for LoadDataContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for LoadDataContext<'input> {}

impl<'input> LoadDataContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::LoadDataContext(
				BaseParserRuleContext::copy_from(ctx,LoadDataContextExt{
        			path:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ShowPartitionsContext<'input> = BaseParserRuleContext<'input,ShowPartitionsContextExt<'input>>;

pub trait ShowPartitionsContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SHOW
	/// Returns `None` if there is no child corresponding to token SHOW
	fn SHOW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SHOW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PARTITIONS
	/// Returns `None` if there is no child corresponding to token PARTITIONS
	fn PARTITIONS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(PARTITIONS, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ShowPartitionsContextAttrs<'input> for ShowPartitionsContext<'input>{}

pub struct ShowPartitionsContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ShowPartitionsContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ShowPartitionsContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ShowPartitionsContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_showPartitions(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_showPartitions(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ShowPartitionsContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_showPartitions(self);
	}
}

impl<'input> CustomRuleContext<'input> for ShowPartitionsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ShowPartitionsContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ShowPartitionsContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ShowPartitionsContext<'input> {}

impl<'input> ShowPartitionsContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ShowPartitionsContext(
				BaseParserRuleContext::copy_from(ctx,ShowPartitionsContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DescribeFunctionContext<'input> = BaseParserRuleContext<'input,DescribeFunctionContextExt<'input>>;

pub trait DescribeFunctionContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token FUNCTION
	/// Returns `None` if there is no child corresponding to token FUNCTION
	fn FUNCTION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FUNCTION, 0)
	}
	fn describeFuncName(&self) -> Option<Rc<DescribeFuncNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token DESC
	/// Returns `None` if there is no child corresponding to token DESC
	fn DESC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DESC, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DESCRIBE
	/// Returns `None` if there is no child corresponding to token DESCRIBE
	fn DESCRIBE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DESCRIBE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXTENDED
	/// Returns `None` if there is no child corresponding to token EXTENDED
	fn EXTENDED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXTENDED, 0)
	}
}

impl<'input> DescribeFunctionContextAttrs<'input> for DescribeFunctionContext<'input>{}

pub struct DescribeFunctionContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DescribeFunctionContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for DescribeFunctionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DescribeFunctionContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_describeFunction(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_describeFunction(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DescribeFunctionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_describeFunction(self);
	}
}

impl<'input> CustomRuleContext<'input> for DescribeFunctionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DescribeFunctionContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DescribeFunctionContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DescribeFunctionContext<'input> {}

impl<'input> DescribeFunctionContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DescribeFunctionContext(
				BaseParserRuleContext::copy_from(ctx,DescribeFunctionContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RenameTableColumnContext<'input> = BaseParserRuleContext<'input,RenameTableColumnContextExt<'input>>;

pub trait RenameTableColumnContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RENAME
	/// Returns `None` if there is no child corresponding to token RENAME
	fn RENAME(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RENAME, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COLUMN
	/// Returns `None` if there is no child corresponding to token COLUMN
	fn COLUMN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COLUMN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TO
	/// Returns `None` if there is no child corresponding to token TO
	fn TO(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TO, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn multipartIdentifier(&self) -> Option<Rc<MultipartIdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn errorCapturingIdentifier(&self) -> Option<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> RenameTableColumnContextAttrs<'input> for RenameTableColumnContext<'input>{}

pub struct RenameTableColumnContextExt<'input>{
	base:StatementContextExt<'input>,
	pub table: Option<Rc<IdentifierReferenceContextAll<'input>>>,
	pub from: Option<Rc<MultipartIdentifierContextAll<'input>>>,
	pub to: Option<Rc<ErrorCapturingIdentifierContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RenameTableColumnContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for RenameTableColumnContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for RenameTableColumnContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_renameTableColumn(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_renameTableColumn(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for RenameTableColumnContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_renameTableColumn(self);
	}
}

impl<'input> CustomRuleContext<'input> for RenameTableColumnContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RenameTableColumnContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RenameTableColumnContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RenameTableColumnContext<'input> {}

impl<'input> RenameTableColumnContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RenameTableColumnContext(
				BaseParserRuleContext::copy_from(ctx,RenameTableColumnContextExt{
        			table:None, from:None, to:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateUserDefinedFunctionContext<'input> = BaseParserRuleContext<'input,CreateUserDefinedFunctionContextExt<'input>>;

pub trait CreateUserDefinedFunctionContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FUNCTION
	/// Returns `None` if there is no child corresponding to token FUNCTION
	fn FUNCTION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FUNCTION, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token LEFT_PAREN in current rule
	fn LEFT_PAREN_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token LEFT_PAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token LEFT_PAREN is less or equal than `i`.
	fn LEFT_PAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token RIGHT_PAREN in current rule
	fn RIGHT_PAREN_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token RIGHT_PAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token RIGHT_PAREN is less or equal than `i`.
	fn RIGHT_PAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, i)
	}
	fn routineCharacteristics(&self) -> Option<Rc<RoutineCharacteristicsContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RETURN
	/// Returns `None` if there is no child corresponding to token RETURN
	fn RETURN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RETURN, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TEMPORARY
	/// Returns `None` if there is no child corresponding to token TEMPORARY
	fn TEMPORARY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TEMPORARY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	fn errorCapturingNot(&self) -> Option<Rc<ErrorCapturingNotContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RETURNS
	/// Returns `None` if there is no child corresponding to token RETURNS
	fn RETURNS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RETURNS, 0)
	}
	fn colDefinitionList(&self) -> Option<Rc<ColDefinitionListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn dataType(&self) -> Option<Rc<DataTypeContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn colTypeList(&self) -> Option<Rc<ColTypeListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> CreateUserDefinedFunctionContextAttrs<'input> for CreateUserDefinedFunctionContext<'input>{}

pub struct CreateUserDefinedFunctionContextExt<'input>{
	base:StatementContextExt<'input>,
	pub parameters: Option<Rc<ColDefinitionListContextAll<'input>>>,
	pub returnParams: Option<Rc<ColTypeListContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateUserDefinedFunctionContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for CreateUserDefinedFunctionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CreateUserDefinedFunctionContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createUserDefinedFunction(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_createUserDefinedFunction(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CreateUserDefinedFunctionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_createUserDefinedFunction(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateUserDefinedFunctionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateUserDefinedFunctionContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateUserDefinedFunctionContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateUserDefinedFunctionContext<'input> {}

impl<'input> CreateUserDefinedFunctionContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateUserDefinedFunctionContext(
				BaseParserRuleContext::copy_from(ctx,CreateUserDefinedFunctionContextExt{
        			parameters:None, returnParams:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type StatementDefaultContext<'input> = BaseParserRuleContext<'input,StatementDefaultContextExt<'input>>;

pub trait StatementDefaultContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> StatementDefaultContextAttrs<'input> for StatementDefaultContext<'input>{}

pub struct StatementDefaultContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{StatementDefaultContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for StatementDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for StatementDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_statementDefault(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_statementDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for StatementDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_statementDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for StatementDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for StatementDefaultContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for StatementDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for StatementDefaultContext<'input> {}

impl<'input> StatementDefaultContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::StatementDefaultContext(
				BaseParserRuleContext::copy_from(ctx,StatementDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AlterClusterByContext<'input> = BaseParserRuleContext<'input,AlterClusterByContextExt<'input>>;

pub trait AlterClusterByContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn clusterBySpec(&self) -> Option<Rc<ClusterBySpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token CLUSTER
	/// Returns `None` if there is no child corresponding to token CLUSTER
	fn CLUSTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CLUSTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token BY
	/// Returns `None` if there is no child corresponding to token BY
	fn BY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(BY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NONE
	/// Returns `None` if there is no child corresponding to token NONE
	fn NONE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(NONE, 0)
	}
}

impl<'input> AlterClusterByContextAttrs<'input> for AlterClusterByContext<'input>{}

pub struct AlterClusterByContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AlterClusterByContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for AlterClusterByContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for AlterClusterByContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_alterClusterBy(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_alterClusterBy(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for AlterClusterByContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_alterClusterBy(self);
	}
}

impl<'input> CustomRuleContext<'input> for AlterClusterByContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for AlterClusterByContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for AlterClusterByContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for AlterClusterByContext<'input> {}

impl<'input> AlterClusterByContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::AlterClusterByContext(
				BaseParserRuleContext::copy_from(ctx,AlterClusterByContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type HiveChangeColumnContext<'input> = BaseParserRuleContext<'input,HiveChangeColumnContextExt<'input>>;

pub trait HiveChangeColumnContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token CHANGE
	/// Returns `None` if there is no child corresponding to token CHANGE
	fn CHANGE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CHANGE, 0)
	}
	fn colType(&self) -> Option<Rc<ColTypeContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn multipartIdentifier(&self) -> Option<Rc<MultipartIdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token COLUMN
	/// Returns `None` if there is no child corresponding to token COLUMN
	fn COLUMN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COLUMN, 0)
	}
	fn colPosition(&self) -> Option<Rc<ColPositionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> HiveChangeColumnContextAttrs<'input> for HiveChangeColumnContext<'input>{}

pub struct HiveChangeColumnContextExt<'input>{
	base:StatementContextExt<'input>,
	pub table: Option<Rc<IdentifierReferenceContextAll<'input>>>,
	pub colName: Option<Rc<MultipartIdentifierContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{HiveChangeColumnContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for HiveChangeColumnContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for HiveChangeColumnContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_hiveChangeColumn(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_hiveChangeColumn(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for HiveChangeColumnContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_hiveChangeColumn(self);
	}
}

impl<'input> CustomRuleContext<'input> for HiveChangeColumnContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for HiveChangeColumnContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for HiveChangeColumnContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for HiveChangeColumnContext<'input> {}

impl<'input> HiveChangeColumnContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::HiveChangeColumnContext(
				BaseParserRuleContext::copy_from(ctx,HiveChangeColumnContextExt{
        			table:None, colName:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DescribeQueryContext<'input> = BaseParserRuleContext<'input,DescribeQueryContextExt<'input>>;

pub trait DescribeQueryContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token DESC
	/// Returns `None` if there is no child corresponding to token DESC
	fn DESC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DESC, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DESCRIBE
	/// Returns `None` if there is no child corresponding to token DESCRIBE
	fn DESCRIBE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DESCRIBE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token QUERY
	/// Returns `None` if there is no child corresponding to token QUERY
	fn QUERY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(QUERY, 0)
	}
}

impl<'input> DescribeQueryContextAttrs<'input> for DescribeQueryContext<'input>{}

pub struct DescribeQueryContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DescribeQueryContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for DescribeQueryContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DescribeQueryContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_describeQuery(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_describeQuery(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DescribeQueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_describeQuery(self);
	}
}

impl<'input> CustomRuleContext<'input> for DescribeQueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DescribeQueryContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DescribeQueryContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DescribeQueryContext<'input> {}

impl<'input> DescribeQueryContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DescribeQueryContext(
				BaseParserRuleContext::copy_from(ctx,DescribeQueryContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TruncateTableContext<'input> = BaseParserRuleContext<'input,TruncateTableContextExt<'input>>;

pub trait TruncateTableContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token TRUNCATE
	/// Returns `None` if there is no child corresponding to token TRUNCATE
	fn TRUNCATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TRUNCATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> TruncateTableContextAttrs<'input> for TruncateTableContext<'input>{}

pub struct TruncateTableContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TruncateTableContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for TruncateTableContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for TruncateTableContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_truncateTable(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_truncateTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for TruncateTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_truncateTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for TruncateTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for TruncateTableContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for TruncateTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for TruncateTableContext<'input> {}

impl<'input> TruncateTableContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::TruncateTableContext(
				BaseParserRuleContext::copy_from(ctx,TruncateTableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetTableSerDeContext<'input> = BaseParserRuleContext<'input,SetTableSerDeContextExt<'input>>;

pub trait SetTableSerDeContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SERDE
	/// Returns `None` if there is no child corresponding to token SERDE
	fn SERDE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SERDE, 0)
	}
	fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token WITH
	/// Returns `None` if there is no child corresponding to token WITH
	fn WITH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(WITH, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SERDEPROPERTIES
	/// Returns `None` if there is no child corresponding to token SERDEPROPERTIES
	fn SERDEPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SERDEPROPERTIES, 0)
	}
	fn propertyList(&self) -> Option<Rc<PropertyListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SetTableSerDeContextAttrs<'input> for SetTableSerDeContext<'input>{}

pub struct SetTableSerDeContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetTableSerDeContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SetTableSerDeContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SetTableSerDeContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setTableSerDe(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_setTableSerDe(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SetTableSerDeContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_setTableSerDe(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetTableSerDeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for SetTableSerDeContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for SetTableSerDeContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for SetTableSerDeContext<'input> {}

impl<'input> SetTableSerDeContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::SetTableSerDeContext(
				BaseParserRuleContext::copy_from(ctx,SetTableSerDeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateViewContext<'input> = BaseParserRuleContext<'input,CreateViewContextExt<'input>>;

pub trait CreateViewContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TEMPORARY
	/// Returns `None` if there is no child corresponding to token TEMPORARY
	fn TEMPORARY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TEMPORARY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	fn errorCapturingNot(&self) -> Option<Rc<ErrorCapturingNotContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	fn identifierCommentList(&self) -> Option<Rc<IdentifierCommentListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn commentSpec_all(&self) ->  Vec<Rc<CommentSpecContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn commentSpec(&self, i: usize) -> Option<Rc<CommentSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn schemaBinding_all(&self) ->  Vec<Rc<SchemaBindingContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn schemaBinding(&self, i: usize) -> Option<Rc<SchemaBindingContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn collationSpec_all(&self) ->  Vec<Rc<CollationSpecContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn collationSpec(&self, i: usize) -> Option<Rc<CollationSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token PARTITIONED in current rule
	fn PARTITIONED_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token PARTITIONED, starting from 0.
	/// Returns `None` if number of children corresponding to token PARTITIONED is less or equal than `i`.
	fn PARTITIONED(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(PARTITIONED, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token ON in current rule
	fn ON_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token ON, starting from 0.
	/// Returns `None` if number of children corresponding to token ON is less or equal than `i`.
	fn ON(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ON, i)
	}
	fn identifierList_all(&self) ->  Vec<Rc<IdentifierListContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn identifierList(&self, i: usize) -> Option<Rc<IdentifierListContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token TBLPROPERTIES in current rule
	fn TBLPROPERTIES_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token TBLPROPERTIES, starting from 0.
	/// Returns `None` if number of children corresponding to token TBLPROPERTIES is less or equal than `i`.
	fn TBLPROPERTIES(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TBLPROPERTIES, i)
	}
	fn propertyList_all(&self) ->  Vec<Rc<PropertyListContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn propertyList(&self, i: usize) -> Option<Rc<PropertyListContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token GLOBAL
	/// Returns `None` if there is no child corresponding to token GLOBAL
	fn GLOBAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(GLOBAL, 0)
	}
}

impl<'input> CreateViewContextAttrs<'input> for CreateViewContext<'input>{}

pub struct CreateViewContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateViewContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for CreateViewContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CreateViewContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createView(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_createView(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CreateViewContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_createView(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateViewContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateViewContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateViewContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateViewContext<'input> {}

impl<'input> CreateViewContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateViewContext(
				BaseParserRuleContext::copy_from(ctx,CreateViewContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DropTablePartitionsContext<'input> = BaseParserRuleContext<'input,DropTablePartitionsContextExt<'input>>;

pub trait DropTablePartitionsContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token DROP
	/// Returns `None` if there is no child corresponding to token DROP
	fn DROP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DROP, 0)
	}
	fn partitionSpec_all(&self) ->  Vec<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn partitionSpec(&self, i: usize) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
	/// Retrieves first TerminalNode corresponding to token PURGE
	/// Returns `None` if there is no child corresponding to token PURGE
	fn PURGE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(PURGE, 0)
	}
}

impl<'input> DropTablePartitionsContextAttrs<'input> for DropTablePartitionsContext<'input>{}

pub struct DropTablePartitionsContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DropTablePartitionsContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for DropTablePartitionsContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DropTablePartitionsContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dropTablePartitions(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_dropTablePartitions(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DropTablePartitionsContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_dropTablePartitions(self);
	}
}

impl<'input> CustomRuleContext<'input> for DropTablePartitionsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DropTablePartitionsContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DropTablePartitionsContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DropTablePartitionsContext<'input> {}

impl<'input> DropTablePartitionsContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DropTablePartitionsContext(
				BaseParserRuleContext::copy_from(ctx,DropTablePartitionsContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DropTableContext<'input> = BaseParserRuleContext<'input,DropTableContextExt<'input>>;

pub trait DropTableContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DROP
	/// Returns `None` if there is no child corresponding to token DROP
	fn DROP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DROP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PURGE
	/// Returns `None` if there is no child corresponding to token PURGE
	fn PURGE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(PURGE, 0)
	}
}

impl<'input> DropTableContextAttrs<'input> for DropTableContext<'input>{}

pub struct DropTableContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DropTableContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for DropTableContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DropTableContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dropTable(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_dropTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DropTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_dropTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for DropTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DropTableContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DropTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DropTableContext<'input> {}

impl<'input> DropTableContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DropTableContext(
				BaseParserRuleContext::copy_from(ctx,DropTableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ShowTableExtendedContext<'input> = BaseParserRuleContext<'input,ShowTableExtendedContextExt<'input>>;

pub trait ShowTableExtendedContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SHOW
	/// Returns `None` if there is no child corresponding to token SHOW
	fn SHOW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SHOW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXTENDED
	/// Returns `None` if there is no child corresponding to token EXTENDED
	fn EXTENDED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXTENDED, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LIKE
	/// Returns `None` if there is no child corresponding to token LIKE
	fn LIKE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LIKE, 0)
	}
	fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IN
	/// Returns `None` if there is no child corresponding to token IN
	fn IN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IN, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ShowTableExtendedContextAttrs<'input> for ShowTableExtendedContext<'input>{}

pub struct ShowTableExtendedContextExt<'input>{
	base:StatementContextExt<'input>,
	pub ns: Option<Rc<IdentifierReferenceContextAll<'input>>>,
	pub pattern: Option<Rc<StringLitContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ShowTableExtendedContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ShowTableExtendedContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ShowTableExtendedContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_showTableExtended(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_showTableExtended(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ShowTableExtendedContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_showTableExtended(self);
	}
}

impl<'input> CustomRuleContext<'input> for ShowTableExtendedContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ShowTableExtendedContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ShowTableExtendedContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ShowTableExtendedContext<'input> {}

impl<'input> ShowTableExtendedContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ShowTableExtendedContext(
				BaseParserRuleContext::copy_from(ctx,ShowTableExtendedContextExt{
        			ns:None, pattern:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DescribeNamespaceContext<'input> = BaseParserRuleContext<'input,DescribeNamespaceContextExt<'input>>;

pub trait DescribeNamespaceContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn namespace(&self) -> Option<Rc<NamespaceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token DESC
	/// Returns `None` if there is no child corresponding to token DESC
	fn DESC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DESC, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DESCRIBE
	/// Returns `None` if there is no child corresponding to token DESCRIBE
	fn DESCRIBE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DESCRIBE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXTENDED
	/// Returns `None` if there is no child corresponding to token EXTENDED
	fn EXTENDED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXTENDED, 0)
	}
}

impl<'input> DescribeNamespaceContextAttrs<'input> for DescribeNamespaceContext<'input>{}

pub struct DescribeNamespaceContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DescribeNamespaceContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for DescribeNamespaceContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DescribeNamespaceContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_describeNamespace(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_describeNamespace(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DescribeNamespaceContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_describeNamespace(self);
	}
}

impl<'input> CustomRuleContext<'input> for DescribeNamespaceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DescribeNamespaceContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DescribeNamespaceContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DescribeNamespaceContext<'input> {}

impl<'input> DescribeNamespaceContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DescribeNamespaceContext(
				BaseParserRuleContext::copy_from(ctx,DescribeNamespaceContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AlterTableAlterColumnContext<'input> = BaseParserRuleContext<'input,AlterTableAlterColumnContextExt<'input>>;

pub trait AlterTableAlterColumnContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves all `TerminalNode`s corresponding to token ALTER in current rule
	fn ALTER_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token ALTER, starting from 0.
	/// Returns `None` if number of children corresponding to token ALTER is less or equal than `i`.
	fn ALTER(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ALTER, i)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token CHANGE
	/// Returns `None` if there is no child corresponding to token CHANGE
	fn CHANGE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CHANGE, 0)
	}
	fn alterColumnSpecList(&self) -> Option<Rc<AlterColumnSpecListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token COLUMN
	/// Returns `None` if there is no child corresponding to token COLUMN
	fn COLUMN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COLUMN, 0)
	}
}

impl<'input> AlterTableAlterColumnContextAttrs<'input> for AlterTableAlterColumnContext<'input>{}

pub struct AlterTableAlterColumnContextExt<'input>{
	base:StatementContextExt<'input>,
	pub table: Option<Rc<IdentifierReferenceContextAll<'input>>>,
	pub columns: Option<Rc<AlterColumnSpecListContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AlterTableAlterColumnContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for AlterTableAlterColumnContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for AlterTableAlterColumnContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_alterTableAlterColumn(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_alterTableAlterColumn(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for AlterTableAlterColumnContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_alterTableAlterColumn(self);
	}
}

impl<'input> CustomRuleContext<'input> for AlterTableAlterColumnContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for AlterTableAlterColumnContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for AlterTableAlterColumnContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for AlterTableAlterColumnContext<'input> {}

impl<'input> AlterTableAlterColumnContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::AlterTableAlterColumnContext(
				BaseParserRuleContext::copy_from(ctx,AlterTableAlterColumnContextExt{
        			table:None, columns:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RefreshFunctionContext<'input> = BaseParserRuleContext<'input,RefreshFunctionContextExt<'input>>;

pub trait RefreshFunctionContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token REFRESH
	/// Returns `None` if there is no child corresponding to token REFRESH
	fn REFRESH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(REFRESH, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FUNCTION
	/// Returns `None` if there is no child corresponding to token FUNCTION
	fn FUNCTION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FUNCTION, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> RefreshFunctionContextAttrs<'input> for RefreshFunctionContext<'input>{}

pub struct RefreshFunctionContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RefreshFunctionContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for RefreshFunctionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for RefreshFunctionContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_refreshFunction(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_refreshFunction(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for RefreshFunctionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_refreshFunction(self);
	}
}

impl<'input> CustomRuleContext<'input> for RefreshFunctionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for RefreshFunctionContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for RefreshFunctionContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for RefreshFunctionContext<'input> {}

impl<'input> RefreshFunctionContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::RefreshFunctionContext(
				BaseParserRuleContext::copy_from(ctx,RefreshFunctionContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CommentTableContext<'input> = BaseParserRuleContext<'input,CommentTableContextExt<'input>>;

pub trait CommentTableContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token COMMENT
	/// Returns `None` if there is no child corresponding to token COMMENT
	fn COMMENT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COMMENT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ON
	/// Returns `None` if there is no child corresponding to token ON
	fn ON(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ON, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token IS
	/// Returns `None` if there is no child corresponding to token IS
	fn IS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IS, 0)
	}
	fn comment(&self) -> Option<Rc<CommentContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> CommentTableContextAttrs<'input> for CommentTableContext<'input>{}

pub struct CommentTableContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CommentTableContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for CommentTableContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CommentTableContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_commentTable(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_commentTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CommentTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_commentTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for CommentTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CommentTableContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CommentTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CommentTableContext<'input> {}

impl<'input> CommentTableContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CommentTableContext(
				BaseParserRuleContext::copy_from(ctx,CommentTableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DescribeProcedureContext<'input> = BaseParserRuleContext<'input,DescribeProcedureContextExt<'input>>;

pub trait DescribeProcedureContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token PROCEDURE
	/// Returns `None` if there is no child corresponding to token PROCEDURE
	fn PROCEDURE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(PROCEDURE, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token DESC
	/// Returns `None` if there is no child corresponding to token DESC
	fn DESC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DESC, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DESCRIBE
	/// Returns `None` if there is no child corresponding to token DESCRIBE
	fn DESCRIBE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DESCRIBE, 0)
	}
}

impl<'input> DescribeProcedureContextAttrs<'input> for DescribeProcedureContext<'input>{}

pub struct DescribeProcedureContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DescribeProcedureContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for DescribeProcedureContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DescribeProcedureContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_describeProcedure(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_describeProcedure(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DescribeProcedureContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_describeProcedure(self);
	}
}

impl<'input> CustomRuleContext<'input> for DescribeProcedureContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DescribeProcedureContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DescribeProcedureContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DescribeProcedureContext<'input> {}

impl<'input> DescribeProcedureContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DescribeProcedureContext(
				BaseParserRuleContext::copy_from(ctx,DescribeProcedureContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateIndexContext<'input> = BaseParserRuleContext<'input,CreateIndexContextExt<'input>>;

pub trait CreateIndexContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token INDEX
	/// Returns `None` if there is no child corresponding to token INDEX
	fn INDEX(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(INDEX, 0)
	}
	fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token ON
	/// Returns `None` if there is no child corresponding to token ON
	fn ON(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ON, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
	fn multipartIdentifierPropertyList(&self) -> Option<Rc<MultipartIdentifierPropertyListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	fn errorCapturingNot(&self) -> Option<Rc<ErrorCapturingNotContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token USING
	/// Returns `None` if there is no child corresponding to token USING
	fn USING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(USING, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OPTIONS
	/// Returns `None` if there is no child corresponding to token OPTIONS
	fn OPTIONS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(OPTIONS, 0)
	}
	fn propertyList(&self) -> Option<Rc<PropertyListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> CreateIndexContextAttrs<'input> for CreateIndexContext<'input>{}

pub struct CreateIndexContextExt<'input>{
	base:StatementContextExt<'input>,
	pub indexType: Option<Rc<IdentifierContextAll<'input>>>,
	pub columns: Option<Rc<MultipartIdentifierPropertyListContextAll<'input>>>,
	pub options: Option<Rc<PropertyListContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateIndexContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for CreateIndexContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CreateIndexContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createIndex(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_createIndex(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CreateIndexContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_createIndex(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateIndexContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateIndexContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateIndexContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateIndexContext<'input> {}

impl<'input> CreateIndexContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateIndexContext(
				BaseParserRuleContext::copy_from(ctx,CreateIndexContextExt{
        			indexType:None, columns:None, options:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type UseNamespaceContext<'input> = BaseParserRuleContext<'input,UseNamespaceContextExt<'input>>;

pub trait UseNamespaceContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token USE
	/// Returns `None` if there is no child corresponding to token USE
	fn USE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(USE, 0)
	}
	fn namespace(&self) -> Option<Rc<NamespaceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> UseNamespaceContextAttrs<'input> for UseNamespaceContext<'input>{}

pub struct UseNamespaceContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UseNamespaceContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for UseNamespaceContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for UseNamespaceContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_useNamespace(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_useNamespace(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for UseNamespaceContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_useNamespace(self);
	}
}

impl<'input> CustomRuleContext<'input> for UseNamespaceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for UseNamespaceContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for UseNamespaceContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for UseNamespaceContext<'input> {}

impl<'input> UseNamespaceContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::UseNamespaceContext(
				BaseParserRuleContext::copy_from(ctx,UseNamespaceContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DropVariableContext<'input> = BaseParserRuleContext<'input,DropVariableContextExt<'input>>;

pub trait DropVariableContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DROP
	/// Returns `None` if there is no child corresponding to token DROP
	fn DROP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DROP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TEMPORARY
	/// Returns `None` if there is no child corresponding to token TEMPORARY
	fn TEMPORARY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TEMPORARY, 0)
	}
	fn variable(&self) -> Option<Rc<VariableContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
}

impl<'input> DropVariableContextAttrs<'input> for DropVariableContext<'input>{}

pub struct DropVariableContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DropVariableContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for DropVariableContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DropVariableContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dropVariable(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_dropVariable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DropVariableContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_dropVariable(self);
	}
}

impl<'input> CustomRuleContext<'input> for DropVariableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DropVariableContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DropVariableContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DropVariableContext<'input> {}

impl<'input> DropVariableContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DropVariableContext(
				BaseParserRuleContext::copy_from(ctx,DropVariableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateNamespaceContext<'input> = BaseParserRuleContext<'input,CreateNamespaceContextExt<'input>>;

pub trait CreateNamespaceContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	fn namespace(&self) -> Option<Rc<NamespaceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	fn errorCapturingNot(&self) -> Option<Rc<ErrorCapturingNotContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	fn commentSpec_all(&self) ->  Vec<Rc<CommentSpecContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn commentSpec(&self, i: usize) -> Option<Rc<CommentSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn locationSpec_all(&self) ->  Vec<Rc<LocationSpecContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn locationSpec(&self, i: usize) -> Option<Rc<LocationSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn collationSpec_all(&self) ->  Vec<Rc<CollationSpecContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn collationSpec(&self, i: usize) -> Option<Rc<CollationSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token WITH in current rule
	fn WITH_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token WITH, starting from 0.
	/// Returns `None` if number of children corresponding to token WITH is less or equal than `i`.
	fn WITH(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(WITH, i)
	}
	fn propertyList_all(&self) ->  Vec<Rc<PropertyListContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn propertyList(&self, i: usize) -> Option<Rc<PropertyListContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token DBPROPERTIES in current rule
	fn DBPROPERTIES_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token DBPROPERTIES, starting from 0.
	/// Returns `None` if number of children corresponding to token DBPROPERTIES is less or equal than `i`.
	fn DBPROPERTIES(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DBPROPERTIES, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token PROPERTIES in current rule
	fn PROPERTIES_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token PROPERTIES, starting from 0.
	/// Returns `None` if number of children corresponding to token PROPERTIES is less or equal than `i`.
	fn PROPERTIES(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(PROPERTIES, i)
	}
}

impl<'input> CreateNamespaceContextAttrs<'input> for CreateNamespaceContext<'input>{}

pub struct CreateNamespaceContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateNamespaceContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for CreateNamespaceContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CreateNamespaceContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createNamespace(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_createNamespace(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CreateNamespaceContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_createNamespace(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateNamespaceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateNamespaceContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateNamespaceContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateNamespaceContext<'input> {}

impl<'input> CreateNamespaceContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateNamespaceContext(
				BaseParserRuleContext::copy_from(ctx,CreateNamespaceContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CallContext<'input> = BaseParserRuleContext<'input,CallContextExt<'input>>;

pub trait CallContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CALL
	/// Returns `None` if there is no child corresponding to token CALL
	fn CALL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CALL, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
	fn functionArgument_all(&self) ->  Vec<Rc<FunctionArgumentContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn functionArgument(&self, i: usize) -> Option<Rc<FunctionArgumentContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> CallContextAttrs<'input> for CallContext<'input>{}

pub struct CallContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CallContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for CallContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CallContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_call(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_call(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CallContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_call(self);
	}
}

impl<'input> CustomRuleContext<'input> for CallContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CallContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CallContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CallContext<'input> {}

impl<'input> CallContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CallContext(
				BaseParserRuleContext::copy_from(ctx,CallContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ShowTblPropertiesContext<'input> = BaseParserRuleContext<'input,ShowTblPropertiesContextExt<'input>>;

pub trait ShowTblPropertiesContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SHOW
	/// Returns `None` if there is no child corresponding to token SHOW
	fn SHOW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SHOW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TBLPROPERTIES
	/// Returns `None` if there is no child corresponding to token TBLPROPERTIES
	fn TBLPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TBLPROPERTIES, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
	fn propertyKeyOrStringLit(&self) -> Option<Rc<PropertyKeyOrStringLitContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ShowTblPropertiesContextAttrs<'input> for ShowTblPropertiesContext<'input>{}

pub struct ShowTblPropertiesContextExt<'input>{
	base:StatementContextExt<'input>,
	pub table: Option<Rc<IdentifierReferenceContextAll<'input>>>,
	pub key: Option<Rc<PropertyKeyOrStringLitContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ShowTblPropertiesContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ShowTblPropertiesContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ShowTblPropertiesContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_showTblProperties(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_showTblProperties(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ShowTblPropertiesContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_showTblProperties(self);
	}
}

impl<'input> CustomRuleContext<'input> for ShowTblPropertiesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ShowTblPropertiesContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ShowTblPropertiesContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ShowTblPropertiesContext<'input> {}

impl<'input> ShowTblPropertiesContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ShowTblPropertiesContext(
				BaseParserRuleContext::copy_from(ctx,ShowTblPropertiesContextExt{
        			table:None, key:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type VisitExecuteImmediateContext<'input> = BaseParserRuleContext<'input,VisitExecuteImmediateContextExt<'input>>;

pub trait VisitExecuteImmediateContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn executeImmediate(&self) -> Option<Rc<ExecuteImmediateContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> VisitExecuteImmediateContextAttrs<'input> for VisitExecuteImmediateContext<'input>{}

pub struct VisitExecuteImmediateContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{VisitExecuteImmediateContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for VisitExecuteImmediateContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for VisitExecuteImmediateContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_visitExecuteImmediate(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_visitExecuteImmediate(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for VisitExecuteImmediateContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_visitExecuteImmediate(self);
	}
}

impl<'input> CustomRuleContext<'input> for VisitExecuteImmediateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for VisitExecuteImmediateContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for VisitExecuteImmediateContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for VisitExecuteImmediateContext<'input> {}

impl<'input> VisitExecuteImmediateContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::VisitExecuteImmediateContext(
				BaseParserRuleContext::copy_from(ctx,VisitExecuteImmediateContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type UnsetTablePropertiesContext<'input> = BaseParserRuleContext<'input,UnsetTablePropertiesContextExt<'input>>;

pub trait UnsetTablePropertiesContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token UNSET
	/// Returns `None` if there is no child corresponding to token UNSET
	fn UNSET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(UNSET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TBLPROPERTIES
	/// Returns `None` if there is no child corresponding to token TBLPROPERTIES
	fn TBLPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TBLPROPERTIES, 0)
	}
	fn propertyList(&self) -> Option<Rc<PropertyListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
}

impl<'input> UnsetTablePropertiesContextAttrs<'input> for UnsetTablePropertiesContext<'input>{}

pub struct UnsetTablePropertiesContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UnsetTablePropertiesContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for UnsetTablePropertiesContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for UnsetTablePropertiesContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_unsetTableProperties(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_unsetTableProperties(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for UnsetTablePropertiesContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_unsetTableProperties(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnsetTablePropertiesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for UnsetTablePropertiesContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for UnsetTablePropertiesContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for UnsetTablePropertiesContext<'input> {}

impl<'input> UnsetTablePropertiesContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::UnsetTablePropertiesContext(
				BaseParserRuleContext::copy_from(ctx,UnsetTablePropertiesContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetTableLocationContext<'input> = BaseParserRuleContext<'input,SetTableLocationContextExt<'input>>;

pub trait SetTableLocationContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	fn locationSpec(&self) -> Option<Rc<LocationSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SetTableLocationContextAttrs<'input> for SetTableLocationContext<'input>{}

pub struct SetTableLocationContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetTableLocationContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SetTableLocationContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SetTableLocationContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setTableLocation(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_setTableLocation(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SetTableLocationContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_setTableLocation(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetTableLocationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for SetTableLocationContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for SetTableLocationContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for SetTableLocationContext<'input> {}

impl<'input> SetTableLocationContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::SetTableLocationContext(
				BaseParserRuleContext::copy_from(ctx,SetTableLocationContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DropTableColumnsContext<'input> = BaseParserRuleContext<'input,DropTableColumnsContextExt<'input>>;

pub trait DropTableColumnsContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token DROP
	/// Returns `None` if there is no child corresponding to token DROP
	fn DROP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DROP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COLUMN
	/// Returns `None` if there is no child corresponding to token COLUMN
	fn COLUMN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COLUMN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COLUMNS
	/// Returns `None` if there is no child corresponding to token COLUMNS
	fn COLUMNS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COLUMNS, 0)
	}
	fn multipartIdentifierList(&self) -> Option<Rc<MultipartIdentifierListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
}

impl<'input> DropTableColumnsContextAttrs<'input> for DropTableColumnsContext<'input>{}

pub struct DropTableColumnsContextExt<'input>{
	base:StatementContextExt<'input>,
	pub columns: Option<Rc<MultipartIdentifierListContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DropTableColumnsContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for DropTableColumnsContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DropTableColumnsContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dropTableColumns(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_dropTableColumns(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DropTableColumnsContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_dropTableColumns(self);
	}
}

impl<'input> CustomRuleContext<'input> for DropTableColumnsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for DropTableColumnsContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for DropTableColumnsContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for DropTableColumnsContext<'input> {}

impl<'input> DropTableColumnsContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::DropTableColumnsContext(
				BaseParserRuleContext::copy_from(ctx,DropTableColumnsContextExt{
        			columns:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ShowViewsContext<'input> = BaseParserRuleContext<'input,ShowViewsContextExt<'input>>;

pub trait ShowViewsContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SHOW
	/// Returns `None` if there is no child corresponding to token SHOW
	fn SHOW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SHOW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEWS
	/// Returns `None` if there is no child corresponding to token VIEWS
	fn VIEWS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(VIEWS, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IN
	/// Returns `None` if there is no child corresponding to token IN
	fn IN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IN, 0)
	}
	fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LIKE
	/// Returns `None` if there is no child corresponding to token LIKE
	fn LIKE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LIKE, 0)
	}
}

impl<'input> ShowViewsContextAttrs<'input> for ShowViewsContext<'input>{}

pub struct ShowViewsContextExt<'input>{
	base:StatementContextExt<'input>,
	pub pattern: Option<Rc<StringLitContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ShowViewsContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ShowViewsContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ShowViewsContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_showViews(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_showViews(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ShowViewsContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_showViews(self);
	}
}

impl<'input> CustomRuleContext<'input> for ShowViewsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ShowViewsContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ShowViewsContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ShowViewsContext<'input> {}

impl<'input> ShowViewsContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ShowViewsContext(
				BaseParserRuleContext::copy_from(ctx,ShowViewsContextExt{
        			pattern:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CreateMetricViewContext<'input> = BaseParserRuleContext<'input,CreateMetricViewContextExt<'input>>;

pub trait CreateMetricViewContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CREATE
	/// Returns `None` if there is no child corresponding to token CREATE
	fn CREATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CREATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	fn codeLiteral(&self) -> Option<Rc<CodeLiteralContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	fn errorCapturingNot(&self) -> Option<Rc<ErrorCapturingNotContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	fn identifierCommentList(&self) -> Option<Rc<IdentifierCommentListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn routineLanguage_all(&self) ->  Vec<Rc<RoutineLanguageContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn routineLanguage(&self, i: usize) -> Option<Rc<RoutineLanguageContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn commentSpec_all(&self) ->  Vec<Rc<CommentSpecContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn commentSpec(&self, i: usize) -> Option<Rc<CommentSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token WITH in current rule
	fn WITH_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token WITH, starting from 0.
	/// Returns `None` if number of children corresponding to token WITH is less or equal than `i`.
	fn WITH(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(WITH, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token METRICS in current rule
	fn METRICS_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token METRICS, starting from 0.
	/// Returns `None` if number of children corresponding to token METRICS is less or equal than `i`.
	fn METRICS(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(METRICS, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token TBLPROPERTIES in current rule
	fn TBLPROPERTIES_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token TBLPROPERTIES, starting from 0.
	/// Returns `None` if number of children corresponding to token TBLPROPERTIES is less or equal than `i`.
	fn TBLPROPERTIES(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TBLPROPERTIES, i)
	}
	fn propertyList_all(&self) ->  Vec<Rc<PropertyListContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn propertyList(&self, i: usize) -> Option<Rc<PropertyListContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> CreateMetricViewContextAttrs<'input> for CreateMetricViewContext<'input>{}

pub struct CreateMetricViewContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CreateMetricViewContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for CreateMetricViewContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CreateMetricViewContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_createMetricView(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_createMetricView(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CreateMetricViewContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_createMetricView(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateMetricViewContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CreateMetricViewContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CreateMetricViewContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CreateMetricViewContext<'input> {}

impl<'input> CreateMetricViewContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CreateMetricViewContext(
				BaseParserRuleContext::copy_from(ctx,CreateMetricViewContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ShowFunctionsContext<'input> = BaseParserRuleContext<'input,ShowFunctionsContextExt<'input>>;

pub trait ShowFunctionsContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SHOW
	/// Returns `None` if there is no child corresponding to token SHOW
	fn SHOW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SHOW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FUNCTIONS
	/// Returns `None` if there is no child corresponding to token FUNCTIONS
	fn FUNCTIONS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FUNCTIONS, 0)
	}
	fn simpleIdentifier(&self) -> Option<Rc<SimpleIdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IN
	/// Returns `None` if there is no child corresponding to token IN
	fn IN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IN, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LIKE
	/// Returns `None` if there is no child corresponding to token LIKE
	fn LIKE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LIKE, 0)
	}
	fn multipartIdentifier(&self) -> Option<Rc<MultipartIdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ShowFunctionsContextAttrs<'input> for ShowFunctionsContext<'input>{}

pub struct ShowFunctionsContextExt<'input>{
	base:StatementContextExt<'input>,
	pub functionScope: Option<Rc<SimpleIdentifierContextAll<'input>>>,
	pub ns: Option<Rc<IdentifierReferenceContextAll<'input>>>,
	pub legacy: Option<Rc<MultipartIdentifierContextAll<'input>>>,
	pub pattern: Option<Rc<StringLitContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ShowFunctionsContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ShowFunctionsContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ShowFunctionsContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_showFunctions(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_showFunctions(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ShowFunctionsContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_showFunctions(self);
	}
}

impl<'input> CustomRuleContext<'input> for ShowFunctionsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for ShowFunctionsContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for ShowFunctionsContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for ShowFunctionsContext<'input> {}

impl<'input> ShowFunctionsContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::ShowFunctionsContext(
				BaseParserRuleContext::copy_from(ctx,ShowFunctionsContextExt{
        			functionScope:None, ns:None, legacy:None, pattern:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CacheTableContext<'input> = BaseParserRuleContext<'input,CacheTableContextExt<'input>>;

pub trait CacheTableContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CACHE
	/// Returns `None` if there is no child corresponding to token CACHE
	fn CACHE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CACHE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LAZY
	/// Returns `None` if there is no child corresponding to token LAZY
	fn LAZY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LAZY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OPTIONS
	/// Returns `None` if there is no child corresponding to token OPTIONS
	fn OPTIONS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(OPTIONS, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn propertyList(&self) -> Option<Rc<PropertyListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
}

impl<'input> CacheTableContextAttrs<'input> for CacheTableContext<'input>{}

pub struct CacheTableContextExt<'input>{
	base:StatementContextExt<'input>,
	pub options: Option<Rc<PropertyListContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CacheTableContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for CacheTableContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CacheTableContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_cacheTable(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_cacheTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CacheTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_cacheTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for CacheTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for CacheTableContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for CacheTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for CacheTableContext<'input> {}

impl<'input> CacheTableContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::CacheTableContext(
				BaseParserRuleContext::copy_from(ctx,CacheTableContextExt{
        			options:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AddTableColumnsContext<'input> = BaseParserRuleContext<'input,AddTableColumnsContextExt<'input>>;

pub trait AddTableColumnsContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token ADD
	/// Returns `None` if there is no child corresponding to token ADD
	fn ADD(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ADD, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COLUMN
	/// Returns `None` if there is no child corresponding to token COLUMN
	fn COLUMN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COLUMN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COLUMNS
	/// Returns `None` if there is no child corresponding to token COLUMNS
	fn COLUMNS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COLUMNS, 0)
	}
	fn qualifiedColTypeWithPositionList(&self) -> Option<Rc<QualifiedColTypeWithPositionListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
}

impl<'input> AddTableColumnsContextAttrs<'input> for AddTableColumnsContext<'input>{}

pub struct AddTableColumnsContextExt<'input>{
	base:StatementContextExt<'input>,
	pub columns: Option<Rc<QualifiedColTypeWithPositionListContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AddTableColumnsContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for AddTableColumnsContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for AddTableColumnsContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_addTableColumns(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_addTableColumns(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for AddTableColumnsContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_addTableColumns(self);
	}
}

impl<'input> CustomRuleContext<'input> for AddTableColumnsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for AddTableColumnsContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for AddTableColumnsContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for AddTableColumnsContext<'input> {}

impl<'input> AddTableColumnsContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::AddTableColumnsContext(
				BaseParserRuleContext::copy_from(ctx,AddTableColumnsContextExt{
        			columns:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetTablePropertiesContext<'input> = BaseParserRuleContext<'input,SetTablePropertiesContextExt<'input>>;

pub trait SetTablePropertiesContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ALTER
	/// Returns `None` if there is no child corresponding to token ALTER
	fn ALTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ALTER, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TBLPROPERTIES
	/// Returns `None` if there is no child corresponding to token TBLPROPERTIES
	fn TBLPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TBLPROPERTIES, 0)
	}
	fn propertyList(&self) -> Option<Rc<PropertyListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token VIEW
	/// Returns `None` if there is no child corresponding to token VIEW
	fn VIEW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(VIEW, 0)
	}
}

impl<'input> SetTablePropertiesContextAttrs<'input> for SetTablePropertiesContext<'input>{}

pub struct SetTablePropertiesContextExt<'input>{
	base:StatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetTablePropertiesContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SetTablePropertiesContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SetTablePropertiesContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setTableProperties(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_setTableProperties(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SetTablePropertiesContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_setTableProperties(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetTablePropertiesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}

impl<'input> Borrow<StatementContextExt<'input>> for SetTablePropertiesContext<'input>{
	fn borrow(&self) -> &StatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StatementContextExt<'input>> for SetTablePropertiesContext<'input>{
	fn borrow_mut(&mut self) -> &mut StatementContextExt<'input> { &mut self.base }
}

impl<'input> StatementContextAttrs<'input> for SetTablePropertiesContext<'input> {}

impl<'input> SetTablePropertiesContextExt<'input>{
	fn new(ctx: &dyn StatementContextAttrs<'input>) -> Rc<StatementContextAll<'input>>  {
		Rc::new(
			StatementContextAll::SetTablePropertiesContext(
				BaseParserRuleContext::copy_from(ctx,SetTablePropertiesContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn statement(&mut self,)
	-> Result<Rc<StatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 58, RULE_statement);
        let mut _localctx: Rc<StatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(1755);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(176,&mut recog.base)? {
				1 =>{
					let tmp = StatementDefaultContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule query*/
					recog.base.set_state(813);
					recog.query()?;

					}
				}
			,
				2 =>{
					let tmp = VisitExecuteImmediateContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule executeImmediate*/
					recog.base.set_state(814);
					recog.executeImmediate()?;

					}
				}
			,
				3 =>{
					let tmp = DmlStatementContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(816);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==WITH {
						{
						/*InvokeRule ctes*/
						recog.base.set_state(815);
						recog.ctes()?;

						}
					}

					/*InvokeRule dmlStatementNoWith*/
					recog.base.set_state(818);
					recog.dmlStatementNoWith()?;

					}
				}
			,
				4 =>{
					let tmp = UseContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(819);
					recog.base.match_token(USE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(820);
					recog.identifierReference()?;

					}
				}
			,
				5 =>{
					let tmp = UseNamespaceContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					recog.base.set_state(821);
					recog.base.match_token(USE,&mut recog.err_handler)?;

					/*InvokeRule namespace*/
					recog.base.set_state(822);
					recog.namespace()?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(823);
					recog.identifierReference()?;

					}
				}
			,
				6 =>{
					let tmp = SetCatalogContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 6);
					_localctx = tmp;
					{
					recog.base.set_state(825);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(826);
					recog.base.match_token(CATALOG,&mut recog.err_handler)?;

					/*InvokeRule catalogIdentifierReference*/
					recog.base.set_state(827);
					recog.catalogIdentifierReference()?;

					}
				}
			,
				7 =>{
					let tmp = CreateNamespaceContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 7);
					_localctx = tmp;
					{
					recog.base.set_state(828);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					/*InvokeRule namespace*/
					recog.base.set_state(829);
					recog.namespace()?;

					recog.base.set_state(834);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(36,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(830);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							/*InvokeRule errorCapturingNot*/
							recog.base.set_state(831);
							recog.errorCapturingNot()?;

							recog.base.set_state(832);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(836);
					recog.identifierReference()?;

					recog.base.set_state(845);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMENT || _la==DEFAULT || _la==LOCATION || _la==WITH {
						{
						recog.base.set_state(843);
						recog.err_handler.sync(&mut recog.base)?;
						match recog.base.input.la(1) {
						 COMMENT 
							=> {
								{
								/*InvokeRule commentSpec*/
								recog.base.set_state(837);
								recog.commentSpec()?;

								}
							}

						 LOCATION 
							=> {
								{
								/*InvokeRule locationSpec*/
								recog.base.set_state(838);
								recog.locationSpec()?;

								}
							}

						 DEFAULT 
							=> {
								{
								/*InvokeRule collationSpec*/
								recog.base.set_state(839);
								recog.collationSpec()?;

								}
							}

						 WITH 
							=> {
								{
								{
								recog.base.set_state(840);
								recog.base.match_token(WITH,&mut recog.err_handler)?;

								recog.base.set_state(841);
								_la = recog.base.input.la(1);
								if { !(_la==DBPROPERTIES || _la==PROPERTIES) } {
									recog.err_handler.recover_inline(&mut recog.base)?;

								}
								else {
									if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
									recog.err_handler.report_match(&mut recog.base);
									recog.base.consume(&mut recog.err_handler);
								}
								/*InvokeRule propertyList*/
								recog.base.set_state(842);
								recog.propertyList()?;

								}
								}
							}

							_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
						}
						}
						recog.base.set_state(847);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				8 =>{
					let tmp = SetNamespacePropertiesContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 8);
					_localctx = tmp;
					{
					recog.base.set_state(848);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					/*InvokeRule namespace*/
					recog.base.set_state(849);
					recog.namespace()?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(850);
					recog.identifierReference()?;

					recog.base.set_state(851);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(852);
					_la = recog.base.input.la(1);
					if { !(_la==DBPROPERTIES || _la==PROPERTIES) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					/*InvokeRule propertyList*/
					recog.base.set_state(853);
					recog.propertyList()?;

					}
				}
			,
				9 =>{
					let tmp = UnsetNamespacePropertiesContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 9);
					_localctx = tmp;
					{
					recog.base.set_state(855);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					/*InvokeRule namespace*/
					recog.base.set_state(856);
					recog.namespace()?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(857);
					recog.identifierReference()?;

					recog.base.set_state(858);
					recog.base.match_token(UNSET,&mut recog.err_handler)?;

					recog.base.set_state(859);
					_la = recog.base.input.la(1);
					if { !(_la==DBPROPERTIES || _la==PROPERTIES) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					/*InvokeRule propertyList*/
					recog.base.set_state(860);
					recog.propertyList()?;

					}
				}
			,
				10 =>{
					let tmp = SetNamespaceCollationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 10);
					_localctx = tmp;
					{
					recog.base.set_state(862);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					/*InvokeRule namespace*/
					recog.base.set_state(863);
					recog.namespace()?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(864);
					recog.identifierReference()?;

					/*InvokeRule collationSpec*/
					recog.base.set_state(865);
					recog.collationSpec()?;

					}
				}
			,
				11 =>{
					let tmp = SetNamespaceLocationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 11);
					_localctx = tmp;
					{
					recog.base.set_state(867);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					/*InvokeRule namespace*/
					recog.base.set_state(868);
					recog.namespace()?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(869);
					recog.identifierReference()?;

					recog.base.set_state(870);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					/*InvokeRule locationSpec*/
					recog.base.set_state(871);
					recog.locationSpec()?;

					}
				}
			,
				12 =>{
					let tmp = DropNamespaceContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 12);
					_localctx = tmp;
					{
					recog.base.set_state(873);
					recog.base.match_token(DROP,&mut recog.err_handler)?;

					/*InvokeRule namespace*/
					recog.base.set_state(874);
					recog.namespace()?;

					recog.base.set_state(877);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(39,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(875);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(876);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(879);
					recog.identifierReference()?;

					recog.base.set_state(881);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==CASCADE || _la==RESTRICT {
						{
						recog.base.set_state(880);
						_la = recog.base.input.la(1);
						if { !(_la==CASCADE || _la==RESTRICT) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
					}

					}
				}
			,
				13 =>{
					let tmp = ShowNamespacesContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 13);
					_localctx = tmp;
					{
					recog.base.set_state(883);
					recog.base.match_token(SHOW,&mut recog.err_handler)?;

					/*InvokeRule namespaces*/
					recog.base.set_state(884);
					recog.namespaces()?;

					recog.base.set_state(887);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(41,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(885);
							_la = recog.base.input.la(1);
							if { !(_la==FROM || _la==IN) } {
								recog.err_handler.recover_inline(&mut recog.base)?;

							}
							else {
								if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
								recog.err_handler.report_match(&mut recog.base);
								recog.base.consume(&mut recog.err_handler);
							}
							/*InvokeRule multipartIdentifier*/
							recog.base.set_state(886);
							recog.multipartIdentifier()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(893);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(43,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(890);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(42,&mut recog.base)? {
								x if x == 1=>{
									{
									recog.base.set_state(889);
									recog.base.match_token(LIKE,&mut recog.err_handler)?;

									}
								}

								_ => {}
							}
							/*InvokeRule stringLit*/
							recog.base.set_state(892);
							let tmp = recog.stringLit()?;
							if let StatementContextAll::ShowNamespacesContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.pattern = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					}
				}
			,
				14 =>{
					let tmp = CreateTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 14);
					_localctx = tmp;
					{
					/*InvokeRule createTableHeader*/
					recog.base.set_state(895);
					recog.createTableHeader()?;

					recog.base.set_state(900);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(44,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(896);
							recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

							/*InvokeRule tableElementList*/
							recog.base.set_state(897);
							recog.tableElementList()?;

							recog.base.set_state(898);
							recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					recog.base.set_state(903);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==USING {
						{
						/*InvokeRule tableProvider*/
						recog.base.set_state(902);
						recog.tableProvider()?;

						}
					}

					/*InvokeRule createTableClauses*/
					recog.base.set_state(905);
					recog.createTableClauses()?;

					recog.base.set_state(910);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LEFT_PAREN || _la==AS || _la==FROM || _la==MAP || _la==REDUCE || _la==SELECT || _la==TABLE || _la==VALUES || _la==WITH {
						{
						recog.base.set_state(907);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==AS {
							{
							recog.base.set_state(906);
							recog.base.match_token(AS,&mut recog.err_handler)?;

							}
						}

						/*InvokeRule query*/
						recog.base.set_state(909);
						recog.query()?;

						}
					}

					}
				}
			,
				15 =>{
					let tmp = CreateTableLikeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 15);
					_localctx = tmp;
					{
					recog.base.set_state(912);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(913);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(918);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(48,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(914);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							/*InvokeRule errorCapturingNot*/
							recog.base.set_state(915);
							recog.errorCapturingNot()?;

							recog.base.set_state(916);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule tableIdentifier*/
					recog.base.set_state(920);
					let tmp = recog.tableIdentifier()?;
					if let StatementContextAll::CreateTableLikeContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.target = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(921);
					recog.base.match_token(LIKE,&mut recog.err_handler)?;

					/*InvokeRule tableIdentifier*/
					recog.base.set_state(922);
					let tmp = recog.tableIdentifier()?;
					if let StatementContextAll::CreateTableLikeContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.source = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(931);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==LOCATION || _la==ROW || _la==STORED || _la==TBLPROPERTIES || _la==USING {
						{
						recog.base.set_state(929);
						recog.err_handler.sync(&mut recog.base)?;
						match recog.base.input.la(1) {
						 USING 
							=> {
								{
								/*InvokeRule tableProvider*/
								recog.base.set_state(923);
								recog.tableProvider()?;

								}
							}

						 ROW 
							=> {
								{
								/*InvokeRule rowFormat*/
								recog.base.set_state(924);
								recog.rowFormat()?;

								}
							}

						 STORED 
							=> {
								{
								/*InvokeRule createFileFormat*/
								recog.base.set_state(925);
								recog.createFileFormat()?;

								}
							}

						 LOCATION 
							=> {
								{
								/*InvokeRule locationSpec*/
								recog.base.set_state(926);
								recog.locationSpec()?;

								}
							}

						 TBLPROPERTIES 
							=> {
								{
								{
								recog.base.set_state(927);
								recog.base.match_token(TBLPROPERTIES,&mut recog.err_handler)?;

								/*InvokeRule propertyList*/
								recog.base.set_state(928);
								let tmp = recog.propertyList()?;
								if let StatementContextAll::CreateTableLikeContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
								ctx.tableProps = Some(tmp.clone()); } else {unreachable!("cant cast");}  

								}
								}
							}

							_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
						}
						}
						recog.base.set_state(933);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}
			,
				16 =>{
					let tmp = ReplaceTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 16);
					_localctx = tmp;
					{
					/*InvokeRule replaceTableHeader*/
					recog.base.set_state(934);
					recog.replaceTableHeader()?;

					recog.base.set_state(939);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(51,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(935);
							recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

							/*InvokeRule tableElementList*/
							recog.base.set_state(936);
							recog.tableElementList()?;

							recog.base.set_state(937);
							recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					recog.base.set_state(942);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==USING {
						{
						/*InvokeRule tableProvider*/
						recog.base.set_state(941);
						recog.tableProvider()?;

						}
					}

					/*InvokeRule createTableClauses*/
					recog.base.set_state(944);
					recog.createTableClauses()?;

					recog.base.set_state(949);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LEFT_PAREN || _la==AS || _la==FROM || _la==MAP || _la==REDUCE || _la==SELECT || _la==TABLE || _la==VALUES || _la==WITH {
						{
						recog.base.set_state(946);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==AS {
							{
							recog.base.set_state(945);
							recog.base.match_token(AS,&mut recog.err_handler)?;

							}
						}

						/*InvokeRule query*/
						recog.base.set_state(948);
						recog.query()?;

						}
					}

					}
				}
			,
				17 =>{
					let tmp = AnalyzeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 17);
					_localctx = tmp;
					{
					recog.base.set_state(951);
					recog.base.match_token(ANALYZE,&mut recog.err_handler)?;

					recog.base.set_state(952);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(953);
					recog.identifierReference()?;

					recog.base.set_state(955);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==PARTITION {
						{
						/*InvokeRule partitionSpec*/
						recog.base.set_state(954);
						recog.partitionSpec()?;

						}
					}

					recog.base.set_state(957);
					recog.base.match_token(COMPUTE,&mut recog.err_handler)?;

					recog.base.set_state(958);
					recog.base.match_token(STATISTICS,&mut recog.err_handler)?;

					recog.base.set_state(966);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(56,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule simpleIdentifier*/
							recog.base.set_state(959);
							recog.simpleIdentifier()?;

							}
						}

						x if x == 2=>{
							{
							recog.base.set_state(960);
							recog.base.match_token(FOR,&mut recog.err_handler)?;

							recog.base.set_state(961);
							recog.base.match_token(COLUMNS,&mut recog.err_handler)?;

							/*InvokeRule identifierSeq*/
							recog.base.set_state(962);
							recog.identifierSeq()?;

							}
						}

						x if x == 3=>{
							{
							recog.base.set_state(963);
							recog.base.match_token(FOR,&mut recog.err_handler)?;

							recog.base.set_state(964);
							recog.base.match_token(ALL,&mut recog.err_handler)?;

							recog.base.set_state(965);
							recog.base.match_token(COLUMNS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}
			,
				18 =>{
					let tmp = AnalyzeTablesContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 18);
					_localctx = tmp;
					{
					recog.base.set_state(968);
					recog.base.match_token(ANALYZE,&mut recog.err_handler)?;

					recog.base.set_state(969);
					recog.base.match_token(TABLES,&mut recog.err_handler)?;

					recog.base.set_state(972);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==FROM || _la==IN {
						{
						recog.base.set_state(970);
						_la = recog.base.input.la(1);
						if { !(_la==FROM || _la==IN) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						/*InvokeRule identifierReference*/
						recog.base.set_state(971);
						recog.identifierReference()?;

						}
					}

					recog.base.set_state(974);
					recog.base.match_token(COMPUTE,&mut recog.err_handler)?;

					recog.base.set_state(975);
					recog.base.match_token(STATISTICS,&mut recog.err_handler)?;

					recog.base.set_state(977);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(58,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule simpleIdentifier*/
							recog.base.set_state(976);
							recog.simpleIdentifier()?;

							}
						}

						_ => {}
					}
					}
				}
			,
				19 =>{
					let tmp = AddTableColumnsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 19);
					_localctx = tmp;
					{
					recog.base.set_state(979);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(980);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(981);
					recog.identifierReference()?;

					recog.base.set_state(982);
					recog.base.match_token(ADD,&mut recog.err_handler)?;

					recog.base.set_state(983);
					_la = recog.base.input.la(1);
					if { !(_la==COLUMN || _la==COLUMNS) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					/*InvokeRule qualifiedColTypeWithPositionList*/
					recog.base.set_state(984);
					let tmp = recog.qualifiedColTypeWithPositionList()?;
					if let StatementContextAll::AddTableColumnsContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.columns = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				20 =>{
					let tmp = AddTableColumnsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 20);
					_localctx = tmp;
					{
					recog.base.set_state(986);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(987);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(988);
					recog.identifierReference()?;

					recog.base.set_state(989);
					recog.base.match_token(ADD,&mut recog.err_handler)?;

					recog.base.set_state(990);
					_la = recog.base.input.la(1);
					if { !(_la==COLUMN || _la==COLUMNS) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(991);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule qualifiedColTypeWithPositionList*/
					recog.base.set_state(992);
					let tmp = recog.qualifiedColTypeWithPositionList()?;
					if let StatementContextAll::AddTableColumnsContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.columns = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(993);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				21 =>{
					let tmp = RenameTableColumnContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 21);
					_localctx = tmp;
					{
					recog.base.set_state(995);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(996);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(997);
					let tmp = recog.identifierReference()?;
					if let StatementContextAll::RenameTableColumnContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.table = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(998);
					recog.base.match_token(RENAME,&mut recog.err_handler)?;

					recog.base.set_state(999);
					recog.base.match_token(COLUMN,&mut recog.err_handler)?;

					/*InvokeRule multipartIdentifier*/
					recog.base.set_state(1000);
					let tmp = recog.multipartIdentifier()?;
					if let StatementContextAll::RenameTableColumnContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.from = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1001);
					recog.base.match_token(TO,&mut recog.err_handler)?;

					/*InvokeRule errorCapturingIdentifier*/
					recog.base.set_state(1002);
					let tmp = recog.errorCapturingIdentifier()?;
					if let StatementContextAll::RenameTableColumnContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.to = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				22 =>{
					let tmp = DropTableColumnsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 22);
					_localctx = tmp;
					{
					recog.base.set_state(1004);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1005);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1006);
					recog.identifierReference()?;

					recog.base.set_state(1007);
					recog.base.match_token(DROP,&mut recog.err_handler)?;

					recog.base.set_state(1008);
					_la = recog.base.input.la(1);
					if { !(_la==COLUMN || _la==COLUMNS) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(1011);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IF {
						{
						recog.base.set_state(1009);
						recog.base.match_token(IF,&mut recog.err_handler)?;

						recog.base.set_state(1010);
						recog.base.match_token(EXISTS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(1013);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule multipartIdentifierList*/
					recog.base.set_state(1014);
					let tmp = recog.multipartIdentifierList()?;
					if let StatementContextAll::DropTableColumnsContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.columns = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1015);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				23 =>{
					let tmp = DropTableColumnsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 23);
					_localctx = tmp;
					{
					recog.base.set_state(1017);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1018);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1019);
					recog.identifierReference()?;

					recog.base.set_state(1020);
					recog.base.match_token(DROP,&mut recog.err_handler)?;

					recog.base.set_state(1021);
					_la = recog.base.input.la(1);
					if { !(_la==COLUMN || _la==COLUMNS) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(1024);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(60,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1022);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(1023);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule multipartIdentifierList*/
					recog.base.set_state(1026);
					let tmp = recog.multipartIdentifierList()?;
					if let StatementContextAll::DropTableColumnsContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.columns = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				24 =>{
					let tmp = RenameTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 24);
					_localctx = tmp;
					{
					recog.base.set_state(1028);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1029);
					_la = recog.base.input.la(1);
					if { !(_la==TABLE || _la==VIEW) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(1030);
					let tmp = recog.identifierReference()?;
					if let StatementContextAll::RenameTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.from = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1031);
					recog.base.match_token(RENAME,&mut recog.err_handler)?;

					recog.base.set_state(1032);
					recog.base.match_token(TO,&mut recog.err_handler)?;

					/*InvokeRule multipartIdentifier*/
					recog.base.set_state(1033);
					let tmp = recog.multipartIdentifier()?;
					if let StatementContextAll::RenameTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.to = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				25 =>{
					let tmp = SetTablePropertiesContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 25);
					_localctx = tmp;
					{
					recog.base.set_state(1035);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1036);
					_la = recog.base.input.la(1);
					if { !(_la==TABLE || _la==VIEW) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(1037);
					recog.identifierReference()?;

					recog.base.set_state(1038);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(1039);
					recog.base.match_token(TBLPROPERTIES,&mut recog.err_handler)?;

					/*InvokeRule propertyList*/
					recog.base.set_state(1040);
					recog.propertyList()?;

					}
				}
			,
				26 =>{
					let tmp = UnsetTablePropertiesContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 26);
					_localctx = tmp;
					{
					recog.base.set_state(1042);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1043);
					_la = recog.base.input.la(1);
					if { !(_la==TABLE || _la==VIEW) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(1044);
					recog.identifierReference()?;

					recog.base.set_state(1045);
					recog.base.match_token(UNSET,&mut recog.err_handler)?;

					recog.base.set_state(1046);
					recog.base.match_token(TBLPROPERTIES,&mut recog.err_handler)?;

					recog.base.set_state(1049);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IF {
						{
						recog.base.set_state(1047);
						recog.base.match_token(IF,&mut recog.err_handler)?;

						recog.base.set_state(1048);
						recog.base.match_token(EXISTS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule propertyList*/
					recog.base.set_state(1051);
					recog.propertyList()?;

					}
				}
			,
				27 =>{
					let tmp = AlterTableAlterColumnContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 27);
					_localctx = tmp;
					{
					recog.base.set_state(1053);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1054);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1055);
					let tmp = recog.identifierReference()?;
					if let StatementContextAll::AlterTableAlterColumnContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.table = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1056);
					_la = recog.base.input.la(1);
					if { !(_la==ALTER || _la==CHANGE) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(1058);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(62,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1057);
							recog.base.match_token(COLUMN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule alterColumnSpecList*/
					recog.base.set_state(1060);
					let tmp = recog.alterColumnSpecList()?;
					if let StatementContextAll::AlterTableAlterColumnContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.columns = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				28 =>{
					let tmp = HiveChangeColumnContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 28);
					_localctx = tmp;
					{
					recog.base.set_state(1062);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1063);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1064);
					let tmp = recog.identifierReference()?;
					if let StatementContextAll::HiveChangeColumnContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.table = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1066);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==PARTITION {
						{
						/*InvokeRule partitionSpec*/
						recog.base.set_state(1065);
						recog.partitionSpec()?;

						}
					}

					recog.base.set_state(1068);
					recog.base.match_token(CHANGE,&mut recog.err_handler)?;

					recog.base.set_state(1070);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(64,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1069);
							recog.base.match_token(COLUMN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule multipartIdentifier*/
					recog.base.set_state(1072);
					let tmp = recog.multipartIdentifier()?;
					if let StatementContextAll::HiveChangeColumnContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.colName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					/*InvokeRule colType*/
					recog.base.set_state(1073);
					recog.colType()?;

					recog.base.set_state(1075);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==AFTER || _la==FIRST {
						{
						/*InvokeRule colPosition*/
						recog.base.set_state(1074);
						recog.colPosition()?;

						}
					}

					}
				}
			,
				29 =>{
					let tmp = HiveReplaceColumnsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 29);
					_localctx = tmp;
					{
					recog.base.set_state(1077);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1078);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1079);
					let tmp = recog.identifierReference()?;
					if let StatementContextAll::HiveReplaceColumnsContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.table = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1081);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==PARTITION {
						{
						/*InvokeRule partitionSpec*/
						recog.base.set_state(1080);
						recog.partitionSpec()?;

						}
					}

					recog.base.set_state(1083);
					recog.base.match_token(REPLACE,&mut recog.err_handler)?;

					recog.base.set_state(1084);
					recog.base.match_token(COLUMNS,&mut recog.err_handler)?;

					recog.base.set_state(1085);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule qualifiedColTypeWithPositionList*/
					recog.base.set_state(1086);
					let tmp = recog.qualifiedColTypeWithPositionList()?;
					if let StatementContextAll::HiveReplaceColumnsContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.columns = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1087);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				30 =>{
					let tmp = SetTableSerDeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 30);
					_localctx = tmp;
					{
					recog.base.set_state(1089);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1090);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1091);
					recog.identifierReference()?;

					recog.base.set_state(1093);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==PARTITION {
						{
						/*InvokeRule partitionSpec*/
						recog.base.set_state(1092);
						recog.partitionSpec()?;

						}
					}

					recog.base.set_state(1095);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(1096);
					recog.base.match_token(SERDE,&mut recog.err_handler)?;

					/*InvokeRule stringLit*/
					recog.base.set_state(1097);
					recog.stringLit()?;

					recog.base.set_state(1101);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==WITH {
						{
						recog.base.set_state(1098);
						recog.base.match_token(WITH,&mut recog.err_handler)?;

						recog.base.set_state(1099);
						recog.base.match_token(SERDEPROPERTIES,&mut recog.err_handler)?;

						/*InvokeRule propertyList*/
						recog.base.set_state(1100);
						recog.propertyList()?;

						}
					}

					}
				}
			,
				31 =>{
					let tmp = SetTableSerDeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 31);
					_localctx = tmp;
					{
					recog.base.set_state(1103);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1104);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1105);
					recog.identifierReference()?;

					recog.base.set_state(1107);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==PARTITION {
						{
						/*InvokeRule partitionSpec*/
						recog.base.set_state(1106);
						recog.partitionSpec()?;

						}
					}

					recog.base.set_state(1109);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(1110);
					recog.base.match_token(SERDEPROPERTIES,&mut recog.err_handler)?;

					/*InvokeRule propertyList*/
					recog.base.set_state(1111);
					recog.propertyList()?;

					}
				}
			,
				32 =>{
					let tmp = AddTablePartitionContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 32);
					_localctx = tmp;
					{
					recog.base.set_state(1113);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1114);
					_la = recog.base.input.la(1);
					if { !(_la==TABLE || _la==VIEW) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(1115);
					recog.identifierReference()?;

					recog.base.set_state(1116);
					recog.base.match_token(ADD,&mut recog.err_handler)?;

					recog.base.set_state(1121);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IF {
						{
						recog.base.set_state(1117);
						recog.base.match_token(IF,&mut recog.err_handler)?;

						/*InvokeRule errorCapturingNot*/
						recog.base.set_state(1118);
						recog.errorCapturingNot()?;

						recog.base.set_state(1119);
						recog.base.match_token(EXISTS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(1124); 
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					loop {
						{
						{
						/*InvokeRule partitionSpecLocation*/
						recog.base.set_state(1123);
						recog.partitionSpecLocation()?;

						}
						}
						recog.base.set_state(1126); 
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if !(_la==PARTITION) {break}
					}
					}
				}
			,
				33 =>{
					let tmp = RenameTablePartitionContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 33);
					_localctx = tmp;
					{
					recog.base.set_state(1128);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1129);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1130);
					recog.identifierReference()?;

					/*InvokeRule partitionSpec*/
					recog.base.set_state(1131);
					let tmp = recog.partitionSpec()?;
					if let StatementContextAll::RenameTablePartitionContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.from = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1132);
					recog.base.match_token(RENAME,&mut recog.err_handler)?;

					recog.base.set_state(1133);
					recog.base.match_token(TO,&mut recog.err_handler)?;

					/*InvokeRule partitionSpec*/
					recog.base.set_state(1134);
					let tmp = recog.partitionSpec()?;
					if let StatementContextAll::RenameTablePartitionContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.to = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				34 =>{
					let tmp = DropTablePartitionsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 34);
					_localctx = tmp;
					{
					recog.base.set_state(1136);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1137);
					_la = recog.base.input.la(1);
					if { !(_la==TABLE || _la==VIEW) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(1138);
					recog.identifierReference()?;

					recog.base.set_state(1139);
					recog.base.match_token(DROP,&mut recog.err_handler)?;

					recog.base.set_state(1142);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IF {
						{
						recog.base.set_state(1140);
						recog.base.match_token(IF,&mut recog.err_handler)?;

						recog.base.set_state(1141);
						recog.base.match_token(EXISTS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule partitionSpec*/
					recog.base.set_state(1144);
					recog.partitionSpec()?;

					recog.base.set_state(1149);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(1145);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule partitionSpec*/
						recog.base.set_state(1146);
						recog.partitionSpec()?;

						}
						}
						recog.base.set_state(1151);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(1153);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==PURGE {
						{
						recog.base.set_state(1152);
						recog.base.match_token(PURGE,&mut recog.err_handler)?;

						}
					}

					}
				}
			,
				35 =>{
					let tmp = SetTableLocationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 35);
					_localctx = tmp;
					{
					recog.base.set_state(1155);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1156);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1157);
					recog.identifierReference()?;

					recog.base.set_state(1159);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==PARTITION {
						{
						/*InvokeRule partitionSpec*/
						recog.base.set_state(1158);
						recog.partitionSpec()?;

						}
					}

					recog.base.set_state(1161);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					/*InvokeRule locationSpec*/
					recog.base.set_state(1162);
					recog.locationSpec()?;

					}
				}
			,
				36 =>{
					let tmp = RecoverPartitionsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 36);
					_localctx = tmp;
					{
					recog.base.set_state(1164);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1165);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1166);
					recog.identifierReference()?;

					recog.base.set_state(1167);
					recog.base.match_token(RECOVER,&mut recog.err_handler)?;

					recog.base.set_state(1168);
					recog.base.match_token(PARTITIONS,&mut recog.err_handler)?;

					}
				}
			,
				37 =>{
					let tmp = AlterClusterByContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 37);
					_localctx = tmp;
					{
					recog.base.set_state(1170);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1171);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1172);
					recog.identifierReference()?;

					recog.base.set_state(1177);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(76,&mut recog.base)? {
						1 =>{
							{
							/*InvokeRule clusterBySpec*/
							recog.base.set_state(1173);
							recog.clusterBySpec()?;

							}
						}
					,
						2 =>{
							{
							recog.base.set_state(1174);
							recog.base.match_token(CLUSTER,&mut recog.err_handler)?;

							recog.base.set_state(1175);
							recog.base.match_token(BY,&mut recog.err_handler)?;

							recog.base.set_state(1176);
							recog.base.match_token(NONE,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}
			,
				38 =>{
					let tmp = AlterTableCollationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 38);
					_localctx = tmp;
					{
					recog.base.set_state(1179);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1180);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1181);
					recog.identifierReference()?;

					/*InvokeRule collationSpec*/
					recog.base.set_state(1182);
					recog.collationSpec()?;

					}
				}
			,
				39 =>{
					let tmp = AddTableConstraintContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 39);
					_localctx = tmp;
					{
					recog.base.set_state(1184);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1185);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1186);
					recog.identifierReference()?;

					recog.base.set_state(1187);
					recog.base.match_token(ADD,&mut recog.err_handler)?;

					/*InvokeRule tableConstraintDefinition*/
					recog.base.set_state(1188);
					recog.tableConstraintDefinition()?;

					}
				}
			,
				40 =>{
					let tmp = DropTableConstraintContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 40);
					_localctx = tmp;
					{
					recog.base.set_state(1190);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1191);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1192);
					recog.identifierReference()?;

					recog.base.set_state(1193);
					recog.base.match_token(DROP,&mut recog.err_handler)?;

					recog.base.set_state(1194);
					recog.base.match_token(CONSTRAINT,&mut recog.err_handler)?;

					recog.base.set_state(1197);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(77,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1195);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(1196);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifier*/
					recog.base.set_state(1199);
					let tmp = recog.identifier()?;
					if let StatementContextAll::DropTableConstraintContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.name = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1201);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==CASCADE || _la==RESTRICT {
						{
						recog.base.set_state(1200);
						_la = recog.base.input.la(1);
						if { !(_la==CASCADE || _la==RESTRICT) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
					}

					}
				}
			,
				41 =>{
					let tmp = DropTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 41);
					_localctx = tmp;
					{
					recog.base.set_state(1203);
					recog.base.match_token(DROP,&mut recog.err_handler)?;

					recog.base.set_state(1204);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(1207);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(79,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1205);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(1206);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(1209);
					recog.identifierReference()?;

					recog.base.set_state(1211);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==PURGE {
						{
						recog.base.set_state(1210);
						recog.base.match_token(PURGE,&mut recog.err_handler)?;

						}
					}

					}
				}
			,
				42 =>{
					let tmp = DropViewContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 42);
					_localctx = tmp;
					{
					recog.base.set_state(1213);
					recog.base.match_token(DROP,&mut recog.err_handler)?;

					recog.base.set_state(1214);
					recog.base.match_token(VIEW,&mut recog.err_handler)?;

					recog.base.set_state(1217);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(81,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1215);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(1216);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(1219);
					recog.identifierReference()?;

					}
				}
			,
				43 =>{
					let tmp = CreateViewContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 43);
					_localctx = tmp;
					{
					recog.base.set_state(1220);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(1223);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OR {
						{
						recog.base.set_state(1221);
						recog.base.match_token(OR,&mut recog.err_handler)?;

						recog.base.set_state(1222);
						recog.base.match_token(REPLACE,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(1229);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==GLOBAL || _la==TEMPORARY {
						{
						recog.base.set_state(1226);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==GLOBAL {
							{
							recog.base.set_state(1225);
							recog.base.match_token(GLOBAL,&mut recog.err_handler)?;

							}
						}

						recog.base.set_state(1228);
						recog.base.match_token(TEMPORARY,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(1231);
					recog.base.match_token(VIEW,&mut recog.err_handler)?;

					recog.base.set_state(1236);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(85,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1232);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							/*InvokeRule errorCapturingNot*/
							recog.base.set_state(1233);
							recog.errorCapturingNot()?;

							recog.base.set_state(1234);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(1238);
					recog.identifierReference()?;

					recog.base.set_state(1240);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LEFT_PAREN {
						{
						/*InvokeRule identifierCommentList*/
						recog.base.set_state(1239);
						recog.identifierCommentList()?;

						}
					}

					recog.base.set_state(1252);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMENT || _la==DEFAULT || _la==PARTITIONED || _la==TBLPROPERTIES || _la==WITH {
						{
						recog.base.set_state(1250);
						recog.err_handler.sync(&mut recog.base)?;
						match recog.base.input.la(1) {
						 COMMENT 
							=> {
								{
								/*InvokeRule commentSpec*/
								recog.base.set_state(1242);
								recog.commentSpec()?;

								}
							}

						 WITH 
							=> {
								{
								/*InvokeRule schemaBinding*/
								recog.base.set_state(1243);
								recog.schemaBinding()?;

								}
							}

						 DEFAULT 
							=> {
								{
								/*InvokeRule collationSpec*/
								recog.base.set_state(1244);
								recog.collationSpec()?;

								}
							}

						 PARTITIONED 
							=> {
								{
								{
								recog.base.set_state(1245);
								recog.base.match_token(PARTITIONED,&mut recog.err_handler)?;

								recog.base.set_state(1246);
								recog.base.match_token(ON,&mut recog.err_handler)?;

								/*InvokeRule identifierList*/
								recog.base.set_state(1247);
								recog.identifierList()?;

								}
								}
							}

						 TBLPROPERTIES 
							=> {
								{
								{
								recog.base.set_state(1248);
								recog.base.match_token(TBLPROPERTIES,&mut recog.err_handler)?;

								/*InvokeRule propertyList*/
								recog.base.set_state(1249);
								recog.propertyList()?;

								}
								}
							}

							_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
						}
						}
						recog.base.set_state(1254);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(1255);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(1256);
					recog.query()?;

					}
				}
			,
				44 =>{
					let tmp = CreateMetricViewContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 44);
					_localctx = tmp;
					{
					recog.base.set_state(1258);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(1261);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OR {
						{
						recog.base.set_state(1259);
						recog.base.match_token(OR,&mut recog.err_handler)?;

						recog.base.set_state(1260);
						recog.base.match_token(REPLACE,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(1263);
					recog.base.match_token(VIEW,&mut recog.err_handler)?;

					recog.base.set_state(1268);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(90,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1264);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							/*InvokeRule errorCapturingNot*/
							recog.base.set_state(1265);
							recog.errorCapturingNot()?;

							recog.base.set_state(1266);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(1270);
					recog.identifierReference()?;

					recog.base.set_state(1272);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LEFT_PAREN {
						{
						/*InvokeRule identifierCommentList*/
						recog.base.set_state(1271);
						recog.identifierCommentList()?;

						}
					}

					recog.base.set_state(1282);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMENT || _la==LANGUAGE || _la==TBLPROPERTIES || _la==WITH {
						{
						recog.base.set_state(1280);
						recog.err_handler.sync(&mut recog.base)?;
						match recog.base.input.la(1) {
						 WITH 
							=> {
								{
								{
								recog.base.set_state(1274);
								recog.base.match_token(WITH,&mut recog.err_handler)?;

								recog.base.set_state(1275);
								recog.base.match_token(METRICS,&mut recog.err_handler)?;

								}
								}
							}

						 LANGUAGE 
							=> {
								{
								/*InvokeRule routineLanguage*/
								recog.base.set_state(1276);
								recog.routineLanguage()?;

								}
							}

						 COMMENT 
							=> {
								{
								/*InvokeRule commentSpec*/
								recog.base.set_state(1277);
								recog.commentSpec()?;

								}
							}

						 TBLPROPERTIES 
							=> {
								{
								{
								recog.base.set_state(1278);
								recog.base.match_token(TBLPROPERTIES,&mut recog.err_handler)?;

								/*InvokeRule propertyList*/
								recog.base.set_state(1279);
								recog.propertyList()?;

								}
								}
							}

							_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
						}
						}
						recog.base.set_state(1284);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(1285);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					/*InvokeRule codeLiteral*/
					recog.base.set_state(1286);
					recog.codeLiteral()?;

					}
				}
			,
				45 =>{
					let tmp = CreateTempViewUsingContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 45);
					_localctx = tmp;
					{
					recog.base.set_state(1288);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(1291);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OR {
						{
						recog.base.set_state(1289);
						recog.base.match_token(OR,&mut recog.err_handler)?;

						recog.base.set_state(1290);
						recog.base.match_token(REPLACE,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(1294);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==GLOBAL {
						{
						recog.base.set_state(1293);
						recog.base.match_token(GLOBAL,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(1296);
					recog.base.match_token(TEMPORARY,&mut recog.err_handler)?;

					recog.base.set_state(1297);
					recog.base.match_token(VIEW,&mut recog.err_handler)?;

					/*InvokeRule tableIdentifier*/
					recog.base.set_state(1298);
					recog.tableIdentifier()?;

					recog.base.set_state(1303);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LEFT_PAREN {
						{
						recog.base.set_state(1299);
						recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

						/*InvokeRule colTypeList*/
						recog.base.set_state(1300);
						recog.colTypeList()?;

						recog.base.set_state(1301);
						recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule tableProvider*/
					recog.base.set_state(1305);
					recog.tableProvider()?;

					recog.base.set_state(1308);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OPTIONS {
						{
						recog.base.set_state(1306);
						recog.base.match_token(OPTIONS,&mut recog.err_handler)?;

						/*InvokeRule propertyList*/
						recog.base.set_state(1307);
						recog.propertyList()?;

						}
					}

					}
				}
			,
				46 =>{
					let tmp = AlterViewQueryContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 46);
					_localctx = tmp;
					{
					recog.base.set_state(1310);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1311);
					recog.base.match_token(VIEW,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1312);
					recog.identifierReference()?;

					recog.base.set_state(1314);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==AS {
						{
						recog.base.set_state(1313);
						recog.base.match_token(AS,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule query*/
					recog.base.set_state(1316);
					recog.query()?;

					}
				}
			,
				47 =>{
					let tmp = AlterViewSchemaBindingContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 47);
					_localctx = tmp;
					{
					recog.base.set_state(1318);
					recog.base.match_token(ALTER,&mut recog.err_handler)?;

					recog.base.set_state(1319);
					recog.base.match_token(VIEW,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1320);
					recog.identifierReference()?;

					/*InvokeRule schemaBinding*/
					recog.base.set_state(1321);
					recog.schemaBinding()?;

					}
				}
			,
				48 =>{
					let tmp = CreateFunctionContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 48);
					_localctx = tmp;
					{
					recog.base.set_state(1323);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(1326);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OR {
						{
						recog.base.set_state(1324);
						recog.base.match_token(OR,&mut recog.err_handler)?;

						recog.base.set_state(1325);
						recog.base.match_token(REPLACE,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(1329);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==TEMPORARY {
						{
						recog.base.set_state(1328);
						recog.base.match_token(TEMPORARY,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(1331);
					recog.base.match_token(FUNCTION,&mut recog.err_handler)?;

					recog.base.set_state(1336);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(101,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1332);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							/*InvokeRule errorCapturingNot*/
							recog.base.set_state(1333);
							recog.errorCapturingNot()?;

							recog.base.set_state(1334);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(1338);
					recog.identifierReference()?;

					recog.base.set_state(1339);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					/*InvokeRule stringLit*/
					recog.base.set_state(1340);
					let tmp = recog.stringLit()?;
					if let StatementContextAll::CreateFunctionContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.className = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1350);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==USING {
						{
						recog.base.set_state(1341);
						recog.base.match_token(USING,&mut recog.err_handler)?;

						/*InvokeRule resource*/
						recog.base.set_state(1342);
						recog.resource()?;

						recog.base.set_state(1347);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						while _la==COMMA {
							{
							{
							recog.base.set_state(1343);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule resource*/
							recog.base.set_state(1344);
							recog.resource()?;

							}
							}
							recog.base.set_state(1349);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
						}
						}
					}

					}
				}
			,
				49 =>{
					let tmp = CreateUserDefinedFunctionContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 49);
					_localctx = tmp;
					{
					recog.base.set_state(1352);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(1355);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OR {
						{
						recog.base.set_state(1353);
						recog.base.match_token(OR,&mut recog.err_handler)?;

						recog.base.set_state(1354);
						recog.base.match_token(REPLACE,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(1358);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==TEMPORARY {
						{
						recog.base.set_state(1357);
						recog.base.match_token(TEMPORARY,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(1360);
					recog.base.match_token(FUNCTION,&mut recog.err_handler)?;

					recog.base.set_state(1365);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(106,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1361);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							/*InvokeRule errorCapturingNot*/
							recog.base.set_state(1362);
							recog.errorCapturingNot()?;

							recog.base.set_state(1363);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(1367);
					recog.identifierReference()?;

					recog.base.set_state(1368);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					recog.base.set_state(1370);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(107,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule colDefinitionList*/
							recog.base.set_state(1369);
							let tmp = recog.colDefinitionList()?;
							if let StatementContextAll::CreateUserDefinedFunctionContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.parameters = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					recog.base.set_state(1372);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					recog.base.set_state(1382);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(109,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1373);
							recog.base.match_token(RETURNS,&mut recog.err_handler)?;

							recog.base.set_state(1380);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(108,&mut recog.base)? {
								1 =>{
									{
									/*InvokeRule dataType*/
									recog.base.set_state(1374);
									recog.dataType()?;

									}
								}
							,
								2 =>{
									{
									recog.base.set_state(1375);
									recog.base.match_token(TABLE,&mut recog.err_handler)?;

									recog.base.set_state(1376);
									recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

									/*InvokeRule colTypeList*/
									recog.base.set_state(1377);
									let tmp = recog.colTypeList()?;
									if let StatementContextAll::CreateUserDefinedFunctionContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
									ctx.returnParams = Some(tmp.clone()); } else {unreachable!("cant cast");}  

									recog.base.set_state(1378);
									recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

									}
								}

								_ => {}
							}
							}
						}

						_ => {}
					}
					/*InvokeRule routineCharacteristics*/
					recog.base.set_state(1384);
					recog.routineCharacteristics()?;

					recog.base.set_state(1385);
					recog.base.match_token(RETURN,&mut recog.err_handler)?;

					recog.base.set_state(1388);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(110,&mut recog.base)? {
						1 =>{
							{
							/*InvokeRule query*/
							recog.base.set_state(1386);
							recog.query()?;

							}
						}
					,
						2 =>{
							{
							/*InvokeRule expression*/
							recog.base.set_state(1387);
							recog.expression()?;

							}
						}

						_ => {}
					}
					}
				}
			,
				50 =>{
					let tmp = DropFunctionContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 50);
					_localctx = tmp;
					{
					recog.base.set_state(1390);
					recog.base.match_token(DROP,&mut recog.err_handler)?;

					recog.base.set_state(1392);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==TEMPORARY {
						{
						recog.base.set_state(1391);
						recog.base.match_token(TEMPORARY,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(1394);
					recog.base.match_token(FUNCTION,&mut recog.err_handler)?;

					recog.base.set_state(1397);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(112,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1395);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(1396);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(1399);
					recog.identifierReference()?;

					}
				}
			,
				51 =>{
					let tmp = CreateVariableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 51);
					_localctx = tmp;
					{
					recog.base.set_state(1400);
					recog.base.match_token(DECLARE,&mut recog.err_handler)?;

					recog.base.set_state(1403);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(113,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1401);
							recog.base.match_token(OR,&mut recog.err_handler)?;

							recog.base.set_state(1402);
							recog.base.match_token(REPLACE,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					recog.base.set_state(1406);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(114,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule variable*/
							recog.base.set_state(1405);
							recog.variable()?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(1408);
					let tmp = recog.identifierReference()?;
					if let StatementContextAll::CreateVariableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.identifierReference = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					let temp = if let StatementContextAll::CreateVariableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.identifierReference.clone().unwrap() } else {unreachable!("cant cast");} ;
					if let StatementContextAll::CreateVariableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.identifierReferences.push(temp); } else {unreachable!("cant cast");}  
					recog.base.set_state(1413);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(115,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(1409);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule identifierReference*/
							recog.base.set_state(1410);
							let tmp = recog.identifierReference()?;
							if let StatementContextAll::CreateVariableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.identifierReference = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							let temp = if let StatementContextAll::CreateVariableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.identifierReference.clone().unwrap() } else {unreachable!("cant cast");} ;
							if let StatementContextAll::CreateVariableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.identifierReferences.push(temp); } else {unreachable!("cant cast");}  
							}
							} 
						}
						recog.base.set_state(1415);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(115,&mut recog.base)?;
					}
					recog.base.set_state(1417);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(116,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule dataType*/
							recog.base.set_state(1416);
							recog.dataType()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(1420);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==DEFAULT || _la==EQ {
						{
						/*InvokeRule variableDefaultExpression*/
						recog.base.set_state(1419);
						recog.variableDefaultExpression()?;

						}
					}

					}
				}
			,
				52 =>{
					let tmp = DropVariableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 52);
					_localctx = tmp;
					{
					recog.base.set_state(1422);
					recog.base.match_token(DROP,&mut recog.err_handler)?;

					recog.base.set_state(1423);
					recog.base.match_token(TEMPORARY,&mut recog.err_handler)?;

					/*InvokeRule variable*/
					recog.base.set_state(1424);
					recog.variable()?;

					recog.base.set_state(1427);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(118,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1425);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(1426);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(1429);
					recog.identifierReference()?;

					}
				}
			,
				53 =>{
					let tmp = ExplainContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 53);
					_localctx = tmp;
					{
					recog.base.set_state(1431);
					recog.base.match_token(EXPLAIN,&mut recog.err_handler)?;

					recog.base.set_state(1433);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==CODEGEN || _la==COST || _la==EXTENDED || _la==FORMATTED || _la==LOGICAL {
						{
						recog.base.set_state(1432);
						_la = recog.base.input.la(1);
						if { !(_la==CODEGEN || _la==COST || _la==EXTENDED || _la==FORMATTED || _la==LOGICAL) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						}
					}

					recog.base.set_state(1437);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(120,&mut recog.base)? {
						1 =>{
							{
							/*InvokeRule statement*/
							recog.base.set_state(1435);
							recog.statement()?;

							}
						}
					,
						2 =>{
							{
							/*InvokeRule setResetStatement*/
							recog.base.set_state(1436);
							recog.setResetStatement()?;

							}
						}

						_ => {}
					}
					}
				}
			,
				54 =>{
					let tmp = ShowTablesContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 54);
					_localctx = tmp;
					{
					recog.base.set_state(1439);
					recog.base.match_token(SHOW,&mut recog.err_handler)?;

					recog.base.set_state(1440);
					recog.base.match_token(TABLES,&mut recog.err_handler)?;

					recog.base.set_state(1443);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(121,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1441);
							_la = recog.base.input.la(1);
							if { !(_la==FROM || _la==IN) } {
								recog.err_handler.recover_inline(&mut recog.base)?;

							}
							else {
								if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
								recog.err_handler.report_match(&mut recog.base);
								recog.base.consume(&mut recog.err_handler);
							}
							/*InvokeRule identifierReference*/
							recog.base.set_state(1442);
							recog.identifierReference()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(1449);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(123,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1446);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(122,&mut recog.base)? {
								x if x == 1=>{
									{
									recog.base.set_state(1445);
									recog.base.match_token(LIKE,&mut recog.err_handler)?;

									}
								}

								_ => {}
							}
							/*InvokeRule stringLit*/
							recog.base.set_state(1448);
							let tmp = recog.stringLit()?;
							if let StatementContextAll::ShowTablesContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.pattern = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					}
				}
			,
				55 =>{
					let tmp = ShowTableExtendedContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 55);
					_localctx = tmp;
					{
					recog.base.set_state(1451);
					recog.base.match_token(SHOW,&mut recog.err_handler)?;

					recog.base.set_state(1452);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(1453);
					recog.base.match_token(EXTENDED,&mut recog.err_handler)?;

					recog.base.set_state(1456);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==FROM || _la==IN {
						{
						recog.base.set_state(1454);
						_la = recog.base.input.la(1);
						if { !(_la==FROM || _la==IN) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						/*InvokeRule identifierReference*/
						recog.base.set_state(1455);
						let tmp = recog.identifierReference()?;
						if let StatementContextAll::ShowTableExtendedContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
						ctx.ns = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(1458);
					recog.base.match_token(LIKE,&mut recog.err_handler)?;

					/*InvokeRule stringLit*/
					recog.base.set_state(1459);
					let tmp = recog.stringLit()?;
					if let StatementContextAll::ShowTableExtendedContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.pattern = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1461);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==PARTITION {
						{
						/*InvokeRule partitionSpec*/
						recog.base.set_state(1460);
						recog.partitionSpec()?;

						}
					}

					}
				}
			,
				56 =>{
					let tmp = ShowTblPropertiesContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 56);
					_localctx = tmp;
					{
					recog.base.set_state(1463);
					recog.base.match_token(SHOW,&mut recog.err_handler)?;

					recog.base.set_state(1464);
					recog.base.match_token(TBLPROPERTIES,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1465);
					let tmp = recog.identifierReference()?;
					if let StatementContextAll::ShowTblPropertiesContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.table = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1470);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LEFT_PAREN {
						{
						recog.base.set_state(1466);
						recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

						/*InvokeRule propertyKeyOrStringLit*/
						recog.base.set_state(1467);
						let tmp = recog.propertyKeyOrStringLit()?;
						if let StatementContextAll::ShowTblPropertiesContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
						ctx.key = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						recog.base.set_state(1468);
						recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

						}
					}

					}
				}
			,
				57 =>{
					let tmp = ShowColumnsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 57);
					_localctx = tmp;
					{
					recog.base.set_state(1472);
					recog.base.match_token(SHOW,&mut recog.err_handler)?;

					recog.base.set_state(1473);
					recog.base.match_token(COLUMNS,&mut recog.err_handler)?;

					recog.base.set_state(1474);
					_la = recog.base.input.la(1);
					if { !(_la==FROM || _la==IN) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(1475);
					let tmp = recog.identifierReference()?;
					if let StatementContextAll::ShowColumnsContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.table = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1478);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==FROM || _la==IN {
						{
						recog.base.set_state(1476);
						_la = recog.base.input.la(1);
						if { !(_la==FROM || _la==IN) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						/*InvokeRule multipartIdentifier*/
						recog.base.set_state(1477);
						let tmp = recog.multipartIdentifier()?;
						if let StatementContextAll::ShowColumnsContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
						ctx.ns = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					}
				}
			,
				58 =>{
					let tmp = ShowViewsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 58);
					_localctx = tmp;
					{
					recog.base.set_state(1480);
					recog.base.match_token(SHOW,&mut recog.err_handler)?;

					recog.base.set_state(1481);
					recog.base.match_token(VIEWS,&mut recog.err_handler)?;

					recog.base.set_state(1484);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(128,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1482);
							_la = recog.base.input.la(1);
							if { !(_la==FROM || _la==IN) } {
								recog.err_handler.recover_inline(&mut recog.base)?;

							}
							else {
								if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
								recog.err_handler.report_match(&mut recog.base);
								recog.base.consume(&mut recog.err_handler);
							}
							/*InvokeRule identifierReference*/
							recog.base.set_state(1483);
							recog.identifierReference()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(1490);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(130,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1487);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(129,&mut recog.base)? {
								x if x == 1=>{
									{
									recog.base.set_state(1486);
									recog.base.match_token(LIKE,&mut recog.err_handler)?;

									}
								}

								_ => {}
							}
							/*InvokeRule stringLit*/
							recog.base.set_state(1489);
							let tmp = recog.stringLit()?;
							if let StatementContextAll::ShowViewsContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.pattern = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					}
				}
			,
				59 =>{
					let tmp = ShowPartitionsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 59);
					_localctx = tmp;
					{
					recog.base.set_state(1492);
					recog.base.match_token(SHOW,&mut recog.err_handler)?;

					recog.base.set_state(1493);
					recog.base.match_token(PARTITIONS,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1494);
					recog.identifierReference()?;

					recog.base.set_state(1496);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==PARTITION {
						{
						/*InvokeRule partitionSpec*/
						recog.base.set_state(1495);
						recog.partitionSpec()?;

						}
					}

					}
				}
			,
				60 =>{
					let tmp = ShowFunctionsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 60);
					_localctx = tmp;
					{
					recog.base.set_state(1498);
					recog.base.match_token(SHOW,&mut recog.err_handler)?;

					recog.base.set_state(1500);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(132,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule simpleIdentifier*/
							recog.base.set_state(1499);
							let tmp = recog.simpleIdentifier()?;
							if let StatementContextAll::ShowFunctionsContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.functionScope = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					recog.base.set_state(1502);
					recog.base.match_token(FUNCTIONS,&mut recog.err_handler)?;

					recog.base.set_state(1505);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(133,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1503);
							_la = recog.base.input.la(1);
							if { !(_la==FROM || _la==IN) } {
								recog.err_handler.recover_inline(&mut recog.base)?;

							}
							else {
								if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
								recog.err_handler.report_match(&mut recog.base);
								recog.base.consume(&mut recog.err_handler);
							}
							/*InvokeRule identifierReference*/
							recog.base.set_state(1504);
							let tmp = recog.identifierReference()?;
							if let StatementContextAll::ShowFunctionsContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.ns = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					recog.base.set_state(1514);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(136,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1508);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(134,&mut recog.base)? {
								x if x == 1=>{
									{
									recog.base.set_state(1507);
									recog.base.match_token(LIKE,&mut recog.err_handler)?;

									}
								}

								_ => {}
							}
							recog.base.set_state(1512);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(135,&mut recog.base)? {
								1 =>{
									{
									/*InvokeRule multipartIdentifier*/
									recog.base.set_state(1510);
									let tmp = recog.multipartIdentifier()?;
									if let StatementContextAll::ShowFunctionsContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
									ctx.legacy = Some(tmp.clone()); } else {unreachable!("cant cast");}  

									}
								}
							,
								2 =>{
									{
									/*InvokeRule stringLit*/
									recog.base.set_state(1511);
									let tmp = recog.stringLit()?;
									if let StatementContextAll::ShowFunctionsContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
									ctx.pattern = Some(tmp.clone()); } else {unreachable!("cant cast");}  

									}
								}

								_ => {}
							}
							}
						}

						_ => {}
					}
					}
				}
			,
				61 =>{
					let tmp = ShowProceduresContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 61);
					_localctx = tmp;
					{
					recog.base.set_state(1516);
					recog.base.match_token(SHOW,&mut recog.err_handler)?;

					recog.base.set_state(1517);
					recog.base.match_token(PROCEDURES,&mut recog.err_handler)?;

					recog.base.set_state(1520);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==FROM || _la==IN {
						{
						recog.base.set_state(1518);
						_la = recog.base.input.la(1);
						if { !(_la==FROM || _la==IN) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						/*InvokeRule identifierReference*/
						recog.base.set_state(1519);
						recog.identifierReference()?;

						}
					}

					}
				}
			,
				62 =>{
					let tmp = ShowCreateTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 62);
					_localctx = tmp;
					{
					recog.base.set_state(1522);
					recog.base.match_token(SHOW,&mut recog.err_handler)?;

					recog.base.set_state(1523);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(1524);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1525);
					recog.identifierReference()?;

					recog.base.set_state(1528);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==AS {
						{
						recog.base.set_state(1526);
						recog.base.match_token(AS,&mut recog.err_handler)?;

						recog.base.set_state(1527);
						recog.base.match_token(SERDE,&mut recog.err_handler)?;

						}
					}

					}
				}
			,
				63 =>{
					let tmp = ShowCurrentNamespaceContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 63);
					_localctx = tmp;
					{
					recog.base.set_state(1530);
					recog.base.match_token(SHOW,&mut recog.err_handler)?;

					recog.base.set_state(1531);
					recog.base.match_token(CURRENT,&mut recog.err_handler)?;

					/*InvokeRule namespace*/
					recog.base.set_state(1532);
					recog.namespace()?;

					}
				}
			,
				64 =>{
					let tmp = ShowCatalogsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 64);
					_localctx = tmp;
					{
					recog.base.set_state(1533);
					recog.base.match_token(SHOW,&mut recog.err_handler)?;

					recog.base.set_state(1534);
					recog.base.match_token(CATALOGS,&mut recog.err_handler)?;

					recog.base.set_state(1539);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(140,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1536);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(139,&mut recog.base)? {
								x if x == 1=>{
									{
									recog.base.set_state(1535);
									recog.base.match_token(LIKE,&mut recog.err_handler)?;

									}
								}

								_ => {}
							}
							/*InvokeRule stringLit*/
							recog.base.set_state(1538);
							let tmp = recog.stringLit()?;
							if let StatementContextAll::ShowCatalogsContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.pattern = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					}
				}
			,
				65 =>{
					let tmp = DescribeFunctionContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 65);
					_localctx = tmp;
					{
					recog.base.set_state(1541);
					_la = recog.base.input.la(1);
					if { !(_la==DESC || _la==DESCRIBE) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(1542);
					recog.base.match_token(FUNCTION,&mut recog.err_handler)?;

					recog.base.set_state(1544);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(141,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1543);
							recog.base.match_token(EXTENDED,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule describeFuncName*/
					recog.base.set_state(1546);
					recog.describeFuncName()?;

					}
				}
			,
				66 =>{
					let tmp = DescribeProcedureContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 66);
					_localctx = tmp;
					{
					recog.base.set_state(1547);
					_la = recog.base.input.la(1);
					if { !(_la==DESC || _la==DESCRIBE) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(1548);
					recog.base.match_token(PROCEDURE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1549);
					recog.identifierReference()?;

					}
				}
			,
				67 =>{
					let tmp = DescribeNamespaceContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 67);
					_localctx = tmp;
					{
					recog.base.set_state(1550);
					_la = recog.base.input.la(1);
					if { !(_la==DESC || _la==DESCRIBE) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					/*InvokeRule namespace*/
					recog.base.set_state(1551);
					recog.namespace()?;

					recog.base.set_state(1553);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(142,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1552);
							recog.base.match_token(EXTENDED,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(1555);
					recog.identifierReference()?;

					}
				}
			,
				68 =>{
					let tmp = DescribeRelationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 68);
					_localctx = tmp;
					{
					recog.base.set_state(1557);
					_la = recog.base.input.la(1);
					if { !(_la==DESC || _la==DESCRIBE) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(1559);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(143,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1558);
							recog.base.match_token(TABLE,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					recog.base.set_state(1562);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(144,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1561);
							if let StatementContextAll::DescribeRelationContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.option = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
							_la = recog.base.input.la(1);
							if { !(_la==EXTENDED || _la==FORMATTED) } {
								let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
								if let StatementContextAll::DescribeRelationContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
								ctx.option = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
							else {
								if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
								recog.err_handler.report_match(&mut recog.base);
								recog.base.consume(&mut recog.err_handler);
							}
							}
						}

						_ => {}
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(1564);
					recog.identifierReference()?;

					recog.base.set_state(1566);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(145,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule partitionSpec*/
							recog.base.set_state(1565);
							recog.partitionSpec()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(1569);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(146,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule describeColName*/
							recog.base.set_state(1568);
							recog.describeColName()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(1573);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==AS {
						{
						recog.base.set_state(1571);
						recog.base.match_token(AS,&mut recog.err_handler)?;

						recog.base.set_state(1572);
						recog.base.match_token(JSON,&mut recog.err_handler)?;

						}
					}

					}
				}
			,
				69 =>{
					let tmp = DescribeQueryContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 69);
					_localctx = tmp;
					{
					recog.base.set_state(1575);
					_la = recog.base.input.la(1);
					if { !(_la==DESC || _la==DESCRIBE) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(1577);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==QUERY {
						{
						recog.base.set_state(1576);
						recog.base.match_token(QUERY,&mut recog.err_handler)?;

						}
					}

					/*InvokeRule query*/
					recog.base.set_state(1579);
					recog.query()?;

					}
				}
			,
				70 =>{
					let tmp = CommentNamespaceContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 70);
					_localctx = tmp;
					{
					recog.base.set_state(1580);
					recog.base.match_token(COMMENT,&mut recog.err_handler)?;

					recog.base.set_state(1581);
					recog.base.match_token(ON,&mut recog.err_handler)?;

					/*InvokeRule namespace*/
					recog.base.set_state(1582);
					recog.namespace()?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1583);
					recog.identifierReference()?;

					recog.base.set_state(1584);
					recog.base.match_token(IS,&mut recog.err_handler)?;

					/*InvokeRule comment*/
					recog.base.set_state(1585);
					recog.comment()?;

					}
				}
			,
				71 =>{
					let tmp = CommentTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 71);
					_localctx = tmp;
					{
					recog.base.set_state(1587);
					recog.base.match_token(COMMENT,&mut recog.err_handler)?;

					recog.base.set_state(1588);
					recog.base.match_token(ON,&mut recog.err_handler)?;

					recog.base.set_state(1589);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1590);
					recog.identifierReference()?;

					recog.base.set_state(1591);
					recog.base.match_token(IS,&mut recog.err_handler)?;

					/*InvokeRule comment*/
					recog.base.set_state(1592);
					recog.comment()?;

					}
				}
			,
				72 =>{
					let tmp = RefreshTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 72);
					_localctx = tmp;
					{
					recog.base.set_state(1594);
					recog.base.match_token(REFRESH,&mut recog.err_handler)?;

					recog.base.set_state(1595);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1596);
					recog.identifierReference()?;

					}
				}
			,
				73 =>{
					let tmp = RefreshFunctionContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 73);
					_localctx = tmp;
					{
					recog.base.set_state(1597);
					recog.base.match_token(REFRESH,&mut recog.err_handler)?;

					recog.base.set_state(1598);
					recog.base.match_token(FUNCTION,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1599);
					recog.identifierReference()?;

					}
				}
			,
				74 =>{
					let tmp = RefreshResourceContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 74);
					_localctx = tmp;
					{
					recog.base.set_state(1600);
					recog.base.match_token(REFRESH,&mut recog.err_handler)?;

					recog.base.set_state(1608);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(150,&mut recog.base)? {
						1 =>{
							{
							/*InvokeRule stringLit*/
							recog.base.set_state(1601);
							recog.stringLit()?;

							}
						}
					,
						2 =>{
							{
							recog.base.set_state(1605);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(149,&mut recog.base)?;
							while { _alt!=1 && _alt!=INVALID_ALT } {
								if _alt==1+1 {
									{
									{
									recog.base.set_state(1602);
									recog.base.match_wildcard(&mut recog.err_handler)?;

									}
									} 
								}
								recog.base.set_state(1607);
								recog.err_handler.sync(&mut recog.base)?;
								_alt = recog.interpreter.adaptive_predict(149,&mut recog.base)?;
							}
							}
						}

						_ => {}
					}
					}
				}
			,
				75 =>{
					let tmp = CacheTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 75);
					_localctx = tmp;
					{
					recog.base.set_state(1610);
					recog.base.match_token(CACHE,&mut recog.err_handler)?;

					recog.base.set_state(1612);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LAZY {
						{
						recog.base.set_state(1611);
						recog.base.match_token(LAZY,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(1614);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1615);
					recog.identifierReference()?;

					recog.base.set_state(1618);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OPTIONS {
						{
						recog.base.set_state(1616);
						recog.base.match_token(OPTIONS,&mut recog.err_handler)?;

						/*InvokeRule propertyList*/
						recog.base.set_state(1617);
						let tmp = recog.propertyList()?;
						if let StatementContextAll::CacheTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
						ctx.options = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(1624);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LEFT_PAREN || _la==AS || _la==FROM || _la==MAP || _la==REDUCE || _la==SELECT || _la==TABLE || _la==VALUES || _la==WITH {
						{
						recog.base.set_state(1621);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==AS {
							{
							recog.base.set_state(1620);
							recog.base.match_token(AS,&mut recog.err_handler)?;

							}
						}

						/*InvokeRule query*/
						recog.base.set_state(1623);
						recog.query()?;

						}
					}

					}
				}
			,
				76 =>{
					let tmp = UncacheTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 76);
					_localctx = tmp;
					{
					recog.base.set_state(1626);
					recog.base.match_token(UNCACHE,&mut recog.err_handler)?;

					recog.base.set_state(1627);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(1630);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(155,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1628);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(1629);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(1632);
					recog.identifierReference()?;

					}
				}
			,
				77 =>{
					let tmp = ClearCacheContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 77);
					_localctx = tmp;
					{
					recog.base.set_state(1633);
					recog.base.match_token(CLEAR,&mut recog.err_handler)?;

					recog.base.set_state(1634);
					recog.base.match_token(CACHE,&mut recog.err_handler)?;

					}
				}
			,
				78 =>{
					let tmp = LoadDataContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 78);
					_localctx = tmp;
					{
					recog.base.set_state(1635);
					recog.base.match_token(LOAD,&mut recog.err_handler)?;

					recog.base.set_state(1636);
					recog.base.match_token(DATA,&mut recog.err_handler)?;

					recog.base.set_state(1638);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LOCAL {
						{
						recog.base.set_state(1637);
						recog.base.match_token(LOCAL,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(1640);
					recog.base.match_token(INPATH,&mut recog.err_handler)?;

					/*InvokeRule stringLit*/
					recog.base.set_state(1641);
					let tmp = recog.stringLit()?;
					if let StatementContextAll::LoadDataContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.path = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1643);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OVERWRITE {
						{
						recog.base.set_state(1642);
						recog.base.match_token(OVERWRITE,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(1645);
					recog.base.match_token(INTO,&mut recog.err_handler)?;

					recog.base.set_state(1646);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1647);
					recog.identifierReference()?;

					recog.base.set_state(1649);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==PARTITION {
						{
						/*InvokeRule partitionSpec*/
						recog.base.set_state(1648);
						recog.partitionSpec()?;

						}
					}

					}
				}
			,
				79 =>{
					let tmp = TruncateTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 79);
					_localctx = tmp;
					{
					recog.base.set_state(1651);
					recog.base.match_token(TRUNCATE,&mut recog.err_handler)?;

					recog.base.set_state(1652);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1653);
					recog.identifierReference()?;

					recog.base.set_state(1655);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==PARTITION {
						{
						/*InvokeRule partitionSpec*/
						recog.base.set_state(1654);
						recog.partitionSpec()?;

						}
					}

					}
				}
			,
				80 =>{
					let tmp = RepairTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 80);
					_localctx = tmp;
					{
					recog.base.set_state(1658);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MSCK {
						{
						recog.base.set_state(1657);
						recog.base.match_token(MSCK,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(1660);
					recog.base.match_token(REPAIR,&mut recog.err_handler)?;

					recog.base.set_state(1661);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1662);
					recog.identifierReference()?;

					recog.base.set_state(1665);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ADD || _la==DROP || _la==SYNC {
						{
						recog.base.set_state(1663);
						if let StatementContextAll::RepairTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
						ctx.option = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
						_la = recog.base.input.la(1);
						if { !(_la==ADD || _la==DROP || _la==SYNC) } {
							let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
							if let StatementContextAll::RepairTableContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
							ctx.option = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						recog.base.set_state(1664);
						recog.base.match_token(PARTITIONS,&mut recog.err_handler)?;

						}
					}

					}
				}
			,
				81 =>{
					let tmp = ManageResourceContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 81);
					_localctx = tmp;
					{
					recog.base.set_state(1667);
					if let StatementContextAll::ManageResourceContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.op = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
					_la = recog.base.input.la(1);
					if { !(_la==ADD || _la==LIST) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						if let StatementContextAll::ManageResourceContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
						ctx.op = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					/*InvokeRule simpleIdentifier*/
					recog.base.set_state(1668);
					recog.simpleIdentifier()?;

					recog.base.set_state(1672);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(162,&mut recog.base)?;
					while { _alt!=1 && _alt!=INVALID_ALT } {
						if _alt==1+1 {
							{
							{
							recog.base.set_state(1669);
							recog.base.match_wildcard(&mut recog.err_handler)?;

							}
							} 
						}
						recog.base.set_state(1674);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(162,&mut recog.base)?;
					}
					}
				}
			,
				82 =>{
					let tmp = CreateIndexContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 82);
					_localctx = tmp;
					{
					recog.base.set_state(1675);
					recog.base.match_token(CREATE,&mut recog.err_handler)?;

					recog.base.set_state(1676);
					recog.base.match_token(INDEX,&mut recog.err_handler)?;

					recog.base.set_state(1681);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(163,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1677);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							/*InvokeRule errorCapturingNot*/
							recog.base.set_state(1678);
							recog.errorCapturingNot()?;

							recog.base.set_state(1679);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifier*/
					recog.base.set_state(1683);
					recog.identifier()?;

					recog.base.set_state(1684);
					recog.base.match_token(ON,&mut recog.err_handler)?;

					recog.base.set_state(1686);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(164,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1685);
							recog.base.match_token(TABLE,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(1688);
					recog.identifierReference()?;

					recog.base.set_state(1691);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==USING {
						{
						recog.base.set_state(1689);
						recog.base.match_token(USING,&mut recog.err_handler)?;

						/*InvokeRule identifier*/
						recog.base.set_state(1690);
						let tmp = recog.identifier()?;
						if let StatementContextAll::CreateIndexContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
						ctx.indexType = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(1693);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule multipartIdentifierPropertyList*/
					recog.base.set_state(1694);
					let tmp = recog.multipartIdentifierPropertyList()?;
					if let StatementContextAll::CreateIndexContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
					ctx.columns = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(1695);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					recog.base.set_state(1698);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OPTIONS {
						{
						recog.base.set_state(1696);
						recog.base.match_token(OPTIONS,&mut recog.err_handler)?;

						/*InvokeRule propertyList*/
						recog.base.set_state(1697);
						let tmp = recog.propertyList()?;
						if let StatementContextAll::CreateIndexContext(ctx) = cast_mut::<_,StatementContextAll >(&mut _localctx){
						ctx.options = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					}
				}
			,
				83 =>{
					let tmp = DropIndexContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 83);
					_localctx = tmp;
					{
					recog.base.set_state(1700);
					recog.base.match_token(DROP,&mut recog.err_handler)?;

					recog.base.set_state(1701);
					recog.base.match_token(INDEX,&mut recog.err_handler)?;

					recog.base.set_state(1704);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(167,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1702);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							recog.base.set_state(1703);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifier*/
					recog.base.set_state(1706);
					recog.identifier()?;

					recog.base.set_state(1707);
					recog.base.match_token(ON,&mut recog.err_handler)?;

					recog.base.set_state(1709);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(168,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1708);
							recog.base.match_token(TABLE,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(1711);
					recog.identifierReference()?;

					}
				}
			,
				84 =>{
					let tmp = CallContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 84);
					_localctx = tmp;
					{
					recog.base.set_state(1713);
					recog.base.match_token(CALL,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(1714);
					recog.identifierReference()?;

					recog.base.set_state(1715);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					recog.base.set_state(1724);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(170,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule functionArgument*/
							recog.base.set_state(1716);
							recog.functionArgument()?;

							recog.base.set_state(1721);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							while _la==COMMA {
								{
								{
								recog.base.set_state(1717);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule functionArgument*/
								recog.base.set_state(1718);
								recog.functionArgument()?;

								}
								}
								recog.base.set_state(1723);
								recog.err_handler.sync(&mut recog.base)?;
								_la = recog.base.input.la(1);
							}
							}
						}

						_ => {}
					}
					recog.base.set_state(1726);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				85 =>{
					let tmp = FailNativeCommandContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 85);
					_localctx = tmp;
					{
					/*InvokeRule unsupportedHiveNativeCommands*/
					recog.base.set_state(1728);
					recog.unsupportedHiveNativeCommands()?;

					recog.base.set_state(1732);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(171,&mut recog.base)?;
					while { _alt!=1 && _alt!=INVALID_ALT } {
						if _alt==1+1 {
							{
							{
							recog.base.set_state(1729);
							recog.base.match_wildcard(&mut recog.err_handler)?;

							}
							} 
						}
						recog.base.set_state(1734);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(171,&mut recog.base)?;
					}
					}
				}
			,
				86 =>{
					let tmp = CreatePipelineDatasetContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 86);
					_localctx = tmp;
					{
					/*InvokeRule createPipelineDatasetHeader*/
					recog.base.set_state(1735);
					recog.createPipelineDatasetHeader()?;

					recog.base.set_state(1741);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LEFT_PAREN {
						{
						recog.base.set_state(1736);
						recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

						recog.base.set_state(1738);
						recog.err_handler.sync(&mut recog.base)?;
						match  recog.interpreter.adaptive_predict(172,&mut recog.base)? {
							x if x == 1=>{
								{
								/*InvokeRule tableElementList*/
								recog.base.set_state(1737);
								recog.tableElementList()?;

								}
							}

							_ => {}
						}
						recog.base.set_state(1740);
						recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(1744);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==USING {
						{
						/*InvokeRule tableProvider*/
						recog.base.set_state(1743);
						recog.tableProvider()?;

						}
					}

					/*InvokeRule createTableClauses*/
					recog.base.set_state(1746);
					recog.createTableClauses()?;

					recog.base.set_state(1749);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==AS {
						{
						recog.base.set_state(1747);
						recog.base.match_token(AS,&mut recog.err_handler)?;

						/*InvokeRule query*/
						recog.base.set_state(1748);
						recog.query()?;

						}
					}

					}
				}
			,
				87 =>{
					let tmp = CreatePipelineInsertIntoFlowContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 87);
					_localctx = tmp;
					{
					/*InvokeRule createPipelineFlowHeader*/
					recog.base.set_state(1751);
					recog.createPipelineFlowHeader()?;

					/*InvokeRule insertInto*/
					recog.base.set_state(1752);
					recog.insertInto()?;

					/*InvokeRule query*/
					recog.base.set_state(1753);
					recog.query()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- materializedView ----------------
pub type MaterializedViewContextAll<'input> = MaterializedViewContext<'input>;


pub type MaterializedViewContext<'input> = BaseParserRuleContext<'input,MaterializedViewContextExt<'input>>;

#[derive(Clone)]
pub struct MaterializedViewContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for MaterializedViewContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for MaterializedViewContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_materializedView(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_materializedView(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for MaterializedViewContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_materializedView(self);
	}
}

impl<'input> CustomRuleContext<'input> for MaterializedViewContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_materializedView }
	//fn type_rule_index() -> usize where Self: Sized { RULE_materializedView }
}
antlr_rust::tid!{MaterializedViewContextExt<'a>}

impl<'input> MaterializedViewContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MaterializedViewContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MaterializedViewContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait MaterializedViewContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<MaterializedViewContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token MATERIALIZED
/// Returns `None` if there is no child corresponding to token MATERIALIZED
fn MATERIALIZED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MATERIALIZED, 0)
}
/// Retrieves first TerminalNode corresponding to token VIEW
/// Returns `None` if there is no child corresponding to token VIEW
fn VIEW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VIEW, 0)
}

}

impl<'input> MaterializedViewContextAttrs<'input> for MaterializedViewContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn materializedView(&mut self,)
	-> Result<Rc<MaterializedViewContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MaterializedViewContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 60, RULE_materializedView);
        let mut _localctx: Rc<MaterializedViewContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1757);
			recog.base.match_token(MATERIALIZED,&mut recog.err_handler)?;

			recog.base.set_state(1758);
			recog.base.match_token(VIEW,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- streamingTable ----------------
pub type StreamingTableContextAll<'input> = StreamingTableContext<'input>;


pub type StreamingTableContext<'input> = BaseParserRuleContext<'input,StreamingTableContextExt<'input>>;

#[derive(Clone)]
pub struct StreamingTableContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for StreamingTableContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for StreamingTableContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_streamingTable(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_streamingTable(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for StreamingTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_streamingTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for StreamingTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_streamingTable }
	//fn type_rule_index() -> usize where Self: Sized { RULE_streamingTable }
}
antlr_rust::tid!{StreamingTableContextExt<'a>}

impl<'input> StreamingTableContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StreamingTableContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StreamingTableContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StreamingTableContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<StreamingTableContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token STREAMING
/// Returns `None` if there is no child corresponding to token STREAMING
fn STREAMING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(STREAMING, 0)
}
/// Retrieves first TerminalNode corresponding to token TABLE
/// Returns `None` if there is no child corresponding to token TABLE
fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TABLE, 0)
}

}

impl<'input> StreamingTableContextAttrs<'input> for StreamingTableContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn streamingTable(&mut self,)
	-> Result<Rc<StreamingTableContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StreamingTableContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 62, RULE_streamingTable);
        let mut _localctx: Rc<StreamingTableContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1760);
			recog.base.match_token(STREAMING,&mut recog.err_handler)?;

			recog.base.set_state(1761);
			recog.base.match_token(TABLE,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- createPipelineDatasetHeader ----------------
pub type CreatePipelineDatasetHeaderContextAll<'input> = CreatePipelineDatasetHeaderContext<'input>;


pub type CreatePipelineDatasetHeaderContext<'input> = BaseParserRuleContext<'input,CreatePipelineDatasetHeaderContextExt<'input>>;

#[derive(Clone)]
pub struct CreatePipelineDatasetHeaderContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for CreatePipelineDatasetHeaderContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CreatePipelineDatasetHeaderContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_createPipelineDatasetHeader(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_createPipelineDatasetHeader(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CreatePipelineDatasetHeaderContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_createPipelineDatasetHeader(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreatePipelineDatasetHeaderContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_createPipelineDatasetHeader }
	//fn type_rule_index() -> usize where Self: Sized { RULE_createPipelineDatasetHeader }
}
antlr_rust::tid!{CreatePipelineDatasetHeaderContextExt<'a>}

impl<'input> CreatePipelineDatasetHeaderContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CreatePipelineDatasetHeaderContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CreatePipelineDatasetHeaderContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait CreatePipelineDatasetHeaderContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<CreatePipelineDatasetHeaderContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token CREATE
/// Returns `None` if there is no child corresponding to token CREATE
fn CREATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CREATE, 0)
}
fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn materializedView(&self) -> Option<Rc<MaterializedViewContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn streamingTable(&self) -> Option<Rc<StreamingTableContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token IF
/// Returns `None` if there is no child corresponding to token IF
fn IF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IF, 0)
}
fn errorCapturingNot(&self) -> Option<Rc<ErrorCapturingNotContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EXISTS
/// Returns `None` if there is no child corresponding to token EXISTS
fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXISTS, 0)
}

}

impl<'input> CreatePipelineDatasetHeaderContextAttrs<'input> for CreatePipelineDatasetHeaderContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn createPipelineDatasetHeader(&mut self,)
	-> Result<Rc<CreatePipelineDatasetHeaderContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CreatePipelineDatasetHeaderContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 64, RULE_createPipelineDatasetHeader);
        let mut _localctx: Rc<CreatePipelineDatasetHeaderContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1763);
			recog.base.match_token(CREATE,&mut recog.err_handler)?;

			recog.base.set_state(1766);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 MATERIALIZED 
				=> {
					{
					/*InvokeRule materializedView*/
					recog.base.set_state(1764);
					recog.materializedView()?;

					}
				}

			 STREAMING 
				=> {
					{
					/*InvokeRule streamingTable*/
					recog.base.set_state(1765);
					recog.streamingTable()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			recog.base.set_state(1772);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(178,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(1768);
					recog.base.match_token(IF,&mut recog.err_handler)?;

					/*InvokeRule errorCapturingNot*/
					recog.base.set_state(1769);
					recog.errorCapturingNot()?;

					recog.base.set_state(1770);
					recog.base.match_token(EXISTS,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			/*InvokeRule identifierReference*/
			recog.base.set_state(1774);
			recog.identifierReference()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- streamRelationPrimary ----------------
#[derive(Debug)]
pub enum StreamRelationPrimaryContextAll<'input>{
	StreamTableNameContext(StreamTableNameContext<'input>),
Error(StreamRelationPrimaryContext<'input>)
}
antlr_rust::tid!{StreamRelationPrimaryContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for StreamRelationPrimaryContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for StreamRelationPrimaryContextAll<'input>{}

impl<'input> Deref for StreamRelationPrimaryContextAll<'input>{
	type Target = dyn StreamRelationPrimaryContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use StreamRelationPrimaryContextAll::*;
		match self{
			StreamTableNameContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for StreamRelationPrimaryContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for StreamRelationPrimaryContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type StreamRelationPrimaryContext<'input> = BaseParserRuleContext<'input,StreamRelationPrimaryContextExt<'input>>;

#[derive(Clone)]
pub struct StreamRelationPrimaryContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for StreamRelationPrimaryContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for StreamRelationPrimaryContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for StreamRelationPrimaryContext<'input>{
}

impl<'input> CustomRuleContext<'input> for StreamRelationPrimaryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_streamRelationPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_streamRelationPrimary }
}
antlr_rust::tid!{StreamRelationPrimaryContextExt<'a>}

impl<'input> StreamRelationPrimaryContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StreamRelationPrimaryContextAll<'input>> {
		Rc::new(
		StreamRelationPrimaryContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StreamRelationPrimaryContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait StreamRelationPrimaryContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<StreamRelationPrimaryContextExt<'input>>{


}

impl<'input> StreamRelationPrimaryContextAttrs<'input> for StreamRelationPrimaryContext<'input>{}

pub type StreamTableNameContext<'input> = BaseParserRuleContext<'input,StreamTableNameContextExt<'input>>;

pub trait StreamTableNameContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token STREAM
	/// Returns `None` if there is no child corresponding to token STREAM
	fn STREAM(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(STREAM, 0)
	}
	fn multipartIdentifier(&self) -> Option<Rc<MultipartIdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn tableAlias(&self) -> Option<Rc<TableAliasContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn optionsClause(&self) -> Option<Rc<OptionsClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn watermarkClause(&self) -> Option<Rc<WatermarkClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
}

impl<'input> StreamTableNameContextAttrs<'input> for StreamTableNameContext<'input>{}

pub struct StreamTableNameContextExt<'input>{
	base:StreamRelationPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{StreamTableNameContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for StreamTableNameContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for StreamTableNameContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_streamTableName(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_streamTableName(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for StreamTableNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_streamTableName(self);
	}
}

impl<'input> CustomRuleContext<'input> for StreamTableNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_streamRelationPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_streamRelationPrimary }
}

impl<'input> Borrow<StreamRelationPrimaryContextExt<'input>> for StreamTableNameContext<'input>{
	fn borrow(&self) -> &StreamRelationPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StreamRelationPrimaryContextExt<'input>> for StreamTableNameContext<'input>{
	fn borrow_mut(&mut self) -> &mut StreamRelationPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> StreamRelationPrimaryContextAttrs<'input> for StreamTableNameContext<'input> {}

impl<'input> StreamTableNameContextExt<'input>{
	fn new(ctx: &dyn StreamRelationPrimaryContextAttrs<'input>) -> Rc<StreamRelationPrimaryContextAll<'input>>  {
		Rc::new(
			StreamRelationPrimaryContextAll::StreamTableNameContext(
				BaseParserRuleContext::copy_from(ctx,StreamTableNameContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn streamRelationPrimary(&mut self,)
	-> Result<Rc<StreamRelationPrimaryContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StreamRelationPrimaryContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 66, RULE_streamRelationPrimary);
        let mut _localctx: Rc<StreamRelationPrimaryContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1798);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(183,&mut recog.base)? {
				1 =>{
					let tmp = StreamTableNameContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(1776);
					recog.base.match_token(STREAM,&mut recog.err_handler)?;

					/*InvokeRule multipartIdentifier*/
					recog.base.set_state(1777);
					recog.multipartIdentifier()?;

					recog.base.set_state(1779);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(179,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule optionsClause*/
							recog.base.set_state(1778);
							recog.optionsClause()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(1782);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(180,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule watermarkClause*/
							recog.base.set_state(1781);
							recog.watermarkClause()?;

							}
						}

						_ => {}
					}
					/*InvokeRule tableAlias*/
					recog.base.set_state(1784);
					recog.tableAlias()?;

					}
				}
			,
				2 =>{
					let tmp = StreamTableNameContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(1786);
					recog.base.match_token(STREAM,&mut recog.err_handler)?;

					recog.base.set_state(1787);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule multipartIdentifier*/
					recog.base.set_state(1788);
					recog.multipartIdentifier()?;

					recog.base.set_state(1789);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					recog.base.set_state(1791);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(181,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule optionsClause*/
							recog.base.set_state(1790);
							recog.optionsClause()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(1794);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(182,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule watermarkClause*/
							recog.base.set_state(1793);
							recog.watermarkClause()?;

							}
						}

						_ => {}
					}
					/*InvokeRule tableAlias*/
					recog.base.set_state(1796);
					recog.tableAlias()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- setResetStatement ----------------
#[derive(Debug)]
pub enum SetResetStatementContextAll<'input>{
	SetQuotedConfigurationContext(SetQuotedConfigurationContext<'input>),
	ResetQuotedConfigurationContext(ResetQuotedConfigurationContext<'input>),
	FailSetRoleContext(FailSetRoleContext<'input>),
	ResetConfigurationContext(ResetConfigurationContext<'input>),
	SetTimeZoneContext(SetTimeZoneContext<'input>),
	SetVariableContext(SetVariableContext<'input>),
	SetConfigurationContext(SetConfigurationContext<'input>),
Error(SetResetStatementContext<'input>)
}
antlr_rust::tid!{SetResetStatementContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for SetResetStatementContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for SetResetStatementContextAll<'input>{}

impl<'input> Deref for SetResetStatementContextAll<'input>{
	type Target = dyn SetResetStatementContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use SetResetStatementContextAll::*;
		match self{
			SetQuotedConfigurationContext(inner) => inner,
			ResetQuotedConfigurationContext(inner) => inner,
			FailSetRoleContext(inner) => inner,
			ResetConfigurationContext(inner) => inner,
			SetTimeZoneContext(inner) => inner,
			SetVariableContext(inner) => inner,
			SetConfigurationContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SetResetStatementContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SetResetStatementContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type SetResetStatementContext<'input> = BaseParserRuleContext<'input,SetResetStatementContextExt<'input>>;

#[derive(Clone)]
pub struct SetResetStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SetResetStatementContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SetResetStatementContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SetResetStatementContext<'input>{
}

impl<'input> CustomRuleContext<'input> for SetResetStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setResetStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setResetStatement }
}
antlr_rust::tid!{SetResetStatementContextExt<'a>}

impl<'input> SetResetStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SetResetStatementContextAll<'input>> {
		Rc::new(
		SetResetStatementContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SetResetStatementContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait SetResetStatementContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SetResetStatementContextExt<'input>>{


}

impl<'input> SetResetStatementContextAttrs<'input> for SetResetStatementContext<'input>{}

pub type SetQuotedConfigurationContext<'input> = BaseParserRuleContext<'input,SetQuotedConfigurationContextExt<'input>>;

pub trait SetQuotedConfigurationContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	fn configKey(&self) -> Option<Rc<ConfigKeyContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token EQ
	/// Returns `None` if there is no child corresponding to token EQ
	fn EQ(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EQ, 0)
	}
	fn configValue(&self) -> Option<Rc<ConfigValueContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SetQuotedConfigurationContextAttrs<'input> for SetQuotedConfigurationContext<'input>{}

pub struct SetQuotedConfigurationContextExt<'input>{
	base:SetResetStatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetQuotedConfigurationContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SetQuotedConfigurationContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SetQuotedConfigurationContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setQuotedConfiguration(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_setQuotedConfiguration(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SetQuotedConfigurationContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_setQuotedConfiguration(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetQuotedConfigurationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setResetStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setResetStatement }
}

impl<'input> Borrow<SetResetStatementContextExt<'input>> for SetQuotedConfigurationContext<'input>{
	fn borrow(&self) -> &SetResetStatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<SetResetStatementContextExt<'input>> for SetQuotedConfigurationContext<'input>{
	fn borrow_mut(&mut self) -> &mut SetResetStatementContextExt<'input> { &mut self.base }
}

impl<'input> SetResetStatementContextAttrs<'input> for SetQuotedConfigurationContext<'input> {}

impl<'input> SetQuotedConfigurationContextExt<'input>{
	fn new(ctx: &dyn SetResetStatementContextAttrs<'input>) -> Rc<SetResetStatementContextAll<'input>>  {
		Rc::new(
			SetResetStatementContextAll::SetQuotedConfigurationContext(
				BaseParserRuleContext::copy_from(ctx,SetQuotedConfigurationContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ResetQuotedConfigurationContext<'input> = BaseParserRuleContext<'input,ResetQuotedConfigurationContextExt<'input>>;

pub trait ResetQuotedConfigurationContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token RESET
	/// Returns `None` if there is no child corresponding to token RESET
	fn RESET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RESET, 0)
	}
	fn configKey(&self) -> Option<Rc<ConfigKeyContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ResetQuotedConfigurationContextAttrs<'input> for ResetQuotedConfigurationContext<'input>{}

pub struct ResetQuotedConfigurationContextExt<'input>{
	base:SetResetStatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ResetQuotedConfigurationContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ResetQuotedConfigurationContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ResetQuotedConfigurationContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_resetQuotedConfiguration(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_resetQuotedConfiguration(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ResetQuotedConfigurationContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_resetQuotedConfiguration(self);
	}
}

impl<'input> CustomRuleContext<'input> for ResetQuotedConfigurationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setResetStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setResetStatement }
}

impl<'input> Borrow<SetResetStatementContextExt<'input>> for ResetQuotedConfigurationContext<'input>{
	fn borrow(&self) -> &SetResetStatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<SetResetStatementContextExt<'input>> for ResetQuotedConfigurationContext<'input>{
	fn borrow_mut(&mut self) -> &mut SetResetStatementContextExt<'input> { &mut self.base }
}

impl<'input> SetResetStatementContextAttrs<'input> for ResetQuotedConfigurationContext<'input> {}

impl<'input> ResetQuotedConfigurationContextExt<'input>{
	fn new(ctx: &dyn SetResetStatementContextAttrs<'input>) -> Rc<SetResetStatementContextAll<'input>>  {
		Rc::new(
			SetResetStatementContextAll::ResetQuotedConfigurationContext(
				BaseParserRuleContext::copy_from(ctx,ResetQuotedConfigurationContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type FailSetRoleContext<'input> = BaseParserRuleContext<'input,FailSetRoleContextExt<'input>>;

pub trait FailSetRoleContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ROLE
	/// Returns `None` if there is no child corresponding to token ROLE
	fn ROLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ROLE, 0)
	}
}

impl<'input> FailSetRoleContextAttrs<'input> for FailSetRoleContext<'input>{}

pub struct FailSetRoleContextExt<'input>{
	base:SetResetStatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FailSetRoleContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for FailSetRoleContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for FailSetRoleContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_failSetRole(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_failSetRole(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for FailSetRoleContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_failSetRole(self);
	}
}

impl<'input> CustomRuleContext<'input> for FailSetRoleContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setResetStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setResetStatement }
}

impl<'input> Borrow<SetResetStatementContextExt<'input>> for FailSetRoleContext<'input>{
	fn borrow(&self) -> &SetResetStatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<SetResetStatementContextExt<'input>> for FailSetRoleContext<'input>{
	fn borrow_mut(&mut self) -> &mut SetResetStatementContextExt<'input> { &mut self.base }
}

impl<'input> SetResetStatementContextAttrs<'input> for FailSetRoleContext<'input> {}

impl<'input> FailSetRoleContextExt<'input>{
	fn new(ctx: &dyn SetResetStatementContextAttrs<'input>) -> Rc<SetResetStatementContextAll<'input>>  {
		Rc::new(
			SetResetStatementContextAll::FailSetRoleContext(
				BaseParserRuleContext::copy_from(ctx,FailSetRoleContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ResetConfigurationContext<'input> = BaseParserRuleContext<'input,ResetConfigurationContextExt<'input>>;

pub trait ResetConfigurationContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token RESET
	/// Returns `None` if there is no child corresponding to token RESET
	fn RESET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RESET, 0)
	}
}

impl<'input> ResetConfigurationContextAttrs<'input> for ResetConfigurationContext<'input>{}

pub struct ResetConfigurationContextExt<'input>{
	base:SetResetStatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ResetConfigurationContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ResetConfigurationContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ResetConfigurationContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_resetConfiguration(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_resetConfiguration(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ResetConfigurationContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_resetConfiguration(self);
	}
}

impl<'input> CustomRuleContext<'input> for ResetConfigurationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setResetStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setResetStatement }
}

impl<'input> Borrow<SetResetStatementContextExt<'input>> for ResetConfigurationContext<'input>{
	fn borrow(&self) -> &SetResetStatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<SetResetStatementContextExt<'input>> for ResetConfigurationContext<'input>{
	fn borrow_mut(&mut self) -> &mut SetResetStatementContextExt<'input> { &mut self.base }
}

impl<'input> SetResetStatementContextAttrs<'input> for ResetConfigurationContext<'input> {}

impl<'input> ResetConfigurationContextExt<'input>{
	fn new(ctx: &dyn SetResetStatementContextAttrs<'input>) -> Rc<SetResetStatementContextAll<'input>>  {
		Rc::new(
			SetResetStatementContextAll::ResetConfigurationContext(
				BaseParserRuleContext::copy_from(ctx,ResetConfigurationContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetTimeZoneContext<'input> = BaseParserRuleContext<'input,SetTimeZoneContextExt<'input>>;

pub trait SetTimeZoneContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TIME
	/// Returns `None` if there is no child corresponding to token TIME
	fn TIME(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TIME, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ZONE
	/// Returns `None` if there is no child corresponding to token ZONE
	fn ZONE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ZONE, 0)
	}
	fn interval(&self) -> Option<Rc<IntervalContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn timezone(&self) -> Option<Rc<TimezoneContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SetTimeZoneContextAttrs<'input> for SetTimeZoneContext<'input>{}

pub struct SetTimeZoneContextExt<'input>{
	base:SetResetStatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetTimeZoneContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SetTimeZoneContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SetTimeZoneContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setTimeZone(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_setTimeZone(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SetTimeZoneContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_setTimeZone(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetTimeZoneContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setResetStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setResetStatement }
}

impl<'input> Borrow<SetResetStatementContextExt<'input>> for SetTimeZoneContext<'input>{
	fn borrow(&self) -> &SetResetStatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<SetResetStatementContextExt<'input>> for SetTimeZoneContext<'input>{
	fn borrow_mut(&mut self) -> &mut SetResetStatementContextExt<'input> { &mut self.base }
}

impl<'input> SetResetStatementContextAttrs<'input> for SetTimeZoneContext<'input> {}

impl<'input> SetTimeZoneContextExt<'input>{
	fn new(ctx: &dyn SetResetStatementContextAttrs<'input>) -> Rc<SetResetStatementContextAll<'input>>  {
		Rc::new(
			SetResetStatementContextAll::SetTimeZoneContext(
				BaseParserRuleContext::copy_from(ctx,SetTimeZoneContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetVariableContext<'input> = BaseParserRuleContext<'input,SetVariableContextExt<'input>>;

pub trait SetVariableContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	fn variable(&self) -> Option<Rc<VariableContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn assignmentList(&self) -> Option<Rc<AssignmentListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token LEFT_PAREN in current rule
	fn LEFT_PAREN_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token LEFT_PAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token LEFT_PAREN is less or equal than `i`.
	fn LEFT_PAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, i)
	}
	fn multipartIdentifierList(&self) -> Option<Rc<MultipartIdentifierListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token RIGHT_PAREN in current rule
	fn RIGHT_PAREN_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token RIGHT_PAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token RIGHT_PAREN is less or equal than `i`.
	fn RIGHT_PAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, i)
	}
	/// Retrieves first TerminalNode corresponding to token EQ
	/// Returns `None` if there is no child corresponding to token EQ
	fn EQ(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EQ, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SetVariableContextAttrs<'input> for SetVariableContext<'input>{}

pub struct SetVariableContextExt<'input>{
	base:SetResetStatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetVariableContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SetVariableContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SetVariableContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setVariable(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_setVariable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SetVariableContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_setVariable(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetVariableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setResetStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setResetStatement }
}

impl<'input> Borrow<SetResetStatementContextExt<'input>> for SetVariableContext<'input>{
	fn borrow(&self) -> &SetResetStatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<SetResetStatementContextExt<'input>> for SetVariableContext<'input>{
	fn borrow_mut(&mut self) -> &mut SetResetStatementContextExt<'input> { &mut self.base }
}

impl<'input> SetResetStatementContextAttrs<'input> for SetVariableContext<'input> {}

impl<'input> SetVariableContextExt<'input>{
	fn new(ctx: &dyn SetResetStatementContextAttrs<'input>) -> Rc<SetResetStatementContextAll<'input>>  {
		Rc::new(
			SetResetStatementContextAll::SetVariableContext(
				BaseParserRuleContext::copy_from(ctx,SetVariableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetConfigurationContext<'input> = BaseParserRuleContext<'input,SetConfigurationContextExt<'input>>;

pub trait SetConfigurationContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SET
	/// Returns `None` if there is no child corresponding to token SET
	fn SET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SET, 0)
	}
	fn configKey(&self) -> Option<Rc<ConfigKeyContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token EQ
	/// Returns `None` if there is no child corresponding to token EQ
	fn EQ(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EQ, 0)
	}
}

impl<'input> SetConfigurationContextAttrs<'input> for SetConfigurationContext<'input>{}

pub struct SetConfigurationContextExt<'input>{
	base:SetResetStatementContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetConfigurationContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SetConfigurationContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SetConfigurationContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setConfiguration(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_setConfiguration(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SetConfigurationContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_setConfiguration(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetConfigurationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setResetStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setResetStatement }
}

impl<'input> Borrow<SetResetStatementContextExt<'input>> for SetConfigurationContext<'input>{
	fn borrow(&self) -> &SetResetStatementContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<SetResetStatementContextExt<'input>> for SetConfigurationContext<'input>{
	fn borrow_mut(&mut self) -> &mut SetResetStatementContextExt<'input> { &mut self.base }
}

impl<'input> SetResetStatementContextAttrs<'input> for SetConfigurationContext<'input> {}

impl<'input> SetConfigurationContextExt<'input>{
	fn new(ctx: &dyn SetResetStatementContextAttrs<'input>) -> Rc<SetResetStatementContextAll<'input>>  {
		Rc::new(
			SetResetStatementContextAll::SetConfigurationContext(
				BaseParserRuleContext::copy_from(ctx,SetConfigurationContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn setResetStatement(&mut self,)
	-> Result<Rc<SetResetStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SetResetStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 68, RULE_setResetStatement);
        let mut _localctx: Rc<SetResetStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(1880);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(191,&mut recog.base)? {
				1 =>{
					let tmp = FailSetRoleContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(1800);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(1801);
					recog.base.match_token(ROLE,&mut recog.err_handler)?;

					recog.base.set_state(1805);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(184,&mut recog.base)?;
					while { _alt!=1 && _alt!=INVALID_ALT } {
						if _alt==1+1 {
							{
							{
							recog.base.set_state(1802);
							recog.base.match_wildcard(&mut recog.err_handler)?;

							}
							} 
						}
						recog.base.set_state(1807);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(184,&mut recog.base)?;
					}
					}
				}
			,
				2 =>{
					let tmp = SetTimeZoneContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(1808);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(1809);
					recog.base.match_token(TIME,&mut recog.err_handler)?;

					recog.base.set_state(1810);
					recog.base.match_token(ZONE,&mut recog.err_handler)?;

					/*InvokeRule interval*/
					recog.base.set_state(1811);
					recog.interval()?;

					}
				}
			,
				3 =>{
					let tmp = SetTimeZoneContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(1812);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(1813);
					recog.base.match_token(TIME,&mut recog.err_handler)?;

					recog.base.set_state(1814);
					recog.base.match_token(ZONE,&mut recog.err_handler)?;

					/*InvokeRule timezone*/
					recog.base.set_state(1815);
					recog.timezone()?;

					}
				}
			,
				4 =>{
					let tmp = SetTimeZoneContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(1816);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(1817);
					recog.base.match_token(TIME,&mut recog.err_handler)?;

					recog.base.set_state(1818);
					recog.base.match_token(ZONE,&mut recog.err_handler)?;

					recog.base.set_state(1822);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(185,&mut recog.base)?;
					while { _alt!=1 && _alt!=INVALID_ALT } {
						if _alt==1+1 {
							{
							{
							recog.base.set_state(1819);
							recog.base.match_wildcard(&mut recog.err_handler)?;

							}
							} 
						}
						recog.base.set_state(1824);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(185,&mut recog.base)?;
					}
					}
				}
			,
				5 =>{
					let tmp = SetVariableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					recog.base.set_state(1825);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					/*InvokeRule variable*/
					recog.base.set_state(1826);
					recog.variable()?;

					/*InvokeRule assignmentList*/
					recog.base.set_state(1827);
					recog.assignmentList()?;

					}
				}
			,
				6 =>{
					let tmp = SetVariableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 6);
					_localctx = tmp;
					{
					recog.base.set_state(1829);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					/*InvokeRule variable*/
					recog.base.set_state(1830);
					recog.variable()?;

					recog.base.set_state(1831);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule multipartIdentifierList*/
					recog.base.set_state(1832);
					recog.multipartIdentifierList()?;

					recog.base.set_state(1833);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					recog.base.set_state(1834);
					recog.base.match_token(EQ,&mut recog.err_handler)?;

					recog.base.set_state(1835);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(1836);
					recog.query()?;

					recog.base.set_state(1837);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				7 =>{
					let tmp = SetQuotedConfigurationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 7);
					_localctx = tmp;
					{
					recog.base.set_state(1839);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					/*InvokeRule configKey*/
					recog.base.set_state(1840);
					recog.configKey()?;

					recog.base.set_state(1841);
					recog.base.match_token(EQ,&mut recog.err_handler)?;

					/*InvokeRule configValue*/
					recog.base.set_state(1842);
					recog.configValue()?;

					}
				}
			,
				8 =>{
					let tmp = SetConfigurationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 8);
					_localctx = tmp;
					{
					recog.base.set_state(1844);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					/*InvokeRule configKey*/
					recog.base.set_state(1845);
					recog.configKey()?;

					recog.base.set_state(1853);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==EQ {
						{
						recog.base.set_state(1846);
						recog.base.match_token(EQ,&mut recog.err_handler)?;

						recog.base.set_state(1850);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(186,&mut recog.base)?;
						while { _alt!=1 && _alt!=INVALID_ALT } {
							if _alt==1+1 {
								{
								{
								recog.base.set_state(1847);
								recog.base.match_wildcard(&mut recog.err_handler)?;

								}
								} 
							}
							recog.base.set_state(1852);
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(186,&mut recog.base)?;
						}
						}
					}

					}
				}
			,
				9 =>{
					let tmp = SetQuotedConfigurationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 9);
					_localctx = tmp;
					{
					recog.base.set_state(1855);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(1859);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(188,&mut recog.base)?;
					while { _alt!=1 && _alt!=INVALID_ALT } {
						if _alt==1+1 {
							{
							{
							recog.base.set_state(1856);
							recog.base.match_wildcard(&mut recog.err_handler)?;

							}
							} 
						}
						recog.base.set_state(1861);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(188,&mut recog.base)?;
					}
					recog.base.set_state(1862);
					recog.base.match_token(EQ,&mut recog.err_handler)?;

					/*InvokeRule configValue*/
					recog.base.set_state(1863);
					recog.configValue()?;

					}
				}
			,
				10 =>{
					let tmp = SetConfigurationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 10);
					_localctx = tmp;
					{
					recog.base.set_state(1864);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(1868);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(189,&mut recog.base)?;
					while { _alt!=1 && _alt!=INVALID_ALT } {
						if _alt==1+1 {
							{
							{
							recog.base.set_state(1865);
							recog.base.match_wildcard(&mut recog.err_handler)?;

							}
							} 
						}
						recog.base.set_state(1870);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(189,&mut recog.base)?;
					}
					}
				}
			,
				11 =>{
					let tmp = ResetQuotedConfigurationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 11);
					_localctx = tmp;
					{
					recog.base.set_state(1871);
					recog.base.match_token(RESET,&mut recog.err_handler)?;

					/*InvokeRule configKey*/
					recog.base.set_state(1872);
					recog.configKey()?;

					}
				}
			,
				12 =>{
					let tmp = ResetConfigurationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 12);
					_localctx = tmp;
					{
					recog.base.set_state(1873);
					recog.base.match_token(RESET,&mut recog.err_handler)?;

					recog.base.set_state(1877);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(190,&mut recog.base)?;
					while { _alt!=1 && _alt!=INVALID_ALT } {
						if _alt==1+1 {
							{
							{
							recog.base.set_state(1874);
							recog.base.match_wildcard(&mut recog.err_handler)?;

							}
							} 
						}
						recog.base.set_state(1879);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(190,&mut recog.base)?;
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- executeImmediate ----------------
pub type ExecuteImmediateContextAll<'input> = ExecuteImmediateContext<'input>;


pub type ExecuteImmediateContext<'input> = BaseParserRuleContext<'input,ExecuteImmediateContextExt<'input>>;

#[derive(Clone)]
pub struct ExecuteImmediateContextExt<'input>{
	pub queryParam: Option<Rc<ExpressionContextAll<'input>>>,
	pub targetVariable: Option<Rc<MultipartIdentifierListContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ExecuteImmediateContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ExecuteImmediateContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_executeImmediate(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_executeImmediate(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ExecuteImmediateContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_executeImmediate(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExecuteImmediateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_executeImmediate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_executeImmediate }
}
antlr_rust::tid!{ExecuteImmediateContextExt<'a>}

impl<'input> ExecuteImmediateContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExecuteImmediateContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExecuteImmediateContextExt{
				queryParam: None, targetVariable: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ExecuteImmediateContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ExecuteImmediateContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EXECUTE
/// Returns `None` if there is no child corresponding to token EXECUTE
fn EXECUTE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXECUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token IMMEDIATE
/// Returns `None` if there is no child corresponding to token IMMEDIATE
fn IMMEDIATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IMMEDIATE, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token INTO
/// Returns `None` if there is no child corresponding to token INTO
fn INTO(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INTO, 0)
}
fn executeImmediateUsing(&self) -> Option<Rc<ExecuteImmediateUsingContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn multipartIdentifierList(&self) -> Option<Rc<MultipartIdentifierListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ExecuteImmediateContextAttrs<'input> for ExecuteImmediateContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn executeImmediate(&mut self,)
	-> Result<Rc<ExecuteImmediateContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExecuteImmediateContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 70, RULE_executeImmediate);
        let mut _localctx: Rc<ExecuteImmediateContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1882);
			recog.base.match_token(EXECUTE,&mut recog.err_handler)?;

			recog.base.set_state(1883);
			recog.base.match_token(IMMEDIATE,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(1884);
			let tmp = recog.expression()?;
			 cast_mut::<_,ExecuteImmediateContext >(&mut _localctx).queryParam = Some(tmp.clone());
			  

			recog.base.set_state(1887);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==INTO {
				{
				recog.base.set_state(1885);
				recog.base.match_token(INTO,&mut recog.err_handler)?;

				/*InvokeRule multipartIdentifierList*/
				recog.base.set_state(1886);
				let tmp = recog.multipartIdentifierList()?;
				 cast_mut::<_,ExecuteImmediateContext >(&mut _localctx).targetVariable = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1890);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==USING {
				{
				/*InvokeRule executeImmediateUsing*/
				recog.base.set_state(1889);
				recog.executeImmediateUsing()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- executeImmediateUsing ----------------
pub type ExecuteImmediateUsingContextAll<'input> = ExecuteImmediateUsingContext<'input>;


pub type ExecuteImmediateUsingContext<'input> = BaseParserRuleContext<'input,ExecuteImmediateUsingContextExt<'input>>;

#[derive(Clone)]
pub struct ExecuteImmediateUsingContextExt<'input>{
	pub params: Option<Rc<NamedExpressionSeqContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ExecuteImmediateUsingContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ExecuteImmediateUsingContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_executeImmediateUsing(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_executeImmediateUsing(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ExecuteImmediateUsingContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_executeImmediateUsing(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExecuteImmediateUsingContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_executeImmediateUsing }
	//fn type_rule_index() -> usize where Self: Sized { RULE_executeImmediateUsing }
}
antlr_rust::tid!{ExecuteImmediateUsingContextExt<'a>}

impl<'input> ExecuteImmediateUsingContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExecuteImmediateUsingContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExecuteImmediateUsingContextExt{
				params: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ExecuteImmediateUsingContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ExecuteImmediateUsingContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token USING
/// Returns `None` if there is no child corresponding to token USING
fn USING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(USING, 0)
}
/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
fn namedExpressionSeq(&self) -> Option<Rc<NamedExpressionSeqContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ExecuteImmediateUsingContextAttrs<'input> for ExecuteImmediateUsingContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn executeImmediateUsing(&mut self,)
	-> Result<Rc<ExecuteImmediateUsingContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExecuteImmediateUsingContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 72, RULE_executeImmediateUsing);
        let mut _localctx: Rc<ExecuteImmediateUsingContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1899);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(194,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(1892);
					recog.base.match_token(USING,&mut recog.err_handler)?;

					recog.base.set_state(1893);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule namedExpressionSeq*/
					recog.base.set_state(1894);
					let tmp = recog.namedExpressionSeq()?;
					 cast_mut::<_,ExecuteImmediateUsingContext >(&mut _localctx).params = Some(tmp.clone());
					  

					recog.base.set_state(1895);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(1897);
					recog.base.match_token(USING,&mut recog.err_handler)?;

					/*InvokeRule namedExpressionSeq*/
					recog.base.set_state(1898);
					let tmp = recog.namedExpressionSeq()?;
					 cast_mut::<_,ExecuteImmediateUsingContext >(&mut _localctx).params = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- timezone ----------------
pub type TimezoneContextAll<'input> = TimezoneContext<'input>;


pub type TimezoneContext<'input> = BaseParserRuleContext<'input,TimezoneContextExt<'input>>;

#[derive(Clone)]
pub struct TimezoneContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for TimezoneContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for TimezoneContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_timezone(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_timezone(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for TimezoneContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_timezone(self);
	}
}

impl<'input> CustomRuleContext<'input> for TimezoneContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_timezone }
	//fn type_rule_index() -> usize where Self: Sized { RULE_timezone }
}
antlr_rust::tid!{TimezoneContextExt<'a>}

impl<'input> TimezoneContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TimezoneContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TimezoneContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TimezoneContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<TimezoneContextExt<'input>>{

fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LOCAL
/// Returns `None` if there is no child corresponding to token LOCAL
fn LOCAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LOCAL, 0)
}

}

impl<'input> TimezoneContextAttrs<'input> for TimezoneContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn timezone(&mut self,)
	-> Result<Rc<TimezoneContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TimezoneContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 74, RULE_timezone);
        let mut _localctx: Rc<TimezoneContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1903);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(195,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule stringLit*/
					recog.base.set_state(1901);
					recog.stringLit()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(1902);
					recog.base.match_token(LOCAL,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- configKey ----------------
pub type ConfigKeyContextAll<'input> = ConfigKeyContext<'input>;


pub type ConfigKeyContext<'input> = BaseParserRuleContext<'input,ConfigKeyContextExt<'input>>;

#[derive(Clone)]
pub struct ConfigKeyContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ConfigKeyContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ConfigKeyContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_configKey(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_configKey(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ConfigKeyContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_configKey(self);
	}
}

impl<'input> CustomRuleContext<'input> for ConfigKeyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_configKey }
	//fn type_rule_index() -> usize where Self: Sized { RULE_configKey }
}
antlr_rust::tid!{ConfigKeyContextExt<'a>}

impl<'input> ConfigKeyContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ConfigKeyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ConfigKeyContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ConfigKeyContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ConfigKeyContextExt<'input>>{

fn quotedIdentifier(&self) -> Option<Rc<QuotedIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ConfigKeyContextAttrs<'input> for ConfigKeyContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn configKey(&mut self,)
	-> Result<Rc<ConfigKeyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ConfigKeyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 76, RULE_configKey);
        let mut _localctx: Rc<ConfigKeyContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule quotedIdentifier*/
			recog.base.set_state(1905);
			recog.quotedIdentifier()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- configValue ----------------
pub type ConfigValueContextAll<'input> = ConfigValueContext<'input>;


pub type ConfigValueContext<'input> = BaseParserRuleContext<'input,ConfigValueContextExt<'input>>;

#[derive(Clone)]
pub struct ConfigValueContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ConfigValueContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ConfigValueContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_configValue(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_configValue(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ConfigValueContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_configValue(self);
	}
}

impl<'input> CustomRuleContext<'input> for ConfigValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_configValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_configValue }
}
antlr_rust::tid!{ConfigValueContextExt<'a>}

impl<'input> ConfigValueContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ConfigValueContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ConfigValueContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ConfigValueContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ConfigValueContextExt<'input>>{

fn backQuotedIdentifier(&self) -> Option<Rc<BackQuotedIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ConfigValueContextAttrs<'input> for ConfigValueContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn configValue(&mut self,)
	-> Result<Rc<ConfigValueContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ConfigValueContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 78, RULE_configValue);
        let mut _localctx: Rc<ConfigValueContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule backQuotedIdentifier*/
			recog.base.set_state(1907);
			recog.backQuotedIdentifier()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unsupportedHiveNativeCommands ----------------
pub type UnsupportedHiveNativeCommandsContextAll<'input> = UnsupportedHiveNativeCommandsContext<'input>;


pub type UnsupportedHiveNativeCommandsContext<'input> = BaseParserRuleContext<'input,UnsupportedHiveNativeCommandsContextExt<'input>>;

#[derive(Clone)]
pub struct UnsupportedHiveNativeCommandsContextExt<'input>{
	pub kw1: Option<TokenType<'input>>,
	pub kw2: Option<TokenType<'input>>,
	pub kw3: Option<TokenType<'input>>,
	pub kw4: Option<TokenType<'input>>,
	pub kw5: Option<TokenType<'input>>,
	pub kw6: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for UnsupportedHiveNativeCommandsContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for UnsupportedHiveNativeCommandsContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unsupportedHiveNativeCommands(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_unsupportedHiveNativeCommands(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for UnsupportedHiveNativeCommandsContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_unsupportedHiveNativeCommands(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnsupportedHiveNativeCommandsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unsupportedHiveNativeCommands }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unsupportedHiveNativeCommands }
}
antlr_rust::tid!{UnsupportedHiveNativeCommandsContextExt<'a>}

impl<'input> UnsupportedHiveNativeCommandsContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnsupportedHiveNativeCommandsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnsupportedHiveNativeCommandsContextExt{
				kw1: None, kw2: None, kw3: None, kw4: None, kw5: None, kw6: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait UnsupportedHiveNativeCommandsContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<UnsupportedHiveNativeCommandsContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token CREATE
/// Returns `None` if there is no child corresponding to token CREATE
fn CREATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CREATE, 0)
}
/// Retrieves first TerminalNode corresponding to token ROLE
/// Returns `None` if there is no child corresponding to token ROLE
fn ROLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ROLE, 0)
}
/// Retrieves first TerminalNode corresponding to token DROP
/// Returns `None` if there is no child corresponding to token DROP
fn DROP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DROP, 0)
}
/// Retrieves first TerminalNode corresponding to token GRANT
/// Returns `None` if there is no child corresponding to token GRANT
fn GRANT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(GRANT, 0)
}
/// Retrieves first TerminalNode corresponding to token REVOKE
/// Returns `None` if there is no child corresponding to token REVOKE
fn REVOKE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(REVOKE, 0)
}
/// Retrieves first TerminalNode corresponding to token SHOW
/// Returns `None` if there is no child corresponding to token SHOW
fn SHOW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SHOW, 0)
}
/// Retrieves first TerminalNode corresponding to token PRINCIPALS
/// Returns `None` if there is no child corresponding to token PRINCIPALS
fn PRINCIPALS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PRINCIPALS, 0)
}
/// Retrieves first TerminalNode corresponding to token ROLES
/// Returns `None` if there is no child corresponding to token ROLES
fn ROLES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ROLES, 0)
}
/// Retrieves first TerminalNode corresponding to token CURRENT
/// Returns `None` if there is no child corresponding to token CURRENT
fn CURRENT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CURRENT, 0)
}
/// Retrieves first TerminalNode corresponding to token EXPORT
/// Returns `None` if there is no child corresponding to token EXPORT
fn EXPORT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXPORT, 0)
}
/// Retrieves first TerminalNode corresponding to token TABLE
/// Returns `None` if there is no child corresponding to token TABLE
fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token IMPORT
/// Returns `None` if there is no child corresponding to token IMPORT
fn IMPORT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IMPORT, 0)
}
/// Retrieves first TerminalNode corresponding to token COMPACTIONS
/// Returns `None` if there is no child corresponding to token COMPACTIONS
fn COMPACTIONS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMPACTIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token TRANSACTIONS
/// Returns `None` if there is no child corresponding to token TRANSACTIONS
fn TRANSACTIONS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TRANSACTIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token INDEXES
/// Returns `None` if there is no child corresponding to token INDEXES
fn INDEXES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INDEXES, 0)
}
/// Retrieves first TerminalNode corresponding to token LOCKS
/// Returns `None` if there is no child corresponding to token LOCKS
fn LOCKS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LOCKS, 0)
}
/// Retrieves first TerminalNode corresponding to token INDEX
/// Returns `None` if there is no child corresponding to token INDEX
fn INDEX(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INDEX, 0)
}
/// Retrieves first TerminalNode corresponding to token ALTER
/// Returns `None` if there is no child corresponding to token ALTER
fn ALTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ALTER, 0)
}
/// Retrieves first TerminalNode corresponding to token LOCK
/// Returns `None` if there is no child corresponding to token LOCK
fn LOCK(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LOCK, 0)
}
/// Retrieves first TerminalNode corresponding to token DATABASE
/// Returns `None` if there is no child corresponding to token DATABASE
fn DATABASE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DATABASE, 0)
}
/// Retrieves first TerminalNode corresponding to token UNLOCK
/// Returns `None` if there is no child corresponding to token UNLOCK
fn UNLOCK(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UNLOCK, 0)
}
/// Retrieves first TerminalNode corresponding to token TEMPORARY
/// Returns `None` if there is no child corresponding to token TEMPORARY
fn TEMPORARY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TEMPORARY, 0)
}
/// Retrieves first TerminalNode corresponding to token MACRO
/// Returns `None` if there is no child corresponding to token MACRO
fn MACRO(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MACRO, 0)
}
fn tableIdentifier(&self) -> Option<Rc<TableIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token NOT
/// Returns `None` if there is no child corresponding to token NOT
fn NOT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NOT, 0)
}
/// Retrieves first TerminalNode corresponding to token CLUSTERED
/// Returns `None` if there is no child corresponding to token CLUSTERED
fn CLUSTERED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CLUSTERED, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
/// Retrieves first TerminalNode corresponding to token SORTED
/// Returns `None` if there is no child corresponding to token SORTED
fn SORTED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SORTED, 0)
}
/// Retrieves first TerminalNode corresponding to token SKEWED
/// Returns `None` if there is no child corresponding to token SKEWED
fn SKEWED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SKEWED, 0)
}
/// Retrieves first TerminalNode corresponding to token STORED
/// Returns `None` if there is no child corresponding to token STORED
fn STORED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(STORED, 0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
/// Retrieves first TerminalNode corresponding to token DIRECTORIES
/// Returns `None` if there is no child corresponding to token DIRECTORIES
fn DIRECTORIES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DIRECTORIES, 0)
}
/// Retrieves first TerminalNode corresponding to token SET
/// Returns `None` if there is no child corresponding to token SET
fn SET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SET, 0)
}
/// Retrieves first TerminalNode corresponding to token LOCATION
/// Returns `None` if there is no child corresponding to token LOCATION
fn LOCATION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LOCATION, 0)
}
/// Retrieves first TerminalNode corresponding to token EXCHANGE
/// Returns `None` if there is no child corresponding to token EXCHANGE
fn EXCHANGE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXCHANGE, 0)
}
/// Retrieves first TerminalNode corresponding to token PARTITION
/// Returns `None` if there is no child corresponding to token PARTITION
fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PARTITION, 0)
}
/// Retrieves first TerminalNode corresponding to token ARCHIVE
/// Returns `None` if there is no child corresponding to token ARCHIVE
fn ARCHIVE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ARCHIVE, 0)
}
/// Retrieves first TerminalNode corresponding to token UNARCHIVE
/// Returns `None` if there is no child corresponding to token UNARCHIVE
fn UNARCHIVE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UNARCHIVE, 0)
}
/// Retrieves first TerminalNode corresponding to token TOUCH
/// Returns `None` if there is no child corresponding to token TOUCH
fn TOUCH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TOUCH, 0)
}
/// Retrieves first TerminalNode corresponding to token COMPACT
/// Returns `None` if there is no child corresponding to token COMPACT
fn COMPACT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMPACT, 0)
}
fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token CONCATENATE
/// Returns `None` if there is no child corresponding to token CONCATENATE
fn CONCATENATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CONCATENATE, 0)
}
/// Retrieves first TerminalNode corresponding to token FILEFORMAT
/// Returns `None` if there is no child corresponding to token FILEFORMAT
fn FILEFORMAT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FILEFORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token REPLACE
/// Returns `None` if there is no child corresponding to token REPLACE
fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(REPLACE, 0)
}
/// Retrieves first TerminalNode corresponding to token COLUMNS
/// Returns `None` if there is no child corresponding to token COLUMNS
fn COLUMNS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COLUMNS, 0)
}
/// Retrieves first TerminalNode corresponding to token START
/// Returns `None` if there is no child corresponding to token START
fn START(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(START, 0)
}
/// Retrieves first TerminalNode corresponding to token TRANSACTION
/// Returns `None` if there is no child corresponding to token TRANSACTION
fn TRANSACTION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TRANSACTION, 0)
}
/// Retrieves first TerminalNode corresponding to token COMMIT
/// Returns `None` if there is no child corresponding to token COMMIT
fn COMMIT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMIT, 0)
}
/// Retrieves first TerminalNode corresponding to token ROLLBACK
/// Returns `None` if there is no child corresponding to token ROLLBACK
fn ROLLBACK(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ROLLBACK, 0)
}
/// Retrieves first TerminalNode corresponding to token DFS
/// Returns `None` if there is no child corresponding to token DFS
fn DFS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DFS, 0)
}

}

impl<'input> UnsupportedHiveNativeCommandsContextAttrs<'input> for UnsupportedHiveNativeCommandsContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unsupportedHiveNativeCommands(&mut self,)
	-> Result<Rc<UnsupportedHiveNativeCommandsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnsupportedHiveNativeCommandsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 80, RULE_unsupportedHiveNativeCommands);
        let mut _localctx: Rc<UnsupportedHiveNativeCommandsContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2077);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(203,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(1909);
					let tmp = recog.base.match_token(CREATE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1910);
					let tmp = recog.base.match_token(ROLE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(1911);
					let tmp = recog.base.match_token(DROP,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1912);
					let tmp = recog.base.match_token(ROLE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(1913);
					let tmp = recog.base.match_token(GRANT,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1915);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(196,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1914);
							let tmp = recog.base.match_token(ROLE,&mut recog.err_handler)?;
							 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
							  

							}
						}

						_ => {}
					}
					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(1917);
					let tmp = recog.base.match_token(REVOKE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1919);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(197,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1918);
							let tmp = recog.base.match_token(ROLE,&mut recog.err_handler)?;
							 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
							  

							}
						}

						_ => {}
					}
					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					recog.base.set_state(1921);
					let tmp = recog.base.match_token(SHOW,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1922);
					let tmp = recog.base.match_token(GRANT,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					recog.base.set_state(1923);
					let tmp = recog.base.match_token(SHOW,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1924);
					let tmp = recog.base.match_token(ROLE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					recog.base.set_state(1926);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(198,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(1925);
							let tmp = recog.base.match_token(GRANT,&mut recog.err_handler)?;
							 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw3 = Some(tmp.clone());
							  

							}
						}

						_ => {}
					}
					}
				}
			,
				7 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					recog.base.set_state(1928);
					let tmp = recog.base.match_token(SHOW,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1929);
					let tmp = recog.base.match_token(PRINCIPALS,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					}
				}
			,
				8 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 8);
					recog.base.enter_outer_alt(None, 8);
					{
					recog.base.set_state(1930);
					let tmp = recog.base.match_token(SHOW,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1931);
					let tmp = recog.base.match_token(ROLES,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					}
				}
			,
				9 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 9);
					recog.base.enter_outer_alt(None, 9);
					{
					recog.base.set_state(1932);
					let tmp = recog.base.match_token(SHOW,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1933);
					let tmp = recog.base.match_token(CURRENT,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					recog.base.set_state(1934);
					let tmp = recog.base.match_token(ROLES,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw3 = Some(tmp.clone());
					  

					}
				}
			,
				10 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 10);
					recog.base.enter_outer_alt(None, 10);
					{
					recog.base.set_state(1935);
					let tmp = recog.base.match_token(EXPORT,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1936);
					let tmp = recog.base.match_token(TABLE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					}
				}
			,
				11 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 11);
					recog.base.enter_outer_alt(None, 11);
					{
					recog.base.set_state(1937);
					let tmp = recog.base.match_token(IMPORT,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1938);
					let tmp = recog.base.match_token(TABLE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					}
				}
			,
				12 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 12);
					recog.base.enter_outer_alt(None, 12);
					{
					recog.base.set_state(1939);
					let tmp = recog.base.match_token(SHOW,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1940);
					let tmp = recog.base.match_token(COMPACTIONS,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					}
				}
			,
				13 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 13);
					recog.base.enter_outer_alt(None, 13);
					{
					recog.base.set_state(1941);
					let tmp = recog.base.match_token(SHOW,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1942);
					let tmp = recog.base.match_token(CREATE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					recog.base.set_state(1943);
					let tmp = recog.base.match_token(TABLE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw3 = Some(tmp.clone());
					  

					}
				}
			,
				14 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 14);
					recog.base.enter_outer_alt(None, 14);
					{
					recog.base.set_state(1944);
					let tmp = recog.base.match_token(SHOW,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1945);
					let tmp = recog.base.match_token(TRANSACTIONS,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					}
				}
			,
				15 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 15);
					recog.base.enter_outer_alt(None, 15);
					{
					recog.base.set_state(1946);
					let tmp = recog.base.match_token(SHOW,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1947);
					let tmp = recog.base.match_token(INDEXES,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					}
				}
			,
				16 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 16);
					recog.base.enter_outer_alt(None, 16);
					{
					recog.base.set_state(1948);
					let tmp = recog.base.match_token(SHOW,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1949);
					let tmp = recog.base.match_token(LOCKS,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					}
				}
			,
				17 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 17);
					recog.base.enter_outer_alt(None, 17);
					{
					recog.base.set_state(1950);
					let tmp = recog.base.match_token(CREATE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1951);
					let tmp = recog.base.match_token(INDEX,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					}
				}
			,
				18 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 18);
					recog.base.enter_outer_alt(None, 18);
					{
					recog.base.set_state(1952);
					let tmp = recog.base.match_token(DROP,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1953);
					let tmp = recog.base.match_token(INDEX,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					}
				}
			,
				19 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 19);
					recog.base.enter_outer_alt(None, 19);
					{
					recog.base.set_state(1954);
					let tmp = recog.base.match_token(ALTER,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1955);
					let tmp = recog.base.match_token(INDEX,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					}
				}
			,
				20 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 20);
					recog.base.enter_outer_alt(None, 20);
					{
					recog.base.set_state(1956);
					let tmp = recog.base.match_token(LOCK,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1957);
					let tmp = recog.base.match_token(TABLE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					}
				}
			,
				21 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 21);
					recog.base.enter_outer_alt(None, 21);
					{
					recog.base.set_state(1958);
					let tmp = recog.base.match_token(LOCK,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1959);
					let tmp = recog.base.match_token(DATABASE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					}
				}
			,
				22 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 22);
					recog.base.enter_outer_alt(None, 22);
					{
					recog.base.set_state(1960);
					let tmp = recog.base.match_token(UNLOCK,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1961);
					let tmp = recog.base.match_token(TABLE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					}
				}
			,
				23 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 23);
					recog.base.enter_outer_alt(None, 23);
					{
					recog.base.set_state(1962);
					let tmp = recog.base.match_token(UNLOCK,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1963);
					let tmp = recog.base.match_token(DATABASE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					}
				}
			,
				24 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 24);
					recog.base.enter_outer_alt(None, 24);
					{
					recog.base.set_state(1964);
					let tmp = recog.base.match_token(CREATE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1965);
					let tmp = recog.base.match_token(TEMPORARY,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					recog.base.set_state(1966);
					let tmp = recog.base.match_token(MACRO,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw3 = Some(tmp.clone());
					  

					}
				}
			,
				25 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 25);
					recog.base.enter_outer_alt(None, 25);
					{
					recog.base.set_state(1967);
					let tmp = recog.base.match_token(DROP,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1968);
					let tmp = recog.base.match_token(TEMPORARY,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					recog.base.set_state(1969);
					let tmp = recog.base.match_token(MACRO,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw3 = Some(tmp.clone());
					  

					}
				}
			,
				26 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 26);
					recog.base.enter_outer_alt(None, 26);
					{
					recog.base.set_state(1970);
					let tmp = recog.base.match_token(ALTER,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1971);
					let tmp = recog.base.match_token(TABLE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					/*InvokeRule tableIdentifier*/
					recog.base.set_state(1972);
					recog.tableIdentifier()?;

					recog.base.set_state(1973);
					let tmp = recog.base.match_token(NOT,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw3 = Some(tmp.clone());
					  

					recog.base.set_state(1974);
					let tmp = recog.base.match_token(CLUSTERED,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw4 = Some(tmp.clone());
					  

					}
				}
			,
				27 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 27);
					recog.base.enter_outer_alt(None, 27);
					{
					recog.base.set_state(1976);
					let tmp = recog.base.match_token(ALTER,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1977);
					let tmp = recog.base.match_token(TABLE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					/*InvokeRule tableIdentifier*/
					recog.base.set_state(1978);
					recog.tableIdentifier()?;

					recog.base.set_state(1979);
					let tmp = recog.base.match_token(CLUSTERED,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw3 = Some(tmp.clone());
					  

					recog.base.set_state(1980);
					let tmp = recog.base.match_token(BY,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw4 = Some(tmp.clone());
					  

					}
				}
			,
				28 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 28);
					recog.base.enter_outer_alt(None, 28);
					{
					recog.base.set_state(1982);
					let tmp = recog.base.match_token(ALTER,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1983);
					let tmp = recog.base.match_token(TABLE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					/*InvokeRule tableIdentifier*/
					recog.base.set_state(1984);
					recog.tableIdentifier()?;

					recog.base.set_state(1985);
					let tmp = recog.base.match_token(NOT,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw3 = Some(tmp.clone());
					  

					recog.base.set_state(1986);
					let tmp = recog.base.match_token(SORTED,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw4 = Some(tmp.clone());
					  

					}
				}
			,
				29 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 29);
					recog.base.enter_outer_alt(None, 29);
					{
					recog.base.set_state(1988);
					let tmp = recog.base.match_token(ALTER,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1989);
					let tmp = recog.base.match_token(TABLE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					/*InvokeRule tableIdentifier*/
					recog.base.set_state(1990);
					recog.tableIdentifier()?;

					recog.base.set_state(1991);
					let tmp = recog.base.match_token(SKEWED,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw3 = Some(tmp.clone());
					  

					recog.base.set_state(1992);
					let tmp = recog.base.match_token(BY,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw4 = Some(tmp.clone());
					  

					}
				}
			,
				30 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 30);
					recog.base.enter_outer_alt(None, 30);
					{
					recog.base.set_state(1994);
					let tmp = recog.base.match_token(ALTER,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(1995);
					let tmp = recog.base.match_token(TABLE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					/*InvokeRule tableIdentifier*/
					recog.base.set_state(1996);
					recog.tableIdentifier()?;

					recog.base.set_state(1997);
					let tmp = recog.base.match_token(NOT,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw3 = Some(tmp.clone());
					  

					recog.base.set_state(1998);
					let tmp = recog.base.match_token(SKEWED,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw4 = Some(tmp.clone());
					  

					}
				}
			,
				31 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 31);
					recog.base.enter_outer_alt(None, 31);
					{
					recog.base.set_state(2000);
					let tmp = recog.base.match_token(ALTER,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(2001);
					let tmp = recog.base.match_token(TABLE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					/*InvokeRule tableIdentifier*/
					recog.base.set_state(2002);
					recog.tableIdentifier()?;

					recog.base.set_state(2003);
					let tmp = recog.base.match_token(NOT,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw3 = Some(tmp.clone());
					  

					recog.base.set_state(2004);
					let tmp = recog.base.match_token(STORED,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw4 = Some(tmp.clone());
					  

					recog.base.set_state(2005);
					let tmp = recog.base.match_token(AS,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw5 = Some(tmp.clone());
					  

					recog.base.set_state(2006);
					let tmp = recog.base.match_token(DIRECTORIES,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw6 = Some(tmp.clone());
					  

					}
				}
			,
				32 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 32);
					recog.base.enter_outer_alt(None, 32);
					{
					recog.base.set_state(2008);
					let tmp = recog.base.match_token(ALTER,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(2009);
					let tmp = recog.base.match_token(TABLE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					/*InvokeRule tableIdentifier*/
					recog.base.set_state(2010);
					recog.tableIdentifier()?;

					recog.base.set_state(2011);
					let tmp = recog.base.match_token(SET,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw3 = Some(tmp.clone());
					  

					recog.base.set_state(2012);
					let tmp = recog.base.match_token(SKEWED,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw4 = Some(tmp.clone());
					  

					recog.base.set_state(2013);
					let tmp = recog.base.match_token(LOCATION,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw5 = Some(tmp.clone());
					  

					}
				}
			,
				33 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 33);
					recog.base.enter_outer_alt(None, 33);
					{
					recog.base.set_state(2015);
					let tmp = recog.base.match_token(ALTER,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(2016);
					let tmp = recog.base.match_token(TABLE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					/*InvokeRule tableIdentifier*/
					recog.base.set_state(2017);
					recog.tableIdentifier()?;

					recog.base.set_state(2018);
					let tmp = recog.base.match_token(EXCHANGE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw3 = Some(tmp.clone());
					  

					recog.base.set_state(2019);
					let tmp = recog.base.match_token(PARTITION,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw4 = Some(tmp.clone());
					  

					}
				}
			,
				34 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 34);
					recog.base.enter_outer_alt(None, 34);
					{
					recog.base.set_state(2021);
					let tmp = recog.base.match_token(ALTER,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(2022);
					let tmp = recog.base.match_token(TABLE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					/*InvokeRule tableIdentifier*/
					recog.base.set_state(2023);
					recog.tableIdentifier()?;

					recog.base.set_state(2024);
					let tmp = recog.base.match_token(ARCHIVE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw3 = Some(tmp.clone());
					  

					recog.base.set_state(2025);
					let tmp = recog.base.match_token(PARTITION,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw4 = Some(tmp.clone());
					  

					}
				}
			,
				35 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 35);
					recog.base.enter_outer_alt(None, 35);
					{
					recog.base.set_state(2027);
					let tmp = recog.base.match_token(ALTER,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(2028);
					let tmp = recog.base.match_token(TABLE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					/*InvokeRule tableIdentifier*/
					recog.base.set_state(2029);
					recog.tableIdentifier()?;

					recog.base.set_state(2030);
					let tmp = recog.base.match_token(UNARCHIVE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw3 = Some(tmp.clone());
					  

					recog.base.set_state(2031);
					let tmp = recog.base.match_token(PARTITION,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw4 = Some(tmp.clone());
					  

					}
				}
			,
				36 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 36);
					recog.base.enter_outer_alt(None, 36);
					{
					recog.base.set_state(2033);
					let tmp = recog.base.match_token(ALTER,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(2034);
					let tmp = recog.base.match_token(TABLE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					/*InvokeRule tableIdentifier*/
					recog.base.set_state(2035);
					recog.tableIdentifier()?;

					recog.base.set_state(2036);
					let tmp = recog.base.match_token(TOUCH,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw3 = Some(tmp.clone());
					  

					}
				}
			,
				37 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 37);
					recog.base.enter_outer_alt(None, 37);
					{
					recog.base.set_state(2038);
					let tmp = recog.base.match_token(ALTER,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(2039);
					let tmp = recog.base.match_token(TABLE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					/*InvokeRule tableIdentifier*/
					recog.base.set_state(2040);
					recog.tableIdentifier()?;

					recog.base.set_state(2042);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==PARTITION {
						{
						/*InvokeRule partitionSpec*/
						recog.base.set_state(2041);
						recog.partitionSpec()?;

						}
					}

					recog.base.set_state(2044);
					let tmp = recog.base.match_token(COMPACT,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw3 = Some(tmp.clone());
					  

					}
				}
			,
				38 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 38);
					recog.base.enter_outer_alt(None, 38);
					{
					recog.base.set_state(2046);
					let tmp = recog.base.match_token(ALTER,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(2047);
					let tmp = recog.base.match_token(TABLE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					/*InvokeRule tableIdentifier*/
					recog.base.set_state(2048);
					recog.tableIdentifier()?;

					recog.base.set_state(2050);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==PARTITION {
						{
						/*InvokeRule partitionSpec*/
						recog.base.set_state(2049);
						recog.partitionSpec()?;

						}
					}

					recog.base.set_state(2052);
					let tmp = recog.base.match_token(CONCATENATE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw3 = Some(tmp.clone());
					  

					}
				}
			,
				39 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 39);
					recog.base.enter_outer_alt(None, 39);
					{
					recog.base.set_state(2054);
					let tmp = recog.base.match_token(ALTER,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(2055);
					let tmp = recog.base.match_token(TABLE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					/*InvokeRule tableIdentifier*/
					recog.base.set_state(2056);
					recog.tableIdentifier()?;

					recog.base.set_state(2058);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==PARTITION {
						{
						/*InvokeRule partitionSpec*/
						recog.base.set_state(2057);
						recog.partitionSpec()?;

						}
					}

					recog.base.set_state(2060);
					let tmp = recog.base.match_token(SET,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw3 = Some(tmp.clone());
					  

					recog.base.set_state(2061);
					let tmp = recog.base.match_token(FILEFORMAT,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw4 = Some(tmp.clone());
					  

					}
				}
			,
				40 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 40);
					recog.base.enter_outer_alt(None, 40);
					{
					recog.base.set_state(2063);
					let tmp = recog.base.match_token(ALTER,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(2064);
					let tmp = recog.base.match_token(TABLE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					/*InvokeRule tableIdentifier*/
					recog.base.set_state(2065);
					recog.tableIdentifier()?;

					recog.base.set_state(2067);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==PARTITION {
						{
						/*InvokeRule partitionSpec*/
						recog.base.set_state(2066);
						recog.partitionSpec()?;

						}
					}

					recog.base.set_state(2069);
					let tmp = recog.base.match_token(REPLACE,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw3 = Some(tmp.clone());
					  

					recog.base.set_state(2070);
					let tmp = recog.base.match_token(COLUMNS,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw4 = Some(tmp.clone());
					  

					}
				}
			,
				41 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 41);
					recog.base.enter_outer_alt(None, 41);
					{
					recog.base.set_state(2072);
					let tmp = recog.base.match_token(START,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					recog.base.set_state(2073);
					let tmp = recog.base.match_token(TRANSACTION,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw2 = Some(tmp.clone());
					  

					}
				}
			,
				42 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 42);
					recog.base.enter_outer_alt(None, 42);
					{
					recog.base.set_state(2074);
					let tmp = recog.base.match_token(COMMIT,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					}
				}
			,
				43 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 43);
					recog.base.enter_outer_alt(None, 43);
					{
					recog.base.set_state(2075);
					let tmp = recog.base.match_token(ROLLBACK,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					}
				}
			,
				44 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 44);
					recog.base.enter_outer_alt(None, 44);
					{
					recog.base.set_state(2076);
					let tmp = recog.base.match_token(DFS,&mut recog.err_handler)?;
					 cast_mut::<_,UnsupportedHiveNativeCommandsContext >(&mut _localctx).kw1 = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- createTableHeader ----------------
pub type CreateTableHeaderContextAll<'input> = CreateTableHeaderContext<'input>;


pub type CreateTableHeaderContext<'input> = BaseParserRuleContext<'input,CreateTableHeaderContextExt<'input>>;

#[derive(Clone)]
pub struct CreateTableHeaderContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for CreateTableHeaderContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CreateTableHeaderContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_createTableHeader(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_createTableHeader(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CreateTableHeaderContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_createTableHeader(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateTableHeaderContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_createTableHeader }
	//fn type_rule_index() -> usize where Self: Sized { RULE_createTableHeader }
}
antlr_rust::tid!{CreateTableHeaderContextExt<'a>}

impl<'input> CreateTableHeaderContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CreateTableHeaderContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CreateTableHeaderContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait CreateTableHeaderContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<CreateTableHeaderContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token CREATE
/// Returns `None` if there is no child corresponding to token CREATE
fn CREATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CREATE, 0)
}
/// Retrieves first TerminalNode corresponding to token TABLE
/// Returns `None` if there is no child corresponding to token TABLE
fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TABLE, 0)
}
fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token TEMPORARY
/// Returns `None` if there is no child corresponding to token TEMPORARY
fn TEMPORARY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TEMPORARY, 0)
}
/// Retrieves first TerminalNode corresponding to token EXTERNAL
/// Returns `None` if there is no child corresponding to token EXTERNAL
fn EXTERNAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXTERNAL, 0)
}
/// Retrieves first TerminalNode corresponding to token IF
/// Returns `None` if there is no child corresponding to token IF
fn IF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IF, 0)
}
fn errorCapturingNot(&self) -> Option<Rc<ErrorCapturingNotContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EXISTS
/// Returns `None` if there is no child corresponding to token EXISTS
fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXISTS, 0)
}

}

impl<'input> CreateTableHeaderContextAttrs<'input> for CreateTableHeaderContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn createTableHeader(&mut self,)
	-> Result<Rc<CreateTableHeaderContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CreateTableHeaderContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 82, RULE_createTableHeader);
        let mut _localctx: Rc<CreateTableHeaderContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2079);
			recog.base.match_token(CREATE,&mut recog.err_handler)?;

			recog.base.set_state(2081);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==TEMPORARY {
				{
				recog.base.set_state(2080);
				recog.base.match_token(TEMPORARY,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(2084);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==EXTERNAL {
				{
				recog.base.set_state(2083);
				recog.base.match_token(EXTERNAL,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(2086);
			recog.base.match_token(TABLE,&mut recog.err_handler)?;

			recog.base.set_state(2091);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(206,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(2087);
					recog.base.match_token(IF,&mut recog.err_handler)?;

					/*InvokeRule errorCapturingNot*/
					recog.base.set_state(2088);
					recog.errorCapturingNot()?;

					recog.base.set_state(2089);
					recog.base.match_token(EXISTS,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			/*InvokeRule identifierReference*/
			recog.base.set_state(2093);
			recog.identifierReference()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- replaceTableHeader ----------------
pub type ReplaceTableHeaderContextAll<'input> = ReplaceTableHeaderContext<'input>;


pub type ReplaceTableHeaderContext<'input> = BaseParserRuleContext<'input,ReplaceTableHeaderContextExt<'input>>;

#[derive(Clone)]
pub struct ReplaceTableHeaderContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ReplaceTableHeaderContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ReplaceTableHeaderContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_replaceTableHeader(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_replaceTableHeader(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ReplaceTableHeaderContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_replaceTableHeader(self);
	}
}

impl<'input> CustomRuleContext<'input> for ReplaceTableHeaderContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_replaceTableHeader }
	//fn type_rule_index() -> usize where Self: Sized { RULE_replaceTableHeader }
}
antlr_rust::tid!{ReplaceTableHeaderContextExt<'a>}

impl<'input> ReplaceTableHeaderContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ReplaceTableHeaderContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ReplaceTableHeaderContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ReplaceTableHeaderContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ReplaceTableHeaderContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token REPLACE
/// Returns `None` if there is no child corresponding to token REPLACE
fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(REPLACE, 0)
}
/// Retrieves first TerminalNode corresponding to token TABLE
/// Returns `None` if there is no child corresponding to token TABLE
fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TABLE, 0)
}
fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token CREATE
/// Returns `None` if there is no child corresponding to token CREATE
fn CREATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CREATE, 0)
}
/// Retrieves first TerminalNode corresponding to token OR
/// Returns `None` if there is no child corresponding to token OR
fn OR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OR, 0)
}

}

impl<'input> ReplaceTableHeaderContextAttrs<'input> for ReplaceTableHeaderContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn replaceTableHeader(&mut self,)
	-> Result<Rc<ReplaceTableHeaderContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ReplaceTableHeaderContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 84, RULE_replaceTableHeader);
        let mut _localctx: Rc<ReplaceTableHeaderContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2097);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==CREATE {
				{
				recog.base.set_state(2095);
				recog.base.match_token(CREATE,&mut recog.err_handler)?;

				recog.base.set_state(2096);
				recog.base.match_token(OR,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(2099);
			recog.base.match_token(REPLACE,&mut recog.err_handler)?;

			recog.base.set_state(2100);
			recog.base.match_token(TABLE,&mut recog.err_handler)?;

			/*InvokeRule identifierReference*/
			recog.base.set_state(2101);
			recog.identifierReference()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- clusterBySpec ----------------
pub type ClusterBySpecContextAll<'input> = ClusterBySpecContext<'input>;


pub type ClusterBySpecContext<'input> = BaseParserRuleContext<'input,ClusterBySpecContextExt<'input>>;

#[derive(Clone)]
pub struct ClusterBySpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ClusterBySpecContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ClusterBySpecContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_clusterBySpec(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_clusterBySpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ClusterBySpecContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_clusterBySpec(self);
	}
}

impl<'input> CustomRuleContext<'input> for ClusterBySpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_clusterBySpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_clusterBySpec }
}
antlr_rust::tid!{ClusterBySpecContextExt<'a>}

impl<'input> ClusterBySpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ClusterBySpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ClusterBySpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ClusterBySpecContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ClusterBySpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token CLUSTER
/// Returns `None` if there is no child corresponding to token CLUSTER
fn CLUSTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CLUSTER, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
fn multipartIdentifierList(&self) -> Option<Rc<MultipartIdentifierListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}

}

impl<'input> ClusterBySpecContextAttrs<'input> for ClusterBySpecContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn clusterBySpec(&mut self,)
	-> Result<Rc<ClusterBySpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ClusterBySpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 86, RULE_clusterBySpec);
        let mut _localctx: Rc<ClusterBySpecContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2103);
			recog.base.match_token(CLUSTER,&mut recog.err_handler)?;

			recog.base.set_state(2104);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			recog.base.set_state(2105);
			recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

			/*InvokeRule multipartIdentifierList*/
			recog.base.set_state(2106);
			recog.multipartIdentifierList()?;

			recog.base.set_state(2107);
			recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- bucketSpec ----------------
pub type BucketSpecContextAll<'input> = BucketSpecContext<'input>;


pub type BucketSpecContext<'input> = BaseParserRuleContext<'input,BucketSpecContextExt<'input>>;

#[derive(Clone)]
pub struct BucketSpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for BucketSpecContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for BucketSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_bucketSpec(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_bucketSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for BucketSpecContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_bucketSpec(self);
	}
}

impl<'input> CustomRuleContext<'input> for BucketSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_bucketSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_bucketSpec }
}
antlr_rust::tid!{BucketSpecContextExt<'a>}

impl<'input> BucketSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<BucketSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,BucketSpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait BucketSpecContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<BucketSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token CLUSTERED
/// Returns `None` if there is no child corresponding to token CLUSTERED
fn CLUSTERED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CLUSTERED, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token BY in current rule
fn BY_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token BY, starting from 0.
/// Returns `None` if number of children corresponding to token BY is less or equal than `i`.
fn BY(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BY, i)
}
fn identifierList(&self) -> Option<Rc<IdentifierListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token INTO
/// Returns `None` if there is no child corresponding to token INTO
fn INTO(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INTO, 0)
}
fn integerValue(&self) -> Option<Rc<IntegerValueContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token BUCKETS
/// Returns `None` if there is no child corresponding to token BUCKETS
fn BUCKETS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BUCKETS, 0)
}
/// Retrieves first TerminalNode corresponding to token SORTED
/// Returns `None` if there is no child corresponding to token SORTED
fn SORTED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SORTED, 0)
}
fn orderedIdentifierList(&self) -> Option<Rc<OrderedIdentifierListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> BucketSpecContextAttrs<'input> for BucketSpecContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn bucketSpec(&mut self,)
	-> Result<Rc<BucketSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = BucketSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 88, RULE_bucketSpec);
        let mut _localctx: Rc<BucketSpecContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2109);
			recog.base.match_token(CLUSTERED,&mut recog.err_handler)?;

			recog.base.set_state(2110);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			/*InvokeRule identifierList*/
			recog.base.set_state(2111);
			recog.identifierList()?;

			recog.base.set_state(2115);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==SORTED {
				{
				recog.base.set_state(2112);
				recog.base.match_token(SORTED,&mut recog.err_handler)?;

				recog.base.set_state(2113);
				recog.base.match_token(BY,&mut recog.err_handler)?;

				/*InvokeRule orderedIdentifierList*/
				recog.base.set_state(2114);
				recog.orderedIdentifierList()?;

				}
			}

			recog.base.set_state(2117);
			recog.base.match_token(INTO,&mut recog.err_handler)?;

			/*InvokeRule integerValue*/
			recog.base.set_state(2118);
			recog.integerValue()?;

			recog.base.set_state(2119);
			recog.base.match_token(BUCKETS,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- skewSpec ----------------
pub type SkewSpecContextAll<'input> = SkewSpecContext<'input>;


pub type SkewSpecContext<'input> = BaseParserRuleContext<'input,SkewSpecContextExt<'input>>;

#[derive(Clone)]
pub struct SkewSpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SkewSpecContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SkewSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_skewSpec(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_skewSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SkewSpecContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_skewSpec(self);
	}
}

impl<'input> CustomRuleContext<'input> for SkewSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_skewSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_skewSpec }
}
antlr_rust::tid!{SkewSpecContextExt<'a>}

impl<'input> SkewSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SkewSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SkewSpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SkewSpecContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SkewSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token SKEWED
/// Returns `None` if there is no child corresponding to token SKEWED
fn SKEWED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SKEWED, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn identifierList(&self) -> Option<Rc<IdentifierListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token ON
/// Returns `None` if there is no child corresponding to token ON
fn ON(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ON, 0)
}
fn constantList(&self) -> Option<Rc<ConstantListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn nestedConstantList(&self) -> Option<Rc<NestedConstantListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token STORED
/// Returns `None` if there is no child corresponding to token STORED
fn STORED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(STORED, 0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
/// Retrieves first TerminalNode corresponding to token DIRECTORIES
/// Returns `None` if there is no child corresponding to token DIRECTORIES
fn DIRECTORIES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DIRECTORIES, 0)
}

}

impl<'input> SkewSpecContextAttrs<'input> for SkewSpecContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn skewSpec(&mut self,)
	-> Result<Rc<SkewSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SkewSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 90, RULE_skewSpec);
        let mut _localctx: Rc<SkewSpecContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2121);
			recog.base.match_token(SKEWED,&mut recog.err_handler)?;

			recog.base.set_state(2122);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			/*InvokeRule identifierList*/
			recog.base.set_state(2123);
			recog.identifierList()?;

			recog.base.set_state(2124);
			recog.base.match_token(ON,&mut recog.err_handler)?;

			recog.base.set_state(2127);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(209,&mut recog.base)? {
				1 =>{
					{
					/*InvokeRule constantList*/
					recog.base.set_state(2125);
					recog.constantList()?;

					}
				}
			,
				2 =>{
					{
					/*InvokeRule nestedConstantList*/
					recog.base.set_state(2126);
					recog.nestedConstantList()?;

					}
				}

				_ => {}
			}
			recog.base.set_state(2132);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(210,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(2129);
					recog.base.match_token(STORED,&mut recog.err_handler)?;

					recog.base.set_state(2130);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					recog.base.set_state(2131);
					recog.base.match_token(DIRECTORIES,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- locationSpec ----------------
pub type LocationSpecContextAll<'input> = LocationSpecContext<'input>;


pub type LocationSpecContext<'input> = BaseParserRuleContext<'input,LocationSpecContextExt<'input>>;

#[derive(Clone)]
pub struct LocationSpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for LocationSpecContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for LocationSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_locationSpec(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_locationSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for LocationSpecContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_locationSpec(self);
	}
}

impl<'input> CustomRuleContext<'input> for LocationSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_locationSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_locationSpec }
}
antlr_rust::tid!{LocationSpecContextExt<'a>}

impl<'input> LocationSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LocationSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LocationSpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait LocationSpecContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<LocationSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LOCATION
/// Returns `None` if there is no child corresponding to token LOCATION
fn LOCATION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LOCATION, 0)
}
fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LocationSpecContextAttrs<'input> for LocationSpecContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn locationSpec(&mut self,)
	-> Result<Rc<LocationSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LocationSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 92, RULE_locationSpec);
        let mut _localctx: Rc<LocationSpecContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2134);
			recog.base.match_token(LOCATION,&mut recog.err_handler)?;

			/*InvokeRule stringLit*/
			recog.base.set_state(2135);
			recog.stringLit()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- schemaBinding ----------------
pub type SchemaBindingContextAll<'input> = SchemaBindingContext<'input>;


pub type SchemaBindingContext<'input> = BaseParserRuleContext<'input,SchemaBindingContextExt<'input>>;

#[derive(Clone)]
pub struct SchemaBindingContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SchemaBindingContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SchemaBindingContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_schemaBinding(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_schemaBinding(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SchemaBindingContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_schemaBinding(self);
	}
}

impl<'input> CustomRuleContext<'input> for SchemaBindingContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_schemaBinding }
	//fn type_rule_index() -> usize where Self: Sized { RULE_schemaBinding }
}
antlr_rust::tid!{SchemaBindingContextExt<'a>}

impl<'input> SchemaBindingContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SchemaBindingContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SchemaBindingContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SchemaBindingContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SchemaBindingContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token SCHEMA
/// Returns `None` if there is no child corresponding to token SCHEMA
fn SCHEMA(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SCHEMA, 0)
}
/// Retrieves first TerminalNode corresponding to token BINDING
/// Returns `None` if there is no child corresponding to token BINDING
fn BINDING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BINDING, 0)
}
/// Retrieves first TerminalNode corresponding to token COMPENSATION
/// Returns `None` if there is no child corresponding to token COMPENSATION
fn COMPENSATION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMPENSATION, 0)
}
/// Retrieves first TerminalNode corresponding to token EVOLUTION
/// Returns `None` if there is no child corresponding to token EVOLUTION
fn EVOLUTION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EVOLUTION, 0)
}
/// Retrieves first TerminalNode corresponding to token TYPE
/// Returns `None` if there is no child corresponding to token TYPE
fn TYPE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TYPE, 0)
}

}

impl<'input> SchemaBindingContextAttrs<'input> for SchemaBindingContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn schemaBinding(&mut self,)
	-> Result<Rc<SchemaBindingContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SchemaBindingContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 94, RULE_schemaBinding);
        let mut _localctx: Rc<SchemaBindingContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2137);
			recog.base.match_token(WITH,&mut recog.err_handler)?;

			recog.base.set_state(2138);
			recog.base.match_token(SCHEMA,&mut recog.err_handler)?;

			recog.base.set_state(2144);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 BINDING 
				=> {
					{
					recog.base.set_state(2139);
					recog.base.match_token(BINDING,&mut recog.err_handler)?;

					}
				}

			 COMPENSATION 
				=> {
					{
					recog.base.set_state(2140);
					recog.base.match_token(COMPENSATION,&mut recog.err_handler)?;

					}
				}

			 EVOLUTION 
				=> {
					{
					recog.base.set_state(2141);
					recog.base.match_token(EVOLUTION,&mut recog.err_handler)?;

					}
				}

			 TYPE 
				=> {
					{
					recog.base.set_state(2142);
					recog.base.match_token(TYPE,&mut recog.err_handler)?;

					recog.base.set_state(2143);
					recog.base.match_token(EVOLUTION,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- commentSpec ----------------
pub type CommentSpecContextAll<'input> = CommentSpecContext<'input>;


pub type CommentSpecContext<'input> = BaseParserRuleContext<'input,CommentSpecContextExt<'input>>;

#[derive(Clone)]
pub struct CommentSpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for CommentSpecContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CommentSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_commentSpec(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_commentSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CommentSpecContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_commentSpec(self);
	}
}

impl<'input> CustomRuleContext<'input> for CommentSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_commentSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_commentSpec }
}
antlr_rust::tid!{CommentSpecContextExt<'a>}

impl<'input> CommentSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CommentSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CommentSpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait CommentSpecContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<CommentSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token COMMENT
/// Returns `None` if there is no child corresponding to token COMMENT
fn COMMENT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMENT, 0)
}
fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CommentSpecContextAttrs<'input> for CommentSpecContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn commentSpec(&mut self,)
	-> Result<Rc<CommentSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CommentSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 96, RULE_commentSpec);
        let mut _localctx: Rc<CommentSpecContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2146);
			recog.base.match_token(COMMENT,&mut recog.err_handler)?;

			/*InvokeRule stringLit*/
			recog.base.set_state(2147);
			recog.stringLit()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- singleQuery ----------------
pub type SingleQueryContextAll<'input> = SingleQueryContext<'input>;


pub type SingleQueryContext<'input> = BaseParserRuleContext<'input,SingleQueryContextExt<'input>>;

#[derive(Clone)]
pub struct SingleQueryContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SingleQueryContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SingleQueryContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_singleQuery(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_singleQuery(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SingleQueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_singleQuery(self);
	}
}

impl<'input> CustomRuleContext<'input> for SingleQueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_singleQuery }
	//fn type_rule_index() -> usize where Self: Sized { RULE_singleQuery }
}
antlr_rust::tid!{SingleQueryContextExt<'a>}

impl<'input> SingleQueryContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SingleQueryContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SingleQueryContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SingleQueryContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SingleQueryContextExt<'input>>{

fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}

}

impl<'input> SingleQueryContextAttrs<'input> for SingleQueryContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn singleQuery(&mut self,)
	-> Result<Rc<SingleQueryContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SingleQueryContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 98, RULE_singleQuery);
        let mut _localctx: Rc<SingleQueryContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule query*/
			recog.base.set_state(2149);
			recog.query()?;

			recog.base.set_state(2150);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- query ----------------
pub type QueryContextAll<'input> = QueryContext<'input>;


pub type QueryContext<'input> = BaseParserRuleContext<'input,QueryContextExt<'input>>;

#[derive(Clone)]
pub struct QueryContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for QueryContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for QueryContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_query(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_query(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for QueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_query(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_query }
	//fn type_rule_index() -> usize where Self: Sized { RULE_query }
}
antlr_rust::tid!{QueryContextExt<'a>}

impl<'input> QueryContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait QueryContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<QueryContextExt<'input>>{

fn queryTerm(&self) -> Option<Rc<QueryTermContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn queryOrganization(&self) -> Option<Rc<QueryOrganizationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn ctes(&self) -> Option<Rc<CtesContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> QueryContextAttrs<'input> for QueryContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn query(&mut self,)
	-> Result<Rc<QueryContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 100, RULE_query);
        let mut _localctx: Rc<QueryContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2153);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==WITH {
				{
				/*InvokeRule ctes*/
				recog.base.set_state(2152);
				recog.ctes()?;

				}
			}

			/*InvokeRule queryTerm*/
			recog.base.set_state(2155);
			recog.queryTerm_rec(0)?;

			/*InvokeRule queryOrganization*/
			recog.base.set_state(2156);
			recog.queryOrganization()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- insertInto ----------------
#[derive(Debug)]
pub enum InsertIntoContextAll<'input>{
	InsertIntoReplaceWhereContext(InsertIntoReplaceWhereContext<'input>),
	InsertOverwriteHiveDirContext(InsertOverwriteHiveDirContext<'input>),
	InsertOverwriteDirContext(InsertOverwriteDirContext<'input>),
	InsertOverwriteTableContext(InsertOverwriteTableContext<'input>),
	InsertIntoTableContext(InsertIntoTableContext<'input>),
Error(InsertIntoContext<'input>)
}
antlr_rust::tid!{InsertIntoContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for InsertIntoContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for InsertIntoContextAll<'input>{}

impl<'input> Deref for InsertIntoContextAll<'input>{
	type Target = dyn InsertIntoContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use InsertIntoContextAll::*;
		match self{
			InsertIntoReplaceWhereContext(inner) => inner,
			InsertOverwriteHiveDirContext(inner) => inner,
			InsertOverwriteDirContext(inner) => inner,
			InsertOverwriteTableContext(inner) => inner,
			InsertIntoTableContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for InsertIntoContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for InsertIntoContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type InsertIntoContext<'input> = BaseParserRuleContext<'input,InsertIntoContextExt<'input>>;

#[derive(Clone)]
pub struct InsertIntoContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for InsertIntoContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for InsertIntoContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for InsertIntoContext<'input>{
}

impl<'input> CustomRuleContext<'input> for InsertIntoContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_insertInto }
	//fn type_rule_index() -> usize where Self: Sized { RULE_insertInto }
}
antlr_rust::tid!{InsertIntoContextExt<'a>}

impl<'input> InsertIntoContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<InsertIntoContextAll<'input>> {
		Rc::new(
		InsertIntoContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,InsertIntoContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait InsertIntoContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<InsertIntoContextExt<'input>>{


}

impl<'input> InsertIntoContextAttrs<'input> for InsertIntoContext<'input>{}

pub type InsertIntoReplaceWhereContext<'input> = BaseParserRuleContext<'input,InsertIntoReplaceWhereContextExt<'input>>;

pub trait InsertIntoReplaceWhereContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token INSERT
	/// Returns `None` if there is no child corresponding to token INSERT
	fn INSERT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(INSERT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token INTO
	/// Returns `None` if there is no child corresponding to token INTO
	fn INTO(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(INTO, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token REPLACE
	/// Returns `None` if there is no child corresponding to token REPLACE
	fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(REPLACE, 0)
	}
	fn whereClause(&self) -> Option<Rc<WhereClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn optionsClause(&self) -> Option<Rc<OptionsClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> InsertIntoReplaceWhereContextAttrs<'input> for InsertIntoReplaceWhereContext<'input>{}

pub struct InsertIntoReplaceWhereContextExt<'input>{
	base:InsertIntoContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{InsertIntoReplaceWhereContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for InsertIntoReplaceWhereContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for InsertIntoReplaceWhereContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_insertIntoReplaceWhere(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_insertIntoReplaceWhere(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for InsertIntoReplaceWhereContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_insertIntoReplaceWhere(self);
	}
}

impl<'input> CustomRuleContext<'input> for InsertIntoReplaceWhereContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_insertInto }
	//fn type_rule_index() -> usize where Self: Sized { RULE_insertInto }
}

impl<'input> Borrow<InsertIntoContextExt<'input>> for InsertIntoReplaceWhereContext<'input>{
	fn borrow(&self) -> &InsertIntoContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<InsertIntoContextExt<'input>> for InsertIntoReplaceWhereContext<'input>{
	fn borrow_mut(&mut self) -> &mut InsertIntoContextExt<'input> { &mut self.base }
}

impl<'input> InsertIntoContextAttrs<'input> for InsertIntoReplaceWhereContext<'input> {}

impl<'input> InsertIntoReplaceWhereContextExt<'input>{
	fn new(ctx: &dyn InsertIntoContextAttrs<'input>) -> Rc<InsertIntoContextAll<'input>>  {
		Rc::new(
			InsertIntoContextAll::InsertIntoReplaceWhereContext(
				BaseParserRuleContext::copy_from(ctx,InsertIntoReplaceWhereContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type InsertOverwriteHiveDirContext<'input> = BaseParserRuleContext<'input,InsertOverwriteHiveDirContextExt<'input>>;

pub trait InsertOverwriteHiveDirContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token INSERT
	/// Returns `None` if there is no child corresponding to token INSERT
	fn INSERT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(INSERT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OVERWRITE
	/// Returns `None` if there is no child corresponding to token OVERWRITE
	fn OVERWRITE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(OVERWRITE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DIRECTORY
	/// Returns `None` if there is no child corresponding to token DIRECTORY
	fn DIRECTORY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DIRECTORY, 0)
	}
	fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LOCAL
	/// Returns `None` if there is no child corresponding to token LOCAL
	fn LOCAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LOCAL, 0)
	}
	fn rowFormat(&self) -> Option<Rc<RowFormatContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn createFileFormat(&self) -> Option<Rc<CreateFileFormatContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> InsertOverwriteHiveDirContextAttrs<'input> for InsertOverwriteHiveDirContext<'input>{}

pub struct InsertOverwriteHiveDirContextExt<'input>{
	base:InsertIntoContextExt<'input>,
	pub path: Option<Rc<StringLitContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{InsertOverwriteHiveDirContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for InsertOverwriteHiveDirContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for InsertOverwriteHiveDirContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_insertOverwriteHiveDir(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_insertOverwriteHiveDir(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for InsertOverwriteHiveDirContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_insertOverwriteHiveDir(self);
	}
}

impl<'input> CustomRuleContext<'input> for InsertOverwriteHiveDirContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_insertInto }
	//fn type_rule_index() -> usize where Self: Sized { RULE_insertInto }
}

impl<'input> Borrow<InsertIntoContextExt<'input>> for InsertOverwriteHiveDirContext<'input>{
	fn borrow(&self) -> &InsertIntoContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<InsertIntoContextExt<'input>> for InsertOverwriteHiveDirContext<'input>{
	fn borrow_mut(&mut self) -> &mut InsertIntoContextExt<'input> { &mut self.base }
}

impl<'input> InsertIntoContextAttrs<'input> for InsertOverwriteHiveDirContext<'input> {}

impl<'input> InsertOverwriteHiveDirContextExt<'input>{
	fn new(ctx: &dyn InsertIntoContextAttrs<'input>) -> Rc<InsertIntoContextAll<'input>>  {
		Rc::new(
			InsertIntoContextAll::InsertOverwriteHiveDirContext(
				BaseParserRuleContext::copy_from(ctx,InsertOverwriteHiveDirContextExt{
        			path:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type InsertOverwriteDirContext<'input> = BaseParserRuleContext<'input,InsertOverwriteDirContextExt<'input>>;

pub trait InsertOverwriteDirContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token INSERT
	/// Returns `None` if there is no child corresponding to token INSERT
	fn INSERT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(INSERT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OVERWRITE
	/// Returns `None` if there is no child corresponding to token OVERWRITE
	fn OVERWRITE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(OVERWRITE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DIRECTORY
	/// Returns `None` if there is no child corresponding to token DIRECTORY
	fn DIRECTORY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DIRECTORY, 0)
	}
	fn tableProvider(&self) -> Option<Rc<TableProviderContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LOCAL
	/// Returns `None` if there is no child corresponding to token LOCAL
	fn LOCAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LOCAL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OPTIONS
	/// Returns `None` if there is no child corresponding to token OPTIONS
	fn OPTIONS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(OPTIONS, 0)
	}
	fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn propertyList(&self) -> Option<Rc<PropertyListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> InsertOverwriteDirContextAttrs<'input> for InsertOverwriteDirContext<'input>{}

pub struct InsertOverwriteDirContextExt<'input>{
	base:InsertIntoContextExt<'input>,
	pub path: Option<Rc<StringLitContextAll<'input>>>,
	pub options: Option<Rc<PropertyListContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{InsertOverwriteDirContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for InsertOverwriteDirContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for InsertOverwriteDirContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_insertOverwriteDir(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_insertOverwriteDir(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for InsertOverwriteDirContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_insertOverwriteDir(self);
	}
}

impl<'input> CustomRuleContext<'input> for InsertOverwriteDirContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_insertInto }
	//fn type_rule_index() -> usize where Self: Sized { RULE_insertInto }
}

impl<'input> Borrow<InsertIntoContextExt<'input>> for InsertOverwriteDirContext<'input>{
	fn borrow(&self) -> &InsertIntoContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<InsertIntoContextExt<'input>> for InsertOverwriteDirContext<'input>{
	fn borrow_mut(&mut self) -> &mut InsertIntoContextExt<'input> { &mut self.base }
}

impl<'input> InsertIntoContextAttrs<'input> for InsertOverwriteDirContext<'input> {}

impl<'input> InsertOverwriteDirContextExt<'input>{
	fn new(ctx: &dyn InsertIntoContextAttrs<'input>) -> Rc<InsertIntoContextAll<'input>>  {
		Rc::new(
			InsertIntoContextAll::InsertOverwriteDirContext(
				BaseParserRuleContext::copy_from(ctx,InsertOverwriteDirContextExt{
        			path:None, options:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type InsertOverwriteTableContext<'input> = BaseParserRuleContext<'input,InsertOverwriteTableContextExt<'input>>;

pub trait InsertOverwriteTableContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token INSERT
	/// Returns `None` if there is no child corresponding to token INSERT
	fn INSERT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(INSERT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OVERWRITE
	/// Returns `None` if there is no child corresponding to token OVERWRITE
	fn OVERWRITE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(OVERWRITE, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn optionsClause(&self) -> Option<Rc<OptionsClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn identifierList(&self) -> Option<Rc<IdentifierListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token BY
	/// Returns `None` if there is no child corresponding to token BY
	fn BY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(BY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NAME
	/// Returns `None` if there is no child corresponding to token NAME
	fn NAME(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(NAME, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	fn errorCapturingNot(&self) -> Option<Rc<ErrorCapturingNotContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
}

impl<'input> InsertOverwriteTableContextAttrs<'input> for InsertOverwriteTableContext<'input>{}

pub struct InsertOverwriteTableContextExt<'input>{
	base:InsertIntoContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{InsertOverwriteTableContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for InsertOverwriteTableContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for InsertOverwriteTableContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_insertOverwriteTable(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_insertOverwriteTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for InsertOverwriteTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_insertOverwriteTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for InsertOverwriteTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_insertInto }
	//fn type_rule_index() -> usize where Self: Sized { RULE_insertInto }
}

impl<'input> Borrow<InsertIntoContextExt<'input>> for InsertOverwriteTableContext<'input>{
	fn borrow(&self) -> &InsertIntoContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<InsertIntoContextExt<'input>> for InsertOverwriteTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut InsertIntoContextExt<'input> { &mut self.base }
}

impl<'input> InsertIntoContextAttrs<'input> for InsertOverwriteTableContext<'input> {}

impl<'input> InsertOverwriteTableContextExt<'input>{
	fn new(ctx: &dyn InsertIntoContextAttrs<'input>) -> Rc<InsertIntoContextAll<'input>>  {
		Rc::new(
			InsertIntoContextAll::InsertOverwriteTableContext(
				BaseParserRuleContext::copy_from(ctx,InsertOverwriteTableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type InsertIntoTableContext<'input> = BaseParserRuleContext<'input,InsertIntoTableContextExt<'input>>;

pub trait InsertIntoTableContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token INSERT
	/// Returns `None` if there is no child corresponding to token INSERT
	fn INSERT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(INSERT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token INTO
	/// Returns `None` if there is no child corresponding to token INTO
	fn INTO(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(INTO, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn optionsClause(&self) -> Option<Rc<OptionsClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token IF
	/// Returns `None` if there is no child corresponding to token IF
	fn IF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IF, 0)
	}
	fn errorCapturingNot(&self) -> Option<Rc<ErrorCapturingNotContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	fn identifierList(&self) -> Option<Rc<IdentifierListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token BY
	/// Returns `None` if there is no child corresponding to token BY
	fn BY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(BY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NAME
	/// Returns `None` if there is no child corresponding to token NAME
	fn NAME(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(NAME, 0)
	}
}

impl<'input> InsertIntoTableContextAttrs<'input> for InsertIntoTableContext<'input>{}

pub struct InsertIntoTableContextExt<'input>{
	base:InsertIntoContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{InsertIntoTableContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for InsertIntoTableContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for InsertIntoTableContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_insertIntoTable(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_insertIntoTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for InsertIntoTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_insertIntoTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for InsertIntoTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_insertInto }
	//fn type_rule_index() -> usize where Self: Sized { RULE_insertInto }
}

impl<'input> Borrow<InsertIntoContextExt<'input>> for InsertIntoTableContext<'input>{
	fn borrow(&self) -> &InsertIntoContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<InsertIntoContextExt<'input>> for InsertIntoTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut InsertIntoContextExt<'input> { &mut self.base }
}

impl<'input> InsertIntoContextAttrs<'input> for InsertIntoTableContext<'input> {}

impl<'input> InsertIntoTableContextExt<'input>{
	fn new(ctx: &dyn InsertIntoContextAttrs<'input>) -> Rc<InsertIntoContextAll<'input>>  {
		Rc::new(
			InsertIntoContextAll::InsertIntoTableContext(
				BaseParserRuleContext::copy_from(ctx,InsertIntoTableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn insertInto(&mut self,)
	-> Result<Rc<InsertIntoContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = InsertIntoContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 102, RULE_insertInto);
        let mut _localctx: Rc<InsertIntoContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2243);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(231,&mut recog.base)? {
				1 =>{
					let tmp = InsertOverwriteTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(2158);
					recog.base.match_token(INSERT,&mut recog.err_handler)?;

					recog.base.set_state(2159);
					recog.base.match_token(OVERWRITE,&mut recog.err_handler)?;

					recog.base.set_state(2161);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(213,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2160);
							recog.base.match_token(TABLE,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(2163);
					recog.identifierReference()?;

					recog.base.set_state(2165);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(214,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule optionsClause*/
							recog.base.set_state(2164);
							recog.optionsClause()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(2174);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==PARTITION {
						{
						/*InvokeRule partitionSpec*/
						recog.base.set_state(2167);
						recog.partitionSpec()?;

						recog.base.set_state(2172);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if _la==IF {
							{
							recog.base.set_state(2168);
							recog.base.match_token(IF,&mut recog.err_handler)?;

							/*InvokeRule errorCapturingNot*/
							recog.base.set_state(2169);
							recog.errorCapturingNot()?;

							recog.base.set_state(2170);
							recog.base.match_token(EXISTS,&mut recog.err_handler)?;

							}
						}

						}
					}

					recog.base.set_state(2179);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(217,&mut recog.base)? {
						x if x == 1=>{
							{
							{
							recog.base.set_state(2176);
							recog.base.match_token(BY,&mut recog.err_handler)?;

							recog.base.set_state(2177);
							recog.base.match_token(NAME,&mut recog.err_handler)?;

							}
							}
						}

						x if x == 2=>{
							{
							/*InvokeRule identifierList*/
							recog.base.set_state(2178);
							recog.identifierList()?;

							}
						}

						_ => {}
					}
					}
				}
			,
				2 =>{
					let tmp = InsertIntoTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(2181);
					recog.base.match_token(INSERT,&mut recog.err_handler)?;

					recog.base.set_state(2182);
					recog.base.match_token(INTO,&mut recog.err_handler)?;

					recog.base.set_state(2184);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(218,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2183);
							recog.base.match_token(TABLE,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(2186);
					recog.identifierReference()?;

					recog.base.set_state(2188);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(219,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule optionsClause*/
							recog.base.set_state(2187);
							recog.optionsClause()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(2191);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==PARTITION {
						{
						/*InvokeRule partitionSpec*/
						recog.base.set_state(2190);
						recog.partitionSpec()?;

						}
					}

					recog.base.set_state(2197);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IF {
						{
						recog.base.set_state(2193);
						recog.base.match_token(IF,&mut recog.err_handler)?;

						/*InvokeRule errorCapturingNot*/
						recog.base.set_state(2194);
						recog.errorCapturingNot()?;

						recog.base.set_state(2195);
						recog.base.match_token(EXISTS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2202);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(222,&mut recog.base)? {
						x if x == 1=>{
							{
							{
							recog.base.set_state(2199);
							recog.base.match_token(BY,&mut recog.err_handler)?;

							recog.base.set_state(2200);
							recog.base.match_token(NAME,&mut recog.err_handler)?;

							}
							}
						}

						x if x == 2=>{
							{
							/*InvokeRule identifierList*/
							recog.base.set_state(2201);
							recog.identifierList()?;

							}
						}

						_ => {}
					}
					}
				}
			,
				3 =>{
					let tmp = InsertIntoReplaceWhereContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(2204);
					recog.base.match_token(INSERT,&mut recog.err_handler)?;

					recog.base.set_state(2205);
					recog.base.match_token(INTO,&mut recog.err_handler)?;

					recog.base.set_state(2207);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(223,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2206);
							recog.base.match_token(TABLE,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifierReference*/
					recog.base.set_state(2209);
					recog.identifierReference()?;

					recog.base.set_state(2211);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==WITH {
						{
						/*InvokeRule optionsClause*/
						recog.base.set_state(2210);
						recog.optionsClause()?;

						}
					}

					recog.base.set_state(2213);
					recog.base.match_token(REPLACE,&mut recog.err_handler)?;

					/*InvokeRule whereClause*/
					recog.base.set_state(2214);
					recog.whereClause()?;

					}
				}
			,
				4 =>{
					let tmp = InsertOverwriteHiveDirContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(2216);
					recog.base.match_token(INSERT,&mut recog.err_handler)?;

					recog.base.set_state(2217);
					recog.base.match_token(OVERWRITE,&mut recog.err_handler)?;

					recog.base.set_state(2219);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LOCAL {
						{
						recog.base.set_state(2218);
						recog.base.match_token(LOCAL,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2221);
					recog.base.match_token(DIRECTORY,&mut recog.err_handler)?;

					/*InvokeRule stringLit*/
					recog.base.set_state(2222);
					let tmp = recog.stringLit()?;
					if let InsertIntoContextAll::InsertOverwriteHiveDirContext(ctx) = cast_mut::<_,InsertIntoContextAll >(&mut _localctx){
					ctx.path = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2224);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ROW {
						{
						/*InvokeRule rowFormat*/
						recog.base.set_state(2223);
						recog.rowFormat()?;

						}
					}

					recog.base.set_state(2227);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==STORED {
						{
						/*InvokeRule createFileFormat*/
						recog.base.set_state(2226);
						recog.createFileFormat()?;

						}
					}

					}
				}
			,
				5 =>{
					let tmp = InsertOverwriteDirContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					recog.base.set_state(2229);
					recog.base.match_token(INSERT,&mut recog.err_handler)?;

					recog.base.set_state(2230);
					recog.base.match_token(OVERWRITE,&mut recog.err_handler)?;

					recog.base.set_state(2232);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LOCAL {
						{
						recog.base.set_state(2231);
						recog.base.match_token(LOCAL,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2234);
					recog.base.match_token(DIRECTORY,&mut recog.err_handler)?;

					recog.base.set_state(2236);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(229,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule stringLit*/
							recog.base.set_state(2235);
							let tmp = recog.stringLit()?;
							if let InsertIntoContextAll::InsertOverwriteDirContext(ctx) = cast_mut::<_,InsertIntoContextAll >(&mut _localctx){
							ctx.path = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					/*InvokeRule tableProvider*/
					recog.base.set_state(2238);
					recog.tableProvider()?;

					recog.base.set_state(2241);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OPTIONS {
						{
						recog.base.set_state(2239);
						recog.base.match_token(OPTIONS,&mut recog.err_handler)?;

						/*InvokeRule propertyList*/
						recog.base.set_state(2240);
						let tmp = recog.propertyList()?;
						if let InsertIntoContextAll::InsertOverwriteDirContext(ctx) = cast_mut::<_,InsertIntoContextAll >(&mut _localctx){
						ctx.options = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionSpecLocation ----------------
pub type PartitionSpecLocationContextAll<'input> = PartitionSpecLocationContext<'input>;


pub type PartitionSpecLocationContext<'input> = BaseParserRuleContext<'input,PartitionSpecLocationContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionSpecLocationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for PartitionSpecLocationContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PartitionSpecLocationContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionSpecLocation(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_partitionSpecLocation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PartitionSpecLocationContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_partitionSpecLocation(self);
	}
}

impl<'input> CustomRuleContext<'input> for PartitionSpecLocationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionSpecLocation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionSpecLocation }
}
antlr_rust::tid!{PartitionSpecLocationContextExt<'a>}

impl<'input> PartitionSpecLocationContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionSpecLocationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionSpecLocationContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionSpecLocationContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<PartitionSpecLocationContextExt<'input>>{

fn partitionSpec(&self) -> Option<Rc<PartitionSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn locationSpec(&self) -> Option<Rc<LocationSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PartitionSpecLocationContextAttrs<'input> for PartitionSpecLocationContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionSpecLocation(&mut self,)
	-> Result<Rc<PartitionSpecLocationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionSpecLocationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 104, RULE_partitionSpecLocation);
        let mut _localctx: Rc<PartitionSpecLocationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule partitionSpec*/
			recog.base.set_state(2245);
			recog.partitionSpec()?;

			recog.base.set_state(2247);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==LOCATION {
				{
				/*InvokeRule locationSpec*/
				recog.base.set_state(2246);
				recog.locationSpec()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionSpec ----------------
pub type PartitionSpecContextAll<'input> = PartitionSpecContext<'input>;


pub type PartitionSpecContext<'input> = BaseParserRuleContext<'input,PartitionSpecContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionSpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for PartitionSpecContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PartitionSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionSpec(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_partitionSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PartitionSpecContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_partitionSpec(self);
	}
}

impl<'input> CustomRuleContext<'input> for PartitionSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionSpec }
}
antlr_rust::tid!{PartitionSpecContextExt<'a>}

impl<'input> PartitionSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionSpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionSpecContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<PartitionSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PARTITION
/// Returns `None` if there is no child corresponding to token PARTITION
fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PARTITION, 0)
}
/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
fn partitionVal_all(&self) ->  Vec<Rc<PartitionValContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn partitionVal(&self, i: usize) -> Option<Rc<PartitionValContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> PartitionSpecContextAttrs<'input> for PartitionSpecContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionSpec(&mut self,)
	-> Result<Rc<PartitionSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 106, RULE_partitionSpec);
        let mut _localctx: Rc<PartitionSpecContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2249);
			recog.base.match_token(PARTITION,&mut recog.err_handler)?;

			recog.base.set_state(2250);
			recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

			/*InvokeRule partitionVal*/
			recog.base.set_state(2251);
			recog.partitionVal()?;

			recog.base.set_state(2256);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2252);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule partitionVal*/
				recog.base.set_state(2253);
				recog.partitionVal()?;

				}
				}
				recog.base.set_state(2258);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(2259);
			recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionVal ----------------
pub type PartitionValContextAll<'input> = PartitionValContext<'input>;


pub type PartitionValContext<'input> = BaseParserRuleContext<'input,PartitionValContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionValContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for PartitionValContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PartitionValContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionVal(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_partitionVal(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PartitionValContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_partitionVal(self);
	}
}

impl<'input> CustomRuleContext<'input> for PartitionValContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionVal }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionVal }
}
antlr_rust::tid!{PartitionValContextExt<'a>}

impl<'input> PartitionValContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionValContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionValContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionValContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<PartitionValContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EQ
/// Returns `None` if there is no child corresponding to token EQ
fn EQ(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EQ, 0)
}
fn constant(&self) -> Option<Rc<ConstantContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token DEFAULT
/// Returns `None` if there is no child corresponding to token DEFAULT
fn DEFAULT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DEFAULT, 0)
}

}

impl<'input> PartitionValContextAttrs<'input> for PartitionValContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionVal(&mut self,)
	-> Result<Rc<PartitionValContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionValContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 108, RULE_partitionVal);
        let mut _localctx: Rc<PartitionValContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2270);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(235,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule identifier*/
					recog.base.set_state(2261);
					recog.identifier()?;

					recog.base.set_state(2264);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==EQ {
						{
						recog.base.set_state(2262);
						recog.base.match_token(EQ,&mut recog.err_handler)?;

						/*InvokeRule constant*/
						recog.base.set_state(2263);
						recog.constant()?;

						}
					}

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule identifier*/
					recog.base.set_state(2266);
					recog.identifier()?;

					recog.base.set_state(2267);
					recog.base.match_token(EQ,&mut recog.err_handler)?;

					recog.base.set_state(2268);
					recog.base.match_token(DEFAULT,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- createPipelineFlowHeader ----------------
pub type CreatePipelineFlowHeaderContextAll<'input> = CreatePipelineFlowHeaderContext<'input>;


pub type CreatePipelineFlowHeaderContext<'input> = BaseParserRuleContext<'input,CreatePipelineFlowHeaderContextExt<'input>>;

#[derive(Clone)]
pub struct CreatePipelineFlowHeaderContextExt<'input>{
	pub flowName: Option<Rc<IdentifierReferenceContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for CreatePipelineFlowHeaderContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CreatePipelineFlowHeaderContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_createPipelineFlowHeader(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_createPipelineFlowHeader(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CreatePipelineFlowHeaderContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_createPipelineFlowHeader(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreatePipelineFlowHeaderContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_createPipelineFlowHeader }
	//fn type_rule_index() -> usize where Self: Sized { RULE_createPipelineFlowHeader }
}
antlr_rust::tid!{CreatePipelineFlowHeaderContextExt<'a>}

impl<'input> CreatePipelineFlowHeaderContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CreatePipelineFlowHeaderContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CreatePipelineFlowHeaderContextExt{
				flowName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CreatePipelineFlowHeaderContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<CreatePipelineFlowHeaderContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token CREATE
/// Returns `None` if there is no child corresponding to token CREATE
fn CREATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CREATE, 0)
}
/// Retrieves first TerminalNode corresponding to token FLOW
/// Returns `None` if there is no child corresponding to token FLOW
fn FLOW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FLOW, 0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn commentSpec(&self) -> Option<Rc<CommentSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CreatePipelineFlowHeaderContextAttrs<'input> for CreatePipelineFlowHeaderContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn createPipelineFlowHeader(&mut self,)
	-> Result<Rc<CreatePipelineFlowHeaderContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CreatePipelineFlowHeaderContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 110, RULE_createPipelineFlowHeader);
        let mut _localctx: Rc<CreatePipelineFlowHeaderContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2272);
			recog.base.match_token(CREATE,&mut recog.err_handler)?;

			recog.base.set_state(2273);
			recog.base.match_token(FLOW,&mut recog.err_handler)?;

			/*InvokeRule identifierReference*/
			recog.base.set_state(2274);
			let tmp = recog.identifierReference()?;
			 cast_mut::<_,CreatePipelineFlowHeaderContext >(&mut _localctx).flowName = Some(tmp.clone());
			  

			recog.base.set_state(2276);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMENT {
				{
				/*InvokeRule commentSpec*/
				recog.base.set_state(2275);
				recog.commentSpec()?;

				}
			}

			recog.base.set_state(2278);
			recog.base.match_token(AS,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- namespace ----------------
pub type NamespaceContextAll<'input> = NamespaceContext<'input>;


pub type NamespaceContext<'input> = BaseParserRuleContext<'input,NamespaceContextExt<'input>>;

#[derive(Clone)]
pub struct NamespaceContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for NamespaceContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for NamespaceContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_namespace(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_namespace(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for NamespaceContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_namespace(self);
	}
}

impl<'input> CustomRuleContext<'input> for NamespaceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_namespace }
	//fn type_rule_index() -> usize where Self: Sized { RULE_namespace }
}
antlr_rust::tid!{NamespaceContextExt<'a>}

impl<'input> NamespaceContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NamespaceContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NamespaceContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait NamespaceContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<NamespaceContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token NAMESPACE
/// Returns `None` if there is no child corresponding to token NAMESPACE
fn NAMESPACE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NAMESPACE, 0)
}
/// Retrieves first TerminalNode corresponding to token DATABASE
/// Returns `None` if there is no child corresponding to token DATABASE
fn DATABASE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DATABASE, 0)
}
/// Retrieves first TerminalNode corresponding to token SCHEMA
/// Returns `None` if there is no child corresponding to token SCHEMA
fn SCHEMA(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SCHEMA, 0)
}

}

impl<'input> NamespaceContextAttrs<'input> for NamespaceContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn namespace(&mut self,)
	-> Result<Rc<NamespaceContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NamespaceContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 112, RULE_namespace);
        let mut _localctx: Rc<NamespaceContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2280);
			_la = recog.base.input.la(1);
			if { !(_la==DATABASE || _la==NAMESPACE || _la==SCHEMA) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- namespaces ----------------
pub type NamespacesContextAll<'input> = NamespacesContext<'input>;


pub type NamespacesContext<'input> = BaseParserRuleContext<'input,NamespacesContextExt<'input>>;

#[derive(Clone)]
pub struct NamespacesContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for NamespacesContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for NamespacesContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_namespaces(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_namespaces(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for NamespacesContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_namespaces(self);
	}
}

impl<'input> CustomRuleContext<'input> for NamespacesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_namespaces }
	//fn type_rule_index() -> usize where Self: Sized { RULE_namespaces }
}
antlr_rust::tid!{NamespacesContextExt<'a>}

impl<'input> NamespacesContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NamespacesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NamespacesContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait NamespacesContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<NamespacesContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token NAMESPACES
/// Returns `None` if there is no child corresponding to token NAMESPACES
fn NAMESPACES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NAMESPACES, 0)
}
/// Retrieves first TerminalNode corresponding to token DATABASES
/// Returns `None` if there is no child corresponding to token DATABASES
fn DATABASES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DATABASES, 0)
}
/// Retrieves first TerminalNode corresponding to token SCHEMAS
/// Returns `None` if there is no child corresponding to token SCHEMAS
fn SCHEMAS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SCHEMAS, 0)
}

}

impl<'input> NamespacesContextAttrs<'input> for NamespacesContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn namespaces(&mut self,)
	-> Result<Rc<NamespacesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NamespacesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 114, RULE_namespaces);
        let mut _localctx: Rc<NamespacesContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2282);
			_la = recog.base.input.la(1);
			if { !(_la==DATABASES || _la==NAMESPACES || _la==SCHEMAS) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- variable ----------------
pub type VariableContextAll<'input> = VariableContext<'input>;


pub type VariableContext<'input> = BaseParserRuleContext<'input,VariableContextExt<'input>>;

#[derive(Clone)]
pub struct VariableContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for VariableContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for VariableContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_variable(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_variable(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for VariableContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_variable(self);
	}
}

impl<'input> CustomRuleContext<'input> for VariableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_variable }
	//fn type_rule_index() -> usize where Self: Sized { RULE_variable }
}
antlr_rust::tid!{VariableContextExt<'a>}

impl<'input> VariableContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<VariableContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,VariableContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait VariableContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<VariableContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token VARIABLE
/// Returns `None` if there is no child corresponding to token VARIABLE
fn VARIABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VARIABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token VAR
/// Returns `None` if there is no child corresponding to token VAR
fn VAR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VAR, 0)
}

}

impl<'input> VariableContextAttrs<'input> for VariableContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn variable(&mut self,)
	-> Result<Rc<VariableContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = VariableContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 116, RULE_variable);
        let mut _localctx: Rc<VariableContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2284);
			_la = recog.base.input.la(1);
			if { !(_la==VAR || _la==VARIABLE) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- describeFuncName ----------------
pub type DescribeFuncNameContextAll<'input> = DescribeFuncNameContext<'input>;


pub type DescribeFuncNameContext<'input> = BaseParserRuleContext<'input,DescribeFuncNameContextExt<'input>>;

#[derive(Clone)]
pub struct DescribeFuncNameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for DescribeFuncNameContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DescribeFuncNameContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_describeFuncName(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_describeFuncName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DescribeFuncNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_describeFuncName(self);
	}
}

impl<'input> CustomRuleContext<'input> for DescribeFuncNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_describeFuncName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_describeFuncName }
}
antlr_rust::tid!{DescribeFuncNameContextExt<'a>}

impl<'input> DescribeFuncNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DescribeFuncNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DescribeFuncNameContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DescribeFuncNameContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<DescribeFuncNameContextExt<'input>>{

fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn comparisonOperator(&self) -> Option<Rc<ComparisonOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn arithmeticOperator(&self) -> Option<Rc<ArithmeticOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn predicateOperator(&self) -> Option<Rc<PredicateOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn shiftOperator(&self) -> Option<Rc<ShiftOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token BANG
/// Returns `None` if there is no child corresponding to token BANG
fn BANG(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BANG, 0)
}

}

impl<'input> DescribeFuncNameContextAttrs<'input> for DescribeFuncNameContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn describeFuncName(&mut self,)
	-> Result<Rc<DescribeFuncNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DescribeFuncNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 118, RULE_describeFuncName);
        let mut _localctx: Rc<DescribeFuncNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2293);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(237,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule identifierReference*/
					recog.base.set_state(2286);
					recog.identifierReference()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule stringLit*/
					recog.base.set_state(2287);
					recog.stringLit()?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule comparisonOperator*/
					recog.base.set_state(2288);
					recog.comparisonOperator()?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule arithmeticOperator*/
					recog.base.set_state(2289);
					recog.arithmeticOperator()?;

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					/*InvokeRule predicateOperator*/
					recog.base.set_state(2290);
					recog.predicateOperator()?;

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					/*InvokeRule shiftOperator*/
					recog.base.set_state(2291);
					recog.shiftOperator()?;

					}
				}
			,
				7 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					recog.base.set_state(2292);
					recog.base.match_token(BANG,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- describeColName ----------------
pub type DescribeColNameContextAll<'input> = DescribeColNameContext<'input>;


pub type DescribeColNameContext<'input> = BaseParserRuleContext<'input,DescribeColNameContextExt<'input>>;

#[derive(Clone)]
pub struct DescribeColNameContextExt<'input>{
	pub errorCapturingIdentifier: Option<Rc<ErrorCapturingIdentifierContextAll<'input>>>,
	pub nameParts:Vec<Rc<ErrorCapturingIdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for DescribeColNameContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DescribeColNameContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_describeColName(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_describeColName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DescribeColNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_describeColName(self);
	}
}

impl<'input> CustomRuleContext<'input> for DescribeColNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_describeColName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_describeColName }
}
antlr_rust::tid!{DescribeColNameContextExt<'a>}

impl<'input> DescribeColNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DescribeColNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DescribeColNameContextExt{
				errorCapturingIdentifier: None, 
				nameParts: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait DescribeColNameContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<DescribeColNameContextExt<'input>>{

fn errorCapturingIdentifier_all(&self) ->  Vec<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn errorCapturingIdentifier(&self, i: usize) -> Option<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token DOT in current rule
fn DOT_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token DOT, starting from 0.
/// Returns `None` if number of children corresponding to token DOT is less or equal than `i`.
fn DOT(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DOT, i)
}

}

impl<'input> DescribeColNameContextAttrs<'input> for DescribeColNameContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn describeColName(&mut self,)
	-> Result<Rc<DescribeColNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DescribeColNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 120, RULE_describeColName);
        let mut _localctx: Rc<DescribeColNameContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule errorCapturingIdentifier*/
			recog.base.set_state(2295);
			let tmp = recog.errorCapturingIdentifier()?;
			 cast_mut::<_,DescribeColNameContext >(&mut _localctx).errorCapturingIdentifier = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,DescribeColNameContext >(&mut _localctx).errorCapturingIdentifier.clone().unwrap()
			 ;
			 cast_mut::<_,DescribeColNameContext >(&mut _localctx).nameParts.push(temp);
			  
			recog.base.set_state(2300);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==DOT {
				{
				{
				recog.base.set_state(2296);
				recog.base.match_token(DOT,&mut recog.err_handler)?;

				/*InvokeRule errorCapturingIdentifier*/
				recog.base.set_state(2297);
				let tmp = recog.errorCapturingIdentifier()?;
				 cast_mut::<_,DescribeColNameContext >(&mut _localctx).errorCapturingIdentifier = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,DescribeColNameContext >(&mut _localctx).errorCapturingIdentifier.clone().unwrap()
				 ;
				 cast_mut::<_,DescribeColNameContext >(&mut _localctx).nameParts.push(temp);
				  
				}
				}
				recog.base.set_state(2302);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- ctes ----------------
pub type CtesContextAll<'input> = CtesContext<'input>;


pub type CtesContext<'input> = BaseParserRuleContext<'input,CtesContextExt<'input>>;

#[derive(Clone)]
pub struct CtesContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for CtesContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CtesContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_ctes(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_ctes(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CtesContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_ctes(self);
	}
}

impl<'input> CustomRuleContext<'input> for CtesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_ctes }
	//fn type_rule_index() -> usize where Self: Sized { RULE_ctes }
}
antlr_rust::tid!{CtesContextExt<'a>}

impl<'input> CtesContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CtesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CtesContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait CtesContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<CtesContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
fn namedQuery_all(&self) ->  Vec<Rc<NamedQueryContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn namedQuery(&self, i: usize) -> Option<Rc<NamedQueryContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RECURSIVE
/// Returns `None` if there is no child corresponding to token RECURSIVE
fn RECURSIVE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RECURSIVE, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> CtesContextAttrs<'input> for CtesContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn ctes(&mut self,)
	-> Result<Rc<CtesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CtesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 122, RULE_ctes);
        let mut _localctx: Rc<CtesContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2303);
			recog.base.match_token(WITH,&mut recog.err_handler)?;

			recog.base.set_state(2305);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(239,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(2304);
					recog.base.match_token(RECURSIVE,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			/*InvokeRule namedQuery*/
			recog.base.set_state(2307);
			recog.namedQuery()?;

			recog.base.set_state(2312);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2308);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule namedQuery*/
				recog.base.set_state(2309);
				recog.namedQuery()?;

				}
				}
				recog.base.set_state(2314);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- namedQuery ----------------
pub type NamedQueryContextAll<'input> = NamedQueryContext<'input>;


pub type NamedQueryContext<'input> = BaseParserRuleContext<'input,NamedQueryContextExt<'input>>;

#[derive(Clone)]
pub struct NamedQueryContextExt<'input>{
	pub name: Option<Rc<ErrorCapturingIdentifierContextAll<'input>>>,
	pub columnAliases: Option<Rc<IdentifierListContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for NamedQueryContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for NamedQueryContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_namedQuery(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_namedQuery(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for NamedQueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_namedQuery(self);
	}
}

impl<'input> CustomRuleContext<'input> for NamedQueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_namedQuery }
	//fn type_rule_index() -> usize where Self: Sized { RULE_namedQuery }
}
antlr_rust::tid!{NamedQueryContextExt<'a>}

impl<'input> NamedQueryContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NamedQueryContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NamedQueryContextExt{
				name: None, columnAliases: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait NamedQueryContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<NamedQueryContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
fn errorCapturingIdentifier(&self) -> Option<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token MAX
/// Returns `None` if there is no child corresponding to token MAX
fn MAX(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MAX, 0)
}
/// Retrieves first TerminalNode corresponding to token RECURSION
/// Returns `None` if there is no child corresponding to token RECURSION
fn RECURSION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RECURSION, 0)
}
/// Retrieves first TerminalNode corresponding to token LEVEL
/// Returns `None` if there is no child corresponding to token LEVEL
fn LEVEL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEVEL, 0)
}
fn integerValue(&self) -> Option<Rc<IntegerValueContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
fn identifierList(&self) -> Option<Rc<IdentifierListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> NamedQueryContextAttrs<'input> for NamedQueryContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn namedQuery(&mut self,)
	-> Result<Rc<NamedQueryContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NamedQueryContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 124, RULE_namedQuery);
        let mut _localctx: Rc<NamedQueryContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule errorCapturingIdentifier*/
			recog.base.set_state(2315);
			let tmp = recog.errorCapturingIdentifier()?;
			 cast_mut::<_,NamedQueryContext >(&mut _localctx).name = Some(tmp.clone());
			  

			recog.base.set_state(2317);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(241,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule identifierList*/
					recog.base.set_state(2316);
					let tmp = recog.identifierList()?;
					 cast_mut::<_,NamedQueryContext >(&mut _localctx).columnAliases = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			recog.base.set_state(2323);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==MAX {
				{
				recog.base.set_state(2319);
				recog.base.match_token(MAX,&mut recog.err_handler)?;

				recog.base.set_state(2320);
				recog.base.match_token(RECURSION,&mut recog.err_handler)?;

				recog.base.set_state(2321);
				recog.base.match_token(LEVEL,&mut recog.err_handler)?;

				/*InvokeRule integerValue*/
				recog.base.set_state(2322);
				recog.integerValue()?;

				}
			}

			recog.base.set_state(2326);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==AS {
				{
				recog.base.set_state(2325);
				recog.base.match_token(AS,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(2328);
			recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

			/*InvokeRule query*/
			recog.base.set_state(2329);
			recog.query()?;

			recog.base.set_state(2330);
			recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableProvider ----------------
pub type TableProviderContextAll<'input> = TableProviderContext<'input>;


pub type TableProviderContext<'input> = BaseParserRuleContext<'input,TableProviderContextExt<'input>>;

#[derive(Clone)]
pub struct TableProviderContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for TableProviderContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for TableProviderContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableProvider(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_tableProvider(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for TableProviderContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_tableProvider(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableProviderContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableProvider }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableProvider }
}
antlr_rust::tid!{TableProviderContextExt<'a>}

impl<'input> TableProviderContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableProviderContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableProviderContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableProviderContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<TableProviderContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token USING
/// Returns `None` if there is no child corresponding to token USING
fn USING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(USING, 0)
}
fn multipartIdentifier(&self) -> Option<Rc<MultipartIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TableProviderContextAttrs<'input> for TableProviderContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableProvider(&mut self,)
	-> Result<Rc<TableProviderContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableProviderContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 126, RULE_tableProvider);
        let mut _localctx: Rc<TableProviderContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2332);
			recog.base.match_token(USING,&mut recog.err_handler)?;

			/*InvokeRule multipartIdentifier*/
			recog.base.set_state(2333);
			recog.multipartIdentifier()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- createTableClauses ----------------
pub type CreateTableClausesContextAll<'input> = CreateTableClausesContext<'input>;


pub type CreateTableClausesContext<'input> = BaseParserRuleContext<'input,CreateTableClausesContextExt<'input>>;

#[derive(Clone)]
pub struct CreateTableClausesContextExt<'input>{
	pub options: Option<Rc<ExpressionPropertyListContextAll<'input>>>,
	pub partitioning: Option<Rc<PartitionFieldListContextAll<'input>>>,
	pub tableProps: Option<Rc<PropertyListContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for CreateTableClausesContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CreateTableClausesContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_createTableClauses(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_createTableClauses(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CreateTableClausesContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_createTableClauses(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateTableClausesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_createTableClauses }
	//fn type_rule_index() -> usize where Self: Sized { RULE_createTableClauses }
}
antlr_rust::tid!{CreateTableClausesContextExt<'a>}

impl<'input> CreateTableClausesContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CreateTableClausesContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CreateTableClausesContextExt{
				options: None, partitioning: None, tableProps: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CreateTableClausesContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<CreateTableClausesContextExt<'input>>{

fn skewSpec_all(&self) ->  Vec<Rc<SkewSpecContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn skewSpec(&self, i: usize) -> Option<Rc<SkewSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn clusterBySpec_all(&self) ->  Vec<Rc<ClusterBySpecContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn clusterBySpec(&self, i: usize) -> Option<Rc<ClusterBySpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn bucketSpec_all(&self) ->  Vec<Rc<BucketSpecContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn bucketSpec(&self, i: usize) -> Option<Rc<BucketSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn rowFormat_all(&self) ->  Vec<Rc<RowFormatContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn rowFormat(&self, i: usize) -> Option<Rc<RowFormatContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn createFileFormat_all(&self) ->  Vec<Rc<CreateFileFormatContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn createFileFormat(&self, i: usize) -> Option<Rc<CreateFileFormatContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn locationSpec_all(&self) ->  Vec<Rc<LocationSpecContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn locationSpec(&self, i: usize) -> Option<Rc<LocationSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn commentSpec_all(&self) ->  Vec<Rc<CommentSpecContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn commentSpec(&self, i: usize) -> Option<Rc<CommentSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn collationSpec_all(&self) ->  Vec<Rc<CollationSpecContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn collationSpec(&self, i: usize) -> Option<Rc<CollationSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token OPTIONS in current rule
fn OPTIONS_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token OPTIONS, starting from 0.
/// Returns `None` if number of children corresponding to token OPTIONS is less or equal than `i`.
fn OPTIONS(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OPTIONS, i)
}
/// Retrieves all `TerminalNode`s corresponding to token PARTITIONED in current rule
fn PARTITIONED_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token PARTITIONED, starting from 0.
/// Returns `None` if number of children corresponding to token PARTITIONED is less or equal than `i`.
fn PARTITIONED(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PARTITIONED, i)
}
/// Retrieves all `TerminalNode`s corresponding to token BY in current rule
fn BY_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token BY, starting from 0.
/// Returns `None` if number of children corresponding to token BY is less or equal than `i`.
fn BY(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BY, i)
}
/// Retrieves all `TerminalNode`s corresponding to token TBLPROPERTIES in current rule
fn TBLPROPERTIES_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token TBLPROPERTIES, starting from 0.
/// Returns `None` if number of children corresponding to token TBLPROPERTIES is less or equal than `i`.
fn TBLPROPERTIES(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TBLPROPERTIES, i)
}
fn expressionPropertyList_all(&self) ->  Vec<Rc<ExpressionPropertyListContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expressionPropertyList(&self, i: usize) -> Option<Rc<ExpressionPropertyListContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn partitionFieldList_all(&self) ->  Vec<Rc<PartitionFieldListContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn partitionFieldList(&self, i: usize) -> Option<Rc<PartitionFieldListContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn propertyList_all(&self) ->  Vec<Rc<PropertyListContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn propertyList(&self, i: usize) -> Option<Rc<PropertyListContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> CreateTableClausesContextAttrs<'input> for CreateTableClausesContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn createTableClauses(&mut self,)
	-> Result<Rc<CreateTableClausesContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CreateTableClausesContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 128, RULE_createTableClauses);
        let mut _localctx: Rc<CreateTableClausesContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2352);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while ((((_la - 51)) & !0x3f) == 0 && ((1usize << (_la - 51)) & ((1usize << (CLUSTER - 51)) | (1usize << (CLUSTERED - 51)) | (1usize << (COMMENT - 51)))) != 0) || _la==DEFAULT || _la==LOCATION || _la==OPTIONS || _la==PARTITIONED || ((((_la - 301)) & !0x3f) == 0 && ((1usize << (_la - 301)) & ((1usize << (ROW - 301)) | (1usize << (SKEWED - 301)) | (1usize << (STORED - 301)))) != 0) || _la==TBLPROPERTIES {
				{
				recog.base.set_state(2350);
				recog.err_handler.sync(&mut recog.base)?;
				match recog.base.input.la(1) {
				 OPTIONS 
					=> {
						{
						{
						recog.base.set_state(2335);
						recog.base.match_token(OPTIONS,&mut recog.err_handler)?;

						/*InvokeRule expressionPropertyList*/
						recog.base.set_state(2336);
						let tmp = recog.expressionPropertyList()?;
						 cast_mut::<_,CreateTableClausesContext >(&mut _localctx).options = Some(tmp.clone());
						  

						}
						}
					}

				 PARTITIONED 
					=> {
						{
						{
						recog.base.set_state(2337);
						recog.base.match_token(PARTITIONED,&mut recog.err_handler)?;

						recog.base.set_state(2338);
						recog.base.match_token(BY,&mut recog.err_handler)?;

						/*InvokeRule partitionFieldList*/
						recog.base.set_state(2339);
						let tmp = recog.partitionFieldList()?;
						 cast_mut::<_,CreateTableClausesContext >(&mut _localctx).partitioning = Some(tmp.clone());
						  

						}
						}
					}

				 SKEWED 
					=> {
						{
						/*InvokeRule skewSpec*/
						recog.base.set_state(2340);
						recog.skewSpec()?;

						}
					}

				 CLUSTER 
					=> {
						{
						/*InvokeRule clusterBySpec*/
						recog.base.set_state(2341);
						recog.clusterBySpec()?;

						}
					}

				 CLUSTERED 
					=> {
						{
						/*InvokeRule bucketSpec*/
						recog.base.set_state(2342);
						recog.bucketSpec()?;

						}
					}

				 ROW 
					=> {
						{
						/*InvokeRule rowFormat*/
						recog.base.set_state(2343);
						recog.rowFormat()?;

						}
					}

				 STORED 
					=> {
						{
						/*InvokeRule createFileFormat*/
						recog.base.set_state(2344);
						recog.createFileFormat()?;

						}
					}

				 LOCATION 
					=> {
						{
						/*InvokeRule locationSpec*/
						recog.base.set_state(2345);
						recog.locationSpec()?;

						}
					}

				 COMMENT 
					=> {
						{
						/*InvokeRule commentSpec*/
						recog.base.set_state(2346);
						recog.commentSpec()?;

						}
					}

				 DEFAULT 
					=> {
						{
						/*InvokeRule collationSpec*/
						recog.base.set_state(2347);
						recog.collationSpec()?;

						}
					}

				 TBLPROPERTIES 
					=> {
						{
						{
						recog.base.set_state(2348);
						recog.base.match_token(TBLPROPERTIES,&mut recog.err_handler)?;

						/*InvokeRule propertyList*/
						recog.base.set_state(2349);
						let tmp = recog.propertyList()?;
						 cast_mut::<_,CreateTableClausesContext >(&mut _localctx).tableProps = Some(tmp.clone());
						  

						}
						}
					}

					_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
				}
				}
				recog.base.set_state(2354);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- propertyList ----------------
pub type PropertyListContextAll<'input> = PropertyListContext<'input>;


pub type PropertyListContext<'input> = BaseParserRuleContext<'input,PropertyListContextExt<'input>>;

#[derive(Clone)]
pub struct PropertyListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for PropertyListContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PropertyListContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_propertyList(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_propertyList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PropertyListContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_propertyList(self);
	}
}

impl<'input> CustomRuleContext<'input> for PropertyListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_propertyList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_propertyList }
}
antlr_rust::tid!{PropertyListContextExt<'a>}

impl<'input> PropertyListContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PropertyListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PropertyListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PropertyListContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<PropertyListContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
fn property_all(&self) ->  Vec<Rc<PropertyContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn property(&self, i: usize) -> Option<Rc<PropertyContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> PropertyListContextAttrs<'input> for PropertyListContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn propertyList(&mut self,)
	-> Result<Rc<PropertyListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PropertyListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 130, RULE_propertyList);
        let mut _localctx: Rc<PropertyListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2355);
			recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

			/*InvokeRule property*/
			recog.base.set_state(2356);
			recog.property()?;

			recog.base.set_state(2361);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2357);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule property*/
				recog.base.set_state(2358);
				recog.property()?;

				}
				}
				recog.base.set_state(2363);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(2364);
			recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- property ----------------
#[derive(Debug)]
pub enum PropertyContextAll<'input>{
	PropertyWithKeyNoEqualsContext(PropertyWithKeyNoEqualsContext<'input>),
	PropertyWithKeyAndEqualsContext(PropertyWithKeyAndEqualsContext<'input>),
Error(PropertyContext<'input>)
}
antlr_rust::tid!{PropertyContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PropertyContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for PropertyContextAll<'input>{}

impl<'input> Deref for PropertyContextAll<'input>{
	type Target = dyn PropertyContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PropertyContextAll::*;
		match self{
			PropertyWithKeyNoEqualsContext(inner) => inner,
			PropertyWithKeyAndEqualsContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PropertyContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PropertyContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PropertyContext<'input> = BaseParserRuleContext<'input,PropertyContextExt<'input>>;

#[derive(Clone)]
pub struct PropertyContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for PropertyContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PropertyContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PropertyContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PropertyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_property }
	//fn type_rule_index() -> usize where Self: Sized { RULE_property }
}
antlr_rust::tid!{PropertyContextExt<'a>}

impl<'input> PropertyContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PropertyContextAll<'input>> {
		Rc::new(
		PropertyContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PropertyContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PropertyContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<PropertyContextExt<'input>>{


}

impl<'input> PropertyContextAttrs<'input> for PropertyContext<'input>{}

pub type PropertyWithKeyNoEqualsContext<'input> = BaseParserRuleContext<'input,PropertyWithKeyNoEqualsContextExt<'input>>;

pub trait PropertyWithKeyNoEqualsContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn propertyKeyOrStringLitNoCoalesce(&self) -> Option<Rc<PropertyKeyOrStringLitNoCoalesceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn propertyValue(&self) -> Option<Rc<PropertyValueContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> PropertyWithKeyNoEqualsContextAttrs<'input> for PropertyWithKeyNoEqualsContext<'input>{}

pub struct PropertyWithKeyNoEqualsContextExt<'input>{
	base:PropertyContextExt<'input>,
	pub key: Option<Rc<PropertyKeyOrStringLitNoCoalesceContextAll<'input>>>,
	pub value: Option<Rc<PropertyValueContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PropertyWithKeyNoEqualsContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for PropertyWithKeyNoEqualsContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PropertyWithKeyNoEqualsContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_propertyWithKeyNoEquals(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_propertyWithKeyNoEquals(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PropertyWithKeyNoEqualsContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_propertyWithKeyNoEquals(self);
	}
}

impl<'input> CustomRuleContext<'input> for PropertyWithKeyNoEqualsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_property }
	//fn type_rule_index() -> usize where Self: Sized { RULE_property }
}

impl<'input> Borrow<PropertyContextExt<'input>> for PropertyWithKeyNoEqualsContext<'input>{
	fn borrow(&self) -> &PropertyContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PropertyContextExt<'input>> for PropertyWithKeyNoEqualsContext<'input>{
	fn borrow_mut(&mut self) -> &mut PropertyContextExt<'input> { &mut self.base }
}

impl<'input> PropertyContextAttrs<'input> for PropertyWithKeyNoEqualsContext<'input> {}

impl<'input> PropertyWithKeyNoEqualsContextExt<'input>{
	fn new(ctx: &dyn PropertyContextAttrs<'input>) -> Rc<PropertyContextAll<'input>>  {
		Rc::new(
			PropertyContextAll::PropertyWithKeyNoEqualsContext(
				BaseParserRuleContext::copy_from(ctx,PropertyWithKeyNoEqualsContextExt{
        			key:None, value:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PropertyWithKeyAndEqualsContext<'input> = BaseParserRuleContext<'input,PropertyWithKeyAndEqualsContextExt<'input>>;

pub trait PropertyWithKeyAndEqualsContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token EQ
	/// Returns `None` if there is no child corresponding to token EQ
	fn EQ(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EQ, 0)
	}
	fn propertyKeyOrStringLit(&self) -> Option<Rc<PropertyKeyOrStringLitContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn propertyValue(&self) -> Option<Rc<PropertyValueContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> PropertyWithKeyAndEqualsContextAttrs<'input> for PropertyWithKeyAndEqualsContext<'input>{}

pub struct PropertyWithKeyAndEqualsContextExt<'input>{
	base:PropertyContextExt<'input>,
	pub key: Option<Rc<PropertyKeyOrStringLitContextAll<'input>>>,
	pub value: Option<Rc<PropertyValueContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PropertyWithKeyAndEqualsContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for PropertyWithKeyAndEqualsContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PropertyWithKeyAndEqualsContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_propertyWithKeyAndEquals(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_propertyWithKeyAndEquals(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PropertyWithKeyAndEqualsContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_propertyWithKeyAndEquals(self);
	}
}

impl<'input> CustomRuleContext<'input> for PropertyWithKeyAndEqualsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_property }
	//fn type_rule_index() -> usize where Self: Sized { RULE_property }
}

impl<'input> Borrow<PropertyContextExt<'input>> for PropertyWithKeyAndEqualsContext<'input>{
	fn borrow(&self) -> &PropertyContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PropertyContextExt<'input>> for PropertyWithKeyAndEqualsContext<'input>{
	fn borrow_mut(&mut self) -> &mut PropertyContextExt<'input> { &mut self.base }
}

impl<'input> PropertyContextAttrs<'input> for PropertyWithKeyAndEqualsContext<'input> {}

impl<'input> PropertyWithKeyAndEqualsContextExt<'input>{
	fn new(ctx: &dyn PropertyContextAttrs<'input>) -> Rc<PropertyContextAll<'input>>  {
		Rc::new(
			PropertyContextAll::PropertyWithKeyAndEqualsContext(
				BaseParserRuleContext::copy_from(ctx,PropertyWithKeyAndEqualsContextExt{
        			key:None, value:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn property(&mut self,)
	-> Result<Rc<PropertyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PropertyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 132, RULE_property);
        let mut _localctx: Rc<PropertyContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2374);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(248,&mut recog.base)? {
				1 =>{
					let tmp = PropertyWithKeyAndEqualsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule propertyKeyOrStringLit*/
					recog.base.set_state(2366);
					let tmp = recog.propertyKeyOrStringLit()?;
					if let PropertyContextAll::PropertyWithKeyAndEqualsContext(ctx) = cast_mut::<_,PropertyContextAll >(&mut _localctx){
					ctx.key = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2367);
					recog.base.match_token(EQ,&mut recog.err_handler)?;

					/*InvokeRule propertyValue*/
					recog.base.set_state(2368);
					let tmp = recog.propertyValue()?;
					if let PropertyContextAll::PropertyWithKeyAndEqualsContext(ctx) = cast_mut::<_,PropertyContextAll >(&mut _localctx){
					ctx.value = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				2 =>{
					let tmp = PropertyWithKeyNoEqualsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule propertyKeyOrStringLitNoCoalesce*/
					recog.base.set_state(2370);
					let tmp = recog.propertyKeyOrStringLitNoCoalesce()?;
					if let PropertyContextAll::PropertyWithKeyNoEqualsContext(ctx) = cast_mut::<_,PropertyContextAll >(&mut _localctx){
					ctx.key = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2372);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(247,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule propertyValue*/
							recog.base.set_state(2371);
							let tmp = recog.propertyValue()?;
							if let PropertyContextAll::PropertyWithKeyNoEqualsContext(ctx) = cast_mut::<_,PropertyContextAll >(&mut _localctx){
							ctx.value = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- propertyKey ----------------
pub type PropertyKeyContextAll<'input> = PropertyKeyContext<'input>;


pub type PropertyKeyContext<'input> = BaseParserRuleContext<'input,PropertyKeyContextExt<'input>>;

#[derive(Clone)]
pub struct PropertyKeyContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for PropertyKeyContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PropertyKeyContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_propertyKey(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_propertyKey(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PropertyKeyContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_propertyKey(self);
	}
}

impl<'input> CustomRuleContext<'input> for PropertyKeyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_propertyKey }
	//fn type_rule_index() -> usize where Self: Sized { RULE_propertyKey }
}
antlr_rust::tid!{PropertyKeyContextExt<'a>}

impl<'input> PropertyKeyContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PropertyKeyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PropertyKeyContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PropertyKeyContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<PropertyKeyContextExt<'input>>{

fn errorCapturingIdentifier_all(&self) ->  Vec<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn errorCapturingIdentifier(&self, i: usize) -> Option<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token DOT in current rule
fn DOT_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token DOT, starting from 0.
/// Returns `None` if number of children corresponding to token DOT is less or equal than `i`.
fn DOT(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DOT, i)
}

}

impl<'input> PropertyKeyContextAttrs<'input> for PropertyKeyContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn propertyKey(&mut self,)
	-> Result<Rc<PropertyKeyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PropertyKeyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 134, RULE_propertyKey);
        let mut _localctx: Rc<PropertyKeyContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule errorCapturingIdentifier*/
			recog.base.set_state(2376);
			recog.errorCapturingIdentifier()?;

			recog.base.set_state(2381);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(249,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(2377);
					recog.base.match_token(DOT,&mut recog.err_handler)?;

					/*InvokeRule errorCapturingIdentifier*/
					recog.base.set_state(2378);
					recog.errorCapturingIdentifier()?;

					}
					} 
				}
				recog.base.set_state(2383);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(249,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- propertyKeyOrStringLit ----------------
pub type PropertyKeyOrStringLitContextAll<'input> = PropertyKeyOrStringLitContext<'input>;


pub type PropertyKeyOrStringLitContext<'input> = BaseParserRuleContext<'input,PropertyKeyOrStringLitContextExt<'input>>;

#[derive(Clone)]
pub struct PropertyKeyOrStringLitContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for PropertyKeyOrStringLitContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PropertyKeyOrStringLitContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_propertyKeyOrStringLit(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_propertyKeyOrStringLit(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PropertyKeyOrStringLitContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_propertyKeyOrStringLit(self);
	}
}

impl<'input> CustomRuleContext<'input> for PropertyKeyOrStringLitContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_propertyKeyOrStringLit }
	//fn type_rule_index() -> usize where Self: Sized { RULE_propertyKeyOrStringLit }
}
antlr_rust::tid!{PropertyKeyOrStringLitContextExt<'a>}

impl<'input> PropertyKeyOrStringLitContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PropertyKeyOrStringLitContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PropertyKeyOrStringLitContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PropertyKeyOrStringLitContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<PropertyKeyOrStringLitContextExt<'input>>{

fn propertyKey(&self) -> Option<Rc<PropertyKeyContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PropertyKeyOrStringLitContextAttrs<'input> for PropertyKeyOrStringLitContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn propertyKeyOrStringLit(&mut self,)
	-> Result<Rc<PropertyKeyOrStringLitContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PropertyKeyOrStringLitContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 136, RULE_propertyKeyOrStringLit);
        let mut _localctx: Rc<PropertyKeyOrStringLitContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2386);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(250,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule propertyKey*/
					recog.base.set_state(2384);
					recog.propertyKey()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule stringLit*/
					recog.base.set_state(2385);
					recog.stringLit()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- propertyKeyOrStringLitNoCoalesce ----------------
pub type PropertyKeyOrStringLitNoCoalesceContextAll<'input> = PropertyKeyOrStringLitNoCoalesceContext<'input>;


pub type PropertyKeyOrStringLitNoCoalesceContext<'input> = BaseParserRuleContext<'input,PropertyKeyOrStringLitNoCoalesceContextExt<'input>>;

#[derive(Clone)]
pub struct PropertyKeyOrStringLitNoCoalesceContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for PropertyKeyOrStringLitNoCoalesceContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PropertyKeyOrStringLitNoCoalesceContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_propertyKeyOrStringLitNoCoalesce(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_propertyKeyOrStringLitNoCoalesce(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PropertyKeyOrStringLitNoCoalesceContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_propertyKeyOrStringLitNoCoalesce(self);
	}
}

impl<'input> CustomRuleContext<'input> for PropertyKeyOrStringLitNoCoalesceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_propertyKeyOrStringLitNoCoalesce }
	//fn type_rule_index() -> usize where Self: Sized { RULE_propertyKeyOrStringLitNoCoalesce }
}
antlr_rust::tid!{PropertyKeyOrStringLitNoCoalesceContextExt<'a>}

impl<'input> PropertyKeyOrStringLitNoCoalesceContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PropertyKeyOrStringLitNoCoalesceContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PropertyKeyOrStringLitNoCoalesceContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PropertyKeyOrStringLitNoCoalesceContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<PropertyKeyOrStringLitNoCoalesceContextExt<'input>>{

fn propertyKey(&self) -> Option<Rc<PropertyKeyContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn singleStringLit(&self) -> Option<Rc<SingleStringLitContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PropertyKeyOrStringLitNoCoalesceContextAttrs<'input> for PropertyKeyOrStringLitNoCoalesceContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn propertyKeyOrStringLitNoCoalesce(&mut self,)
	-> Result<Rc<PropertyKeyOrStringLitNoCoalesceContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PropertyKeyOrStringLitNoCoalesceContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 138, RULE_propertyKeyOrStringLitNoCoalesce);
        let mut _localctx: Rc<PropertyKeyOrStringLitNoCoalesceContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2390);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(251,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule propertyKey*/
					recog.base.set_state(2388);
					recog.propertyKey()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule singleStringLit*/
					recog.base.set_state(2389);
					recog.singleStringLit()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- propertyValue ----------------
pub type PropertyValueContextAll<'input> = PropertyValueContext<'input>;


pub type PropertyValueContext<'input> = BaseParserRuleContext<'input,PropertyValueContextExt<'input>>;

#[derive(Clone)]
pub struct PropertyValueContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for PropertyValueContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PropertyValueContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_propertyValue(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_propertyValue(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PropertyValueContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_propertyValue(self);
	}
}

impl<'input> CustomRuleContext<'input> for PropertyValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_propertyValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_propertyValue }
}
antlr_rust::tid!{PropertyValueContextExt<'a>}

impl<'input> PropertyValueContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PropertyValueContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PropertyValueContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PropertyValueContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<PropertyValueContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INTEGER_VALUE, 0)
}
/// Retrieves first TerminalNode corresponding to token DECIMAL_VALUE
/// Returns `None` if there is no child corresponding to token DECIMAL_VALUE
fn DECIMAL_VALUE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DECIMAL_VALUE, 0)
}
fn booleanValue(&self) -> Option<Rc<BooleanValueContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PropertyValueContextAttrs<'input> for PropertyValueContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn propertyValue(&mut self,)
	-> Result<Rc<PropertyValueContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PropertyValueContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 140, RULE_propertyValue);
        let mut _localctx: Rc<PropertyValueContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2396);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(252,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2392);
					recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2393);
					recog.base.match_token(DECIMAL_VALUE,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule booleanValue*/
					recog.base.set_state(2394);
					recog.booleanValue()?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule stringLit*/
					recog.base.set_state(2395);
					recog.stringLit()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- expressionPropertyList ----------------
pub type ExpressionPropertyListContextAll<'input> = ExpressionPropertyListContext<'input>;


pub type ExpressionPropertyListContext<'input> = BaseParserRuleContext<'input,ExpressionPropertyListContextExt<'input>>;

#[derive(Clone)]
pub struct ExpressionPropertyListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ExpressionPropertyListContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ExpressionPropertyListContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_expressionPropertyList(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_expressionPropertyList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ExpressionPropertyListContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_expressionPropertyList(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExpressionPropertyListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_expressionPropertyList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_expressionPropertyList }
}
antlr_rust::tid!{ExpressionPropertyListContextExt<'a>}

impl<'input> ExpressionPropertyListContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExpressionPropertyListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExpressionPropertyListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ExpressionPropertyListContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ExpressionPropertyListContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
fn expressionProperty_all(&self) ->  Vec<Rc<ExpressionPropertyContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expressionProperty(&self, i: usize) -> Option<Rc<ExpressionPropertyContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ExpressionPropertyListContextAttrs<'input> for ExpressionPropertyListContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn expressionPropertyList(&mut self,)
	-> Result<Rc<ExpressionPropertyListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExpressionPropertyListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 142, RULE_expressionPropertyList);
        let mut _localctx: Rc<ExpressionPropertyListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2398);
			recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

			/*InvokeRule expressionProperty*/
			recog.base.set_state(2399);
			recog.expressionProperty()?;

			recog.base.set_state(2404);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2400);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule expressionProperty*/
				recog.base.set_state(2401);
				recog.expressionProperty()?;

				}
				}
				recog.base.set_state(2406);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(2407);
			recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- expressionProperty ----------------
#[derive(Debug)]
pub enum ExpressionPropertyContextAll<'input>{
	ExpressionPropertyWithKeyAndEqualsContext(ExpressionPropertyWithKeyAndEqualsContext<'input>),
	ExpressionPropertyWithKeyNoEqualsContext(ExpressionPropertyWithKeyNoEqualsContext<'input>),
Error(ExpressionPropertyContext<'input>)
}
antlr_rust::tid!{ExpressionPropertyContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for ExpressionPropertyContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for ExpressionPropertyContextAll<'input>{}

impl<'input> Deref for ExpressionPropertyContextAll<'input>{
	type Target = dyn ExpressionPropertyContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use ExpressionPropertyContextAll::*;
		match self{
			ExpressionPropertyWithKeyAndEqualsContext(inner) => inner,
			ExpressionPropertyWithKeyNoEqualsContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ExpressionPropertyContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ExpressionPropertyContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type ExpressionPropertyContext<'input> = BaseParserRuleContext<'input,ExpressionPropertyContextExt<'input>>;

#[derive(Clone)]
pub struct ExpressionPropertyContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ExpressionPropertyContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ExpressionPropertyContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ExpressionPropertyContext<'input>{
}

impl<'input> CustomRuleContext<'input> for ExpressionPropertyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_expressionProperty }
	//fn type_rule_index() -> usize where Self: Sized { RULE_expressionProperty }
}
antlr_rust::tid!{ExpressionPropertyContextExt<'a>}

impl<'input> ExpressionPropertyContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExpressionPropertyContextAll<'input>> {
		Rc::new(
		ExpressionPropertyContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExpressionPropertyContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait ExpressionPropertyContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ExpressionPropertyContextExt<'input>>{


}

impl<'input> ExpressionPropertyContextAttrs<'input> for ExpressionPropertyContext<'input>{}

pub type ExpressionPropertyWithKeyAndEqualsContext<'input> = BaseParserRuleContext<'input,ExpressionPropertyWithKeyAndEqualsContextExt<'input>>;

pub trait ExpressionPropertyWithKeyAndEqualsContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token EQ
	/// Returns `None` if there is no child corresponding to token EQ
	fn EQ(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EQ, 0)
	}
	fn propertyKeyOrStringLit(&self) -> Option<Rc<PropertyKeyOrStringLitContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ExpressionPropertyWithKeyAndEqualsContextAttrs<'input> for ExpressionPropertyWithKeyAndEqualsContext<'input>{}

pub struct ExpressionPropertyWithKeyAndEqualsContextExt<'input>{
	base:ExpressionPropertyContextExt<'input>,
	pub key: Option<Rc<PropertyKeyOrStringLitContextAll<'input>>>,
	pub value: Option<Rc<ExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ExpressionPropertyWithKeyAndEqualsContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ExpressionPropertyWithKeyAndEqualsContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ExpressionPropertyWithKeyAndEqualsContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_expressionPropertyWithKeyAndEquals(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_expressionPropertyWithKeyAndEquals(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ExpressionPropertyWithKeyAndEqualsContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_expressionPropertyWithKeyAndEquals(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExpressionPropertyWithKeyAndEqualsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_expressionProperty }
	//fn type_rule_index() -> usize where Self: Sized { RULE_expressionProperty }
}

impl<'input> Borrow<ExpressionPropertyContextExt<'input>> for ExpressionPropertyWithKeyAndEqualsContext<'input>{
	fn borrow(&self) -> &ExpressionPropertyContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ExpressionPropertyContextExt<'input>> for ExpressionPropertyWithKeyAndEqualsContext<'input>{
	fn borrow_mut(&mut self) -> &mut ExpressionPropertyContextExt<'input> { &mut self.base }
}

impl<'input> ExpressionPropertyContextAttrs<'input> for ExpressionPropertyWithKeyAndEqualsContext<'input> {}

impl<'input> ExpressionPropertyWithKeyAndEqualsContextExt<'input>{
	fn new(ctx: &dyn ExpressionPropertyContextAttrs<'input>) -> Rc<ExpressionPropertyContextAll<'input>>  {
		Rc::new(
			ExpressionPropertyContextAll::ExpressionPropertyWithKeyAndEqualsContext(
				BaseParserRuleContext::copy_from(ctx,ExpressionPropertyWithKeyAndEqualsContextExt{
        			key:None, value:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ExpressionPropertyWithKeyNoEqualsContext<'input> = BaseParserRuleContext<'input,ExpressionPropertyWithKeyNoEqualsContextExt<'input>>;

pub trait ExpressionPropertyWithKeyNoEqualsContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn propertyKeyOrStringLitNoCoalesce(&self) -> Option<Rc<PropertyKeyOrStringLitNoCoalesceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ExpressionPropertyWithKeyNoEqualsContextAttrs<'input> for ExpressionPropertyWithKeyNoEqualsContext<'input>{}

pub struct ExpressionPropertyWithKeyNoEqualsContextExt<'input>{
	base:ExpressionPropertyContextExt<'input>,
	pub key: Option<Rc<PropertyKeyOrStringLitNoCoalesceContextAll<'input>>>,
	pub value: Option<Rc<ExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ExpressionPropertyWithKeyNoEqualsContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ExpressionPropertyWithKeyNoEqualsContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ExpressionPropertyWithKeyNoEqualsContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_expressionPropertyWithKeyNoEquals(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_expressionPropertyWithKeyNoEquals(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ExpressionPropertyWithKeyNoEqualsContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_expressionPropertyWithKeyNoEquals(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExpressionPropertyWithKeyNoEqualsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_expressionProperty }
	//fn type_rule_index() -> usize where Self: Sized { RULE_expressionProperty }
}

impl<'input> Borrow<ExpressionPropertyContextExt<'input>> for ExpressionPropertyWithKeyNoEqualsContext<'input>{
	fn borrow(&self) -> &ExpressionPropertyContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ExpressionPropertyContextExt<'input>> for ExpressionPropertyWithKeyNoEqualsContext<'input>{
	fn borrow_mut(&mut self) -> &mut ExpressionPropertyContextExt<'input> { &mut self.base }
}

impl<'input> ExpressionPropertyContextAttrs<'input> for ExpressionPropertyWithKeyNoEqualsContext<'input> {}

impl<'input> ExpressionPropertyWithKeyNoEqualsContextExt<'input>{
	fn new(ctx: &dyn ExpressionPropertyContextAttrs<'input>) -> Rc<ExpressionPropertyContextAll<'input>>  {
		Rc::new(
			ExpressionPropertyContextAll::ExpressionPropertyWithKeyNoEqualsContext(
				BaseParserRuleContext::copy_from(ctx,ExpressionPropertyWithKeyNoEqualsContextExt{
        			key:None, value:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn expressionProperty(&mut self,)
	-> Result<Rc<ExpressionPropertyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExpressionPropertyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 144, RULE_expressionProperty);
        let mut _localctx: Rc<ExpressionPropertyContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2417);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(255,&mut recog.base)? {
				1 =>{
					let tmp = ExpressionPropertyWithKeyAndEqualsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule propertyKeyOrStringLit*/
					recog.base.set_state(2409);
					let tmp = recog.propertyKeyOrStringLit()?;
					if let ExpressionPropertyContextAll::ExpressionPropertyWithKeyAndEqualsContext(ctx) = cast_mut::<_,ExpressionPropertyContextAll >(&mut _localctx){
					ctx.key = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2410);
					recog.base.match_token(EQ,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2411);
					let tmp = recog.expression()?;
					if let ExpressionPropertyContextAll::ExpressionPropertyWithKeyAndEqualsContext(ctx) = cast_mut::<_,ExpressionPropertyContextAll >(&mut _localctx){
					ctx.value = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				2 =>{
					let tmp = ExpressionPropertyWithKeyNoEqualsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule propertyKeyOrStringLitNoCoalesce*/
					recog.base.set_state(2413);
					let tmp = recog.propertyKeyOrStringLitNoCoalesce()?;
					if let ExpressionPropertyContextAll::ExpressionPropertyWithKeyNoEqualsContext(ctx) = cast_mut::<_,ExpressionPropertyContextAll >(&mut _localctx){
					ctx.key = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2415);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(254,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule expression*/
							recog.base.set_state(2414);
							let tmp = recog.expression()?;
							if let ExpressionPropertyContextAll::ExpressionPropertyWithKeyNoEqualsContext(ctx) = cast_mut::<_,ExpressionPropertyContextAll >(&mut _localctx){
							ctx.value = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- constantList ----------------
pub type ConstantListContextAll<'input> = ConstantListContext<'input>;


pub type ConstantListContext<'input> = BaseParserRuleContext<'input,ConstantListContextExt<'input>>;

#[derive(Clone)]
pub struct ConstantListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ConstantListContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ConstantListContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_constantList(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_constantList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ConstantListContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_constantList(self);
	}
}

impl<'input> CustomRuleContext<'input> for ConstantListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_constantList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_constantList }
}
antlr_rust::tid!{ConstantListContextExt<'a>}

impl<'input> ConstantListContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ConstantListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ConstantListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ConstantListContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ConstantListContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
fn constant_all(&self) ->  Vec<Rc<ConstantContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn constant(&self, i: usize) -> Option<Rc<ConstantContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ConstantListContextAttrs<'input> for ConstantListContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn constantList(&mut self,)
	-> Result<Rc<ConstantListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ConstantListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 146, RULE_constantList);
        let mut _localctx: Rc<ConstantListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2419);
			recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

			/*InvokeRule constant*/
			recog.base.set_state(2420);
			recog.constant()?;

			recog.base.set_state(2425);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2421);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule constant*/
				recog.base.set_state(2422);
				recog.constant()?;

				}
				}
				recog.base.set_state(2427);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(2428);
			recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- nestedConstantList ----------------
pub type NestedConstantListContextAll<'input> = NestedConstantListContext<'input>;


pub type NestedConstantListContext<'input> = BaseParserRuleContext<'input,NestedConstantListContextExt<'input>>;

#[derive(Clone)]
pub struct NestedConstantListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for NestedConstantListContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for NestedConstantListContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_nestedConstantList(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_nestedConstantList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for NestedConstantListContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_nestedConstantList(self);
	}
}

impl<'input> CustomRuleContext<'input> for NestedConstantListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nestedConstantList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nestedConstantList }
}
antlr_rust::tid!{NestedConstantListContextExt<'a>}

impl<'input> NestedConstantListContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NestedConstantListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NestedConstantListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait NestedConstantListContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<NestedConstantListContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
fn constantList_all(&self) ->  Vec<Rc<ConstantListContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn constantList(&self, i: usize) -> Option<Rc<ConstantListContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> NestedConstantListContextAttrs<'input> for NestedConstantListContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn nestedConstantList(&mut self,)
	-> Result<Rc<NestedConstantListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NestedConstantListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 148, RULE_nestedConstantList);
        let mut _localctx: Rc<NestedConstantListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2430);
			recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

			/*InvokeRule constantList*/
			recog.base.set_state(2431);
			recog.constantList()?;

			recog.base.set_state(2436);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2432);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule constantList*/
				recog.base.set_state(2433);
				recog.constantList()?;

				}
				}
				recog.base.set_state(2438);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(2439);
			recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- createFileFormat ----------------
pub type CreateFileFormatContextAll<'input> = CreateFileFormatContext<'input>;


pub type CreateFileFormatContext<'input> = BaseParserRuleContext<'input,CreateFileFormatContextExt<'input>>;

#[derive(Clone)]
pub struct CreateFileFormatContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for CreateFileFormatContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CreateFileFormatContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_createFileFormat(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_createFileFormat(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CreateFileFormatContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_createFileFormat(self);
	}
}

impl<'input> CustomRuleContext<'input> for CreateFileFormatContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_createFileFormat }
	//fn type_rule_index() -> usize where Self: Sized { RULE_createFileFormat }
}
antlr_rust::tid!{CreateFileFormatContextExt<'a>}

impl<'input> CreateFileFormatContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CreateFileFormatContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CreateFileFormatContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait CreateFileFormatContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<CreateFileFormatContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token STORED
/// Returns `None` if there is no child corresponding to token STORED
fn STORED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(STORED, 0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
fn fileFormat(&self) -> Option<Rc<FileFormatContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn storageHandler(&self) -> Option<Rc<StorageHandlerContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CreateFileFormatContextAttrs<'input> for CreateFileFormatContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn createFileFormat(&mut self,)
	-> Result<Rc<CreateFileFormatContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CreateFileFormatContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 150, RULE_createFileFormat);
        let mut _localctx: Rc<CreateFileFormatContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2447);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(258,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2441);
					recog.base.match_token(STORED,&mut recog.err_handler)?;

					recog.base.set_state(2442);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					/*InvokeRule fileFormat*/
					recog.base.set_state(2443);
					recog.fileFormat()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2444);
					recog.base.match_token(STORED,&mut recog.err_handler)?;

					recog.base.set_state(2445);
					recog.base.match_token(BY,&mut recog.err_handler)?;

					/*InvokeRule storageHandler*/
					recog.base.set_state(2446);
					recog.storageHandler()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- fileFormat ----------------
#[derive(Debug)]
pub enum FileFormatContextAll<'input>{
	TableFileFormatContext(TableFileFormatContext<'input>),
	GenericFileFormatContext(GenericFileFormatContext<'input>),
Error(FileFormatContext<'input>)
}
antlr_rust::tid!{FileFormatContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for FileFormatContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for FileFormatContextAll<'input>{}

impl<'input> Deref for FileFormatContextAll<'input>{
	type Target = dyn FileFormatContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use FileFormatContextAll::*;
		match self{
			TableFileFormatContext(inner) => inner,
			GenericFileFormatContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for FileFormatContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for FileFormatContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type FileFormatContext<'input> = BaseParserRuleContext<'input,FileFormatContextExt<'input>>;

#[derive(Clone)]
pub struct FileFormatContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for FileFormatContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for FileFormatContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for FileFormatContext<'input>{
}

impl<'input> CustomRuleContext<'input> for FileFormatContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_fileFormat }
	//fn type_rule_index() -> usize where Self: Sized { RULE_fileFormat }
}
antlr_rust::tid!{FileFormatContextExt<'a>}

impl<'input> FileFormatContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FileFormatContextAll<'input>> {
		Rc::new(
		FileFormatContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FileFormatContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait FileFormatContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<FileFormatContextExt<'input>>{


}

impl<'input> FileFormatContextAttrs<'input> for FileFormatContext<'input>{}

pub type TableFileFormatContext<'input> = BaseParserRuleContext<'input,TableFileFormatContextExt<'input>>;

pub trait TableFileFormatContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token INPUTFORMAT
	/// Returns `None` if there is no child corresponding to token INPUTFORMAT
	fn INPUTFORMAT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(INPUTFORMAT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OUTPUTFORMAT
	/// Returns `None` if there is no child corresponding to token OUTPUTFORMAT
	fn OUTPUTFORMAT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(OUTPUTFORMAT, 0)
	}
	fn stringLit_all(&self) ->  Vec<Rc<StringLitContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn stringLit(&self, i: usize) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> TableFileFormatContextAttrs<'input> for TableFileFormatContext<'input>{}

pub struct TableFileFormatContextExt<'input>{
	base:FileFormatContextExt<'input>,
	pub inFmt: Option<Rc<StringLitContextAll<'input>>>,
	pub outFmt: Option<Rc<StringLitContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TableFileFormatContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for TableFileFormatContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for TableFileFormatContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_tableFileFormat(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_tableFileFormat(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for TableFileFormatContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_tableFileFormat(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableFileFormatContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_fileFormat }
	//fn type_rule_index() -> usize where Self: Sized { RULE_fileFormat }
}

impl<'input> Borrow<FileFormatContextExt<'input>> for TableFileFormatContext<'input>{
	fn borrow(&self) -> &FileFormatContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<FileFormatContextExt<'input>> for TableFileFormatContext<'input>{
	fn borrow_mut(&mut self) -> &mut FileFormatContextExt<'input> { &mut self.base }
}

impl<'input> FileFormatContextAttrs<'input> for TableFileFormatContext<'input> {}

impl<'input> TableFileFormatContextExt<'input>{
	fn new(ctx: &dyn FileFormatContextAttrs<'input>) -> Rc<FileFormatContextAll<'input>>  {
		Rc::new(
			FileFormatContextAll::TableFileFormatContext(
				BaseParserRuleContext::copy_from(ctx,TableFileFormatContextExt{
        			inFmt:None, outFmt:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type GenericFileFormatContext<'input> = BaseParserRuleContext<'input,GenericFileFormatContextExt<'input>>;

pub trait GenericFileFormatContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn simpleIdentifier(&self) -> Option<Rc<SimpleIdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> GenericFileFormatContextAttrs<'input> for GenericFileFormatContext<'input>{}

pub struct GenericFileFormatContextExt<'input>{
	base:FileFormatContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{GenericFileFormatContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for GenericFileFormatContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for GenericFileFormatContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_genericFileFormat(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_genericFileFormat(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for GenericFileFormatContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_genericFileFormat(self);
	}
}

impl<'input> CustomRuleContext<'input> for GenericFileFormatContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_fileFormat }
	//fn type_rule_index() -> usize where Self: Sized { RULE_fileFormat }
}

impl<'input> Borrow<FileFormatContextExt<'input>> for GenericFileFormatContext<'input>{
	fn borrow(&self) -> &FileFormatContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<FileFormatContextExt<'input>> for GenericFileFormatContext<'input>{
	fn borrow_mut(&mut self) -> &mut FileFormatContextExt<'input> { &mut self.base }
}

impl<'input> FileFormatContextAttrs<'input> for GenericFileFormatContext<'input> {}

impl<'input> GenericFileFormatContextExt<'input>{
	fn new(ctx: &dyn FileFormatContextAttrs<'input>) -> Rc<FileFormatContextAll<'input>>  {
		Rc::new(
			FileFormatContextAll::GenericFileFormatContext(
				BaseParserRuleContext::copy_from(ctx,GenericFileFormatContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn fileFormat(&mut self,)
	-> Result<Rc<FileFormatContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FileFormatContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 152, RULE_fileFormat);
        let mut _localctx: Rc<FileFormatContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2455);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(259,&mut recog.base)? {
				1 =>{
					let tmp = TableFileFormatContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(2449);
					recog.base.match_token(INPUTFORMAT,&mut recog.err_handler)?;

					/*InvokeRule stringLit*/
					recog.base.set_state(2450);
					let tmp = recog.stringLit()?;
					if let FileFormatContextAll::TableFileFormatContext(ctx) = cast_mut::<_,FileFormatContextAll >(&mut _localctx){
					ctx.inFmt = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2451);
					recog.base.match_token(OUTPUTFORMAT,&mut recog.err_handler)?;

					/*InvokeRule stringLit*/
					recog.base.set_state(2452);
					let tmp = recog.stringLit()?;
					if let FileFormatContextAll::TableFileFormatContext(ctx) = cast_mut::<_,FileFormatContextAll >(&mut _localctx){
					ctx.outFmt = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				2 =>{
					let tmp = GenericFileFormatContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule simpleIdentifier*/
					recog.base.set_state(2454);
					recog.simpleIdentifier()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- storageHandler ----------------
pub type StorageHandlerContextAll<'input> = StorageHandlerContext<'input>;


pub type StorageHandlerContext<'input> = BaseParserRuleContext<'input,StorageHandlerContextExt<'input>>;

#[derive(Clone)]
pub struct StorageHandlerContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for StorageHandlerContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for StorageHandlerContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_storageHandler(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_storageHandler(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for StorageHandlerContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_storageHandler(self);
	}
}

impl<'input> CustomRuleContext<'input> for StorageHandlerContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_storageHandler }
	//fn type_rule_index() -> usize where Self: Sized { RULE_storageHandler }
}
antlr_rust::tid!{StorageHandlerContextExt<'a>}

impl<'input> StorageHandlerContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StorageHandlerContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StorageHandlerContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StorageHandlerContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<StorageHandlerContextExt<'input>>{

fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token SERDEPROPERTIES
/// Returns `None` if there is no child corresponding to token SERDEPROPERTIES
fn SERDEPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SERDEPROPERTIES, 0)
}
fn propertyList(&self) -> Option<Rc<PropertyListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> StorageHandlerContextAttrs<'input> for StorageHandlerContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn storageHandler(&mut self,)
	-> Result<Rc<StorageHandlerContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StorageHandlerContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 154, RULE_storageHandler);
        let mut _localctx: Rc<StorageHandlerContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule stringLit*/
			recog.base.set_state(2457);
			recog.stringLit()?;

			recog.base.set_state(2461);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(260,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(2458);
					recog.base.match_token(WITH,&mut recog.err_handler)?;

					recog.base.set_state(2459);
					recog.base.match_token(SERDEPROPERTIES,&mut recog.err_handler)?;

					/*InvokeRule propertyList*/
					recog.base.set_state(2460);
					recog.propertyList()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- resource ----------------
pub type ResourceContextAll<'input> = ResourceContext<'input>;


pub type ResourceContext<'input> = BaseParserRuleContext<'input,ResourceContextExt<'input>>;

#[derive(Clone)]
pub struct ResourceContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ResourceContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ResourceContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_resource(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_resource(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ResourceContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_resource(self);
	}
}

impl<'input> CustomRuleContext<'input> for ResourceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_resource }
	//fn type_rule_index() -> usize where Self: Sized { RULE_resource }
}
antlr_rust::tid!{ResourceContextExt<'a>}

impl<'input> ResourceContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ResourceContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ResourceContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ResourceContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ResourceContextExt<'input>>{

fn simpleIdentifier(&self) -> Option<Rc<SimpleIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ResourceContextAttrs<'input> for ResourceContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn resource(&mut self,)
	-> Result<Rc<ResourceContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ResourceContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 156, RULE_resource);
        let mut _localctx: Rc<ResourceContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule simpleIdentifier*/
			recog.base.set_state(2463);
			recog.simpleIdentifier()?;

			/*InvokeRule stringLit*/
			recog.base.set_state(2464);
			recog.stringLit()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dmlStatementNoWith ----------------
#[derive(Debug)]
pub enum DmlStatementNoWithContextAll<'input>{
	DeleteFromTableContext(DeleteFromTableContext<'input>),
	SingleInsertQueryContext(SingleInsertQueryContext<'input>),
	MultiInsertQueryContext(MultiInsertQueryContext<'input>),
	UpdateTableContext(UpdateTableContext<'input>),
	MergeIntoTableContext(MergeIntoTableContext<'input>),
Error(DmlStatementNoWithContext<'input>)
}
antlr_rust::tid!{DmlStatementNoWithContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for DmlStatementNoWithContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for DmlStatementNoWithContextAll<'input>{}

impl<'input> Deref for DmlStatementNoWithContextAll<'input>{
	type Target = dyn DmlStatementNoWithContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use DmlStatementNoWithContextAll::*;
		match self{
			DeleteFromTableContext(inner) => inner,
			SingleInsertQueryContext(inner) => inner,
			MultiInsertQueryContext(inner) => inner,
			UpdateTableContext(inner) => inner,
			MergeIntoTableContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DmlStatementNoWithContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DmlStatementNoWithContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type DmlStatementNoWithContext<'input> = BaseParserRuleContext<'input,DmlStatementNoWithContextExt<'input>>;

#[derive(Clone)]
pub struct DmlStatementNoWithContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for DmlStatementNoWithContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DmlStatementNoWithContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DmlStatementNoWithContext<'input>{
}

impl<'input> CustomRuleContext<'input> for DmlStatementNoWithContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dmlStatementNoWith }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dmlStatementNoWith }
}
antlr_rust::tid!{DmlStatementNoWithContextExt<'a>}

impl<'input> DmlStatementNoWithContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DmlStatementNoWithContextAll<'input>> {
		Rc::new(
		DmlStatementNoWithContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DmlStatementNoWithContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait DmlStatementNoWithContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<DmlStatementNoWithContextExt<'input>>{


}

impl<'input> DmlStatementNoWithContextAttrs<'input> for DmlStatementNoWithContext<'input>{}

pub type DeleteFromTableContext<'input> = BaseParserRuleContext<'input,DeleteFromTableContextExt<'input>>;

pub trait DeleteFromTableContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DELETE
	/// Returns `None` if there is no child corresponding to token DELETE
	fn DELETE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DELETE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn tableAlias(&self) -> Option<Rc<TableAliasContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn whereClause(&self) -> Option<Rc<WhereClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> DeleteFromTableContextAttrs<'input> for DeleteFromTableContext<'input>{}

pub struct DeleteFromTableContextExt<'input>{
	base:DmlStatementNoWithContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DeleteFromTableContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for DeleteFromTableContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DeleteFromTableContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_deleteFromTable(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_deleteFromTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DeleteFromTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_deleteFromTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for DeleteFromTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dmlStatementNoWith }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dmlStatementNoWith }
}

impl<'input> Borrow<DmlStatementNoWithContextExt<'input>> for DeleteFromTableContext<'input>{
	fn borrow(&self) -> &DmlStatementNoWithContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<DmlStatementNoWithContextExt<'input>> for DeleteFromTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut DmlStatementNoWithContextExt<'input> { &mut self.base }
}

impl<'input> DmlStatementNoWithContextAttrs<'input> for DeleteFromTableContext<'input> {}

impl<'input> DeleteFromTableContextExt<'input>{
	fn new(ctx: &dyn DmlStatementNoWithContextAttrs<'input>) -> Rc<DmlStatementNoWithContextAll<'input>>  {
		Rc::new(
			DmlStatementNoWithContextAll::DeleteFromTableContext(
				BaseParserRuleContext::copy_from(ctx,DeleteFromTableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SingleInsertQueryContext<'input> = BaseParserRuleContext<'input,SingleInsertQueryContextExt<'input>>;

pub trait SingleInsertQueryContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn insertInto(&self) -> Option<Rc<InsertIntoContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SingleInsertQueryContextAttrs<'input> for SingleInsertQueryContext<'input>{}

pub struct SingleInsertQueryContextExt<'input>{
	base:DmlStatementNoWithContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SingleInsertQueryContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SingleInsertQueryContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SingleInsertQueryContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_singleInsertQuery(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_singleInsertQuery(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SingleInsertQueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_singleInsertQuery(self);
	}
}

impl<'input> CustomRuleContext<'input> for SingleInsertQueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dmlStatementNoWith }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dmlStatementNoWith }
}

impl<'input> Borrow<DmlStatementNoWithContextExt<'input>> for SingleInsertQueryContext<'input>{
	fn borrow(&self) -> &DmlStatementNoWithContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<DmlStatementNoWithContextExt<'input>> for SingleInsertQueryContext<'input>{
	fn borrow_mut(&mut self) -> &mut DmlStatementNoWithContextExt<'input> { &mut self.base }
}

impl<'input> DmlStatementNoWithContextAttrs<'input> for SingleInsertQueryContext<'input> {}

impl<'input> SingleInsertQueryContextExt<'input>{
	fn new(ctx: &dyn DmlStatementNoWithContextAttrs<'input>) -> Rc<DmlStatementNoWithContextAll<'input>>  {
		Rc::new(
			DmlStatementNoWithContextAll::SingleInsertQueryContext(
				BaseParserRuleContext::copy_from(ctx,SingleInsertQueryContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type MultiInsertQueryContext<'input> = BaseParserRuleContext<'input,MultiInsertQueryContextExt<'input>>;

pub trait MultiInsertQueryContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn fromClause(&self) -> Option<Rc<FromClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn multiInsertQueryBody_all(&self) ->  Vec<Rc<MultiInsertQueryBodyContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn multiInsertQueryBody(&self, i: usize) -> Option<Rc<MultiInsertQueryBodyContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> MultiInsertQueryContextAttrs<'input> for MultiInsertQueryContext<'input>{}

pub struct MultiInsertQueryContextExt<'input>{
	base:DmlStatementNoWithContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{MultiInsertQueryContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for MultiInsertQueryContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for MultiInsertQueryContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_multiInsertQuery(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_multiInsertQuery(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for MultiInsertQueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_multiInsertQuery(self);
	}
}

impl<'input> CustomRuleContext<'input> for MultiInsertQueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dmlStatementNoWith }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dmlStatementNoWith }
}

impl<'input> Borrow<DmlStatementNoWithContextExt<'input>> for MultiInsertQueryContext<'input>{
	fn borrow(&self) -> &DmlStatementNoWithContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<DmlStatementNoWithContextExt<'input>> for MultiInsertQueryContext<'input>{
	fn borrow_mut(&mut self) -> &mut DmlStatementNoWithContextExt<'input> { &mut self.base }
}

impl<'input> DmlStatementNoWithContextAttrs<'input> for MultiInsertQueryContext<'input> {}

impl<'input> MultiInsertQueryContextExt<'input>{
	fn new(ctx: &dyn DmlStatementNoWithContextAttrs<'input>) -> Rc<DmlStatementNoWithContextAll<'input>>  {
		Rc::new(
			DmlStatementNoWithContextAll::MultiInsertQueryContext(
				BaseParserRuleContext::copy_from(ctx,MultiInsertQueryContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type UpdateTableContext<'input> = BaseParserRuleContext<'input,UpdateTableContextExt<'input>>;

pub trait UpdateTableContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token UPDATE
	/// Returns `None` if there is no child corresponding to token UPDATE
	fn UPDATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(UPDATE, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn tableAlias(&self) -> Option<Rc<TableAliasContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn setClause(&self) -> Option<Rc<SetClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn whereClause(&self) -> Option<Rc<WhereClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> UpdateTableContextAttrs<'input> for UpdateTableContext<'input>{}

pub struct UpdateTableContextExt<'input>{
	base:DmlStatementNoWithContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UpdateTableContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for UpdateTableContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for UpdateTableContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_updateTable(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_updateTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for UpdateTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_updateTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for UpdateTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dmlStatementNoWith }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dmlStatementNoWith }
}

impl<'input> Borrow<DmlStatementNoWithContextExt<'input>> for UpdateTableContext<'input>{
	fn borrow(&self) -> &DmlStatementNoWithContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<DmlStatementNoWithContextExt<'input>> for UpdateTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut DmlStatementNoWithContextExt<'input> { &mut self.base }
}

impl<'input> DmlStatementNoWithContextAttrs<'input> for UpdateTableContext<'input> {}

impl<'input> UpdateTableContextExt<'input>{
	fn new(ctx: &dyn DmlStatementNoWithContextAttrs<'input>) -> Rc<DmlStatementNoWithContextAll<'input>>  {
		Rc::new(
			DmlStatementNoWithContextAll::UpdateTableContext(
				BaseParserRuleContext::copy_from(ctx,UpdateTableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type MergeIntoTableContext<'input> = BaseParserRuleContext<'input,MergeIntoTableContextExt<'input>>;

pub trait MergeIntoTableContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token MERGE
	/// Returns `None` if there is no child corresponding to token MERGE
	fn MERGE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(MERGE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token INTO
	/// Returns `None` if there is no child corresponding to token INTO
	fn INTO(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(INTO, 0)
	}
	/// Retrieves first TerminalNode corresponding to token USING
	/// Returns `None` if there is no child corresponding to token USING
	fn USING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(USING, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ON
	/// Returns `None` if there is no child corresponding to token ON
	fn ON(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ON, 0)
	}
	fn identifierReference_all(&self) ->  Vec<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn identifierReference(&self, i: usize) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn tableAlias_all(&self) ->  Vec<Rc<TableAliasContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn tableAlias(&self, i: usize) -> Option<Rc<TableAliasContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token WITH
	/// Returns `None` if there is no child corresponding to token WITH
	fn WITH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(WITH, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SCHEMA
	/// Returns `None` if there is no child corresponding to token SCHEMA
	fn SCHEMA(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SCHEMA, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EVOLUTION
	/// Returns `None` if there is no child corresponding to token EVOLUTION
	fn EVOLUTION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EVOLUTION, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn matchedClause_all(&self) ->  Vec<Rc<MatchedClauseContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn matchedClause(&self, i: usize) -> Option<Rc<MatchedClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn notMatchedClause_all(&self) ->  Vec<Rc<NotMatchedClauseContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn notMatchedClause(&self, i: usize) -> Option<Rc<NotMatchedClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn notMatchedBySourceClause_all(&self) ->  Vec<Rc<NotMatchedBySourceClauseContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn notMatchedBySourceClause(&self, i: usize) -> Option<Rc<NotMatchedBySourceClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> MergeIntoTableContextAttrs<'input> for MergeIntoTableContext<'input>{}

pub struct MergeIntoTableContextExt<'input>{
	base:DmlStatementNoWithContextExt<'input>,
	pub target: Option<Rc<IdentifierReferenceContextAll<'input>>>,
	pub targetAlias: Option<Rc<TableAliasContextAll<'input>>>,
	pub source: Option<Rc<IdentifierReferenceContextAll<'input>>>,
	pub sourceQuery: Option<Rc<QueryContextAll<'input>>>,
	pub sourceAlias: Option<Rc<TableAliasContextAll<'input>>>,
	pub mergeCondition: Option<Rc<BooleanExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{MergeIntoTableContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for MergeIntoTableContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for MergeIntoTableContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_mergeIntoTable(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_mergeIntoTable(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for MergeIntoTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_mergeIntoTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for MergeIntoTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dmlStatementNoWith }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dmlStatementNoWith }
}

impl<'input> Borrow<DmlStatementNoWithContextExt<'input>> for MergeIntoTableContext<'input>{
	fn borrow(&self) -> &DmlStatementNoWithContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<DmlStatementNoWithContextExt<'input>> for MergeIntoTableContext<'input>{
	fn borrow_mut(&mut self) -> &mut DmlStatementNoWithContextExt<'input> { &mut self.base }
}

impl<'input> DmlStatementNoWithContextAttrs<'input> for MergeIntoTableContext<'input> {}

impl<'input> MergeIntoTableContextExt<'input>{
	fn new(ctx: &dyn DmlStatementNoWithContextAttrs<'input>) -> Rc<DmlStatementNoWithContextAll<'input>>  {
		Rc::new(
			DmlStatementNoWithContextAll::MergeIntoTableContext(
				BaseParserRuleContext::copy_from(ctx,MergeIntoTableContextExt{
        			target:None, targetAlias:None, source:None, sourceQuery:None, sourceAlias:None, mergeCondition:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dmlStatementNoWith(&mut self,)
	-> Result<Rc<DmlStatementNoWithContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DmlStatementNoWithContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 158, RULE_dmlStatementNoWith);
        let mut _localctx: Rc<DmlStatementNoWithContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(2527);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 INSERT 
				=> {
					let tmp = SingleInsertQueryContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule insertInto*/
					recog.base.set_state(2466);
					recog.insertInto()?;

					/*InvokeRule query*/
					recog.base.set_state(2467);
					recog.query()?;

					}
				}

			 FROM 
				=> {
					let tmp = MultiInsertQueryContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule fromClause*/
					recog.base.set_state(2469);
					recog.fromClause()?;

					recog.base.set_state(2471); 
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					loop {
						{
						{
						/*InvokeRule multiInsertQueryBody*/
						recog.base.set_state(2470);
						recog.multiInsertQueryBody()?;

						}
						}
						recog.base.set_state(2473); 
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if !(_la==INSERT) {break}
					}
					}
				}

			 DELETE 
				=> {
					let tmp = DeleteFromTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(2475);
					recog.base.match_token(DELETE,&mut recog.err_handler)?;

					recog.base.set_state(2476);
					recog.base.match_token(FROM,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(2477);
					recog.identifierReference()?;

					/*InvokeRule tableAlias*/
					recog.base.set_state(2478);
					recog.tableAlias()?;

					recog.base.set_state(2480);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==WHERE {
						{
						/*InvokeRule whereClause*/
						recog.base.set_state(2479);
						recog.whereClause()?;

						}
					}

					}
				}

			 UPDATE 
				=> {
					let tmp = UpdateTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(2482);
					recog.base.match_token(UPDATE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(2483);
					recog.identifierReference()?;

					/*InvokeRule tableAlias*/
					recog.base.set_state(2484);
					recog.tableAlias()?;

					/*InvokeRule setClause*/
					recog.base.set_state(2485);
					recog.setClause()?;

					recog.base.set_state(2487);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==WHERE {
						{
						/*InvokeRule whereClause*/
						recog.base.set_state(2486);
						recog.whereClause()?;

						}
					}

					}
				}

			 MERGE 
				=> {
					let tmp = MergeIntoTableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					recog.base.set_state(2489);
					recog.base.match_token(MERGE,&mut recog.err_handler)?;

					recog.base.set_state(2493);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==WITH {
						{
						recog.base.set_state(2490);
						recog.base.match_token(WITH,&mut recog.err_handler)?;

						recog.base.set_state(2491);
						recog.base.match_token(SCHEMA,&mut recog.err_handler)?;

						recog.base.set_state(2492);
						recog.base.match_token(EVOLUTION,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2495);
					recog.base.match_token(INTO,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(2496);
					let tmp = recog.identifierReference()?;
					if let DmlStatementNoWithContextAll::MergeIntoTableContext(ctx) = cast_mut::<_,DmlStatementNoWithContextAll >(&mut _localctx){
					ctx.target = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					/*InvokeRule tableAlias*/
					recog.base.set_state(2497);
					let tmp = recog.tableAlias()?;
					if let DmlStatementNoWithContextAll::MergeIntoTableContext(ctx) = cast_mut::<_,DmlStatementNoWithContextAll >(&mut _localctx){
					ctx.targetAlias = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2498);
					recog.base.match_token(USING,&mut recog.err_handler)?;

					recog.base.set_state(2504);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(265,&mut recog.base)? {
						1 =>{
							{
							/*InvokeRule identifierReference*/
							recog.base.set_state(2499);
							let tmp = recog.identifierReference()?;
							if let DmlStatementNoWithContextAll::MergeIntoTableContext(ctx) = cast_mut::<_,DmlStatementNoWithContextAll >(&mut _localctx){
							ctx.source = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						2 =>{
							{
							recog.base.set_state(2500);
							recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

							/*InvokeRule query*/
							recog.base.set_state(2501);
							let tmp = recog.query()?;
							if let DmlStatementNoWithContextAll::MergeIntoTableContext(ctx) = cast_mut::<_,DmlStatementNoWithContextAll >(&mut _localctx){
							ctx.sourceQuery = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							recog.base.set_state(2502);
							recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule tableAlias*/
					recog.base.set_state(2506);
					let tmp = recog.tableAlias()?;
					if let DmlStatementNoWithContextAll::MergeIntoTableContext(ctx) = cast_mut::<_,DmlStatementNoWithContextAll >(&mut _localctx){
					ctx.sourceAlias = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2507);
					recog.base.match_token(ON,&mut recog.err_handler)?;

					/*InvokeRule booleanExpression*/
					recog.base.set_state(2508);
					let tmp = recog.booleanExpression_rec(0)?;
					if let DmlStatementNoWithContextAll::MergeIntoTableContext(ctx) = cast_mut::<_,DmlStatementNoWithContextAll >(&mut _localctx){
					ctx.mergeCondition = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(2512);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(266,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							/*InvokeRule matchedClause*/
							recog.base.set_state(2509);
							recog.matchedClause()?;

							}
							} 
						}
						recog.base.set_state(2514);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(266,&mut recog.base)?;
					}
					recog.base.set_state(2518);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(267,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							/*InvokeRule notMatchedClause*/
							recog.base.set_state(2515);
							recog.notMatchedClause()?;

							}
							} 
						}
						recog.base.set_state(2520);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(267,&mut recog.base)?;
					}
					recog.base.set_state(2524);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==WHEN {
						{
						{
						/*InvokeRule notMatchedBySourceClause*/
						recog.base.set_state(2521);
						recog.notMatchedBySourceClause()?;

						}
						}
						recog.base.set_state(2526);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- identifierReference ----------------
pub type IdentifierReferenceContextAll<'input> = IdentifierReferenceContext<'input>;


pub type IdentifierReferenceContext<'input> = BaseParserRuleContext<'input,IdentifierReferenceContextExt<'input>>;

#[derive(Clone)]
pub struct IdentifierReferenceContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for IdentifierReferenceContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for IdentifierReferenceContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_identifierReference(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_identifierReference(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for IdentifierReferenceContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_identifierReference(self);
	}
}

impl<'input> CustomRuleContext<'input> for IdentifierReferenceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identifierReference }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identifierReference }
}
antlr_rust::tid!{IdentifierReferenceContextExt<'a>}

impl<'input> IdentifierReferenceContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IdentifierReferenceContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IdentifierReferenceContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait IdentifierReferenceContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<IdentifierReferenceContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token IDENTIFIER_KW
/// Returns `None` if there is no child corresponding to token IDENTIFIER_KW
fn IDENTIFIER_KW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IDENTIFIER_KW, 0)
}
/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
fn multipartIdentifier(&self) -> Option<Rc<MultipartIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> IdentifierReferenceContextAttrs<'input> for IdentifierReferenceContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn identifierReference(&mut self,)
	-> Result<Rc<IdentifierReferenceContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IdentifierReferenceContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 160, RULE_identifierReference);
        let mut _localctx: Rc<IdentifierReferenceContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2535);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(270,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2529);
					recog.base.match_token(IDENTIFIER_KW,&mut recog.err_handler)?;

					recog.base.set_state(2530);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2531);
					recog.expression()?;

					recog.base.set_state(2532);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule multipartIdentifier*/
					recog.base.set_state(2534);
					recog.multipartIdentifier()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- catalogIdentifierReference ----------------
pub type CatalogIdentifierReferenceContextAll<'input> = CatalogIdentifierReferenceContext<'input>;


pub type CatalogIdentifierReferenceContext<'input> = BaseParserRuleContext<'input,CatalogIdentifierReferenceContextExt<'input>>;

#[derive(Clone)]
pub struct CatalogIdentifierReferenceContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for CatalogIdentifierReferenceContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CatalogIdentifierReferenceContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_catalogIdentifierReference(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_catalogIdentifierReference(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CatalogIdentifierReferenceContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_catalogIdentifierReference(self);
	}
}

impl<'input> CustomRuleContext<'input> for CatalogIdentifierReferenceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_catalogIdentifierReference }
	//fn type_rule_index() -> usize where Self: Sized { RULE_catalogIdentifierReference }
}
antlr_rust::tid!{CatalogIdentifierReferenceContextExt<'a>}

impl<'input> CatalogIdentifierReferenceContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CatalogIdentifierReferenceContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CatalogIdentifierReferenceContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait CatalogIdentifierReferenceContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<CatalogIdentifierReferenceContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token IDENTIFIER_KW
/// Returns `None` if there is no child corresponding to token IDENTIFIER_KW
fn IDENTIFIER_KW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IDENTIFIER_KW, 0)
}
/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
fn errorCapturingIdentifier(&self) -> Option<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CatalogIdentifierReferenceContextAttrs<'input> for CatalogIdentifierReferenceContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn catalogIdentifierReference(&mut self,)
	-> Result<Rc<CatalogIdentifierReferenceContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CatalogIdentifierReferenceContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 162, RULE_catalogIdentifierReference);
        let mut _localctx: Rc<CatalogIdentifierReferenceContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2544);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(271,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2537);
					recog.base.match_token(IDENTIFIER_KW,&mut recog.err_handler)?;

					recog.base.set_state(2538);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2539);
					recog.expression()?;

					recog.base.set_state(2540);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule errorCapturingIdentifier*/
					recog.base.set_state(2542);
					recog.errorCapturingIdentifier()?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule stringLit*/
					recog.base.set_state(2543);
					recog.stringLit()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- queryOrganization ----------------
pub type QueryOrganizationContextAll<'input> = QueryOrganizationContext<'input>;


pub type QueryOrganizationContext<'input> = BaseParserRuleContext<'input,QueryOrganizationContextExt<'input>>;

#[derive(Clone)]
pub struct QueryOrganizationContextExt<'input>{
	pub sortItem: Option<Rc<SortItemContextAll<'input>>>,
	pub order:Vec<Rc<SortItemContextAll<'input>>>,
	pub expression: Option<Rc<ExpressionContextAll<'input>>>,
	pub clusterBy:Vec<Rc<ExpressionContextAll<'input>>>,
	pub distributeBy:Vec<Rc<ExpressionContextAll<'input>>>,
	pub sort:Vec<Rc<SortItemContextAll<'input>>>,
	pub limit: Option<Rc<ExpressionContextAll<'input>>>,
	pub offset: Option<Rc<ExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for QueryOrganizationContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for QueryOrganizationContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_queryOrganization(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_queryOrganization(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for QueryOrganizationContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_queryOrganization(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryOrganizationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryOrganization }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryOrganization }
}
antlr_rust::tid!{QueryOrganizationContextExt<'a>}

impl<'input> QueryOrganizationContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryOrganizationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryOrganizationContextExt{
				sortItem: None, expression: None, limit: None, offset: None, 
				order: Vec::new(), clusterBy: Vec::new(), distributeBy: Vec::new(), sort: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait QueryOrganizationContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<QueryOrganizationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ORDER
/// Returns `None` if there is no child corresponding to token ORDER
fn ORDER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ORDER, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token BY in current rule
fn BY_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token BY, starting from 0.
/// Returns `None` if number of children corresponding to token BY is less or equal than `i`.
fn BY(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BY, i)
}
/// Retrieves first TerminalNode corresponding to token CLUSTER
/// Returns `None` if there is no child corresponding to token CLUSTER
fn CLUSTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CLUSTER, 0)
}
/// Retrieves first TerminalNode corresponding to token DISTRIBUTE
/// Returns `None` if there is no child corresponding to token DISTRIBUTE
fn DISTRIBUTE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DISTRIBUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token SORT
/// Returns `None` if there is no child corresponding to token SORT
fn SORT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SORT, 0)
}
fn windowClause(&self) -> Option<Rc<WindowClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LIMIT
/// Returns `None` if there is no child corresponding to token LIMIT
fn LIMIT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LIMIT, 0)
}
/// Retrieves first TerminalNode corresponding to token OFFSET
/// Returns `None` if there is no child corresponding to token OFFSET
fn OFFSET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OFFSET, 0)
}
fn sortItem_all(&self) ->  Vec<Rc<SortItemContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn sortItem(&self, i: usize) -> Option<Rc<SortItemContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token ALL
/// Returns `None` if there is no child corresponding to token ALL
fn ALL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ALL, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> QueryOrganizationContextAttrs<'input> for QueryOrganizationContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn queryOrganization(&mut self,)
	-> Result<Rc<QueryOrganizationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryOrganizationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 164, RULE_queryOrganization);
        let mut _localctx: Rc<QueryOrganizationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2556);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(273,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(2546);
					recog.base.match_token(ORDER,&mut recog.err_handler)?;

					recog.base.set_state(2547);
					recog.base.match_token(BY,&mut recog.err_handler)?;

					/*InvokeRule sortItem*/
					recog.base.set_state(2548);
					let tmp = recog.sortItem()?;
					 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).sortItem = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,QueryOrganizationContext >(&mut _localctx).sortItem.clone().unwrap()
					 ;
					 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).order.push(temp);
					  
					recog.base.set_state(2553);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(272,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(2549);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule sortItem*/
							recog.base.set_state(2550);
							let tmp = recog.sortItem()?;
							 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).sortItem = Some(tmp.clone());
							  

							let temp =  cast_mut::<_,QueryOrganizationContext >(&mut _localctx).sortItem.clone().unwrap()
							 ;
							 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).order.push(temp);
							  
							}
							} 
						}
						recog.base.set_state(2555);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(272,&mut recog.base)?;
					}
					}
				}

				_ => {}
			}
			recog.base.set_state(2568);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(275,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(2558);
					recog.base.match_token(CLUSTER,&mut recog.err_handler)?;

					recog.base.set_state(2559);
					recog.base.match_token(BY,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2560);
					let tmp = recog.expression()?;
					 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).expression = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,QueryOrganizationContext >(&mut _localctx).expression.clone().unwrap()
					 ;
					 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).clusterBy.push(temp);
					  
					recog.base.set_state(2565);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(274,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(2561);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule expression*/
							recog.base.set_state(2562);
							let tmp = recog.expression()?;
							 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).expression = Some(tmp.clone());
							  

							let temp =  cast_mut::<_,QueryOrganizationContext >(&mut _localctx).expression.clone().unwrap()
							 ;
							 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).clusterBy.push(temp);
							  
							}
							} 
						}
						recog.base.set_state(2567);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(274,&mut recog.base)?;
					}
					}
				}

				_ => {}
			}
			recog.base.set_state(2580);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(277,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(2570);
					recog.base.match_token(DISTRIBUTE,&mut recog.err_handler)?;

					recog.base.set_state(2571);
					recog.base.match_token(BY,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2572);
					let tmp = recog.expression()?;
					 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).expression = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,QueryOrganizationContext >(&mut _localctx).expression.clone().unwrap()
					 ;
					 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).distributeBy.push(temp);
					  
					recog.base.set_state(2577);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(276,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(2573);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule expression*/
							recog.base.set_state(2574);
							let tmp = recog.expression()?;
							 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).expression = Some(tmp.clone());
							  

							let temp =  cast_mut::<_,QueryOrganizationContext >(&mut _localctx).expression.clone().unwrap()
							 ;
							 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).distributeBy.push(temp);
							  
							}
							} 
						}
						recog.base.set_state(2579);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(276,&mut recog.base)?;
					}
					}
				}

				_ => {}
			}
			recog.base.set_state(2592);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(279,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(2582);
					recog.base.match_token(SORT,&mut recog.err_handler)?;

					recog.base.set_state(2583);
					recog.base.match_token(BY,&mut recog.err_handler)?;

					/*InvokeRule sortItem*/
					recog.base.set_state(2584);
					let tmp = recog.sortItem()?;
					 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).sortItem = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,QueryOrganizationContext >(&mut _localctx).sortItem.clone().unwrap()
					 ;
					 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).sort.push(temp);
					  
					recog.base.set_state(2589);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(278,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(2585);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule sortItem*/
							recog.base.set_state(2586);
							let tmp = recog.sortItem()?;
							 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).sortItem = Some(tmp.clone());
							  

							let temp =  cast_mut::<_,QueryOrganizationContext >(&mut _localctx).sortItem.clone().unwrap()
							 ;
							 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).sort.push(temp);
							  
							}
							} 
						}
						recog.base.set_state(2591);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(278,&mut recog.base)?;
					}
					}
				}

				_ => {}
			}
			recog.base.set_state(2595);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(280,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule windowClause*/
					recog.base.set_state(2594);
					recog.windowClause()?;

					}
				}

				_ => {}
			}
			recog.base.set_state(2602);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(282,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(2597);
					recog.base.match_token(LIMIT,&mut recog.err_handler)?;

					recog.base.set_state(2600);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(281,&mut recog.base)? {
						1 =>{
							{
							recog.base.set_state(2598);
							recog.base.match_token(ALL,&mut recog.err_handler)?;

							}
						}
					,
						2 =>{
							{
							/*InvokeRule expression*/
							recog.base.set_state(2599);
							let tmp = recog.expression()?;
							 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).limit = Some(tmp.clone());
							  

							}
						}

						_ => {}
					}
					}
				}

				_ => {}
			}
			recog.base.set_state(2606);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(283,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(2604);
					recog.base.match_token(OFFSET,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2605);
					let tmp = recog.expression()?;
					 cast_mut::<_,QueryOrganizationContext >(&mut _localctx).offset = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- multiInsertQueryBody ----------------
pub type MultiInsertQueryBodyContextAll<'input> = MultiInsertQueryBodyContext<'input>;


pub type MultiInsertQueryBodyContext<'input> = BaseParserRuleContext<'input,MultiInsertQueryBodyContextExt<'input>>;

#[derive(Clone)]
pub struct MultiInsertQueryBodyContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for MultiInsertQueryBodyContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for MultiInsertQueryBodyContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_multiInsertQueryBody(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_multiInsertQueryBody(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for MultiInsertQueryBodyContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_multiInsertQueryBody(self);
	}
}

impl<'input> CustomRuleContext<'input> for MultiInsertQueryBodyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_multiInsertQueryBody }
	//fn type_rule_index() -> usize where Self: Sized { RULE_multiInsertQueryBody }
}
antlr_rust::tid!{MultiInsertQueryBodyContextExt<'a>}

impl<'input> MultiInsertQueryBodyContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MultiInsertQueryBodyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MultiInsertQueryBodyContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait MultiInsertQueryBodyContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<MultiInsertQueryBodyContextExt<'input>>{

fn insertInto(&self) -> Option<Rc<InsertIntoContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn fromStatementBody(&self) -> Option<Rc<FromStatementBodyContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MultiInsertQueryBodyContextAttrs<'input> for MultiInsertQueryBodyContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn multiInsertQueryBody(&mut self,)
	-> Result<Rc<MultiInsertQueryBodyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MultiInsertQueryBodyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 166, RULE_multiInsertQueryBody);
        let mut _localctx: Rc<MultiInsertQueryBodyContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule insertInto*/
			recog.base.set_state(2608);
			recog.insertInto()?;

			/*InvokeRule fromStatementBody*/
			recog.base.set_state(2609);
			recog.fromStatementBody()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- queryTerm ----------------
#[derive(Debug)]
pub enum QueryTermContextAll<'input>{
	OperatorPipeStatementContext(OperatorPipeStatementContext<'input>),
	QueryTermDefaultContext(QueryTermDefaultContext<'input>),
	SetOperationContext(SetOperationContext<'input>),
Error(QueryTermContext<'input>)
}
antlr_rust::tid!{QueryTermContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for QueryTermContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for QueryTermContextAll<'input>{}

impl<'input> Deref for QueryTermContextAll<'input>{
	type Target = dyn QueryTermContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use QueryTermContextAll::*;
		match self{
			OperatorPipeStatementContext(inner) => inner,
			QueryTermDefaultContext(inner) => inner,
			SetOperationContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for QueryTermContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for QueryTermContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type QueryTermContext<'input> = BaseParserRuleContext<'input,QueryTermContextExt<'input>>;

#[derive(Clone)]
pub struct QueryTermContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for QueryTermContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for QueryTermContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for QueryTermContext<'input>{
}

impl<'input> CustomRuleContext<'input> for QueryTermContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryTerm }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryTerm }
}
antlr_rust::tid!{QueryTermContextExt<'a>}

impl<'input> QueryTermContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryTermContextAll<'input>> {
		Rc::new(
		QueryTermContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryTermContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait QueryTermContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<QueryTermContextExt<'input>>{


}

impl<'input> QueryTermContextAttrs<'input> for QueryTermContext<'input>{}

pub type OperatorPipeStatementContext<'input> = BaseParserRuleContext<'input,OperatorPipeStatementContextExt<'input>>;

pub trait OperatorPipeStatementContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token OPERATOR_PIPE
	/// Returns `None` if there is no child corresponding to token OPERATOR_PIPE
	fn OPERATOR_PIPE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(OPERATOR_PIPE, 0)
	}
	fn operatorPipeRightSide(&self) -> Option<Rc<OperatorPipeRightSideContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn queryTerm(&self) -> Option<Rc<QueryTermContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token PIPE
	/// Returns `None` if there is no child corresponding to token PIPE
	fn PIPE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(PIPE, 0)
	}
}

impl<'input> OperatorPipeStatementContextAttrs<'input> for OperatorPipeStatementContext<'input>{}

pub struct OperatorPipeStatementContextExt<'input>{
	base:QueryTermContextExt<'input>,
	pub left: Option<Rc<QueryTermContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{OperatorPipeStatementContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for OperatorPipeStatementContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for OperatorPipeStatementContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_operatorPipeStatement(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_operatorPipeStatement(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for OperatorPipeStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_operatorPipeStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for OperatorPipeStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryTerm }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryTerm }
}

impl<'input> Borrow<QueryTermContextExt<'input>> for OperatorPipeStatementContext<'input>{
	fn borrow(&self) -> &QueryTermContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<QueryTermContextExt<'input>> for OperatorPipeStatementContext<'input>{
	fn borrow_mut(&mut self) -> &mut QueryTermContextExt<'input> { &mut self.base }
}

impl<'input> QueryTermContextAttrs<'input> for OperatorPipeStatementContext<'input> {}

impl<'input> OperatorPipeStatementContextExt<'input>{
	fn new(ctx: &dyn QueryTermContextAttrs<'input>) -> Rc<QueryTermContextAll<'input>>  {
		Rc::new(
			QueryTermContextAll::OperatorPipeStatementContext(
				BaseParserRuleContext::copy_from(ctx,OperatorPipeStatementContextExt{
        			left:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type QueryTermDefaultContext<'input> = BaseParserRuleContext<'input,QueryTermDefaultContextExt<'input>>;

pub trait QueryTermDefaultContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn queryPrimary(&self) -> Option<Rc<QueryPrimaryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> QueryTermDefaultContextAttrs<'input> for QueryTermDefaultContext<'input>{}

pub struct QueryTermDefaultContextExt<'input>{
	base:QueryTermContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{QueryTermDefaultContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for QueryTermDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for QueryTermDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_queryTermDefault(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_queryTermDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for QueryTermDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_queryTermDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryTermDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryTerm }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryTerm }
}

impl<'input> Borrow<QueryTermContextExt<'input>> for QueryTermDefaultContext<'input>{
	fn borrow(&self) -> &QueryTermContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<QueryTermContextExt<'input>> for QueryTermDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut QueryTermContextExt<'input> { &mut self.base }
}

impl<'input> QueryTermContextAttrs<'input> for QueryTermDefaultContext<'input> {}

impl<'input> QueryTermDefaultContextExt<'input>{
	fn new(ctx: &dyn QueryTermContextAttrs<'input>) -> Rc<QueryTermContextAll<'input>>  {
		Rc::new(
			QueryTermContextAll::QueryTermDefaultContext(
				BaseParserRuleContext::copy_from(ctx,QueryTermDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SetOperationContext<'input> = BaseParserRuleContext<'input,SetOperationContextExt<'input>>;

pub trait SetOperationContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn queryTerm_all(&self) ->  Vec<Rc<QueryTermContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn queryTerm(&self, i: usize) -> Option<Rc<QueryTermContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token INTERSECT
	/// Returns `None` if there is no child corresponding to token INTERSECT
	fn INTERSECT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(INTERSECT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token UNION
	/// Returns `None` if there is no child corresponding to token UNION
	fn UNION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(UNION, 0)
	}
	/// Retrieves first TerminalNode corresponding to token EXCEPT
	/// Returns `None` if there is no child corresponding to token EXCEPT
	fn EXCEPT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXCEPT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SETMINUS
	/// Returns `None` if there is no child corresponding to token SETMINUS
	fn SETMINUS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SETMINUS, 0)
	}
	fn setQuantifier(&self) -> Option<Rc<SetQuantifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SetOperationContextAttrs<'input> for SetOperationContext<'input>{}

pub struct SetOperationContextExt<'input>{
	base:QueryTermContextExt<'input>,
	pub left: Option<Rc<QueryTermContextAll<'input>>>,
	pub operator: Option<TokenType<'input>>,
	pub right: Option<Rc<QueryTermContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SetOperationContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SetOperationContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SetOperationContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_setOperation(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_setOperation(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SetOperationContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_setOperation(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetOperationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryTerm }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryTerm }
}

impl<'input> Borrow<QueryTermContextExt<'input>> for SetOperationContext<'input>{
	fn borrow(&self) -> &QueryTermContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<QueryTermContextExt<'input>> for SetOperationContext<'input>{
	fn borrow_mut(&mut self) -> &mut QueryTermContextExt<'input> { &mut self.base }
}

impl<'input> QueryTermContextAttrs<'input> for SetOperationContext<'input> {}

impl<'input> SetOperationContextExt<'input>{
	fn new(ctx: &dyn QueryTermContextAttrs<'input>) -> Rc<QueryTermContextAll<'input>>  {
		Rc::new(
			QueryTermContextAll::SetOperationContext(
				BaseParserRuleContext::copy_from(ctx,SetOperationContextExt{
					operator:None, 
        			left:None, right:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn  queryTerm(&mut self,)
	-> Result<Rc<QueryTermContextAll<'input>>,ANTLRError> {
		self.queryTerm_rec(0)
	}

	fn queryTerm_rec(&mut self, _p: isize)
	-> Result<Rc<QueryTermContextAll<'input>>,ANTLRError> {
		let recog = self;
		let _parentctx = recog.ctx.take();
		let _parentState = recog.base.get_state();
		let mut _localctx = QueryTermContextExt::new(_parentctx.clone(), recog.base.get_state());
		recog.base.enter_recursion_rule(_localctx.clone(), 168, RULE_queryTerm, _p);
	    let mut _localctx: Rc<QueryTermContextAll> = _localctx;
        let mut _prevctx = _localctx.clone();
		let _startState = 168;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {
			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			{
			let mut tmp = QueryTermDefaultContextExt::new(&**_localctx);
			recog.ctx = Some(tmp.clone());
			_localctx = tmp;
			_prevctx = _localctx.clone();


			/*InvokeRule queryPrimary*/
			recog.base.set_state(2612);
			recog.queryPrimary()?;

			}

			let tmp = recog.input.lt(-1).cloned();
			recog.ctx.as_ref().unwrap().set_stop(tmp);
			recog.base.set_state(2644);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(288,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					recog.trigger_exit_rule_event();
					_prevctx = _localctx.clone();
					{
					recog.base.set_state(2642);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(287,&mut recog.base)? {
						1 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = SetOperationContextExt::new(&**QueryTermContextExt::new(_parentctx.clone(), _parentState));
							if let QueryTermContextAll::SetOperationContext(ctx) = cast_mut::<_,QueryTermContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_queryTerm);
							_localctx = tmp;
							recog.base.set_state(2614);
							if !({recog.precpred(None, 5)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 5)".to_owned()), None))?;
							}
							recog.base.set_state(2615);
							if !({legacy_setops_precedence_enabled}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("legacy_setops_precedence_enabled".to_owned()), None))?;
							}
							recog.base.set_state(2616);
							if let QueryTermContextAll::SetOperationContext(ctx) = cast_mut::<_,QueryTermContextAll >(&mut _localctx){
							ctx.operator = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
							_la = recog.base.input.la(1);
							if { !(_la==EXCEPT || _la==INTERSECT || _la==SETMINUS || _la==UNION) } {
								let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
								if let QueryTermContextAll::SetOperationContext(ctx) = cast_mut::<_,QueryTermContextAll >(&mut _localctx){
								ctx.operator = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
							else {
								if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
								recog.err_handler.report_match(&mut recog.base);
								recog.base.consume(&mut recog.err_handler);
							}
							recog.base.set_state(2618);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==ALL || _la==DISTINCT {
								{
								/*InvokeRule setQuantifier*/
								recog.base.set_state(2617);
								recog.setQuantifier()?;

								}
							}

							/*InvokeRule queryTerm*/
							recog.base.set_state(2620);
							let tmp = recog.queryTerm_rec(6)?;
							if let QueryTermContextAll::SetOperationContext(ctx) = cast_mut::<_,QueryTermContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						2 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = SetOperationContextExt::new(&**QueryTermContextExt::new(_parentctx.clone(), _parentState));
							if let QueryTermContextAll::SetOperationContext(ctx) = cast_mut::<_,QueryTermContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_queryTerm);
							_localctx = tmp;
							recog.base.set_state(2621);
							if !({recog.precpred(None, 4)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 4)".to_owned()), None))?;
							}
							recog.base.set_state(2622);
							if !({!legacy_setops_precedence_enabled}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("!legacy_setops_precedence_enabled".to_owned()), None))?;
							}
							recog.base.set_state(2623);
							let tmp = recog.base.match_token(INTERSECT,&mut recog.err_handler)?;
							if let QueryTermContextAll::SetOperationContext(ctx) = cast_mut::<_,QueryTermContextAll >(&mut _localctx){
							ctx.operator = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							recog.base.set_state(2625);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==ALL || _la==DISTINCT {
								{
								/*InvokeRule setQuantifier*/
								recog.base.set_state(2624);
								recog.setQuantifier()?;

								}
							}

							/*InvokeRule queryTerm*/
							recog.base.set_state(2627);
							let tmp = recog.queryTerm_rec(5)?;
							if let QueryTermContextAll::SetOperationContext(ctx) = cast_mut::<_,QueryTermContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						3 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = SetOperationContextExt::new(&**QueryTermContextExt::new(_parentctx.clone(), _parentState));
							if let QueryTermContextAll::SetOperationContext(ctx) = cast_mut::<_,QueryTermContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_queryTerm);
							_localctx = tmp;
							recog.base.set_state(2628);
							if !({recog.precpred(None, 3)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 3)".to_owned()), None))?;
							}
							recog.base.set_state(2629);
							if !({!legacy_setops_precedence_enabled}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("!legacy_setops_precedence_enabled".to_owned()), None))?;
							}
							recog.base.set_state(2630);
							if let QueryTermContextAll::SetOperationContext(ctx) = cast_mut::<_,QueryTermContextAll >(&mut _localctx){
							ctx.operator = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
							_la = recog.base.input.la(1);
							if { !(_la==EXCEPT || _la==SETMINUS || _la==UNION) } {
								let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
								if let QueryTermContextAll::SetOperationContext(ctx) = cast_mut::<_,QueryTermContextAll >(&mut _localctx){
								ctx.operator = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
							else {
								if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
								recog.err_handler.report_match(&mut recog.base);
								recog.base.consume(&mut recog.err_handler);
							}
							recog.base.set_state(2632);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==ALL || _la==DISTINCT {
								{
								/*InvokeRule setQuantifier*/
								recog.base.set_state(2631);
								recog.setQuantifier()?;

								}
							}

							/*InvokeRule queryTerm*/
							recog.base.set_state(2634);
							let tmp = recog.queryTerm_rec(4)?;
							if let QueryTermContextAll::SetOperationContext(ctx) = cast_mut::<_,QueryTermContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						4 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = OperatorPipeStatementContextExt::new(&**QueryTermContextExt::new(_parentctx.clone(), _parentState));
							if let QueryTermContextAll::OperatorPipeStatementContext(ctx) = cast_mut::<_,QueryTermContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_queryTerm);
							_localctx = tmp;
							recog.base.set_state(2635);
							if !({recog.precpred(None, 2)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 2)".to_owned()), None))?;
							}
							recog.base.set_state(2636);
							recog.base.match_token(OPERATOR_PIPE,&mut recog.err_handler)?;

							/*InvokeRule operatorPipeRightSide*/
							recog.base.set_state(2637);
							recog.operatorPipeRightSide()?;

							}
						}
					,
						5 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = OperatorPipeStatementContextExt::new(&**QueryTermContextExt::new(_parentctx.clone(), _parentState));
							if let QueryTermContextAll::OperatorPipeStatementContext(ctx) = cast_mut::<_,QueryTermContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_queryTerm);
							_localctx = tmp;
							recog.base.set_state(2638);
							if !({recog.precpred(None, 1)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 1)".to_owned()), None))?;
							}
							recog.base.set_state(2639);
							if !({isOperatorPipeStart()}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("isOperatorPipeStart()".to_owned()), None))?;
							}
							recog.base.set_state(2640);
							recog.base.match_token(PIPE,&mut recog.err_handler)?;

							/*InvokeRule operatorPipeRightSide*/
							recog.base.set_state(2641);
							recog.operatorPipeRightSide()?;

							}
						}

						_ => {}
					}
					} 
				}
				recog.base.set_state(2646);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(288,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_) => {},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re)=>{
			//_localctx.exception = re;
			recog.err_handler.report_error(&mut recog.base, re);
	        recog.err_handler.recover(&mut recog.base, re)?;}
		}
		recog.base.unroll_recursion_context(_parentctx);

		Ok(_localctx)
	}
}
//------------------- queryPrimary ----------------
#[derive(Debug)]
pub enum QueryPrimaryContextAll<'input>{
	SubqueryContext(SubqueryContext<'input>),
	QueryPrimaryDefaultContext(QueryPrimaryDefaultContext<'input>),
	InlineTableDefault1Context(InlineTableDefault1Context<'input>),
	FromStmtContext(FromStmtContext<'input>),
	TableContext(TableContext<'input>),
Error(QueryPrimaryContext<'input>)
}
antlr_rust::tid!{QueryPrimaryContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for QueryPrimaryContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for QueryPrimaryContextAll<'input>{}

impl<'input> Deref for QueryPrimaryContextAll<'input>{
	type Target = dyn QueryPrimaryContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use QueryPrimaryContextAll::*;
		match self{
			SubqueryContext(inner) => inner,
			QueryPrimaryDefaultContext(inner) => inner,
			InlineTableDefault1Context(inner) => inner,
			FromStmtContext(inner) => inner,
			TableContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for QueryPrimaryContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for QueryPrimaryContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type QueryPrimaryContext<'input> = BaseParserRuleContext<'input,QueryPrimaryContextExt<'input>>;

#[derive(Clone)]
pub struct QueryPrimaryContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for QueryPrimaryContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for QueryPrimaryContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for QueryPrimaryContext<'input>{
}

impl<'input> CustomRuleContext<'input> for QueryPrimaryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryPrimary }
}
antlr_rust::tid!{QueryPrimaryContextExt<'a>}

impl<'input> QueryPrimaryContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryPrimaryContextAll<'input>> {
		Rc::new(
		QueryPrimaryContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryPrimaryContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait QueryPrimaryContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<QueryPrimaryContextExt<'input>>{


}

impl<'input> QueryPrimaryContextAttrs<'input> for QueryPrimaryContext<'input>{}

pub type SubqueryContext<'input> = BaseParserRuleContext<'input,SubqueryContextExt<'input>>;

pub trait SubqueryContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
}

impl<'input> SubqueryContextAttrs<'input> for SubqueryContext<'input>{}

pub struct SubqueryContextExt<'input>{
	base:QueryPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SubqueryContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SubqueryContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SubqueryContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_subquery(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_subquery(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SubqueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_subquery(self);
	}
}

impl<'input> CustomRuleContext<'input> for SubqueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryPrimary }
}

impl<'input> Borrow<QueryPrimaryContextExt<'input>> for SubqueryContext<'input>{
	fn borrow(&self) -> &QueryPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<QueryPrimaryContextExt<'input>> for SubqueryContext<'input>{
	fn borrow_mut(&mut self) -> &mut QueryPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> QueryPrimaryContextAttrs<'input> for SubqueryContext<'input> {}

impl<'input> SubqueryContextExt<'input>{
	fn new(ctx: &dyn QueryPrimaryContextAttrs<'input>) -> Rc<QueryPrimaryContextAll<'input>>  {
		Rc::new(
			QueryPrimaryContextAll::SubqueryContext(
				BaseParserRuleContext::copy_from(ctx,SubqueryContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type QueryPrimaryDefaultContext<'input> = BaseParserRuleContext<'input,QueryPrimaryDefaultContextExt<'input>>;

pub trait QueryPrimaryDefaultContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn querySpecification(&self) -> Option<Rc<QuerySpecificationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> QueryPrimaryDefaultContextAttrs<'input> for QueryPrimaryDefaultContext<'input>{}

pub struct QueryPrimaryDefaultContextExt<'input>{
	base:QueryPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{QueryPrimaryDefaultContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for QueryPrimaryDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for QueryPrimaryDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_queryPrimaryDefault(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_queryPrimaryDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for QueryPrimaryDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_queryPrimaryDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryPrimaryDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryPrimary }
}

impl<'input> Borrow<QueryPrimaryContextExt<'input>> for QueryPrimaryDefaultContext<'input>{
	fn borrow(&self) -> &QueryPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<QueryPrimaryContextExt<'input>> for QueryPrimaryDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut QueryPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> QueryPrimaryContextAttrs<'input> for QueryPrimaryDefaultContext<'input> {}

impl<'input> QueryPrimaryDefaultContextExt<'input>{
	fn new(ctx: &dyn QueryPrimaryContextAttrs<'input>) -> Rc<QueryPrimaryContextAll<'input>>  {
		Rc::new(
			QueryPrimaryContextAll::QueryPrimaryDefaultContext(
				BaseParserRuleContext::copy_from(ctx,QueryPrimaryDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type InlineTableDefault1Context<'input> = BaseParserRuleContext<'input,InlineTableDefault1ContextExt<'input>>;

pub trait InlineTableDefault1ContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn inlineTable(&self) -> Option<Rc<InlineTableContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> InlineTableDefault1ContextAttrs<'input> for InlineTableDefault1Context<'input>{}

pub struct InlineTableDefault1ContextExt<'input>{
	base:QueryPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{InlineTableDefault1ContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for InlineTableDefault1Context<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for InlineTableDefault1Context<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_inlineTableDefault1(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_inlineTableDefault1(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for InlineTableDefault1Context<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_inlineTableDefault1(self);
	}
}

impl<'input> CustomRuleContext<'input> for InlineTableDefault1ContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryPrimary }
}

impl<'input> Borrow<QueryPrimaryContextExt<'input>> for InlineTableDefault1Context<'input>{
	fn borrow(&self) -> &QueryPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<QueryPrimaryContextExt<'input>> for InlineTableDefault1Context<'input>{
	fn borrow_mut(&mut self) -> &mut QueryPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> QueryPrimaryContextAttrs<'input> for InlineTableDefault1Context<'input> {}

impl<'input> InlineTableDefault1ContextExt<'input>{
	fn new(ctx: &dyn QueryPrimaryContextAttrs<'input>) -> Rc<QueryPrimaryContextAll<'input>>  {
		Rc::new(
			QueryPrimaryContextAll::InlineTableDefault1Context(
				BaseParserRuleContext::copy_from(ctx,InlineTableDefault1ContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type FromStmtContext<'input> = BaseParserRuleContext<'input,FromStmtContextExt<'input>>;

pub trait FromStmtContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn fromStatement(&self) -> Option<Rc<FromStatementContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> FromStmtContextAttrs<'input> for FromStmtContext<'input>{}

pub struct FromStmtContextExt<'input>{
	base:QueryPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FromStmtContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for FromStmtContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for FromStmtContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_fromStmt(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_fromStmt(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for FromStmtContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_fromStmt(self);
	}
}

impl<'input> CustomRuleContext<'input> for FromStmtContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryPrimary }
}

impl<'input> Borrow<QueryPrimaryContextExt<'input>> for FromStmtContext<'input>{
	fn borrow(&self) -> &QueryPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<QueryPrimaryContextExt<'input>> for FromStmtContext<'input>{
	fn borrow_mut(&mut self) -> &mut QueryPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> QueryPrimaryContextAttrs<'input> for FromStmtContext<'input> {}

impl<'input> FromStmtContextExt<'input>{
	fn new(ctx: &dyn QueryPrimaryContextAttrs<'input>) -> Rc<QueryPrimaryContextAll<'input>>  {
		Rc::new(
			QueryPrimaryContextAll::FromStmtContext(
				BaseParserRuleContext::copy_from(ctx,FromStmtContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TableContext<'input> = BaseParserRuleContext<'input,TableContextExt<'input>>;

pub trait TableContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token TABLE
	/// Returns `None` if there is no child corresponding to token TABLE
	fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TABLE, 0)
	}
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> TableContextAttrs<'input> for TableContext<'input>{}

pub struct TableContextExt<'input>{
	base:QueryPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TableContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for TableContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for TableContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_table(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_table(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for TableContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_table(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryPrimary }
}

impl<'input> Borrow<QueryPrimaryContextExt<'input>> for TableContext<'input>{
	fn borrow(&self) -> &QueryPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<QueryPrimaryContextExt<'input>> for TableContext<'input>{
	fn borrow_mut(&mut self) -> &mut QueryPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> QueryPrimaryContextAttrs<'input> for TableContext<'input> {}

impl<'input> TableContextExt<'input>{
	fn new(ctx: &dyn QueryPrimaryContextAttrs<'input>) -> Rc<QueryPrimaryContextAll<'input>>  {
		Rc::new(
			QueryPrimaryContextAll::TableContext(
				BaseParserRuleContext::copy_from(ctx,TableContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn queryPrimary(&mut self,)
	-> Result<Rc<QueryPrimaryContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryPrimaryContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 170, RULE_queryPrimary);
        let mut _localctx: Rc<QueryPrimaryContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2656);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 MAP | REDUCE | SELECT 
				=> {
					let tmp = QueryPrimaryDefaultContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule querySpecification*/
					recog.base.set_state(2647);
					recog.querySpecification()?;

					}
				}

			 FROM 
				=> {
					let tmp = FromStmtContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule fromStatement*/
					recog.base.set_state(2648);
					recog.fromStatement()?;

					}
				}

			 TABLE 
				=> {
					let tmp = TableContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(2649);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(2650);
					recog.identifierReference()?;

					}
				}

			 VALUES 
				=> {
					let tmp = InlineTableDefault1ContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					/*InvokeRule inlineTable*/
					recog.base.set_state(2651);
					recog.inlineTable()?;

					}
				}

			 LEFT_PAREN 
				=> {
					let tmp = SubqueryContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					recog.base.set_state(2652);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(2653);
					recog.query()?;

					recog.base.set_state(2654);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- sortItem ----------------
pub type SortItemContextAll<'input> = SortItemContext<'input>;


pub type SortItemContext<'input> = BaseParserRuleContext<'input,SortItemContextExt<'input>>;

#[derive(Clone)]
pub struct SortItemContextExt<'input>{
	pub ordering: Option<TokenType<'input>>,
	pub nullOrder: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SortItemContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SortItemContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_sortItem(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_sortItem(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SortItemContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_sortItem(self);
	}
}

impl<'input> CustomRuleContext<'input> for SortItemContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sortItem }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sortItem }
}
antlr_rust::tid!{SortItemContextExt<'a>}

impl<'input> SortItemContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SortItemContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SortItemContextExt{
				ordering: None, nullOrder: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SortItemContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SortItemContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token NULLS
/// Returns `None` if there is no child corresponding to token NULLS
fn NULLS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NULLS, 0)
}
/// Retrieves first TerminalNode corresponding to token ASC
/// Returns `None` if there is no child corresponding to token ASC
fn ASC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ASC, 0)
}
/// Retrieves first TerminalNode corresponding to token DESC
/// Returns `None` if there is no child corresponding to token DESC
fn DESC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DESC, 0)
}
/// Retrieves first TerminalNode corresponding to token LAST
/// Returns `None` if there is no child corresponding to token LAST
fn LAST(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LAST, 0)
}
/// Retrieves first TerminalNode corresponding to token FIRST
/// Returns `None` if there is no child corresponding to token FIRST
fn FIRST(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FIRST, 0)
}

}

impl<'input> SortItemContextAttrs<'input> for SortItemContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn sortItem(&mut self,)
	-> Result<Rc<SortItemContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SortItemContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 172, RULE_sortItem);
        let mut _localctx: Rc<SortItemContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(2658);
			recog.expression()?;

			recog.base.set_state(2660);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(290,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(2659);
					 cast_mut::<_,SortItemContext >(&mut _localctx).ordering = recog.base.input.lt(1).cloned();
					 
					_la = recog.base.input.la(1);
					if { !(_la==ASC || _la==DESC) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						 cast_mut::<_,SortItemContext >(&mut _localctx).ordering = Some(tmp.clone());
						  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					}
				}

				_ => {}
			}
			recog.base.set_state(2664);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(291,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(2662);
					recog.base.match_token(NULLS,&mut recog.err_handler)?;

					recog.base.set_state(2663);
					 cast_mut::<_,SortItemContext >(&mut _localctx).nullOrder = recog.base.input.lt(1).cloned();
					 
					_la = recog.base.input.la(1);
					if { !(_la==FIRST || _la==LAST) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						 cast_mut::<_,SortItemContext >(&mut _localctx).nullOrder = Some(tmp.clone());
						  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- fromStatement ----------------
pub type FromStatementContextAll<'input> = FromStatementContext<'input>;


pub type FromStatementContext<'input> = BaseParserRuleContext<'input,FromStatementContextExt<'input>>;

#[derive(Clone)]
pub struct FromStatementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for FromStatementContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for FromStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_fromStatement(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_fromStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for FromStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_fromStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for FromStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_fromStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_fromStatement }
}
antlr_rust::tid!{FromStatementContextExt<'a>}

impl<'input> FromStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FromStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FromStatementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FromStatementContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<FromStatementContextExt<'input>>{

fn fromClause(&self) -> Option<Rc<FromClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn fromStatementBody_all(&self) ->  Vec<Rc<FromStatementBodyContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn fromStatementBody(&self, i: usize) -> Option<Rc<FromStatementBodyContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> FromStatementContextAttrs<'input> for FromStatementContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn fromStatement(&mut self,)
	-> Result<Rc<FromStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FromStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 174, RULE_fromStatement);
        let mut _localctx: Rc<FromStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule fromClause*/
			recog.base.set_state(2666);
			recog.fromClause()?;

			recog.base.set_state(2670);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(292,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					/*InvokeRule fromStatementBody*/
					recog.base.set_state(2667);
					recog.fromStatementBody()?;

					}
					} 
				}
				recog.base.set_state(2672);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(292,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- fromStatementBody ----------------
pub type FromStatementBodyContextAll<'input> = FromStatementBodyContext<'input>;


pub type FromStatementBodyContext<'input> = BaseParserRuleContext<'input,FromStatementBodyContextExt<'input>>;

#[derive(Clone)]
pub struct FromStatementBodyContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for FromStatementBodyContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for FromStatementBodyContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_fromStatementBody(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_fromStatementBody(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for FromStatementBodyContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_fromStatementBody(self);
	}
}

impl<'input> CustomRuleContext<'input> for FromStatementBodyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_fromStatementBody }
	//fn type_rule_index() -> usize where Self: Sized { RULE_fromStatementBody }
}
antlr_rust::tid!{FromStatementBodyContextExt<'a>}

impl<'input> FromStatementBodyContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FromStatementBodyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FromStatementBodyContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FromStatementBodyContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<FromStatementBodyContextExt<'input>>{

fn transformClause(&self) -> Option<Rc<TransformClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn queryOrganization(&self) -> Option<Rc<QueryOrganizationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn whereClause(&self) -> Option<Rc<WhereClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn selectClause(&self) -> Option<Rc<SelectClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn lateralView_all(&self) ->  Vec<Rc<LateralViewContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn lateralView(&self, i: usize) -> Option<Rc<LateralViewContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn aggregationClause(&self) -> Option<Rc<AggregationClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn havingClause(&self) -> Option<Rc<HavingClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn windowClause(&self) -> Option<Rc<WindowClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FromStatementBodyContextAttrs<'input> for FromStatementBodyContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn fromStatementBody(&mut self,)
	-> Result<Rc<FromStatementBodyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FromStatementBodyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 176, RULE_fromStatementBody);
        let mut _localctx: Rc<FromStatementBodyContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(2700);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(299,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule transformClause*/
					recog.base.set_state(2673);
					recog.transformClause()?;

					recog.base.set_state(2675);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(293,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule whereClause*/
							recog.base.set_state(2674);
							recog.whereClause()?;

							}
						}

						_ => {}
					}
					/*InvokeRule queryOrganization*/
					recog.base.set_state(2677);
					recog.queryOrganization()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule selectClause*/
					recog.base.set_state(2679);
					recog.selectClause()?;

					recog.base.set_state(2683);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(294,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							/*InvokeRule lateralView*/
							recog.base.set_state(2680);
							recog.lateralView()?;

							}
							} 
						}
						recog.base.set_state(2685);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(294,&mut recog.base)?;
					}
					recog.base.set_state(2687);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(295,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule whereClause*/
							recog.base.set_state(2686);
							recog.whereClause()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(2690);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(296,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule aggregationClause*/
							recog.base.set_state(2689);
							recog.aggregationClause()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(2693);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(297,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule havingClause*/
							recog.base.set_state(2692);
							recog.havingClause()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(2696);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(298,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule windowClause*/
							recog.base.set_state(2695);
							recog.windowClause()?;

							}
						}

						_ => {}
					}
					/*InvokeRule queryOrganization*/
					recog.base.set_state(2698);
					recog.queryOrganization()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- querySpecification ----------------
#[derive(Debug)]
pub enum QuerySpecificationContextAll<'input>{
	RegularQuerySpecificationContext(RegularQuerySpecificationContext<'input>),
	TransformQuerySpecificationContext(TransformQuerySpecificationContext<'input>),
Error(QuerySpecificationContext<'input>)
}
antlr_rust::tid!{QuerySpecificationContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for QuerySpecificationContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for QuerySpecificationContextAll<'input>{}

impl<'input> Deref for QuerySpecificationContextAll<'input>{
	type Target = dyn QuerySpecificationContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use QuerySpecificationContextAll::*;
		match self{
			RegularQuerySpecificationContext(inner) => inner,
			TransformQuerySpecificationContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for QuerySpecificationContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for QuerySpecificationContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type QuerySpecificationContext<'input> = BaseParserRuleContext<'input,QuerySpecificationContextExt<'input>>;

#[derive(Clone)]
pub struct QuerySpecificationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for QuerySpecificationContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for QuerySpecificationContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for QuerySpecificationContext<'input>{
}

impl<'input> CustomRuleContext<'input> for QuerySpecificationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_querySpecification }
	//fn type_rule_index() -> usize where Self: Sized { RULE_querySpecification }
}
antlr_rust::tid!{QuerySpecificationContextExt<'a>}

impl<'input> QuerySpecificationContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QuerySpecificationContextAll<'input>> {
		Rc::new(
		QuerySpecificationContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QuerySpecificationContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait QuerySpecificationContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<QuerySpecificationContextExt<'input>>{


}

impl<'input> QuerySpecificationContextAttrs<'input> for QuerySpecificationContext<'input>{}

pub type RegularQuerySpecificationContext<'input> = BaseParserRuleContext<'input,RegularQuerySpecificationContextExt<'input>>;

pub trait RegularQuerySpecificationContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn selectClause(&self) -> Option<Rc<SelectClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn fromClause(&self) -> Option<Rc<FromClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn lateralView_all(&self) ->  Vec<Rc<LateralViewContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn lateralView(&self, i: usize) -> Option<Rc<LateralViewContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn whereClause(&self) -> Option<Rc<WhereClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn aggregationClause(&self) -> Option<Rc<AggregationClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn havingClause(&self) -> Option<Rc<HavingClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn windowClause(&self) -> Option<Rc<WindowClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> RegularQuerySpecificationContextAttrs<'input> for RegularQuerySpecificationContext<'input>{}

pub struct RegularQuerySpecificationContextExt<'input>{
	base:QuerySpecificationContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RegularQuerySpecificationContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for RegularQuerySpecificationContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for RegularQuerySpecificationContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_regularQuerySpecification(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_regularQuerySpecification(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for RegularQuerySpecificationContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_regularQuerySpecification(self);
	}
}

impl<'input> CustomRuleContext<'input> for RegularQuerySpecificationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_querySpecification }
	//fn type_rule_index() -> usize where Self: Sized { RULE_querySpecification }
}

impl<'input> Borrow<QuerySpecificationContextExt<'input>> for RegularQuerySpecificationContext<'input>{
	fn borrow(&self) -> &QuerySpecificationContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<QuerySpecificationContextExt<'input>> for RegularQuerySpecificationContext<'input>{
	fn borrow_mut(&mut self) -> &mut QuerySpecificationContextExt<'input> { &mut self.base }
}

impl<'input> QuerySpecificationContextAttrs<'input> for RegularQuerySpecificationContext<'input> {}

impl<'input> RegularQuerySpecificationContextExt<'input>{
	fn new(ctx: &dyn QuerySpecificationContextAttrs<'input>) -> Rc<QuerySpecificationContextAll<'input>>  {
		Rc::new(
			QuerySpecificationContextAll::RegularQuerySpecificationContext(
				BaseParserRuleContext::copy_from(ctx,RegularQuerySpecificationContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TransformQuerySpecificationContext<'input> = BaseParserRuleContext<'input,TransformQuerySpecificationContextExt<'input>>;

pub trait TransformQuerySpecificationContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn transformClause(&self) -> Option<Rc<TransformClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn fromClause(&self) -> Option<Rc<FromClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn lateralView_all(&self) ->  Vec<Rc<LateralViewContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn lateralView(&self, i: usize) -> Option<Rc<LateralViewContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn whereClause(&self) -> Option<Rc<WhereClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn aggregationClause(&self) -> Option<Rc<AggregationClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn havingClause(&self) -> Option<Rc<HavingClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn windowClause(&self) -> Option<Rc<WindowClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> TransformQuerySpecificationContextAttrs<'input> for TransformQuerySpecificationContext<'input>{}

pub struct TransformQuerySpecificationContextExt<'input>{
	base:QuerySpecificationContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TransformQuerySpecificationContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for TransformQuerySpecificationContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for TransformQuerySpecificationContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_transformQuerySpecification(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_transformQuerySpecification(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for TransformQuerySpecificationContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_transformQuerySpecification(self);
	}
}

impl<'input> CustomRuleContext<'input> for TransformQuerySpecificationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_querySpecification }
	//fn type_rule_index() -> usize where Self: Sized { RULE_querySpecification }
}

impl<'input> Borrow<QuerySpecificationContextExt<'input>> for TransformQuerySpecificationContext<'input>{
	fn borrow(&self) -> &QuerySpecificationContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<QuerySpecificationContextExt<'input>> for TransformQuerySpecificationContext<'input>{
	fn borrow_mut(&mut self) -> &mut QuerySpecificationContextExt<'input> { &mut self.base }
}

impl<'input> QuerySpecificationContextAttrs<'input> for TransformQuerySpecificationContext<'input> {}

impl<'input> TransformQuerySpecificationContextExt<'input>{
	fn new(ctx: &dyn QuerySpecificationContextAttrs<'input>) -> Rc<QuerySpecificationContextAll<'input>>  {
		Rc::new(
			QuerySpecificationContextAll::TransformQuerySpecificationContext(
				BaseParserRuleContext::copy_from(ctx,TransformQuerySpecificationContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn querySpecification(&mut self,)
	-> Result<Rc<QuerySpecificationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QuerySpecificationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 178, RULE_querySpecification);
        let mut _localctx: Rc<QuerySpecificationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(2746);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(312,&mut recog.base)? {
				1 =>{
					let tmp = TransformQuerySpecificationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule transformClause*/
					recog.base.set_state(2702);
					recog.transformClause()?;

					recog.base.set_state(2704);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(300,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule fromClause*/
							recog.base.set_state(2703);
							recog.fromClause()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(2709);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(301,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							/*InvokeRule lateralView*/
							recog.base.set_state(2706);
							recog.lateralView()?;

							}
							} 
						}
						recog.base.set_state(2711);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(301,&mut recog.base)?;
					}
					recog.base.set_state(2713);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(302,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule whereClause*/
							recog.base.set_state(2712);
							recog.whereClause()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(2716);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(303,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule aggregationClause*/
							recog.base.set_state(2715);
							recog.aggregationClause()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(2719);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(304,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule havingClause*/
							recog.base.set_state(2718);
							recog.havingClause()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(2722);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(305,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule windowClause*/
							recog.base.set_state(2721);
							recog.windowClause()?;

							}
						}

						_ => {}
					}
					}
				}
			,
				2 =>{
					let tmp = RegularQuerySpecificationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule selectClause*/
					recog.base.set_state(2724);
					recog.selectClause()?;

					recog.base.set_state(2726);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(306,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule fromClause*/
							recog.base.set_state(2725);
							recog.fromClause()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(2731);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(307,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							/*InvokeRule lateralView*/
							recog.base.set_state(2728);
							recog.lateralView()?;

							}
							} 
						}
						recog.base.set_state(2733);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(307,&mut recog.base)?;
					}
					recog.base.set_state(2735);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(308,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule whereClause*/
							recog.base.set_state(2734);
							recog.whereClause()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(2738);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(309,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule aggregationClause*/
							recog.base.set_state(2737);
							recog.aggregationClause()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(2741);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(310,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule havingClause*/
							recog.base.set_state(2740);
							recog.havingClause()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(2744);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(311,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule windowClause*/
							recog.base.set_state(2743);
							recog.windowClause()?;

							}
						}

						_ => {}
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- transformClause ----------------
pub type TransformClauseContextAll<'input> = TransformClauseContext<'input>;


pub type TransformClauseContext<'input> = BaseParserRuleContext<'input,TransformClauseContextExt<'input>>;

#[derive(Clone)]
pub struct TransformClauseContextExt<'input>{
	pub kind: Option<TokenType<'input>>,
	pub inRowFormat: Option<Rc<RowFormatContextAll<'input>>>,
	pub recordWriter: Option<Rc<StringLitContextAll<'input>>>,
	pub script: Option<Rc<StringLitContextAll<'input>>>,
	pub outRowFormat: Option<Rc<RowFormatContextAll<'input>>>,
	pub recordReader: Option<Rc<StringLitContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for TransformClauseContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for TransformClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_transformClause(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_transformClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for TransformClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_transformClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for TransformClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_transformClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_transformClause }
}
antlr_rust::tid!{TransformClauseContextExt<'a>}

impl<'input> TransformClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TransformClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TransformClauseContextExt{
				kind: None, 
				inRowFormat: None, recordWriter: None, script: None, outRowFormat: None, recordReader: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TransformClauseContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<TransformClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token USING
/// Returns `None` if there is no child corresponding to token USING
fn USING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(USING, 0)
}
fn stringLit_all(&self) ->  Vec<Rc<StringLitContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn stringLit(&self, i: usize) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token SELECT
/// Returns `None` if there is no child corresponding to token SELECT
fn SELECT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SELECT, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token LEFT_PAREN in current rule
fn LEFT_PAREN_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LEFT_PAREN, starting from 0.
/// Returns `None` if number of children corresponding to token LEFT_PAREN is less or equal than `i`.
fn LEFT_PAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, i)
}
fn expressionSeq(&self) -> Option<Rc<ExpressionSeqContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves all `TerminalNode`s corresponding to token RIGHT_PAREN in current rule
fn RIGHT_PAREN_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token RIGHT_PAREN, starting from 0.
/// Returns `None` if number of children corresponding to token RIGHT_PAREN is less or equal than `i`.
fn RIGHT_PAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, i)
}
/// Retrieves first TerminalNode corresponding to token TRANSFORM
/// Returns `None` if there is no child corresponding to token TRANSFORM
fn TRANSFORM(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TRANSFORM, 0)
}
/// Retrieves first TerminalNode corresponding to token MAP
/// Returns `None` if there is no child corresponding to token MAP
fn MAP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MAP, 0)
}
/// Retrieves first TerminalNode corresponding to token REDUCE
/// Returns `None` if there is no child corresponding to token REDUCE
fn REDUCE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(REDUCE, 0)
}
/// Retrieves first TerminalNode corresponding to token RECORDWRITER
/// Returns `None` if there is no child corresponding to token RECORDWRITER
fn RECORDWRITER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RECORDWRITER, 0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
/// Retrieves first TerminalNode corresponding to token RECORDREADER
/// Returns `None` if there is no child corresponding to token RECORDREADER
fn RECORDREADER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RECORDREADER, 0)
}
fn rowFormat_all(&self) ->  Vec<Rc<RowFormatContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn rowFormat(&self, i: usize) -> Option<Rc<RowFormatContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn setQuantifier(&self) -> Option<Rc<SetQuantifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn identifierSeq(&self) -> Option<Rc<IdentifierSeqContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn colTypeList(&self) -> Option<Rc<ColTypeListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TransformClauseContextAttrs<'input> for TransformClauseContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn transformClause(&mut self,)
	-> Result<Rc<TransformClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TransformClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 180, RULE_transformClause);
        let mut _localctx: Rc<TransformClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2767);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 SELECT 
				=> {
					{
					recog.base.set_state(2748);
					recog.base.match_token(SELECT,&mut recog.err_handler)?;

					recog.base.set_state(2749);
					let tmp = recog.base.match_token(TRANSFORM,&mut recog.err_handler)?;
					 cast_mut::<_,TransformClauseContext >(&mut _localctx).kind = Some(tmp.clone());
					  

					recog.base.set_state(2750);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					recog.base.set_state(2752);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(313,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule setQuantifier*/
							recog.base.set_state(2751);
							recog.setQuantifier()?;

							}
						}

						_ => {}
					}
					/*InvokeRule expressionSeq*/
					recog.base.set_state(2754);
					recog.expressionSeq()?;

					recog.base.set_state(2755);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}

			 MAP 
				=> {
					{
					recog.base.set_state(2757);
					let tmp = recog.base.match_token(MAP,&mut recog.err_handler)?;
					 cast_mut::<_,TransformClauseContext >(&mut _localctx).kind = Some(tmp.clone());
					  

					recog.base.set_state(2759);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(314,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule setQuantifier*/
							recog.base.set_state(2758);
							recog.setQuantifier()?;

							}
						}

						_ => {}
					}
					/*InvokeRule expressionSeq*/
					recog.base.set_state(2761);
					recog.expressionSeq()?;

					}
				}

			 REDUCE 
				=> {
					{
					recog.base.set_state(2762);
					let tmp = recog.base.match_token(REDUCE,&mut recog.err_handler)?;
					 cast_mut::<_,TransformClauseContext >(&mut _localctx).kind = Some(tmp.clone());
					  

					recog.base.set_state(2764);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(315,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule setQuantifier*/
							recog.base.set_state(2763);
							recog.setQuantifier()?;

							}
						}

						_ => {}
					}
					/*InvokeRule expressionSeq*/
					recog.base.set_state(2766);
					recog.expressionSeq()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			recog.base.set_state(2770);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ROW {
				{
				/*InvokeRule rowFormat*/
				recog.base.set_state(2769);
				let tmp = recog.rowFormat()?;
				 cast_mut::<_,TransformClauseContext >(&mut _localctx).inRowFormat = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(2774);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==RECORDWRITER {
				{
				recog.base.set_state(2772);
				recog.base.match_token(RECORDWRITER,&mut recog.err_handler)?;

				/*InvokeRule stringLit*/
				recog.base.set_state(2773);
				let tmp = recog.stringLit()?;
				 cast_mut::<_,TransformClauseContext >(&mut _localctx).recordWriter = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(2776);
			recog.base.match_token(USING,&mut recog.err_handler)?;

			/*InvokeRule stringLit*/
			recog.base.set_state(2777);
			let tmp = recog.stringLit()?;
			 cast_mut::<_,TransformClauseContext >(&mut _localctx).script = Some(tmp.clone());
			  

			recog.base.set_state(2790);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(321,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(2778);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					recog.base.set_state(2788);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(320,&mut recog.base)? {
						1 =>{
							{
							/*InvokeRule identifierSeq*/
							recog.base.set_state(2779);
							recog.identifierSeq()?;

							}
						}
					,
						2 =>{
							{
							/*InvokeRule colTypeList*/
							recog.base.set_state(2780);
							recog.colTypeList()?;

							}
						}
					,
						3 =>{
							{
							{
							recog.base.set_state(2781);
							recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

							recog.base.set_state(2784);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(319,&mut recog.base)? {
								1 =>{
									{
									/*InvokeRule identifierSeq*/
									recog.base.set_state(2782);
									recog.identifierSeq()?;

									}
								}
							,
								2 =>{
									{
									/*InvokeRule colTypeList*/
									recog.base.set_state(2783);
									recog.colTypeList()?;

									}
								}

								_ => {}
							}
							recog.base.set_state(2786);
							recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

							}
							}
						}

						_ => {}
					}
					}
				}

				_ => {}
			}
			recog.base.set_state(2793);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(322,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule rowFormat*/
					recog.base.set_state(2792);
					let tmp = recog.rowFormat()?;
					 cast_mut::<_,TransformClauseContext >(&mut _localctx).outRowFormat = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			recog.base.set_state(2797);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(323,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(2795);
					recog.base.match_token(RECORDREADER,&mut recog.err_handler)?;

					/*InvokeRule stringLit*/
					recog.base.set_state(2796);
					let tmp = recog.stringLit()?;
					 cast_mut::<_,TransformClauseContext >(&mut _localctx).recordReader = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- selectClause ----------------
pub type SelectClauseContextAll<'input> = SelectClauseContext<'input>;


pub type SelectClauseContext<'input> = BaseParserRuleContext<'input,SelectClauseContextExt<'input>>;

#[derive(Clone)]
pub struct SelectClauseContextExt<'input>{
	pub hint: Option<Rc<HintContextAll<'input>>>,
	pub hints:Vec<Rc<HintContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SelectClauseContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SelectClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_selectClause(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_selectClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SelectClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_selectClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for SelectClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_selectClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_selectClause }
}
antlr_rust::tid!{SelectClauseContextExt<'a>}

impl<'input> SelectClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SelectClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SelectClauseContextExt{
				hint: None, 
				hints: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait SelectClauseContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SelectClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token SELECT
/// Returns `None` if there is no child corresponding to token SELECT
fn SELECT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SELECT, 0)
}
fn namedExpressionSeq(&self) -> Option<Rc<NamedExpressionSeqContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn setQuantifier(&self) -> Option<Rc<SetQuantifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn hint_all(&self) ->  Vec<Rc<HintContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn hint(&self, i: usize) -> Option<Rc<HintContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> SelectClauseContextAttrs<'input> for SelectClauseContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn selectClause(&mut self,)
	-> Result<Rc<SelectClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SelectClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 182, RULE_selectClause);
        let mut _localctx: Rc<SelectClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2799);
			recog.base.match_token(SELECT,&mut recog.err_handler)?;

			recog.base.set_state(2803);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(324,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					/*InvokeRule hint*/
					recog.base.set_state(2800);
					let tmp = recog.hint()?;
					 cast_mut::<_,SelectClauseContext >(&mut _localctx).hint = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,SelectClauseContext >(&mut _localctx).hint.clone().unwrap()
					 ;
					 cast_mut::<_,SelectClauseContext >(&mut _localctx).hints.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(2805);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(324,&mut recog.base)?;
			}
			recog.base.set_state(2807);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(325,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule setQuantifier*/
					recog.base.set_state(2806);
					recog.setQuantifier()?;

					}
				}

				_ => {}
			}
			/*InvokeRule namedExpressionSeq*/
			recog.base.set_state(2809);
			recog.namedExpressionSeq()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- setClause ----------------
pub type SetClauseContextAll<'input> = SetClauseContext<'input>;


pub type SetClauseContext<'input> = BaseParserRuleContext<'input,SetClauseContextExt<'input>>;

#[derive(Clone)]
pub struct SetClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SetClauseContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SetClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_setClause(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_setClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SetClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_setClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setClause }
}
antlr_rust::tid!{SetClauseContextExt<'a>}

impl<'input> SetClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SetClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SetClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SetClauseContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SetClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token SET
/// Returns `None` if there is no child corresponding to token SET
fn SET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SET, 0)
}
fn assignmentList(&self) -> Option<Rc<AssignmentListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SetClauseContextAttrs<'input> for SetClauseContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn setClause(&mut self,)
	-> Result<Rc<SetClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SetClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 184, RULE_setClause);
        let mut _localctx: Rc<SetClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2811);
			recog.base.match_token(SET,&mut recog.err_handler)?;

			/*InvokeRule assignmentList*/
			recog.base.set_state(2812);
			recog.assignmentList()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- matchedClause ----------------
pub type MatchedClauseContextAll<'input> = MatchedClauseContext<'input>;


pub type MatchedClauseContext<'input> = BaseParserRuleContext<'input,MatchedClauseContextExt<'input>>;

#[derive(Clone)]
pub struct MatchedClauseContextExt<'input>{
	pub matchedCond: Option<Rc<BooleanExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for MatchedClauseContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for MatchedClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_matchedClause(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_matchedClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for MatchedClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_matchedClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for MatchedClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_matchedClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_matchedClause }
}
antlr_rust::tid!{MatchedClauseContextExt<'a>}

impl<'input> MatchedClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MatchedClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MatchedClauseContextExt{
				matchedCond: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait MatchedClauseContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<MatchedClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WHEN
/// Returns `None` if there is no child corresponding to token WHEN
fn WHEN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WHEN, 0)
}
/// Retrieves first TerminalNode corresponding to token MATCHED
/// Returns `None` if there is no child corresponding to token MATCHED
fn MATCHED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MATCHED, 0)
}
/// Retrieves first TerminalNode corresponding to token THEN
/// Returns `None` if there is no child corresponding to token THEN
fn THEN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(THEN, 0)
}
fn matchedAction(&self) -> Option<Rc<MatchedActionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AND
/// Returns `None` if there is no child corresponding to token AND
fn AND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AND, 0)
}
fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MatchedClauseContextAttrs<'input> for MatchedClauseContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn matchedClause(&mut self,)
	-> Result<Rc<MatchedClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MatchedClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 186, RULE_matchedClause);
        let mut _localctx: Rc<MatchedClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2814);
			recog.base.match_token(WHEN,&mut recog.err_handler)?;

			recog.base.set_state(2815);
			recog.base.match_token(MATCHED,&mut recog.err_handler)?;

			recog.base.set_state(2818);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==AND {
				{
				recog.base.set_state(2816);
				recog.base.match_token(AND,&mut recog.err_handler)?;

				/*InvokeRule booleanExpression*/
				recog.base.set_state(2817);
				let tmp = recog.booleanExpression_rec(0)?;
				 cast_mut::<_,MatchedClauseContext >(&mut _localctx).matchedCond = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(2820);
			recog.base.match_token(THEN,&mut recog.err_handler)?;

			/*InvokeRule matchedAction*/
			recog.base.set_state(2821);
			recog.matchedAction()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- notMatchedClause ----------------
pub type NotMatchedClauseContextAll<'input> = NotMatchedClauseContext<'input>;


pub type NotMatchedClauseContext<'input> = BaseParserRuleContext<'input,NotMatchedClauseContextExt<'input>>;

#[derive(Clone)]
pub struct NotMatchedClauseContextExt<'input>{
	pub notMatchedCond: Option<Rc<BooleanExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for NotMatchedClauseContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for NotMatchedClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_notMatchedClause(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_notMatchedClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for NotMatchedClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_notMatchedClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for NotMatchedClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_notMatchedClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_notMatchedClause }
}
antlr_rust::tid!{NotMatchedClauseContextExt<'a>}

impl<'input> NotMatchedClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NotMatchedClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NotMatchedClauseContextExt{
				notMatchedCond: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait NotMatchedClauseContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<NotMatchedClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WHEN
/// Returns `None` if there is no child corresponding to token WHEN
fn WHEN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WHEN, 0)
}
fn errorCapturingNot(&self) -> Option<Rc<ErrorCapturingNotContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token MATCHED
/// Returns `None` if there is no child corresponding to token MATCHED
fn MATCHED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MATCHED, 0)
}
/// Retrieves first TerminalNode corresponding to token THEN
/// Returns `None` if there is no child corresponding to token THEN
fn THEN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(THEN, 0)
}
fn notMatchedAction(&self) -> Option<Rc<NotMatchedActionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
/// Retrieves first TerminalNode corresponding to token TARGET
/// Returns `None` if there is no child corresponding to token TARGET
fn TARGET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TARGET, 0)
}
/// Retrieves first TerminalNode corresponding to token AND
/// Returns `None` if there is no child corresponding to token AND
fn AND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AND, 0)
}
fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> NotMatchedClauseContextAttrs<'input> for NotMatchedClauseContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn notMatchedClause(&mut self,)
	-> Result<Rc<NotMatchedClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NotMatchedClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 188, RULE_notMatchedClause);
        let mut _localctx: Rc<NotMatchedClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2823);
			recog.base.match_token(WHEN,&mut recog.err_handler)?;

			/*InvokeRule errorCapturingNot*/
			recog.base.set_state(2824);
			recog.errorCapturingNot()?;

			recog.base.set_state(2825);
			recog.base.match_token(MATCHED,&mut recog.err_handler)?;

			recog.base.set_state(2828);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==BY {
				{
				recog.base.set_state(2826);
				recog.base.match_token(BY,&mut recog.err_handler)?;

				recog.base.set_state(2827);
				recog.base.match_token(TARGET,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(2832);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==AND {
				{
				recog.base.set_state(2830);
				recog.base.match_token(AND,&mut recog.err_handler)?;

				/*InvokeRule booleanExpression*/
				recog.base.set_state(2831);
				let tmp = recog.booleanExpression_rec(0)?;
				 cast_mut::<_,NotMatchedClauseContext >(&mut _localctx).notMatchedCond = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(2834);
			recog.base.match_token(THEN,&mut recog.err_handler)?;

			/*InvokeRule notMatchedAction*/
			recog.base.set_state(2835);
			recog.notMatchedAction()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- notMatchedBySourceClause ----------------
pub type NotMatchedBySourceClauseContextAll<'input> = NotMatchedBySourceClauseContext<'input>;


pub type NotMatchedBySourceClauseContext<'input> = BaseParserRuleContext<'input,NotMatchedBySourceClauseContextExt<'input>>;

#[derive(Clone)]
pub struct NotMatchedBySourceClauseContextExt<'input>{
	pub notMatchedBySourceCond: Option<Rc<BooleanExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for NotMatchedBySourceClauseContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for NotMatchedBySourceClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_notMatchedBySourceClause(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_notMatchedBySourceClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for NotMatchedBySourceClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_notMatchedBySourceClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for NotMatchedBySourceClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_notMatchedBySourceClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_notMatchedBySourceClause }
}
antlr_rust::tid!{NotMatchedBySourceClauseContextExt<'a>}

impl<'input> NotMatchedBySourceClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NotMatchedBySourceClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NotMatchedBySourceClauseContextExt{
				notMatchedBySourceCond: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait NotMatchedBySourceClauseContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<NotMatchedBySourceClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WHEN
/// Returns `None` if there is no child corresponding to token WHEN
fn WHEN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WHEN, 0)
}
fn errorCapturingNot(&self) -> Option<Rc<ErrorCapturingNotContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token MATCHED
/// Returns `None` if there is no child corresponding to token MATCHED
fn MATCHED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MATCHED, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
/// Retrieves first TerminalNode corresponding to token SOURCE
/// Returns `None` if there is no child corresponding to token SOURCE
fn SOURCE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SOURCE, 0)
}
/// Retrieves first TerminalNode corresponding to token THEN
/// Returns `None` if there is no child corresponding to token THEN
fn THEN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(THEN, 0)
}
fn notMatchedBySourceAction(&self) -> Option<Rc<NotMatchedBySourceActionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AND
/// Returns `None` if there is no child corresponding to token AND
fn AND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AND, 0)
}
fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> NotMatchedBySourceClauseContextAttrs<'input> for NotMatchedBySourceClauseContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn notMatchedBySourceClause(&mut self,)
	-> Result<Rc<NotMatchedBySourceClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NotMatchedBySourceClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 190, RULE_notMatchedBySourceClause);
        let mut _localctx: Rc<NotMatchedBySourceClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2837);
			recog.base.match_token(WHEN,&mut recog.err_handler)?;

			/*InvokeRule errorCapturingNot*/
			recog.base.set_state(2838);
			recog.errorCapturingNot()?;

			recog.base.set_state(2839);
			recog.base.match_token(MATCHED,&mut recog.err_handler)?;

			recog.base.set_state(2840);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			recog.base.set_state(2841);
			recog.base.match_token(SOURCE,&mut recog.err_handler)?;

			recog.base.set_state(2844);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==AND {
				{
				recog.base.set_state(2842);
				recog.base.match_token(AND,&mut recog.err_handler)?;

				/*InvokeRule booleanExpression*/
				recog.base.set_state(2843);
				let tmp = recog.booleanExpression_rec(0)?;
				 cast_mut::<_,NotMatchedBySourceClauseContext >(&mut _localctx).notMatchedBySourceCond = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(2846);
			recog.base.match_token(THEN,&mut recog.err_handler)?;

			/*InvokeRule notMatchedBySourceAction*/
			recog.base.set_state(2847);
			recog.notMatchedBySourceAction()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- matchedAction ----------------
pub type MatchedActionContextAll<'input> = MatchedActionContext<'input>;


pub type MatchedActionContext<'input> = BaseParserRuleContext<'input,MatchedActionContextExt<'input>>;

#[derive(Clone)]
pub struct MatchedActionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for MatchedActionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for MatchedActionContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_matchedAction(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_matchedAction(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for MatchedActionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_matchedAction(self);
	}
}

impl<'input> CustomRuleContext<'input> for MatchedActionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_matchedAction }
	//fn type_rule_index() -> usize where Self: Sized { RULE_matchedAction }
}
antlr_rust::tid!{MatchedActionContextExt<'a>}

impl<'input> MatchedActionContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MatchedActionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MatchedActionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait MatchedActionContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<MatchedActionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DELETE
/// Returns `None` if there is no child corresponding to token DELETE
fn DELETE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DELETE, 0)
}
/// Retrieves first TerminalNode corresponding to token UPDATE
/// Returns `None` if there is no child corresponding to token UPDATE
fn UPDATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UPDATE, 0)
}
/// Retrieves first TerminalNode corresponding to token SET
/// Returns `None` if there is no child corresponding to token SET
fn SET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SET, 0)
}
/// Retrieves first TerminalNode corresponding to token ASTERISK
/// Returns `None` if there is no child corresponding to token ASTERISK
fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ASTERISK, 0)
}
fn assignmentList(&self) -> Option<Rc<AssignmentListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MatchedActionContextAttrs<'input> for MatchedActionContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn matchedAction(&mut self,)
	-> Result<Rc<MatchedActionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MatchedActionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 192, RULE_matchedAction);
        let mut _localctx: Rc<MatchedActionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2856);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(330,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2849);
					recog.base.match_token(DELETE,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2850);
					recog.base.match_token(UPDATE,&mut recog.err_handler)?;

					recog.base.set_state(2851);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					recog.base.set_state(2852);
					recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(2853);
					recog.base.match_token(UPDATE,&mut recog.err_handler)?;

					recog.base.set_state(2854);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					/*InvokeRule assignmentList*/
					recog.base.set_state(2855);
					recog.assignmentList()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- notMatchedAction ----------------
pub type NotMatchedActionContextAll<'input> = NotMatchedActionContext<'input>;


pub type NotMatchedActionContext<'input> = BaseParserRuleContext<'input,NotMatchedActionContextExt<'input>>;

#[derive(Clone)]
pub struct NotMatchedActionContextExt<'input>{
	pub columns: Option<Rc<MultipartIdentifierListContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for NotMatchedActionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for NotMatchedActionContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_notMatchedAction(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_notMatchedAction(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for NotMatchedActionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_notMatchedAction(self);
	}
}

impl<'input> CustomRuleContext<'input> for NotMatchedActionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_notMatchedAction }
	//fn type_rule_index() -> usize where Self: Sized { RULE_notMatchedAction }
}
antlr_rust::tid!{NotMatchedActionContextExt<'a>}

impl<'input> NotMatchedActionContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NotMatchedActionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NotMatchedActionContextExt{
				columns: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait NotMatchedActionContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<NotMatchedActionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token INSERT
/// Returns `None` if there is no child corresponding to token INSERT
fn INSERT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INSERT, 0)
}
/// Retrieves first TerminalNode corresponding to token ASTERISK
/// Returns `None` if there is no child corresponding to token ASTERISK
fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ASTERISK, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token LEFT_PAREN in current rule
fn LEFT_PAREN_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LEFT_PAREN, starting from 0.
/// Returns `None` if number of children corresponding to token LEFT_PAREN is less or equal than `i`.
fn LEFT_PAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, i)
}
/// Retrieves all `TerminalNode`s corresponding to token RIGHT_PAREN in current rule
fn RIGHT_PAREN_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token RIGHT_PAREN, starting from 0.
/// Returns `None` if number of children corresponding to token RIGHT_PAREN is less or equal than `i`.
fn RIGHT_PAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, i)
}
/// Retrieves first TerminalNode corresponding to token VALUES
/// Returns `None` if there is no child corresponding to token VALUES
fn VALUES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VALUES, 0)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn multipartIdentifierList(&self) -> Option<Rc<MultipartIdentifierListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> NotMatchedActionContextAttrs<'input> for NotMatchedActionContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn notMatchedAction(&mut self,)
	-> Result<Rc<NotMatchedActionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NotMatchedActionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 194, RULE_notMatchedAction);
        let mut _localctx: Rc<NotMatchedActionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2876);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(332,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2858);
					recog.base.match_token(INSERT,&mut recog.err_handler)?;

					recog.base.set_state(2859);
					recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2860);
					recog.base.match_token(INSERT,&mut recog.err_handler)?;

					recog.base.set_state(2861);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule multipartIdentifierList*/
					recog.base.set_state(2862);
					let tmp = recog.multipartIdentifierList()?;
					 cast_mut::<_,NotMatchedActionContext >(&mut _localctx).columns = Some(tmp.clone());
					  

					recog.base.set_state(2863);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					recog.base.set_state(2864);
					recog.base.match_token(VALUES,&mut recog.err_handler)?;

					recog.base.set_state(2865);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(2866);
					recog.expression()?;

					recog.base.set_state(2871);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(2867);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule expression*/
						recog.base.set_state(2868);
						recog.expression()?;

						}
						}
						recog.base.set_state(2873);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(2874);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- notMatchedBySourceAction ----------------
pub type NotMatchedBySourceActionContextAll<'input> = NotMatchedBySourceActionContext<'input>;


pub type NotMatchedBySourceActionContext<'input> = BaseParserRuleContext<'input,NotMatchedBySourceActionContextExt<'input>>;

#[derive(Clone)]
pub struct NotMatchedBySourceActionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for NotMatchedBySourceActionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for NotMatchedBySourceActionContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_notMatchedBySourceAction(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_notMatchedBySourceAction(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for NotMatchedBySourceActionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_notMatchedBySourceAction(self);
	}
}

impl<'input> CustomRuleContext<'input> for NotMatchedBySourceActionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_notMatchedBySourceAction }
	//fn type_rule_index() -> usize where Self: Sized { RULE_notMatchedBySourceAction }
}
antlr_rust::tid!{NotMatchedBySourceActionContextExt<'a>}

impl<'input> NotMatchedBySourceActionContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NotMatchedBySourceActionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NotMatchedBySourceActionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait NotMatchedBySourceActionContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<NotMatchedBySourceActionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DELETE
/// Returns `None` if there is no child corresponding to token DELETE
fn DELETE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DELETE, 0)
}
/// Retrieves first TerminalNode corresponding to token UPDATE
/// Returns `None` if there is no child corresponding to token UPDATE
fn UPDATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UPDATE, 0)
}
/// Retrieves first TerminalNode corresponding to token SET
/// Returns `None` if there is no child corresponding to token SET
fn SET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SET, 0)
}
fn assignmentList(&self) -> Option<Rc<AssignmentListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> NotMatchedBySourceActionContextAttrs<'input> for NotMatchedBySourceActionContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn notMatchedBySourceAction(&mut self,)
	-> Result<Rc<NotMatchedBySourceActionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NotMatchedBySourceActionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 196, RULE_notMatchedBySourceAction);
        let mut _localctx: Rc<NotMatchedBySourceActionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2882);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 DELETE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2878);
					recog.base.match_token(DELETE,&mut recog.err_handler)?;

					}
				}

			 UPDATE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2879);
					recog.base.match_token(UPDATE,&mut recog.err_handler)?;

					recog.base.set_state(2880);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					/*InvokeRule assignmentList*/
					recog.base.set_state(2881);
					recog.assignmentList()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- exceptClause ----------------
pub type ExceptClauseContextAll<'input> = ExceptClauseContext<'input>;


pub type ExceptClauseContext<'input> = BaseParserRuleContext<'input,ExceptClauseContextExt<'input>>;

#[derive(Clone)]
pub struct ExceptClauseContextExt<'input>{
	pub exceptCols: Option<Rc<MultipartIdentifierListContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ExceptClauseContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ExceptClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_exceptClause(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_exceptClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ExceptClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_exceptClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExceptClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_exceptClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_exceptClause }
}
antlr_rust::tid!{ExceptClauseContextExt<'a>}

impl<'input> ExceptClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExceptClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExceptClauseContextExt{
				exceptCols: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ExceptClauseContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ExceptClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EXCEPT
/// Returns `None` if there is no child corresponding to token EXCEPT
fn EXCEPT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXCEPT, 0)
}
/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
fn multipartIdentifierList(&self) -> Option<Rc<MultipartIdentifierListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ExceptClauseContextAttrs<'input> for ExceptClauseContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn exceptClause(&mut self,)
	-> Result<Rc<ExceptClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExceptClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 198, RULE_exceptClause);
        let mut _localctx: Rc<ExceptClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2884);
			recog.base.match_token(EXCEPT,&mut recog.err_handler)?;

			recog.base.set_state(2885);
			recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

			/*InvokeRule multipartIdentifierList*/
			recog.base.set_state(2886);
			let tmp = recog.multipartIdentifierList()?;
			 cast_mut::<_,ExceptClauseContext >(&mut _localctx).exceptCols = Some(tmp.clone());
			  

			recog.base.set_state(2887);
			recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- assignmentList ----------------
pub type AssignmentListContextAll<'input> = AssignmentListContext<'input>;


pub type AssignmentListContext<'input> = BaseParserRuleContext<'input,AssignmentListContextExt<'input>>;

#[derive(Clone)]
pub struct AssignmentListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for AssignmentListContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for AssignmentListContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_assignmentList(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_assignmentList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for AssignmentListContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_assignmentList(self);
	}
}

impl<'input> CustomRuleContext<'input> for AssignmentListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_assignmentList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_assignmentList }
}
antlr_rust::tid!{AssignmentListContextExt<'a>}

impl<'input> AssignmentListContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AssignmentListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AssignmentListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AssignmentListContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<AssignmentListContextExt<'input>>{

fn assignment_all(&self) ->  Vec<Rc<AssignmentContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn assignment(&self, i: usize) -> Option<Rc<AssignmentContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> AssignmentListContextAttrs<'input> for AssignmentListContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn assignmentList(&mut self,)
	-> Result<Rc<AssignmentListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AssignmentListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 200, RULE_assignmentList);
        let mut _localctx: Rc<AssignmentListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule assignment*/
			recog.base.set_state(2889);
			recog.assignment()?;

			recog.base.set_state(2894);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2890);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule assignment*/
				recog.base.set_state(2891);
				recog.assignment()?;

				}
				}
				recog.base.set_state(2896);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- assignment ----------------
pub type AssignmentContextAll<'input> = AssignmentContext<'input>;


pub type AssignmentContext<'input> = BaseParserRuleContext<'input,AssignmentContextExt<'input>>;

#[derive(Clone)]
pub struct AssignmentContextExt<'input>{
	pub key: Option<Rc<MultipartIdentifierContextAll<'input>>>,
	pub value: Option<Rc<ExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for AssignmentContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for AssignmentContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_assignment(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_assignment(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for AssignmentContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_assignment(self);
	}
}

impl<'input> CustomRuleContext<'input> for AssignmentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_assignment }
	//fn type_rule_index() -> usize where Self: Sized { RULE_assignment }
}
antlr_rust::tid!{AssignmentContextExt<'a>}

impl<'input> AssignmentContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AssignmentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AssignmentContextExt{
				key: None, value: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AssignmentContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<AssignmentContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EQ
/// Returns `None` if there is no child corresponding to token EQ
fn EQ(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EQ, 0)
}
fn multipartIdentifier(&self) -> Option<Rc<MultipartIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AssignmentContextAttrs<'input> for AssignmentContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn assignment(&mut self,)
	-> Result<Rc<AssignmentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AssignmentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 202, RULE_assignment);
        let mut _localctx: Rc<AssignmentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule multipartIdentifier*/
			recog.base.set_state(2897);
			let tmp = recog.multipartIdentifier()?;
			 cast_mut::<_,AssignmentContext >(&mut _localctx).key = Some(tmp.clone());
			  

			recog.base.set_state(2898);
			recog.base.match_token(EQ,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(2899);
			let tmp = recog.expression()?;
			 cast_mut::<_,AssignmentContext >(&mut _localctx).value = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- whereClause ----------------
pub type WhereClauseContextAll<'input> = WhereClauseContext<'input>;


pub type WhereClauseContext<'input> = BaseParserRuleContext<'input,WhereClauseContextExt<'input>>;

#[derive(Clone)]
pub struct WhereClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for WhereClauseContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for WhereClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_whereClause(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_whereClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for WhereClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_whereClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for WhereClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_whereClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_whereClause }
}
antlr_rust::tid!{WhereClauseContextExt<'a>}

impl<'input> WhereClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WhereClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WhereClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait WhereClauseContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<WhereClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WHERE
/// Returns `None` if there is no child corresponding to token WHERE
fn WHERE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WHERE, 0)
}
fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> WhereClauseContextAttrs<'input> for WhereClauseContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn whereClause(&mut self,)
	-> Result<Rc<WhereClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WhereClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 204, RULE_whereClause);
        let mut _localctx: Rc<WhereClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2901);
			recog.base.match_token(WHERE,&mut recog.err_handler)?;

			/*InvokeRule booleanExpression*/
			recog.base.set_state(2902);
			recog.booleanExpression_rec(0)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- havingClause ----------------
pub type HavingClauseContextAll<'input> = HavingClauseContext<'input>;


pub type HavingClauseContext<'input> = BaseParserRuleContext<'input,HavingClauseContextExt<'input>>;

#[derive(Clone)]
pub struct HavingClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for HavingClauseContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for HavingClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_havingClause(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_havingClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for HavingClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_havingClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for HavingClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_havingClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_havingClause }
}
antlr_rust::tid!{HavingClauseContextExt<'a>}

impl<'input> HavingClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<HavingClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,HavingClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait HavingClauseContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<HavingClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token HAVING
/// Returns `None` if there is no child corresponding to token HAVING
fn HAVING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(HAVING, 0)
}
fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> HavingClauseContextAttrs<'input> for HavingClauseContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn havingClause(&mut self,)
	-> Result<Rc<HavingClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = HavingClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 206, RULE_havingClause);
        let mut _localctx: Rc<HavingClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2904);
			recog.base.match_token(HAVING,&mut recog.err_handler)?;

			/*InvokeRule booleanExpression*/
			recog.base.set_state(2905);
			recog.booleanExpression_rec(0)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- hint ----------------
pub type HintContextAll<'input> = HintContext<'input>;


pub type HintContext<'input> = BaseParserRuleContext<'input,HintContextExt<'input>>;

#[derive(Clone)]
pub struct HintContextExt<'input>{
	pub hintStatement: Option<Rc<HintStatementContextAll<'input>>>,
	pub hintStatements:Vec<Rc<HintStatementContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for HintContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for HintContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_hint(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_hint(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for HintContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_hint(self);
	}
}

impl<'input> CustomRuleContext<'input> for HintContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_hint }
	//fn type_rule_index() -> usize where Self: Sized { RULE_hint }
}
antlr_rust::tid!{HintContextExt<'a>}

impl<'input> HintContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<HintContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,HintContextExt{
				hintStatement: None, 
				hintStatements: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait HintContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<HintContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token HENT_START
/// Returns `None` if there is no child corresponding to token HENT_START
fn HENT_START(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(HENT_START, 0)
}
/// Retrieves first TerminalNode corresponding to token HENT_END
/// Returns `None` if there is no child corresponding to token HENT_END
fn HENT_END(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(HENT_END, 0)
}
fn hintStatement_all(&self) ->  Vec<Rc<HintStatementContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn hintStatement(&self, i: usize) -> Option<Rc<HintStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> HintContextAttrs<'input> for HintContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn hint(&mut self,)
	-> Result<Rc<HintContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = HintContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 208, RULE_hint);
        let mut _localctx: Rc<HintContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2907);
			recog.base.match_token(HENT_START,&mut recog.err_handler)?;

			/*InvokeRule hintStatement*/
			recog.base.set_state(2908);
			let tmp = recog.hintStatement()?;
			 cast_mut::<_,HintContext >(&mut _localctx).hintStatement = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,HintContext >(&mut _localctx).hintStatement.clone().unwrap()
			 ;
			 cast_mut::<_,HintContext >(&mut _localctx).hintStatements.push(temp);
			  
			recog.base.set_state(2915);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(336,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(2910);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(335,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2909);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule hintStatement*/
					recog.base.set_state(2912);
					let tmp = recog.hintStatement()?;
					 cast_mut::<_,HintContext >(&mut _localctx).hintStatement = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,HintContext >(&mut _localctx).hintStatement.clone().unwrap()
					 ;
					 cast_mut::<_,HintContext >(&mut _localctx).hintStatements.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(2917);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(336,&mut recog.base)?;
			}
			recog.base.set_state(2918);
			recog.base.match_token(HENT_END,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- hintStatement ----------------
pub type HintStatementContextAll<'input> = HintStatementContext<'input>;


pub type HintStatementContext<'input> = BaseParserRuleContext<'input,HintStatementContextExt<'input>>;

#[derive(Clone)]
pub struct HintStatementContextExt<'input>{
	pub hintName: Option<Rc<SimpleIdentifierContextAll<'input>>>,
	pub primaryExpression: Option<Rc<PrimaryExpressionContextAll<'input>>>,
	pub parameters:Vec<Rc<PrimaryExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for HintStatementContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for HintStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_hintStatement(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_hintStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for HintStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_hintStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for HintStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_hintStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_hintStatement }
}
antlr_rust::tid!{HintStatementContextExt<'a>}

impl<'input> HintStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<HintStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,HintStatementContextExt{
				hintName: None, primaryExpression: None, 
				parameters: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait HintStatementContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<HintStatementContextExt<'input>>{

fn simpleIdentifier(&self) -> Option<Rc<SimpleIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
fn primaryExpression_all(&self) ->  Vec<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn primaryExpression(&self, i: usize) -> Option<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> HintStatementContextAttrs<'input> for HintStatementContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn hintStatement(&mut self,)
	-> Result<Rc<HintStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = HintStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 210, RULE_hintStatement);
        let mut _localctx: Rc<HintStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2933);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(338,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule simpleIdentifier*/
					recog.base.set_state(2920);
					let tmp = recog.simpleIdentifier()?;
					 cast_mut::<_,HintStatementContext >(&mut _localctx).hintName = Some(tmp.clone());
					  

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule simpleIdentifier*/
					recog.base.set_state(2921);
					let tmp = recog.simpleIdentifier()?;
					 cast_mut::<_,HintStatementContext >(&mut _localctx).hintName = Some(tmp.clone());
					  

					recog.base.set_state(2922);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule primaryExpression*/
					recog.base.set_state(2923);
					let tmp = recog.primaryExpression_rec(0)?;
					 cast_mut::<_,HintStatementContext >(&mut _localctx).primaryExpression = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,HintStatementContext >(&mut _localctx).primaryExpression.clone().unwrap()
					 ;
					 cast_mut::<_,HintStatementContext >(&mut _localctx).parameters.push(temp);
					  
					recog.base.set_state(2928);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(2924);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule primaryExpression*/
						recog.base.set_state(2925);
						let tmp = recog.primaryExpression_rec(0)?;
						 cast_mut::<_,HintStatementContext >(&mut _localctx).primaryExpression = Some(tmp.clone());
						  

						let temp =  cast_mut::<_,HintStatementContext >(&mut _localctx).primaryExpression.clone().unwrap()
						 ;
						 cast_mut::<_,HintStatementContext >(&mut _localctx).parameters.push(temp);
						  
						}
						}
						recog.base.set_state(2930);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(2931);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- fromClause ----------------
pub type FromClauseContextAll<'input> = FromClauseContext<'input>;


pub type FromClauseContext<'input> = BaseParserRuleContext<'input,FromClauseContextExt<'input>>;

#[derive(Clone)]
pub struct FromClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for FromClauseContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for FromClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_fromClause(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_fromClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for FromClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_fromClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for FromClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_fromClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_fromClause }
}
antlr_rust::tid!{FromClauseContextExt<'a>}

impl<'input> FromClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FromClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FromClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FromClauseContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<FromClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token FROM
/// Returns `None` if there is no child corresponding to token FROM
fn FROM(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FROM, 0)
}
fn relation_all(&self) ->  Vec<Rc<RelationContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn relation(&self, i: usize) -> Option<Rc<RelationContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
fn lateralView_all(&self) ->  Vec<Rc<LateralViewContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn lateralView(&self, i: usize) -> Option<Rc<LateralViewContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn pivotClause(&self) -> Option<Rc<PivotClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn unpivotClause(&self) -> Option<Rc<UnpivotClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FromClauseContextAttrs<'input> for FromClauseContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn fromClause(&mut self,)
	-> Result<Rc<FromClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FromClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 212, RULE_fromClause);
        let mut _localctx: Rc<FromClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2935);
			recog.base.match_token(FROM,&mut recog.err_handler)?;

			/*InvokeRule relation*/
			recog.base.set_state(2936);
			recog.relation()?;

			recog.base.set_state(2941);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(339,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(2937);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule relation*/
					recog.base.set_state(2938);
					recog.relation()?;

					}
					} 
				}
				recog.base.set_state(2943);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(339,&mut recog.base)?;
			}
			recog.base.set_state(2947);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(340,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					/*InvokeRule lateralView*/
					recog.base.set_state(2944);
					recog.lateralView()?;

					}
					} 
				}
				recog.base.set_state(2949);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(340,&mut recog.base)?;
			}
			recog.base.set_state(2951);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(341,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule pivotClause*/
					recog.base.set_state(2950);
					recog.pivotClause()?;

					}
				}

				_ => {}
			}
			recog.base.set_state(2954);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(342,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule unpivotClause*/
					recog.base.set_state(2953);
					recog.unpivotClause()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- temporalClause ----------------
pub type TemporalClauseContextAll<'input> = TemporalClauseContext<'input>;


pub type TemporalClauseContext<'input> = BaseParserRuleContext<'input,TemporalClauseContextExt<'input>>;

#[derive(Clone)]
pub struct TemporalClauseContextExt<'input>{
	pub timestamp: Option<Rc<ValueExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for TemporalClauseContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for TemporalClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_temporalClause(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_temporalClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for TemporalClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_temporalClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for TemporalClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_temporalClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_temporalClause }
}
antlr_rust::tid!{TemporalClauseContextExt<'a>}

impl<'input> TemporalClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TemporalClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TemporalClauseContextExt{
				timestamp: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TemporalClauseContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<TemporalClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
/// Retrieves first TerminalNode corresponding to token OF
/// Returns `None` if there is no child corresponding to token OF
fn OF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OF, 0)
}
fn version(&self) -> Option<Rc<VersionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token SYSTEM_VERSION
/// Returns `None` if there is no child corresponding to token SYSTEM_VERSION
fn SYSTEM_VERSION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SYSTEM_VERSION, 0)
}
/// Retrieves first TerminalNode corresponding to token VERSION
/// Returns `None` if there is no child corresponding to token VERSION
fn VERSION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VERSION, 0)
}
/// Retrieves first TerminalNode corresponding to token FOR
/// Returns `None` if there is no child corresponding to token FOR
fn FOR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FOR, 0)
}
/// Retrieves first TerminalNode corresponding to token SYSTEM_TIME
/// Returns `None` if there is no child corresponding to token SYSTEM_TIME
fn SYSTEM_TIME(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SYSTEM_TIME, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMP
/// Returns `None` if there is no child corresponding to token TIMESTAMP
fn TIMESTAMP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP, 0)
}
fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TemporalClauseContextAttrs<'input> for TemporalClauseContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn temporalClause(&mut self,)
	-> Result<Rc<TemporalClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TemporalClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 214, RULE_temporalClause);
        let mut _localctx: Rc<TemporalClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2970);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(345,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2957);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==FOR {
						{
						recog.base.set_state(2956);
						recog.base.match_token(FOR,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2959);
					_la = recog.base.input.la(1);
					if { !(_la==SYSTEM_VERSION || _la==VERSION) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(2960);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					recog.base.set_state(2961);
					recog.base.match_token(OF,&mut recog.err_handler)?;

					/*InvokeRule version*/
					recog.base.set_state(2962);
					recog.version()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2964);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==FOR {
						{
						recog.base.set_state(2963);
						recog.base.match_token(FOR,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(2966);
					_la = recog.base.input.la(1);
					if { !(_la==SYSTEM_TIME || _la==TIMESTAMP) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(2967);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					recog.base.set_state(2968);
					recog.base.match_token(OF,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(2969);
					let tmp = recog.valueExpression_rec(0)?;
					 cast_mut::<_,TemporalClauseContext >(&mut _localctx).timestamp = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- aggregationClause ----------------
pub type AggregationClauseContextAll<'input> = AggregationClauseContext<'input>;


pub type AggregationClauseContext<'input> = BaseParserRuleContext<'input,AggregationClauseContextExt<'input>>;

#[derive(Clone)]
pub struct AggregationClauseContextExt<'input>{
	pub groupByClause: Option<Rc<GroupByClauseContextAll<'input>>>,
	pub groupingExpressionsWithGroupingAnalytics:Vec<Rc<GroupByClauseContextAll<'input>>>,
	pub namedExpression: Option<Rc<NamedExpressionContextAll<'input>>>,
	pub groupingExpressions:Vec<Rc<NamedExpressionContextAll<'input>>>,
	pub kind: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for AggregationClauseContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for AggregationClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_aggregationClause(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_aggregationClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for AggregationClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_aggregationClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for AggregationClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_aggregationClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_aggregationClause }
}
antlr_rust::tid!{AggregationClauseContextExt<'a>}

impl<'input> AggregationClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AggregationClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AggregationClauseContextExt{
				kind: None, 
				groupByClause: None, namedExpression: None, 
				groupingExpressionsWithGroupingAnalytics: Vec::new(), groupingExpressions: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait AggregationClauseContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<AggregationClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token GROUP
/// Returns `None` if there is no child corresponding to token GROUP
fn GROUP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(GROUP, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn groupByClause_all(&self) ->  Vec<Rc<GroupByClauseContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn groupByClause(&self, i: usize) -> Option<Rc<GroupByClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
fn namedExpression_all(&self) ->  Vec<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn namedExpression(&self, i: usize) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token SETS
/// Returns `None` if there is no child corresponding to token SETS
fn SETS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SETS, 0)
}
/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
fn groupingSet_all(&self) ->  Vec<Rc<GroupingSetContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn groupingSet(&self, i: usize) -> Option<Rc<GroupingSetContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token ROLLUP
/// Returns `None` if there is no child corresponding to token ROLLUP
fn ROLLUP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ROLLUP, 0)
}
/// Retrieves first TerminalNode corresponding to token CUBE
/// Returns `None` if there is no child corresponding to token CUBE
fn CUBE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CUBE, 0)
}
/// Retrieves first TerminalNode corresponding to token GROUPING
/// Returns `None` if there is no child corresponding to token GROUPING
fn GROUPING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(GROUPING, 0)
}

}

impl<'input> AggregationClauseContextAttrs<'input> for AggregationClauseContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn aggregationClause(&mut self,)
	-> Result<Rc<AggregationClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AggregationClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 216, RULE_aggregationClause);
        let mut _localctx: Rc<AggregationClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(3011);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(350,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2972);
					recog.base.match_token(GROUP,&mut recog.err_handler)?;

					recog.base.set_state(2973);
					recog.base.match_token(BY,&mut recog.err_handler)?;

					/*InvokeRule groupByClause*/
					recog.base.set_state(2974);
					let tmp = recog.groupByClause()?;
					 cast_mut::<_,AggregationClauseContext >(&mut _localctx).groupByClause = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,AggregationClauseContext >(&mut _localctx).groupByClause.clone().unwrap()
					 ;
					 cast_mut::<_,AggregationClauseContext >(&mut _localctx).groupingExpressionsWithGroupingAnalytics.push(temp);
					  
					recog.base.set_state(2979);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(346,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(2975);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule groupByClause*/
							recog.base.set_state(2976);
							let tmp = recog.groupByClause()?;
							 cast_mut::<_,AggregationClauseContext >(&mut _localctx).groupByClause = Some(tmp.clone());
							  

							let temp =  cast_mut::<_,AggregationClauseContext >(&mut _localctx).groupByClause.clone().unwrap()
							 ;
							 cast_mut::<_,AggregationClauseContext >(&mut _localctx).groupingExpressionsWithGroupingAnalytics.push(temp);
							  
							}
							} 
						}
						recog.base.set_state(2981);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(346,&mut recog.base)?;
					}
					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(2982);
					recog.base.match_token(GROUP,&mut recog.err_handler)?;

					recog.base.set_state(2983);
					recog.base.match_token(BY,&mut recog.err_handler)?;

					/*InvokeRule namedExpression*/
					recog.base.set_state(2984);
					let tmp = recog.namedExpression()?;
					 cast_mut::<_,AggregationClauseContext >(&mut _localctx).namedExpression = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,AggregationClauseContext >(&mut _localctx).namedExpression.clone().unwrap()
					 ;
					 cast_mut::<_,AggregationClauseContext >(&mut _localctx).groupingExpressions.push(temp);
					  
					recog.base.set_state(2989);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(347,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(2985);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule namedExpression*/
							recog.base.set_state(2986);
							let tmp = recog.namedExpression()?;
							 cast_mut::<_,AggregationClauseContext >(&mut _localctx).namedExpression = Some(tmp.clone());
							  

							let temp =  cast_mut::<_,AggregationClauseContext >(&mut _localctx).namedExpression.clone().unwrap()
							 ;
							 cast_mut::<_,AggregationClauseContext >(&mut _localctx).groupingExpressions.push(temp);
							  
							}
							} 
						}
						recog.base.set_state(2991);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(347,&mut recog.base)?;
					}
					recog.base.set_state(3009);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(349,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(2992);
							recog.base.match_token(WITH,&mut recog.err_handler)?;

							recog.base.set_state(2993);
							let tmp = recog.base.match_token(ROLLUP,&mut recog.err_handler)?;
							 cast_mut::<_,AggregationClauseContext >(&mut _localctx).kind = Some(tmp.clone());
							  

							}
						}

						x if x == 2=>{
							{
							recog.base.set_state(2994);
							recog.base.match_token(WITH,&mut recog.err_handler)?;

							recog.base.set_state(2995);
							let tmp = recog.base.match_token(CUBE,&mut recog.err_handler)?;
							 cast_mut::<_,AggregationClauseContext >(&mut _localctx).kind = Some(tmp.clone());
							  

							}
						}

						x if x == 3=>{
							{
							recog.base.set_state(2996);
							let tmp = recog.base.match_token(GROUPING,&mut recog.err_handler)?;
							 cast_mut::<_,AggregationClauseContext >(&mut _localctx).kind = Some(tmp.clone());
							  

							recog.base.set_state(2997);
							recog.base.match_token(SETS,&mut recog.err_handler)?;

							recog.base.set_state(2998);
							recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

							/*InvokeRule groupingSet*/
							recog.base.set_state(2999);
							recog.groupingSet()?;

							recog.base.set_state(3004);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							while _la==COMMA {
								{
								{
								recog.base.set_state(3000);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule groupingSet*/
								recog.base.set_state(3001);
								recog.groupingSet()?;

								}
								}
								recog.base.set_state(3006);
								recog.err_handler.sync(&mut recog.base)?;
								_la = recog.base.input.la(1);
							}
							recog.base.set_state(3007);
							recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- groupByClause ----------------
pub type GroupByClauseContextAll<'input> = GroupByClauseContext<'input>;


pub type GroupByClauseContext<'input> = BaseParserRuleContext<'input,GroupByClauseContextExt<'input>>;

#[derive(Clone)]
pub struct GroupByClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for GroupByClauseContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for GroupByClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_groupByClause(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_groupByClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for GroupByClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_groupByClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for GroupByClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupByClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupByClause }
}
antlr_rust::tid!{GroupByClauseContextExt<'a>}

impl<'input> GroupByClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GroupByClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GroupByClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait GroupByClauseContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<GroupByClauseContextExt<'input>>{

fn groupingAnalytics(&self) -> Option<Rc<GroupingAnalyticsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> GroupByClauseContextAttrs<'input> for GroupByClauseContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn groupByClause(&mut self,)
	-> Result<Rc<GroupByClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GroupByClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 218, RULE_groupByClause);
        let mut _localctx: Rc<GroupByClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3015);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(351,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule groupingAnalytics*/
					recog.base.set_state(3013);
					recog.groupingAnalytics()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule expression*/
					recog.base.set_state(3014);
					recog.expression()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- groupingAnalytics ----------------
pub type GroupingAnalyticsContextAll<'input> = GroupingAnalyticsContext<'input>;


pub type GroupingAnalyticsContext<'input> = BaseParserRuleContext<'input,GroupingAnalyticsContextExt<'input>>;

#[derive(Clone)]
pub struct GroupingAnalyticsContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for GroupingAnalyticsContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for GroupingAnalyticsContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_groupingAnalytics(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_groupingAnalytics(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for GroupingAnalyticsContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_groupingAnalytics(self);
	}
}

impl<'input> CustomRuleContext<'input> for GroupingAnalyticsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupingAnalytics }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupingAnalytics }
}
antlr_rust::tid!{GroupingAnalyticsContextExt<'a>}

impl<'input> GroupingAnalyticsContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GroupingAnalyticsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GroupingAnalyticsContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait GroupingAnalyticsContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<GroupingAnalyticsContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
fn groupingSet_all(&self) ->  Vec<Rc<GroupingSetContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn groupingSet(&self, i: usize) -> Option<Rc<GroupingSetContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token ROLLUP
/// Returns `None` if there is no child corresponding to token ROLLUP
fn ROLLUP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ROLLUP, 0)
}
/// Retrieves first TerminalNode corresponding to token CUBE
/// Returns `None` if there is no child corresponding to token CUBE
fn CUBE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CUBE, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
/// Retrieves first TerminalNode corresponding to token GROUPING
/// Returns `None` if there is no child corresponding to token GROUPING
fn GROUPING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(GROUPING, 0)
}
/// Retrieves first TerminalNode corresponding to token SETS
/// Returns `None` if there is no child corresponding to token SETS
fn SETS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SETS, 0)
}
fn groupingElement_all(&self) ->  Vec<Rc<GroupingElementContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn groupingElement(&self, i: usize) -> Option<Rc<GroupingElementContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> GroupingAnalyticsContextAttrs<'input> for GroupingAnalyticsContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn groupingAnalytics(&mut self,)
	-> Result<Rc<GroupingAnalyticsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GroupingAnalyticsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 220, RULE_groupingAnalytics);
        let mut _localctx: Rc<GroupingAnalyticsContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3042);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 CUBE | ROLLUP 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3017);
					_la = recog.base.input.la(1);
					if { !(_la==CUBE || _la==ROLLUP) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(3018);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule groupingSet*/
					recog.base.set_state(3019);
					recog.groupingSet()?;

					recog.base.set_state(3024);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(3020);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule groupingSet*/
						recog.base.set_state(3021);
						recog.groupingSet()?;

						}
						}
						recog.base.set_state(3026);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(3027);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}

			 GROUPING 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3029);
					recog.base.match_token(GROUPING,&mut recog.err_handler)?;

					recog.base.set_state(3030);
					recog.base.match_token(SETS,&mut recog.err_handler)?;

					recog.base.set_state(3031);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule groupingElement*/
					recog.base.set_state(3032);
					recog.groupingElement()?;

					recog.base.set_state(3037);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(3033);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule groupingElement*/
						recog.base.set_state(3034);
						recog.groupingElement()?;

						}
						}
						recog.base.set_state(3039);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(3040);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- groupingElement ----------------
pub type GroupingElementContextAll<'input> = GroupingElementContext<'input>;


pub type GroupingElementContext<'input> = BaseParserRuleContext<'input,GroupingElementContextExt<'input>>;

#[derive(Clone)]
pub struct GroupingElementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for GroupingElementContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for GroupingElementContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_groupingElement(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_groupingElement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for GroupingElementContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_groupingElement(self);
	}
}

impl<'input> CustomRuleContext<'input> for GroupingElementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupingElement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupingElement }
}
antlr_rust::tid!{GroupingElementContextExt<'a>}

impl<'input> GroupingElementContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GroupingElementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GroupingElementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait GroupingElementContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<GroupingElementContextExt<'input>>{

fn groupingAnalytics(&self) -> Option<Rc<GroupingAnalyticsContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn groupingSet(&self) -> Option<Rc<GroupingSetContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> GroupingElementContextAttrs<'input> for GroupingElementContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn groupingElement(&mut self,)
	-> Result<Rc<GroupingElementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GroupingElementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 222, RULE_groupingElement);
        let mut _localctx: Rc<GroupingElementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3046);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(355,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule groupingAnalytics*/
					recog.base.set_state(3044);
					recog.groupingAnalytics()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule groupingSet*/
					recog.base.set_state(3045);
					recog.groupingSet()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- groupingSet ----------------
pub type GroupingSetContextAll<'input> = GroupingSetContext<'input>;


pub type GroupingSetContext<'input> = BaseParserRuleContext<'input,GroupingSetContextExt<'input>>;

#[derive(Clone)]
pub struct GroupingSetContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for GroupingSetContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for GroupingSetContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_groupingSet(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_groupingSet(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for GroupingSetContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_groupingSet(self);
	}
}

impl<'input> CustomRuleContext<'input> for GroupingSetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_groupingSet }
	//fn type_rule_index() -> usize where Self: Sized { RULE_groupingSet }
}
antlr_rust::tid!{GroupingSetContextExt<'a>}

impl<'input> GroupingSetContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GroupingSetContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GroupingSetContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait GroupingSetContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<GroupingSetContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> GroupingSetContextAttrs<'input> for GroupingSetContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn groupingSet(&mut self,)
	-> Result<Rc<GroupingSetContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GroupingSetContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 224, RULE_groupingSet);
        let mut _localctx: Rc<GroupingSetContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3061);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(358,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3048);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					recog.base.set_state(3057);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(357,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule expression*/
							recog.base.set_state(3049);
							recog.expression()?;

							recog.base.set_state(3054);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							while _la==COMMA {
								{
								{
								recog.base.set_state(3050);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule expression*/
								recog.base.set_state(3051);
								recog.expression()?;

								}
								}
								recog.base.set_state(3056);
								recog.err_handler.sync(&mut recog.base)?;
								_la = recog.base.input.la(1);
							}
							}
						}

						_ => {}
					}
					recog.base.set_state(3059);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule expression*/
					recog.base.set_state(3060);
					recog.expression()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pivotClause ----------------
pub type PivotClauseContextAll<'input> = PivotClauseContext<'input>;


pub type PivotClauseContext<'input> = BaseParserRuleContext<'input,PivotClauseContextExt<'input>>;

#[derive(Clone)]
pub struct PivotClauseContextExt<'input>{
	pub aggregates: Option<Rc<NamedExpressionSeqContextAll<'input>>>,
	pub pivotValue: Option<Rc<PivotValueContextAll<'input>>>,
	pub pivotValues:Vec<Rc<PivotValueContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for PivotClauseContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PivotClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_pivotClause(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_pivotClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PivotClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_pivotClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for PivotClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotClause }
}
antlr_rust::tid!{PivotClauseContextExt<'a>}

impl<'input> PivotClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PivotClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PivotClauseContextExt{
				aggregates: None, pivotValue: None, 
				pivotValues: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait PivotClauseContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<PivotClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PIVOT
/// Returns `None` if there is no child corresponding to token PIVOT
fn PIVOT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PIVOT, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token LEFT_PAREN in current rule
fn LEFT_PAREN_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LEFT_PAREN, starting from 0.
/// Returns `None` if number of children corresponding to token LEFT_PAREN is less or equal than `i`.
fn LEFT_PAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, i)
}
/// Retrieves first TerminalNode corresponding to token FOR
/// Returns `None` if there is no child corresponding to token FOR
fn FOR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FOR, 0)
}
fn pivotColumn(&self) -> Option<Rc<PivotColumnContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token IN
/// Returns `None` if there is no child corresponding to token IN
fn IN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token RIGHT_PAREN in current rule
fn RIGHT_PAREN_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token RIGHT_PAREN, starting from 0.
/// Returns `None` if number of children corresponding to token RIGHT_PAREN is less or equal than `i`.
fn RIGHT_PAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, i)
}
fn namedExpressionSeq(&self) -> Option<Rc<NamedExpressionSeqContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn pivotValue_all(&self) ->  Vec<Rc<PivotValueContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn pivotValue(&self, i: usize) -> Option<Rc<PivotValueContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> PivotClauseContextAttrs<'input> for PivotClauseContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pivotClause(&mut self,)
	-> Result<Rc<PivotClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PivotClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 226, RULE_pivotClause);
        let mut _localctx: Rc<PivotClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3063);
			recog.base.match_token(PIVOT,&mut recog.err_handler)?;

			recog.base.set_state(3064);
			recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

			/*InvokeRule namedExpressionSeq*/
			recog.base.set_state(3065);
			let tmp = recog.namedExpressionSeq()?;
			 cast_mut::<_,PivotClauseContext >(&mut _localctx).aggregates = Some(tmp.clone());
			  

			recog.base.set_state(3066);
			recog.base.match_token(FOR,&mut recog.err_handler)?;

			/*InvokeRule pivotColumn*/
			recog.base.set_state(3067);
			recog.pivotColumn()?;

			recog.base.set_state(3068);
			recog.base.match_token(IN,&mut recog.err_handler)?;

			recog.base.set_state(3069);
			recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

			/*InvokeRule pivotValue*/
			recog.base.set_state(3070);
			let tmp = recog.pivotValue()?;
			 cast_mut::<_,PivotClauseContext >(&mut _localctx).pivotValue = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,PivotClauseContext >(&mut _localctx).pivotValue.clone().unwrap()
			 ;
			 cast_mut::<_,PivotClauseContext >(&mut _localctx).pivotValues.push(temp);
			  
			recog.base.set_state(3075);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(3071);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule pivotValue*/
				recog.base.set_state(3072);
				let tmp = recog.pivotValue()?;
				 cast_mut::<_,PivotClauseContext >(&mut _localctx).pivotValue = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,PivotClauseContext >(&mut _localctx).pivotValue.clone().unwrap()
				 ;
				 cast_mut::<_,PivotClauseContext >(&mut _localctx).pivotValues.push(temp);
				  
				}
				}
				recog.base.set_state(3077);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(3078);
			recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

			recog.base.set_state(3079);
			recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pivotColumn ----------------
pub type PivotColumnContextAll<'input> = PivotColumnContext<'input>;


pub type PivotColumnContext<'input> = BaseParserRuleContext<'input,PivotColumnContextExt<'input>>;

#[derive(Clone)]
pub struct PivotColumnContextExt<'input>{
	pub errorCapturingIdentifier: Option<Rc<ErrorCapturingIdentifierContextAll<'input>>>,
	pub identifiers:Vec<Rc<ErrorCapturingIdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for PivotColumnContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PivotColumnContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_pivotColumn(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_pivotColumn(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PivotColumnContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_pivotColumn(self);
	}
}

impl<'input> CustomRuleContext<'input> for PivotColumnContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotColumn }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotColumn }
}
antlr_rust::tid!{PivotColumnContextExt<'a>}

impl<'input> PivotColumnContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PivotColumnContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PivotColumnContextExt{
				errorCapturingIdentifier: None, 
				identifiers: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait PivotColumnContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<PivotColumnContextExt<'input>>{

fn errorCapturingIdentifier_all(&self) ->  Vec<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn errorCapturingIdentifier(&self, i: usize) -> Option<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> PivotColumnContextAttrs<'input> for PivotColumnContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pivotColumn(&mut self,)
	-> Result<Rc<PivotColumnContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PivotColumnContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 228, RULE_pivotColumn);
        let mut _localctx: Rc<PivotColumnContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3093);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(361,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule errorCapturingIdentifier*/
					recog.base.set_state(3081);
					let tmp = recog.errorCapturingIdentifier()?;
					 cast_mut::<_,PivotColumnContext >(&mut _localctx).errorCapturingIdentifier = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,PivotColumnContext >(&mut _localctx).errorCapturingIdentifier.clone().unwrap()
					 ;
					 cast_mut::<_,PivotColumnContext >(&mut _localctx).identifiers.push(temp);
					  
					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3082);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule errorCapturingIdentifier*/
					recog.base.set_state(3083);
					let tmp = recog.errorCapturingIdentifier()?;
					 cast_mut::<_,PivotColumnContext >(&mut _localctx).errorCapturingIdentifier = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,PivotColumnContext >(&mut _localctx).errorCapturingIdentifier.clone().unwrap()
					 ;
					 cast_mut::<_,PivotColumnContext >(&mut _localctx).identifiers.push(temp);
					  
					recog.base.set_state(3088);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(3084);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule errorCapturingIdentifier*/
						recog.base.set_state(3085);
						let tmp = recog.errorCapturingIdentifier()?;
						 cast_mut::<_,PivotColumnContext >(&mut _localctx).errorCapturingIdentifier = Some(tmp.clone());
						  

						let temp =  cast_mut::<_,PivotColumnContext >(&mut _localctx).errorCapturingIdentifier.clone().unwrap()
						 ;
						 cast_mut::<_,PivotColumnContext >(&mut _localctx).identifiers.push(temp);
						  
						}
						}
						recog.base.set_state(3090);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(3091);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pivotValue ----------------
pub type PivotValueContextAll<'input> = PivotValueContext<'input>;


pub type PivotValueContext<'input> = BaseParserRuleContext<'input,PivotValueContextExt<'input>>;

#[derive(Clone)]
pub struct PivotValueContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for PivotValueContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PivotValueContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_pivotValue(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_pivotValue(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PivotValueContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_pivotValue(self);
	}
}

impl<'input> CustomRuleContext<'input> for PivotValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pivotValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pivotValue }
}
antlr_rust::tid!{PivotValueContextExt<'a>}

impl<'input> PivotValueContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PivotValueContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PivotValueContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PivotValueContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<PivotValueContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn errorCapturingIdentifier(&self) -> Option<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}

}

impl<'input> PivotValueContextAttrs<'input> for PivotValueContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pivotValue(&mut self,)
	-> Result<Rc<PivotValueContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PivotValueContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 230, RULE_pivotValue);
        let mut _localctx: Rc<PivotValueContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(3095);
			recog.expression()?;

			recog.base.set_state(3100);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(363,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(3097);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(362,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3096);
							recog.base.match_token(AS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule errorCapturingIdentifier*/
					recog.base.set_state(3099);
					recog.errorCapturingIdentifier()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unpivotClause ----------------
pub type UnpivotClauseContextAll<'input> = UnpivotClauseContext<'input>;


pub type UnpivotClauseContext<'input> = BaseParserRuleContext<'input,UnpivotClauseContextExt<'input>>;

#[derive(Clone)]
pub struct UnpivotClauseContextExt<'input>{
	pub nullOperator: Option<Rc<UnpivotNullClauseContextAll<'input>>>,
	pub operator: Option<Rc<UnpivotOperatorContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for UnpivotClauseContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for UnpivotClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unpivotClause(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_unpivotClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for UnpivotClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_unpivotClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnpivotClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unpivotClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unpivotClause }
}
antlr_rust::tid!{UnpivotClauseContextExt<'a>}

impl<'input> UnpivotClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnpivotClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnpivotClauseContextExt{
				nullOperator: None, operator: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait UnpivotClauseContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<UnpivotClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token UNPIVOT
/// Returns `None` if there is no child corresponding to token UNPIVOT
fn UNPIVOT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UNPIVOT, 0)
}
/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
fn unpivotOperator(&self) -> Option<Rc<UnpivotOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn errorCapturingIdentifier(&self) -> Option<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn unpivotNullClause(&self) -> Option<Rc<UnpivotNullClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}

}

impl<'input> UnpivotClauseContextAttrs<'input> for UnpivotClauseContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unpivotClause(&mut self,)
	-> Result<Rc<UnpivotClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnpivotClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 232, RULE_unpivotClause);
        let mut _localctx: Rc<UnpivotClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3102);
			recog.base.match_token(UNPIVOT,&mut recog.err_handler)?;

			recog.base.set_state(3104);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==EXCLUDE || _la==INCLUDE {
				{
				/*InvokeRule unpivotNullClause*/
				recog.base.set_state(3103);
				let tmp = recog.unpivotNullClause()?;
				 cast_mut::<_,UnpivotClauseContext >(&mut _localctx).nullOperator = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(3106);
			recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

			/*InvokeRule unpivotOperator*/
			recog.base.set_state(3107);
			let tmp = recog.unpivotOperator()?;
			 cast_mut::<_,UnpivotClauseContext >(&mut _localctx).operator = Some(tmp.clone());
			  

			recog.base.set_state(3108);
			recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

			recog.base.set_state(3113);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(366,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(3110);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(365,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3109);
							recog.base.match_token(AS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule errorCapturingIdentifier*/
					recog.base.set_state(3112);
					recog.errorCapturingIdentifier()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unpivotNullClause ----------------
pub type UnpivotNullClauseContextAll<'input> = UnpivotNullClauseContext<'input>;


pub type UnpivotNullClauseContext<'input> = BaseParserRuleContext<'input,UnpivotNullClauseContextExt<'input>>;

#[derive(Clone)]
pub struct UnpivotNullClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for UnpivotNullClauseContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for UnpivotNullClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unpivotNullClause(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_unpivotNullClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for UnpivotNullClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_unpivotNullClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnpivotNullClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unpivotNullClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unpivotNullClause }
}
antlr_rust::tid!{UnpivotNullClauseContextExt<'a>}

impl<'input> UnpivotNullClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnpivotNullClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnpivotNullClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait UnpivotNullClauseContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<UnpivotNullClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token NULLS
/// Returns `None` if there is no child corresponding to token NULLS
fn NULLS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NULLS, 0)
}
/// Retrieves first TerminalNode corresponding to token INCLUDE
/// Returns `None` if there is no child corresponding to token INCLUDE
fn INCLUDE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INCLUDE, 0)
}
/// Retrieves first TerminalNode corresponding to token EXCLUDE
/// Returns `None` if there is no child corresponding to token EXCLUDE
fn EXCLUDE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXCLUDE, 0)
}

}

impl<'input> UnpivotNullClauseContextAttrs<'input> for UnpivotNullClauseContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unpivotNullClause(&mut self,)
	-> Result<Rc<UnpivotNullClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnpivotNullClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 234, RULE_unpivotNullClause);
        let mut _localctx: Rc<UnpivotNullClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3115);
			_la = recog.base.input.la(1);
			if { !(_la==EXCLUDE || _la==INCLUDE) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(3116);
			recog.base.match_token(NULLS,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unpivotOperator ----------------
pub type UnpivotOperatorContextAll<'input> = UnpivotOperatorContext<'input>;


pub type UnpivotOperatorContext<'input> = BaseParserRuleContext<'input,UnpivotOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct UnpivotOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for UnpivotOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for UnpivotOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unpivotOperator(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_unpivotOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for UnpivotOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_unpivotOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnpivotOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unpivotOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unpivotOperator }
}
antlr_rust::tid!{UnpivotOperatorContextExt<'a>}

impl<'input> UnpivotOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnpivotOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnpivotOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait UnpivotOperatorContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<UnpivotOperatorContextExt<'input>>{

fn unpivotSingleValueColumnClause(&self) -> Option<Rc<UnpivotSingleValueColumnClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn unpivotMultiValueColumnClause(&self) -> Option<Rc<UnpivotMultiValueColumnClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> UnpivotOperatorContextAttrs<'input> for UnpivotOperatorContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unpivotOperator(&mut self,)
	-> Result<Rc<UnpivotOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnpivotOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 236, RULE_unpivotOperator);
        let mut _localctx: Rc<UnpivotOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3120);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(367,&mut recog.base)? {
				1 =>{
					{
					/*InvokeRule unpivotSingleValueColumnClause*/
					recog.base.set_state(3118);
					recog.unpivotSingleValueColumnClause()?;

					}
				}
			,
				2 =>{
					{
					/*InvokeRule unpivotMultiValueColumnClause*/
					recog.base.set_state(3119);
					recog.unpivotMultiValueColumnClause()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unpivotSingleValueColumnClause ----------------
pub type UnpivotSingleValueColumnClauseContextAll<'input> = UnpivotSingleValueColumnClauseContext<'input>;


pub type UnpivotSingleValueColumnClauseContext<'input> = BaseParserRuleContext<'input,UnpivotSingleValueColumnClauseContextExt<'input>>;

#[derive(Clone)]
pub struct UnpivotSingleValueColumnClauseContextExt<'input>{
	pub unpivotColumnAndAlias: Option<Rc<UnpivotColumnAndAliasContextAll<'input>>>,
	pub unpivotColumns:Vec<Rc<UnpivotColumnAndAliasContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for UnpivotSingleValueColumnClauseContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for UnpivotSingleValueColumnClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unpivotSingleValueColumnClause(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_unpivotSingleValueColumnClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for UnpivotSingleValueColumnClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_unpivotSingleValueColumnClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnpivotSingleValueColumnClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unpivotSingleValueColumnClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unpivotSingleValueColumnClause }
}
antlr_rust::tid!{UnpivotSingleValueColumnClauseContextExt<'a>}

impl<'input> UnpivotSingleValueColumnClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnpivotSingleValueColumnClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnpivotSingleValueColumnClauseContextExt{
				unpivotColumnAndAlias: None, 
				unpivotColumns: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait UnpivotSingleValueColumnClauseContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<UnpivotSingleValueColumnClauseContextExt<'input>>{

fn unpivotValueColumn(&self) -> Option<Rc<UnpivotValueColumnContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token FOR
/// Returns `None` if there is no child corresponding to token FOR
fn FOR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FOR, 0)
}
fn unpivotNameColumn(&self) -> Option<Rc<UnpivotNameColumnContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token IN
/// Returns `None` if there is no child corresponding to token IN
fn IN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IN, 0)
}
/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
fn unpivotColumnAndAlias_all(&self) ->  Vec<Rc<UnpivotColumnAndAliasContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn unpivotColumnAndAlias(&self, i: usize) -> Option<Rc<UnpivotColumnAndAliasContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> UnpivotSingleValueColumnClauseContextAttrs<'input> for UnpivotSingleValueColumnClauseContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unpivotSingleValueColumnClause(&mut self,)
	-> Result<Rc<UnpivotSingleValueColumnClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnpivotSingleValueColumnClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 238, RULE_unpivotSingleValueColumnClause);
        let mut _localctx: Rc<UnpivotSingleValueColumnClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule unpivotValueColumn*/
			recog.base.set_state(3122);
			recog.unpivotValueColumn()?;

			recog.base.set_state(3123);
			recog.base.match_token(FOR,&mut recog.err_handler)?;

			/*InvokeRule unpivotNameColumn*/
			recog.base.set_state(3124);
			recog.unpivotNameColumn()?;

			recog.base.set_state(3125);
			recog.base.match_token(IN,&mut recog.err_handler)?;

			recog.base.set_state(3126);
			recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

			/*InvokeRule unpivotColumnAndAlias*/
			recog.base.set_state(3127);
			let tmp = recog.unpivotColumnAndAlias()?;
			 cast_mut::<_,UnpivotSingleValueColumnClauseContext >(&mut _localctx).unpivotColumnAndAlias = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,UnpivotSingleValueColumnClauseContext >(&mut _localctx).unpivotColumnAndAlias.clone().unwrap()
			 ;
			 cast_mut::<_,UnpivotSingleValueColumnClauseContext >(&mut _localctx).unpivotColumns.push(temp);
			  
			recog.base.set_state(3132);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(3128);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule unpivotColumnAndAlias*/
				recog.base.set_state(3129);
				let tmp = recog.unpivotColumnAndAlias()?;
				 cast_mut::<_,UnpivotSingleValueColumnClauseContext >(&mut _localctx).unpivotColumnAndAlias = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,UnpivotSingleValueColumnClauseContext >(&mut _localctx).unpivotColumnAndAlias.clone().unwrap()
				 ;
				 cast_mut::<_,UnpivotSingleValueColumnClauseContext >(&mut _localctx).unpivotColumns.push(temp);
				  
				}
				}
				recog.base.set_state(3134);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(3135);
			recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unpivotMultiValueColumnClause ----------------
pub type UnpivotMultiValueColumnClauseContextAll<'input> = UnpivotMultiValueColumnClauseContext<'input>;


pub type UnpivotMultiValueColumnClauseContext<'input> = BaseParserRuleContext<'input,UnpivotMultiValueColumnClauseContextExt<'input>>;

#[derive(Clone)]
pub struct UnpivotMultiValueColumnClauseContextExt<'input>{
	pub unpivotValueColumn: Option<Rc<UnpivotValueColumnContextAll<'input>>>,
	pub unpivotValueColumns:Vec<Rc<UnpivotValueColumnContextAll<'input>>>,
	pub unpivotColumnSet: Option<Rc<UnpivotColumnSetContextAll<'input>>>,
	pub unpivotColumnSets:Vec<Rc<UnpivotColumnSetContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for UnpivotMultiValueColumnClauseContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for UnpivotMultiValueColumnClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unpivotMultiValueColumnClause(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_unpivotMultiValueColumnClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for UnpivotMultiValueColumnClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_unpivotMultiValueColumnClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnpivotMultiValueColumnClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unpivotMultiValueColumnClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unpivotMultiValueColumnClause }
}
antlr_rust::tid!{UnpivotMultiValueColumnClauseContextExt<'a>}

impl<'input> UnpivotMultiValueColumnClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnpivotMultiValueColumnClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnpivotMultiValueColumnClauseContextExt{
				unpivotValueColumn: None, unpivotColumnSet: None, 
				unpivotValueColumns: Vec::new(), unpivotColumnSets: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait UnpivotMultiValueColumnClauseContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<UnpivotMultiValueColumnClauseContextExt<'input>>{

/// Retrieves all `TerminalNode`s corresponding to token LEFT_PAREN in current rule
fn LEFT_PAREN_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LEFT_PAREN, starting from 0.
/// Returns `None` if number of children corresponding to token LEFT_PAREN is less or equal than `i`.
fn LEFT_PAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, i)
}
/// Retrieves all `TerminalNode`s corresponding to token RIGHT_PAREN in current rule
fn RIGHT_PAREN_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token RIGHT_PAREN, starting from 0.
/// Returns `None` if number of children corresponding to token RIGHT_PAREN is less or equal than `i`.
fn RIGHT_PAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, i)
}
/// Retrieves first TerminalNode corresponding to token FOR
/// Returns `None` if there is no child corresponding to token FOR
fn FOR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FOR, 0)
}
fn unpivotNameColumn(&self) -> Option<Rc<UnpivotNameColumnContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token IN
/// Returns `None` if there is no child corresponding to token IN
fn IN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IN, 0)
}
fn unpivotValueColumn_all(&self) ->  Vec<Rc<UnpivotValueColumnContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn unpivotValueColumn(&self, i: usize) -> Option<Rc<UnpivotValueColumnContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn unpivotColumnSet_all(&self) ->  Vec<Rc<UnpivotColumnSetContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn unpivotColumnSet(&self, i: usize) -> Option<Rc<UnpivotColumnSetContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> UnpivotMultiValueColumnClauseContextAttrs<'input> for UnpivotMultiValueColumnClauseContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unpivotMultiValueColumnClause(&mut self,)
	-> Result<Rc<UnpivotMultiValueColumnClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnpivotMultiValueColumnClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 240, RULE_unpivotMultiValueColumnClause);
        let mut _localctx: Rc<UnpivotMultiValueColumnClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3137);
			recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

			/*InvokeRule unpivotValueColumn*/
			recog.base.set_state(3138);
			let tmp = recog.unpivotValueColumn()?;
			 cast_mut::<_,UnpivotMultiValueColumnClauseContext >(&mut _localctx).unpivotValueColumn = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,UnpivotMultiValueColumnClauseContext >(&mut _localctx).unpivotValueColumn.clone().unwrap()
			 ;
			 cast_mut::<_,UnpivotMultiValueColumnClauseContext >(&mut _localctx).unpivotValueColumns.push(temp);
			  
			recog.base.set_state(3143);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(3139);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule unpivotValueColumn*/
				recog.base.set_state(3140);
				let tmp = recog.unpivotValueColumn()?;
				 cast_mut::<_,UnpivotMultiValueColumnClauseContext >(&mut _localctx).unpivotValueColumn = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,UnpivotMultiValueColumnClauseContext >(&mut _localctx).unpivotValueColumn.clone().unwrap()
				 ;
				 cast_mut::<_,UnpivotMultiValueColumnClauseContext >(&mut _localctx).unpivotValueColumns.push(temp);
				  
				}
				}
				recog.base.set_state(3145);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(3146);
			recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

			recog.base.set_state(3147);
			recog.base.match_token(FOR,&mut recog.err_handler)?;

			/*InvokeRule unpivotNameColumn*/
			recog.base.set_state(3148);
			recog.unpivotNameColumn()?;

			recog.base.set_state(3149);
			recog.base.match_token(IN,&mut recog.err_handler)?;

			recog.base.set_state(3150);
			recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

			/*InvokeRule unpivotColumnSet*/
			recog.base.set_state(3151);
			let tmp = recog.unpivotColumnSet()?;
			 cast_mut::<_,UnpivotMultiValueColumnClauseContext >(&mut _localctx).unpivotColumnSet = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,UnpivotMultiValueColumnClauseContext >(&mut _localctx).unpivotColumnSet.clone().unwrap()
			 ;
			 cast_mut::<_,UnpivotMultiValueColumnClauseContext >(&mut _localctx).unpivotColumnSets.push(temp);
			  
			recog.base.set_state(3156);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(3152);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule unpivotColumnSet*/
				recog.base.set_state(3153);
				let tmp = recog.unpivotColumnSet()?;
				 cast_mut::<_,UnpivotMultiValueColumnClauseContext >(&mut _localctx).unpivotColumnSet = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,UnpivotMultiValueColumnClauseContext >(&mut _localctx).unpivotColumnSet.clone().unwrap()
				 ;
				 cast_mut::<_,UnpivotMultiValueColumnClauseContext >(&mut _localctx).unpivotColumnSets.push(temp);
				  
				}
				}
				recog.base.set_state(3158);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(3159);
			recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unpivotColumnSet ----------------
pub type UnpivotColumnSetContextAll<'input> = UnpivotColumnSetContext<'input>;


pub type UnpivotColumnSetContext<'input> = BaseParserRuleContext<'input,UnpivotColumnSetContextExt<'input>>;

#[derive(Clone)]
pub struct UnpivotColumnSetContextExt<'input>{
	pub unpivotColumn: Option<Rc<UnpivotColumnContextAll<'input>>>,
	pub unpivotColumns:Vec<Rc<UnpivotColumnContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for UnpivotColumnSetContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for UnpivotColumnSetContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unpivotColumnSet(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_unpivotColumnSet(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for UnpivotColumnSetContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_unpivotColumnSet(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnpivotColumnSetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unpivotColumnSet }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unpivotColumnSet }
}
antlr_rust::tid!{UnpivotColumnSetContextExt<'a>}

impl<'input> UnpivotColumnSetContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnpivotColumnSetContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnpivotColumnSetContextExt{
				unpivotColumn: None, 
				unpivotColumns: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait UnpivotColumnSetContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<UnpivotColumnSetContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
fn unpivotColumn_all(&self) ->  Vec<Rc<UnpivotColumnContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn unpivotColumn(&self, i: usize) -> Option<Rc<UnpivotColumnContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
fn unpivotAlias(&self) -> Option<Rc<UnpivotAliasContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> UnpivotColumnSetContextAttrs<'input> for UnpivotColumnSetContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unpivotColumnSet(&mut self,)
	-> Result<Rc<UnpivotColumnSetContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnpivotColumnSetContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 242, RULE_unpivotColumnSet);
        let mut _localctx: Rc<UnpivotColumnSetContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3161);
			recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

			/*InvokeRule unpivotColumn*/
			recog.base.set_state(3162);
			let tmp = recog.unpivotColumn()?;
			 cast_mut::<_,UnpivotColumnSetContext >(&mut _localctx).unpivotColumn = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,UnpivotColumnSetContext >(&mut _localctx).unpivotColumn.clone().unwrap()
			 ;
			 cast_mut::<_,UnpivotColumnSetContext >(&mut _localctx).unpivotColumns.push(temp);
			  
			recog.base.set_state(3167);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(3163);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule unpivotColumn*/
				recog.base.set_state(3164);
				let tmp = recog.unpivotColumn()?;
				 cast_mut::<_,UnpivotColumnSetContext >(&mut _localctx).unpivotColumn = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,UnpivotColumnSetContext >(&mut _localctx).unpivotColumn.clone().unwrap()
				 ;
				 cast_mut::<_,UnpivotColumnSetContext >(&mut _localctx).unpivotColumns.push(temp);
				  
				}
				}
				recog.base.set_state(3169);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(3170);
			recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

			recog.base.set_state(3172);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(372,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule unpivotAlias*/
					recog.base.set_state(3171);
					recog.unpivotAlias()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unpivotValueColumn ----------------
pub type UnpivotValueColumnContextAll<'input> = UnpivotValueColumnContext<'input>;


pub type UnpivotValueColumnContext<'input> = BaseParserRuleContext<'input,UnpivotValueColumnContextExt<'input>>;

#[derive(Clone)]
pub struct UnpivotValueColumnContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for UnpivotValueColumnContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for UnpivotValueColumnContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unpivotValueColumn(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_unpivotValueColumn(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for UnpivotValueColumnContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_unpivotValueColumn(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnpivotValueColumnContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unpivotValueColumn }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unpivotValueColumn }
}
antlr_rust::tid!{UnpivotValueColumnContextExt<'a>}

impl<'input> UnpivotValueColumnContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnpivotValueColumnContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnpivotValueColumnContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait UnpivotValueColumnContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<UnpivotValueColumnContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> UnpivotValueColumnContextAttrs<'input> for UnpivotValueColumnContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unpivotValueColumn(&mut self,)
	-> Result<Rc<UnpivotValueColumnContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnpivotValueColumnContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 244, RULE_unpivotValueColumn);
        let mut _localctx: Rc<UnpivotValueColumnContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(3174);
			recog.identifier()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unpivotNameColumn ----------------
pub type UnpivotNameColumnContextAll<'input> = UnpivotNameColumnContext<'input>;


pub type UnpivotNameColumnContext<'input> = BaseParserRuleContext<'input,UnpivotNameColumnContextExt<'input>>;

#[derive(Clone)]
pub struct UnpivotNameColumnContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for UnpivotNameColumnContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for UnpivotNameColumnContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unpivotNameColumn(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_unpivotNameColumn(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for UnpivotNameColumnContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_unpivotNameColumn(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnpivotNameColumnContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unpivotNameColumn }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unpivotNameColumn }
}
antlr_rust::tid!{UnpivotNameColumnContextExt<'a>}

impl<'input> UnpivotNameColumnContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnpivotNameColumnContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnpivotNameColumnContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait UnpivotNameColumnContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<UnpivotNameColumnContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> UnpivotNameColumnContextAttrs<'input> for UnpivotNameColumnContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unpivotNameColumn(&mut self,)
	-> Result<Rc<UnpivotNameColumnContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnpivotNameColumnContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 246, RULE_unpivotNameColumn);
        let mut _localctx: Rc<UnpivotNameColumnContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(3176);
			recog.identifier()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unpivotColumnAndAlias ----------------
pub type UnpivotColumnAndAliasContextAll<'input> = UnpivotColumnAndAliasContext<'input>;


pub type UnpivotColumnAndAliasContext<'input> = BaseParserRuleContext<'input,UnpivotColumnAndAliasContextExt<'input>>;

#[derive(Clone)]
pub struct UnpivotColumnAndAliasContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for UnpivotColumnAndAliasContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for UnpivotColumnAndAliasContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unpivotColumnAndAlias(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_unpivotColumnAndAlias(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for UnpivotColumnAndAliasContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_unpivotColumnAndAlias(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnpivotColumnAndAliasContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unpivotColumnAndAlias }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unpivotColumnAndAlias }
}
antlr_rust::tid!{UnpivotColumnAndAliasContextExt<'a>}

impl<'input> UnpivotColumnAndAliasContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnpivotColumnAndAliasContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnpivotColumnAndAliasContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait UnpivotColumnAndAliasContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<UnpivotColumnAndAliasContextExt<'input>>{

fn unpivotColumn(&self) -> Option<Rc<UnpivotColumnContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn unpivotAlias(&self) -> Option<Rc<UnpivotAliasContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> UnpivotColumnAndAliasContextAttrs<'input> for UnpivotColumnAndAliasContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unpivotColumnAndAlias(&mut self,)
	-> Result<Rc<UnpivotColumnAndAliasContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnpivotColumnAndAliasContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 248, RULE_unpivotColumnAndAlias);
        let mut _localctx: Rc<UnpivotColumnAndAliasContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule unpivotColumn*/
			recog.base.set_state(3178);
			recog.unpivotColumn()?;

			recog.base.set_state(3180);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(373,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule unpivotAlias*/
					recog.base.set_state(3179);
					recog.unpivotAlias()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unpivotColumn ----------------
pub type UnpivotColumnContextAll<'input> = UnpivotColumnContext<'input>;


pub type UnpivotColumnContext<'input> = BaseParserRuleContext<'input,UnpivotColumnContextExt<'input>>;

#[derive(Clone)]
pub struct UnpivotColumnContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for UnpivotColumnContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for UnpivotColumnContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unpivotColumn(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_unpivotColumn(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for UnpivotColumnContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_unpivotColumn(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnpivotColumnContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unpivotColumn }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unpivotColumn }
}
antlr_rust::tid!{UnpivotColumnContextExt<'a>}

impl<'input> UnpivotColumnContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnpivotColumnContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnpivotColumnContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait UnpivotColumnContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<UnpivotColumnContextExt<'input>>{

fn multipartIdentifier(&self) -> Option<Rc<MultipartIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> UnpivotColumnContextAttrs<'input> for UnpivotColumnContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unpivotColumn(&mut self,)
	-> Result<Rc<UnpivotColumnContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnpivotColumnContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 250, RULE_unpivotColumn);
        let mut _localctx: Rc<UnpivotColumnContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule multipartIdentifier*/
			recog.base.set_state(3182);
			recog.multipartIdentifier()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unpivotAlias ----------------
pub type UnpivotAliasContextAll<'input> = UnpivotAliasContext<'input>;


pub type UnpivotAliasContext<'input> = BaseParserRuleContext<'input,UnpivotAliasContextExt<'input>>;

#[derive(Clone)]
pub struct UnpivotAliasContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for UnpivotAliasContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for UnpivotAliasContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unpivotAlias(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_unpivotAlias(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for UnpivotAliasContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_unpivotAlias(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnpivotAliasContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unpivotAlias }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unpivotAlias }
}
antlr_rust::tid!{UnpivotAliasContextExt<'a>}

impl<'input> UnpivotAliasContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnpivotAliasContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnpivotAliasContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait UnpivotAliasContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<UnpivotAliasContextExt<'input>>{

fn errorCapturingIdentifier(&self) -> Option<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}

}

impl<'input> UnpivotAliasContextAttrs<'input> for UnpivotAliasContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unpivotAlias(&mut self,)
	-> Result<Rc<UnpivotAliasContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnpivotAliasContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 252, RULE_unpivotAlias);
        let mut _localctx: Rc<UnpivotAliasContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3185);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(374,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(3184);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			/*InvokeRule errorCapturingIdentifier*/
			recog.base.set_state(3187);
			recog.errorCapturingIdentifier()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- lateralView ----------------
pub type LateralViewContextAll<'input> = LateralViewContext<'input>;


pub type LateralViewContext<'input> = BaseParserRuleContext<'input,LateralViewContextExt<'input>>;

#[derive(Clone)]
pub struct LateralViewContextExt<'input>{
	pub tblName: Option<Rc<IdentifierContextAll<'input>>>,
	pub identifier: Option<Rc<IdentifierContextAll<'input>>>,
	pub colName:Vec<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for LateralViewContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for LateralViewContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_lateralView(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_lateralView(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for LateralViewContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_lateralView(self);
	}
}

impl<'input> CustomRuleContext<'input> for LateralViewContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_lateralView }
	//fn type_rule_index() -> usize where Self: Sized { RULE_lateralView }
}
antlr_rust::tid!{LateralViewContextExt<'a>}

impl<'input> LateralViewContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LateralViewContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LateralViewContextExt{
				tblName: None, identifier: None, 
				colName: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait LateralViewContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<LateralViewContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LATERAL
/// Returns `None` if there is no child corresponding to token LATERAL
fn LATERAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LATERAL, 0)
}
/// Retrieves first TerminalNode corresponding to token VIEW
/// Returns `None` if there is no child corresponding to token VIEW
fn VIEW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VIEW, 0)
}
fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token OUTER
/// Returns `None` if there is no child corresponding to token OUTER
fn OUTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OUTER, 0)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}

}

impl<'input> LateralViewContextAttrs<'input> for LateralViewContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn lateralView(&mut self,)
	-> Result<Rc<LateralViewContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LateralViewContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 254, RULE_lateralView);
        let mut _localctx: Rc<LateralViewContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3189);
			recog.base.match_token(LATERAL,&mut recog.err_handler)?;

			recog.base.set_state(3190);
			recog.base.match_token(VIEW,&mut recog.err_handler)?;

			recog.base.set_state(3192);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(375,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(3191);
					recog.base.match_token(OUTER,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			/*InvokeRule qualifiedName*/
			recog.base.set_state(3194);
			recog.qualifiedName()?;

			recog.base.set_state(3195);
			recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

			recog.base.set_state(3204);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(377,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule expression*/
					recog.base.set_state(3196);
					recog.expression()?;

					recog.base.set_state(3201);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(3197);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule expression*/
						recog.base.set_state(3198);
						recog.expression()?;

						}
						}
						recog.base.set_state(3203);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}

				_ => {}
			}
			recog.base.set_state(3206);
			recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

			/*InvokeRule identifier*/
			recog.base.set_state(3207);
			let tmp = recog.identifier()?;
			 cast_mut::<_,LateralViewContext >(&mut _localctx).tblName = Some(tmp.clone());
			  

			recog.base.set_state(3219);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(380,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(3209);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(378,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3208);
							recog.base.match_token(AS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule identifier*/
					recog.base.set_state(3211);
					let tmp = recog.identifier()?;
					 cast_mut::<_,LateralViewContext >(&mut _localctx).identifier = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,LateralViewContext >(&mut _localctx).identifier.clone().unwrap()
					 ;
					 cast_mut::<_,LateralViewContext >(&mut _localctx).colName.push(temp);
					  
					recog.base.set_state(3216);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(379,&mut recog.base)?;
					while { _alt!=2 && _alt!=INVALID_ALT } {
						if _alt==1 {
							{
							{
							recog.base.set_state(3212);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule identifier*/
							recog.base.set_state(3213);
							let tmp = recog.identifier()?;
							 cast_mut::<_,LateralViewContext >(&mut _localctx).identifier = Some(tmp.clone());
							  

							let temp =  cast_mut::<_,LateralViewContext >(&mut _localctx).identifier.clone().unwrap()
							 ;
							 cast_mut::<_,LateralViewContext >(&mut _localctx).colName.push(temp);
							  
							}
							} 
						}
						recog.base.set_state(3218);
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(379,&mut recog.base)?;
					}
					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- watermarkClause ----------------
pub type WatermarkClauseContextAll<'input> = WatermarkClauseContext<'input>;


pub type WatermarkClauseContext<'input> = BaseParserRuleContext<'input,WatermarkClauseContextExt<'input>>;

#[derive(Clone)]
pub struct WatermarkClauseContextExt<'input>{
	pub colName: Option<Rc<NamedExpressionContextAll<'input>>>,
	pub delay: Option<Rc<IntervalContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for WatermarkClauseContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for WatermarkClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_watermarkClause(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_watermarkClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for WatermarkClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_watermarkClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for WatermarkClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_watermarkClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_watermarkClause }
}
antlr_rust::tid!{WatermarkClauseContextExt<'a>}

impl<'input> WatermarkClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WatermarkClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WatermarkClauseContextExt{
				colName: None, delay: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait WatermarkClauseContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<WatermarkClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WATERMARK
/// Returns `None` if there is no child corresponding to token WATERMARK
fn WATERMARK(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WATERMARK, 0)
}
/// Retrieves first TerminalNode corresponding to token DELAY
/// Returns `None` if there is no child corresponding to token DELAY
fn DELAY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DELAY, 0)
}
/// Retrieves first TerminalNode corresponding to token OF
/// Returns `None` if there is no child corresponding to token OF
fn OF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OF, 0)
}
fn namedExpression(&self) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn interval(&self) -> Option<Rc<IntervalContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> WatermarkClauseContextAttrs<'input> for WatermarkClauseContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn watermarkClause(&mut self,)
	-> Result<Rc<WatermarkClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WatermarkClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 256, RULE_watermarkClause);
        let mut _localctx: Rc<WatermarkClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3221);
			recog.base.match_token(WATERMARK,&mut recog.err_handler)?;

			/*InvokeRule namedExpression*/
			recog.base.set_state(3222);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,WatermarkClauseContext >(&mut _localctx).colName = Some(tmp.clone());
			  

			recog.base.set_state(3223);
			recog.base.match_token(DELAY,&mut recog.err_handler)?;

			recog.base.set_state(3224);
			recog.base.match_token(OF,&mut recog.err_handler)?;

			/*InvokeRule interval*/
			recog.base.set_state(3225);
			let tmp = recog.interval()?;
			 cast_mut::<_,WatermarkClauseContext >(&mut _localctx).delay = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- setQuantifier ----------------
pub type SetQuantifierContextAll<'input> = SetQuantifierContext<'input>;


pub type SetQuantifierContext<'input> = BaseParserRuleContext<'input,SetQuantifierContextExt<'input>>;

#[derive(Clone)]
pub struct SetQuantifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SetQuantifierContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SetQuantifierContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_setQuantifier(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_setQuantifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SetQuantifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_setQuantifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetQuantifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setQuantifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setQuantifier }
}
antlr_rust::tid!{SetQuantifierContextExt<'a>}

impl<'input> SetQuantifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SetQuantifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SetQuantifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SetQuantifierContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SetQuantifierContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DISTINCT
/// Returns `None` if there is no child corresponding to token DISTINCT
fn DISTINCT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DISTINCT, 0)
}
/// Retrieves first TerminalNode corresponding to token ALL
/// Returns `None` if there is no child corresponding to token ALL
fn ALL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ALL, 0)
}

}

impl<'input> SetQuantifierContextAttrs<'input> for SetQuantifierContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn setQuantifier(&mut self,)
	-> Result<Rc<SetQuantifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SetQuantifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 258, RULE_setQuantifier);
        let mut _localctx: Rc<SetQuantifierContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3227);
			_la = recog.base.input.la(1);
			if { !(_la==ALL || _la==DISTINCT) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- relation ----------------
pub type RelationContextAll<'input> = RelationContext<'input>;


pub type RelationContext<'input> = BaseParserRuleContext<'input,RelationContextExt<'input>>;

#[derive(Clone)]
pub struct RelationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for RelationContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for RelationContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_relation(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_relation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for RelationContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_relation(self);
	}
}

impl<'input> CustomRuleContext<'input> for RelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relation }
}
antlr_rust::tid!{RelationContextExt<'a>}

impl<'input> RelationContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RelationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RelationContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RelationContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<RelationContextExt<'input>>{

fn relationPrimary(&self) -> Option<Rc<RelationPrimaryContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LATERAL
/// Returns `None` if there is no child corresponding to token LATERAL
fn LATERAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LATERAL, 0)
}
fn relationExtension_all(&self) ->  Vec<Rc<RelationExtensionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn relationExtension(&self, i: usize) -> Option<Rc<RelationExtensionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> RelationContextAttrs<'input> for RelationContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn relation(&mut self,)
	-> Result<Rc<RelationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RelationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 260, RULE_relation);
        let mut _localctx: Rc<RelationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3230);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(381,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(3229);
					recog.base.match_token(LATERAL,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			/*InvokeRule relationPrimary*/
			recog.base.set_state(3232);
			recog.relationPrimary()?;

			recog.base.set_state(3236);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(382,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					/*InvokeRule relationExtension*/
					recog.base.set_state(3233);
					recog.relationExtension()?;

					}
					} 
				}
				recog.base.set_state(3238);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(382,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- relationExtension ----------------
pub type RelationExtensionContextAll<'input> = RelationExtensionContext<'input>;


pub type RelationExtensionContext<'input> = BaseParserRuleContext<'input,RelationExtensionContextExt<'input>>;

#[derive(Clone)]
pub struct RelationExtensionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for RelationExtensionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for RelationExtensionContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_relationExtension(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_relationExtension(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for RelationExtensionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_relationExtension(self);
	}
}

impl<'input> CustomRuleContext<'input> for RelationExtensionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relationExtension }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relationExtension }
}
antlr_rust::tid!{RelationExtensionContextExt<'a>}

impl<'input> RelationExtensionContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RelationExtensionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RelationExtensionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RelationExtensionContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<RelationExtensionContextExt<'input>>{

fn joinRelation(&self) -> Option<Rc<JoinRelationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn pivotClause(&self) -> Option<Rc<PivotClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn unpivotClause(&self) -> Option<Rc<UnpivotClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> RelationExtensionContextAttrs<'input> for RelationExtensionContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn relationExtension(&mut self,)
	-> Result<Rc<RelationExtensionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RelationExtensionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 262, RULE_relationExtension);
        let mut _localctx: Rc<RelationExtensionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3242);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ANTI | CROSS | FULL | INNER | JOIN | LEFT | NATURAL | RIGHT | SEMI 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule joinRelation*/
					recog.base.set_state(3239);
					recog.joinRelation()?;

					}
				}

			 PIVOT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule pivotClause*/
					recog.base.set_state(3240);
					recog.pivotClause()?;

					}
				}

			 UNPIVOT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule unpivotClause*/
					recog.base.set_state(3241);
					recog.unpivotClause()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- joinRelation ----------------
pub type JoinRelationContextAll<'input> = JoinRelationContext<'input>;


pub type JoinRelationContext<'input> = BaseParserRuleContext<'input,JoinRelationContextExt<'input>>;

#[derive(Clone)]
pub struct JoinRelationContextExt<'input>{
	pub right: Option<Rc<RelationPrimaryContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for JoinRelationContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for JoinRelationContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_joinRelation(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_joinRelation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for JoinRelationContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_joinRelation(self);
	}
}

impl<'input> CustomRuleContext<'input> for JoinRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_joinRelation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_joinRelation }
}
antlr_rust::tid!{JoinRelationContextExt<'a>}

impl<'input> JoinRelationContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JoinRelationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JoinRelationContextExt{
				right: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait JoinRelationContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<JoinRelationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token JOIN
/// Returns `None` if there is no child corresponding to token JOIN
fn JOIN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(JOIN, 0)
}
fn relationPrimary(&self) -> Option<Rc<RelationPrimaryContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn joinType(&self) -> Option<Rc<JoinTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LATERAL
/// Returns `None` if there is no child corresponding to token LATERAL
fn LATERAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LATERAL, 0)
}
fn joinCriteria(&self) -> Option<Rc<JoinCriteriaContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token NATURAL
/// Returns `None` if there is no child corresponding to token NATURAL
fn NATURAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NATURAL, 0)
}

}

impl<'input> JoinRelationContextAttrs<'input> for JoinRelationContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn joinRelation(&mut self,)
	-> Result<Rc<JoinRelationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JoinRelationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 264, RULE_joinRelation);
        let mut _localctx: Rc<JoinRelationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3261);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ANTI | CROSS | FULL | INNER | JOIN | LEFT | RIGHT | SEMI 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					{
					/*InvokeRule joinType*/
					recog.base.set_state(3244);
					recog.joinType()?;

					}
					recog.base.set_state(3245);
					recog.base.match_token(JOIN,&mut recog.err_handler)?;

					recog.base.set_state(3247);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(384,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3246);
							recog.base.match_token(LATERAL,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule relationPrimary*/
					recog.base.set_state(3249);
					let tmp = recog.relationPrimary()?;
					 cast_mut::<_,JoinRelationContext >(&mut _localctx).right = Some(tmp.clone());
					  

					recog.base.set_state(3251);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(385,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule joinCriteria*/
							recog.base.set_state(3250);
							recog.joinCriteria()?;

							}
						}

						_ => {}
					}
					}
				}

			 NATURAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3253);
					recog.base.match_token(NATURAL,&mut recog.err_handler)?;

					/*InvokeRule joinType*/
					recog.base.set_state(3254);
					recog.joinType()?;

					recog.base.set_state(3255);
					recog.base.match_token(JOIN,&mut recog.err_handler)?;

					recog.base.set_state(3257);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(386,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3256);
							recog.base.match_token(LATERAL,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule relationPrimary*/
					recog.base.set_state(3259);
					let tmp = recog.relationPrimary()?;
					 cast_mut::<_,JoinRelationContext >(&mut _localctx).right = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- joinType ----------------
pub type JoinTypeContextAll<'input> = JoinTypeContext<'input>;


pub type JoinTypeContext<'input> = BaseParserRuleContext<'input,JoinTypeContextExt<'input>>;

#[derive(Clone)]
pub struct JoinTypeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for JoinTypeContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for JoinTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_joinType(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_joinType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for JoinTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_joinType(self);
	}
}

impl<'input> CustomRuleContext<'input> for JoinTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_joinType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_joinType }
}
antlr_rust::tid!{JoinTypeContextExt<'a>}

impl<'input> JoinTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JoinTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JoinTypeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait JoinTypeContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<JoinTypeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token INNER
/// Returns `None` if there is no child corresponding to token INNER
fn INNER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INNER, 0)
}
/// Retrieves first TerminalNode corresponding to token CROSS
/// Returns `None` if there is no child corresponding to token CROSS
fn CROSS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CROSS, 0)
}
/// Retrieves first TerminalNode corresponding to token LEFT
/// Returns `None` if there is no child corresponding to token LEFT
fn LEFT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT, 0)
}
/// Retrieves first TerminalNode corresponding to token OUTER
/// Returns `None` if there is no child corresponding to token OUTER
fn OUTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OUTER, 0)
}
/// Retrieves first TerminalNode corresponding to token SEMI
/// Returns `None` if there is no child corresponding to token SEMI
fn SEMI(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SEMI, 0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT
/// Returns `None` if there is no child corresponding to token RIGHT
fn RIGHT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT, 0)
}
/// Retrieves first TerminalNode corresponding to token FULL
/// Returns `None` if there is no child corresponding to token FULL
fn FULL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FULL, 0)
}
/// Retrieves first TerminalNode corresponding to token ANTI
/// Returns `None` if there is no child corresponding to token ANTI
fn ANTI(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ANTI, 0)
}

}

impl<'input> JoinTypeContextAttrs<'input> for JoinTypeContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn joinType(&mut self,)
	-> Result<Rc<JoinTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JoinTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 266, RULE_joinType);
        let mut _localctx: Rc<JoinTypeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3287);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(394,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3264);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==INNER {
						{
						recog.base.set_state(3263);
						recog.base.match_token(INNER,&mut recog.err_handler)?;

						}
					}

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3266);
					recog.base.match_token(CROSS,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(3267);
					recog.base.match_token(LEFT,&mut recog.err_handler)?;

					recog.base.set_state(3269);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OUTER {
						{
						recog.base.set_state(3268);
						recog.base.match_token(OUTER,&mut recog.err_handler)?;

						}
					}

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(3272);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LEFT {
						{
						recog.base.set_state(3271);
						recog.base.match_token(LEFT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3274);
					recog.base.match_token(SEMI,&mut recog.err_handler)?;

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					recog.base.set_state(3275);
					recog.base.match_token(RIGHT,&mut recog.err_handler)?;

					recog.base.set_state(3277);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OUTER {
						{
						recog.base.set_state(3276);
						recog.base.match_token(OUTER,&mut recog.err_handler)?;

						}
					}

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					recog.base.set_state(3279);
					recog.base.match_token(FULL,&mut recog.err_handler)?;

					recog.base.set_state(3281);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==OUTER {
						{
						recog.base.set_state(3280);
						recog.base.match_token(OUTER,&mut recog.err_handler)?;

						}
					}

					}
				}
			,
				7 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					recog.base.set_state(3284);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LEFT {
						{
						recog.base.set_state(3283);
						recog.base.match_token(LEFT,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3286);
					recog.base.match_token(ANTI,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- joinCriteria ----------------
pub type JoinCriteriaContextAll<'input> = JoinCriteriaContext<'input>;


pub type JoinCriteriaContext<'input> = BaseParserRuleContext<'input,JoinCriteriaContextExt<'input>>;

#[derive(Clone)]
pub struct JoinCriteriaContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for JoinCriteriaContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for JoinCriteriaContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_joinCriteria(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_joinCriteria(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for JoinCriteriaContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_joinCriteria(self);
	}
}

impl<'input> CustomRuleContext<'input> for JoinCriteriaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_joinCriteria }
	//fn type_rule_index() -> usize where Self: Sized { RULE_joinCriteria }
}
antlr_rust::tid!{JoinCriteriaContextExt<'a>}

impl<'input> JoinCriteriaContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JoinCriteriaContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JoinCriteriaContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait JoinCriteriaContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<JoinCriteriaContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ON
/// Returns `None` if there is no child corresponding to token ON
fn ON(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ON, 0)
}
fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token USING
/// Returns `None` if there is no child corresponding to token USING
fn USING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(USING, 0)
}
fn identifierList(&self) -> Option<Rc<IdentifierListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> JoinCriteriaContextAttrs<'input> for JoinCriteriaContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn joinCriteria(&mut self,)
	-> Result<Rc<JoinCriteriaContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JoinCriteriaContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 268, RULE_joinCriteria);
        let mut _localctx: Rc<JoinCriteriaContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3293);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ON 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3289);
					recog.base.match_token(ON,&mut recog.err_handler)?;

					/*InvokeRule booleanExpression*/
					recog.base.set_state(3290);
					recog.booleanExpression_rec(0)?;

					}
				}

			 USING 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3291);
					recog.base.match_token(USING,&mut recog.err_handler)?;

					/*InvokeRule identifierList*/
					recog.base.set_state(3292);
					recog.identifierList()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- sample ----------------
pub type SampleContextAll<'input> = SampleContext<'input>;


pub type SampleContext<'input> = BaseParserRuleContext<'input,SampleContextExt<'input>>;

#[derive(Clone)]
pub struct SampleContextExt<'input>{
	pub seed: Option<Rc<IntegerValueContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SampleContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SampleContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_sample(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_sample(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SampleContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_sample(self);
	}
}

impl<'input> CustomRuleContext<'input> for SampleContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sample }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sample }
}
antlr_rust::tid!{SampleContextExt<'a>}

impl<'input> SampleContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SampleContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SampleContextExt{
				seed: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SampleContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SampleContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token TABLESAMPLE
/// Returns `None` if there is no child corresponding to token TABLESAMPLE
fn TABLESAMPLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TABLESAMPLE, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token LEFT_PAREN in current rule
fn LEFT_PAREN_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LEFT_PAREN, starting from 0.
/// Returns `None` if number of children corresponding to token LEFT_PAREN is less or equal than `i`.
fn LEFT_PAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, i)
}
/// Retrieves all `TerminalNode`s corresponding to token RIGHT_PAREN in current rule
fn RIGHT_PAREN_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token RIGHT_PAREN, starting from 0.
/// Returns `None` if number of children corresponding to token RIGHT_PAREN is less or equal than `i`.
fn RIGHT_PAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, i)
}
fn sampleMethod(&self) -> Option<Rc<SampleMethodContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token REPEATABLE
/// Returns `None` if there is no child corresponding to token REPEATABLE
fn REPEATABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(REPEATABLE, 0)
}
fn integerValue(&self) -> Option<Rc<IntegerValueContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SampleContextAttrs<'input> for SampleContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn sample(&mut self,)
	-> Result<Rc<SampleContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SampleContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 270, RULE_sample);
        let mut _localctx: Rc<SampleContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3295);
			recog.base.match_token(TABLESAMPLE,&mut recog.err_handler)?;

			recog.base.set_state(3296);
			recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

			recog.base.set_state(3298);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(396,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule sampleMethod*/
					recog.base.set_state(3297);
					recog.sampleMethod()?;

					}
				}

				_ => {}
			}
			recog.base.set_state(3300);
			recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

			recog.base.set_state(3306);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(397,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(3301);
					recog.base.match_token(REPEATABLE,&mut recog.err_handler)?;

					recog.base.set_state(3302);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule integerValue*/
					recog.base.set_state(3303);
					let tmp = recog.integerValue()?;
					 cast_mut::<_,SampleContext >(&mut _localctx).seed = Some(tmp.clone());
					  

					recog.base.set_state(3304);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- sampleMethod ----------------
#[derive(Debug)]
pub enum SampleMethodContextAll<'input>{
	SampleByRowsContext(SampleByRowsContext<'input>),
	SampleByPercentileContext(SampleByPercentileContext<'input>),
	SampleByBucketContext(SampleByBucketContext<'input>),
	SampleByBytesContext(SampleByBytesContext<'input>),
Error(SampleMethodContext<'input>)
}
antlr_rust::tid!{SampleMethodContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for SampleMethodContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for SampleMethodContextAll<'input>{}

impl<'input> Deref for SampleMethodContextAll<'input>{
	type Target = dyn SampleMethodContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use SampleMethodContextAll::*;
		match self{
			SampleByRowsContext(inner) => inner,
			SampleByPercentileContext(inner) => inner,
			SampleByBucketContext(inner) => inner,
			SampleByBytesContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SampleMethodContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SampleMethodContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type SampleMethodContext<'input> = BaseParserRuleContext<'input,SampleMethodContextExt<'input>>;

#[derive(Clone)]
pub struct SampleMethodContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SampleMethodContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SampleMethodContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SampleMethodContext<'input>{
}

impl<'input> CustomRuleContext<'input> for SampleMethodContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sampleMethod }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sampleMethod }
}
antlr_rust::tid!{SampleMethodContextExt<'a>}

impl<'input> SampleMethodContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SampleMethodContextAll<'input>> {
		Rc::new(
		SampleMethodContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SampleMethodContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait SampleMethodContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SampleMethodContextExt<'input>>{


}

impl<'input> SampleMethodContextAttrs<'input> for SampleMethodContext<'input>{}

pub type SampleByRowsContext<'input> = BaseParserRuleContext<'input,SampleByRowsContextExt<'input>>;

pub trait SampleByRowsContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token ROWS
	/// Returns `None` if there is no child corresponding to token ROWS
	fn ROWS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ROWS, 0)
	}
}

impl<'input> SampleByRowsContextAttrs<'input> for SampleByRowsContext<'input>{}

pub struct SampleByRowsContextExt<'input>{
	base:SampleMethodContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SampleByRowsContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SampleByRowsContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SampleByRowsContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_sampleByRows(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_sampleByRows(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SampleByRowsContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_sampleByRows(self);
	}
}

impl<'input> CustomRuleContext<'input> for SampleByRowsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sampleMethod }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sampleMethod }
}

impl<'input> Borrow<SampleMethodContextExt<'input>> for SampleByRowsContext<'input>{
	fn borrow(&self) -> &SampleMethodContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<SampleMethodContextExt<'input>> for SampleByRowsContext<'input>{
	fn borrow_mut(&mut self) -> &mut SampleMethodContextExt<'input> { &mut self.base }
}

impl<'input> SampleMethodContextAttrs<'input> for SampleByRowsContext<'input> {}

impl<'input> SampleByRowsContextExt<'input>{
	fn new(ctx: &dyn SampleMethodContextAttrs<'input>) -> Rc<SampleMethodContextAll<'input>>  {
		Rc::new(
			SampleMethodContextAll::SampleByRowsContext(
				BaseParserRuleContext::copy_from(ctx,SampleByRowsContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SampleByPercentileContext<'input> = BaseParserRuleContext<'input,SampleByPercentileContextExt<'input>>;

pub trait SampleByPercentileContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token PERCENTLIT
	/// Returns `None` if there is no child corresponding to token PERCENTLIT
	fn PERCENTLIT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(PERCENTLIT, 0)
	}
	fn integerValue(&self) -> Option<Rc<IntegerValueContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token DECIMAL_VALUE
	/// Returns `None` if there is no child corresponding to token DECIMAL_VALUE
	fn DECIMAL_VALUE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DECIMAL_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
}

impl<'input> SampleByPercentileContextAttrs<'input> for SampleByPercentileContext<'input>{}

pub struct SampleByPercentileContextExt<'input>{
	base:SampleMethodContextExt<'input>,
	pub negativeSign: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SampleByPercentileContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SampleByPercentileContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SampleByPercentileContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_sampleByPercentile(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_sampleByPercentile(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SampleByPercentileContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_sampleByPercentile(self);
	}
}

impl<'input> CustomRuleContext<'input> for SampleByPercentileContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sampleMethod }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sampleMethod }
}

impl<'input> Borrow<SampleMethodContextExt<'input>> for SampleByPercentileContext<'input>{
	fn borrow(&self) -> &SampleMethodContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<SampleMethodContextExt<'input>> for SampleByPercentileContext<'input>{
	fn borrow_mut(&mut self) -> &mut SampleMethodContextExt<'input> { &mut self.base }
}

impl<'input> SampleMethodContextAttrs<'input> for SampleByPercentileContext<'input> {}

impl<'input> SampleByPercentileContextExt<'input>{
	fn new(ctx: &dyn SampleMethodContextAttrs<'input>) -> Rc<SampleMethodContextAll<'input>>  {
		Rc::new(
			SampleMethodContextAll::SampleByPercentileContext(
				BaseParserRuleContext::copy_from(ctx,SampleByPercentileContextExt{
					negativeSign:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SampleByBucketContext<'input> = BaseParserRuleContext<'input,SampleByBucketContextExt<'input>>;

pub trait SampleByBucketContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token OUT
	/// Returns `None` if there is no child corresponding to token OUT
	fn OUT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(OUT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OF
	/// Returns `None` if there is no child corresponding to token OF
	fn OF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(OF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token BUCKET
	/// Returns `None` if there is no child corresponding to token BUCKET
	fn BUCKET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(BUCKET, 0)
	}
	fn integerValue_all(&self) ->  Vec<Rc<IntegerValueContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn integerValue(&self, i: usize) -> Option<Rc<IntegerValueContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token ON
	/// Returns `None` if there is no child corresponding to token ON
	fn ON(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ON, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
}

impl<'input> SampleByBucketContextAttrs<'input> for SampleByBucketContext<'input>{}

pub struct SampleByBucketContextExt<'input>{
	base:SampleMethodContextExt<'input>,
	pub sampleType: Option<TokenType<'input>>,
	pub numerator: Option<Rc<IntegerValueContextAll<'input>>>,
	pub denominator: Option<Rc<IntegerValueContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SampleByBucketContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SampleByBucketContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SampleByBucketContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_sampleByBucket(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_sampleByBucket(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SampleByBucketContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_sampleByBucket(self);
	}
}

impl<'input> CustomRuleContext<'input> for SampleByBucketContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sampleMethod }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sampleMethod }
}

impl<'input> Borrow<SampleMethodContextExt<'input>> for SampleByBucketContext<'input>{
	fn borrow(&self) -> &SampleMethodContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<SampleMethodContextExt<'input>> for SampleByBucketContext<'input>{
	fn borrow_mut(&mut self) -> &mut SampleMethodContextExt<'input> { &mut self.base }
}

impl<'input> SampleMethodContextAttrs<'input> for SampleByBucketContext<'input> {}

impl<'input> SampleByBucketContextExt<'input>{
	fn new(ctx: &dyn SampleMethodContextAttrs<'input>) -> Rc<SampleMethodContextAll<'input>>  {
		Rc::new(
			SampleMethodContextAll::SampleByBucketContext(
				BaseParserRuleContext::copy_from(ctx,SampleByBucketContextExt{
					sampleType:None, 
        			numerator:None, denominator:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SampleByBytesContext<'input> = BaseParserRuleContext<'input,SampleByBytesContextExt<'input>>;

pub trait SampleByBytesContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SampleByBytesContextAttrs<'input> for SampleByBytesContext<'input>{}

pub struct SampleByBytesContextExt<'input>{
	base:SampleMethodContextExt<'input>,
	pub bytes: Option<Rc<ExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SampleByBytesContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SampleByBytesContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SampleByBytesContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_sampleByBytes(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_sampleByBytes(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SampleByBytesContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_sampleByBytes(self);
	}
}

impl<'input> CustomRuleContext<'input> for SampleByBytesContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sampleMethod }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sampleMethod }
}

impl<'input> Borrow<SampleMethodContextExt<'input>> for SampleByBytesContext<'input>{
	fn borrow(&self) -> &SampleMethodContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<SampleMethodContextExt<'input>> for SampleByBytesContext<'input>{
	fn borrow_mut(&mut self) -> &mut SampleMethodContextExt<'input> { &mut self.base }
}

impl<'input> SampleMethodContextAttrs<'input> for SampleByBytesContext<'input> {}

impl<'input> SampleByBytesContextExt<'input>{
	fn new(ctx: &dyn SampleMethodContextAttrs<'input>) -> Rc<SampleMethodContextAll<'input>>  {
		Rc::new(
			SampleMethodContextAll::SampleByBytesContext(
				BaseParserRuleContext::copy_from(ctx,SampleByBytesContextExt{
        			bytes:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn sampleMethod(&mut self,)
	-> Result<Rc<SampleMethodContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SampleMethodContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 272, RULE_sampleMethod);
        let mut _localctx: Rc<SampleMethodContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3335);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(402,&mut recog.base)? {
				1 =>{
					let tmp = SampleByPercentileContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(3309);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(398,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3308);
							let tmp = recog.base.match_token(MINUS,&mut recog.err_handler)?;
							if let SampleMethodContextAll::SampleByPercentileContext(ctx) = cast_mut::<_,SampleMethodContextAll >(&mut _localctx){
							ctx.negativeSign = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					recog.base.set_state(3313);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(399,&mut recog.base)? {
						1 =>{
							{
							/*InvokeRule integerValue*/
							recog.base.set_state(3311);
							recog.integerValue()?;

							}
						}
					,
						2 =>{
							{
							recog.base.set_state(3312);
							recog.base.match_token(DECIMAL_VALUE,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					recog.base.set_state(3315);
					recog.base.match_token(PERCENTLIT,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = SampleByRowsContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule expression*/
					recog.base.set_state(3316);
					recog.expression()?;

					recog.base.set_state(3317);
					recog.base.match_token(ROWS,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					let tmp = SampleByBucketContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(3319);
					let tmp = recog.base.match_token(BUCKET,&mut recog.err_handler)?;
					if let SampleMethodContextAll::SampleByBucketContext(ctx) = cast_mut::<_,SampleMethodContextAll >(&mut _localctx){
					ctx.sampleType = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					/*InvokeRule integerValue*/
					recog.base.set_state(3320);
					let tmp = recog.integerValue()?;
					if let SampleMethodContextAll::SampleByBucketContext(ctx) = cast_mut::<_,SampleMethodContextAll >(&mut _localctx){
					ctx.numerator = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(3321);
					recog.base.match_token(OUT,&mut recog.err_handler)?;

					recog.base.set_state(3322);
					recog.base.match_token(OF,&mut recog.err_handler)?;

					/*InvokeRule integerValue*/
					recog.base.set_state(3323);
					let tmp = recog.integerValue()?;
					if let SampleMethodContextAll::SampleByBucketContext(ctx) = cast_mut::<_,SampleMethodContextAll >(&mut _localctx){
					ctx.denominator = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(3332);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ON {
						{
						recog.base.set_state(3324);
						recog.base.match_token(ON,&mut recog.err_handler)?;

						recog.base.set_state(3330);
						recog.err_handler.sync(&mut recog.base)?;
						match  recog.interpreter.adaptive_predict(400,&mut recog.base)? {
							1 =>{
								{
								/*InvokeRule identifier*/
								recog.base.set_state(3325);
								recog.identifier()?;

								}
							}
						,
							2 =>{
								{
								/*InvokeRule qualifiedName*/
								recog.base.set_state(3326);
								recog.qualifiedName()?;

								recog.base.set_state(3327);
								recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

								recog.base.set_state(3328);
								recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

								}
							}

							_ => {}
						}
						}
					}

					}
				}
			,
				4 =>{
					let tmp = SampleByBytesContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					/*InvokeRule expression*/
					recog.base.set_state(3334);
					let tmp = recog.expression()?;
					if let SampleMethodContextAll::SampleByBytesContext(ctx) = cast_mut::<_,SampleMethodContextAll >(&mut _localctx){
					ctx.bytes = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- identifierList ----------------
pub type IdentifierListContextAll<'input> = IdentifierListContext<'input>;


pub type IdentifierListContext<'input> = BaseParserRuleContext<'input,IdentifierListContextExt<'input>>;

#[derive(Clone)]
pub struct IdentifierListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for IdentifierListContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for IdentifierListContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_identifierList(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_identifierList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for IdentifierListContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_identifierList(self);
	}
}

impl<'input> CustomRuleContext<'input> for IdentifierListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identifierList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identifierList }
}
antlr_rust::tid!{IdentifierListContextExt<'a>}

impl<'input> IdentifierListContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IdentifierListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IdentifierListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait IdentifierListContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<IdentifierListContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
fn identifierSeq(&self) -> Option<Rc<IdentifierSeqContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}

}

impl<'input> IdentifierListContextAttrs<'input> for IdentifierListContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn identifierList(&mut self,)
	-> Result<Rc<IdentifierListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IdentifierListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 274, RULE_identifierList);
        let mut _localctx: Rc<IdentifierListContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3337);
			recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

			/*InvokeRule identifierSeq*/
			recog.base.set_state(3338);
			recog.identifierSeq()?;

			recog.base.set_state(3339);
			recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- identifierSeq ----------------
pub type IdentifierSeqContextAll<'input> = IdentifierSeqContext<'input>;


pub type IdentifierSeqContext<'input> = BaseParserRuleContext<'input,IdentifierSeqContextExt<'input>>;

#[derive(Clone)]
pub struct IdentifierSeqContextExt<'input>{
	pub errorCapturingIdentifier: Option<Rc<ErrorCapturingIdentifierContextAll<'input>>>,
	pub ident:Vec<Rc<ErrorCapturingIdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for IdentifierSeqContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for IdentifierSeqContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_identifierSeq(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_identifierSeq(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for IdentifierSeqContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_identifierSeq(self);
	}
}

impl<'input> CustomRuleContext<'input> for IdentifierSeqContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identifierSeq }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identifierSeq }
}
antlr_rust::tid!{IdentifierSeqContextExt<'a>}

impl<'input> IdentifierSeqContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IdentifierSeqContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IdentifierSeqContextExt{
				errorCapturingIdentifier: None, 
				ident: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait IdentifierSeqContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<IdentifierSeqContextExt<'input>>{

fn errorCapturingIdentifier_all(&self) ->  Vec<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn errorCapturingIdentifier(&self, i: usize) -> Option<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> IdentifierSeqContextAttrs<'input> for IdentifierSeqContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn identifierSeq(&mut self,)
	-> Result<Rc<IdentifierSeqContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IdentifierSeqContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 276, RULE_identifierSeq);
        let mut _localctx: Rc<IdentifierSeqContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule errorCapturingIdentifier*/
			recog.base.set_state(3341);
			let tmp = recog.errorCapturingIdentifier()?;
			 cast_mut::<_,IdentifierSeqContext >(&mut _localctx).errorCapturingIdentifier = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,IdentifierSeqContext >(&mut _localctx).errorCapturingIdentifier.clone().unwrap()
			 ;
			 cast_mut::<_,IdentifierSeqContext >(&mut _localctx).ident.push(temp);
			  
			recog.base.set_state(3346);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(403,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(3342);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule errorCapturingIdentifier*/
					recog.base.set_state(3343);
					let tmp = recog.errorCapturingIdentifier()?;
					 cast_mut::<_,IdentifierSeqContext >(&mut _localctx).errorCapturingIdentifier = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,IdentifierSeqContext >(&mut _localctx).errorCapturingIdentifier.clone().unwrap()
					 ;
					 cast_mut::<_,IdentifierSeqContext >(&mut _localctx).ident.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(3348);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(403,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- orderedIdentifierList ----------------
pub type OrderedIdentifierListContextAll<'input> = OrderedIdentifierListContext<'input>;


pub type OrderedIdentifierListContext<'input> = BaseParserRuleContext<'input,OrderedIdentifierListContextExt<'input>>;

#[derive(Clone)]
pub struct OrderedIdentifierListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for OrderedIdentifierListContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for OrderedIdentifierListContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_orderedIdentifierList(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_orderedIdentifierList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for OrderedIdentifierListContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_orderedIdentifierList(self);
	}
}

impl<'input> CustomRuleContext<'input> for OrderedIdentifierListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_orderedIdentifierList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_orderedIdentifierList }
}
antlr_rust::tid!{OrderedIdentifierListContextExt<'a>}

impl<'input> OrderedIdentifierListContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<OrderedIdentifierListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,OrderedIdentifierListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait OrderedIdentifierListContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<OrderedIdentifierListContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
fn orderedIdentifier_all(&self) ->  Vec<Rc<OrderedIdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn orderedIdentifier(&self, i: usize) -> Option<Rc<OrderedIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> OrderedIdentifierListContextAttrs<'input> for OrderedIdentifierListContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn orderedIdentifierList(&mut self,)
	-> Result<Rc<OrderedIdentifierListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = OrderedIdentifierListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 278, RULE_orderedIdentifierList);
        let mut _localctx: Rc<OrderedIdentifierListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3349);
			recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

			/*InvokeRule orderedIdentifier*/
			recog.base.set_state(3350);
			recog.orderedIdentifier()?;

			recog.base.set_state(3355);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(3351);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule orderedIdentifier*/
				recog.base.set_state(3352);
				recog.orderedIdentifier()?;

				}
				}
				recog.base.set_state(3357);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(3358);
			recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- orderedIdentifier ----------------
pub type OrderedIdentifierContextAll<'input> = OrderedIdentifierContext<'input>;


pub type OrderedIdentifierContext<'input> = BaseParserRuleContext<'input,OrderedIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct OrderedIdentifierContextExt<'input>{
	pub ident: Option<Rc<ErrorCapturingIdentifierContextAll<'input>>>,
	pub ordering: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for OrderedIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for OrderedIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_orderedIdentifier(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_orderedIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for OrderedIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_orderedIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for OrderedIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_orderedIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_orderedIdentifier }
}
antlr_rust::tid!{OrderedIdentifierContextExt<'a>}

impl<'input> OrderedIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<OrderedIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,OrderedIdentifierContextExt{
				ordering: None, 
				ident: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait OrderedIdentifierContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<OrderedIdentifierContextExt<'input>>{

fn errorCapturingIdentifier(&self) -> Option<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token ASC
/// Returns `None` if there is no child corresponding to token ASC
fn ASC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ASC, 0)
}
/// Retrieves first TerminalNode corresponding to token DESC
/// Returns `None` if there is no child corresponding to token DESC
fn DESC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DESC, 0)
}

}

impl<'input> OrderedIdentifierContextAttrs<'input> for OrderedIdentifierContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn orderedIdentifier(&mut self,)
	-> Result<Rc<OrderedIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = OrderedIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 280, RULE_orderedIdentifier);
        let mut _localctx: Rc<OrderedIdentifierContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule errorCapturingIdentifier*/
			recog.base.set_state(3360);
			let tmp = recog.errorCapturingIdentifier()?;
			 cast_mut::<_,OrderedIdentifierContext >(&mut _localctx).ident = Some(tmp.clone());
			  

			recog.base.set_state(3362);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ASC || _la==DESC {
				{
				recog.base.set_state(3361);
				 cast_mut::<_,OrderedIdentifierContext >(&mut _localctx).ordering = recog.base.input.lt(1).cloned();
				 
				_la = recog.base.input.la(1);
				if { !(_la==ASC || _la==DESC) } {
					let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
					 cast_mut::<_,OrderedIdentifierContext >(&mut _localctx).ordering = Some(tmp.clone());
					  

				}
				else {
					if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
					recog.err_handler.report_match(&mut recog.base);
					recog.base.consume(&mut recog.err_handler);
				}
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- identifierCommentList ----------------
pub type IdentifierCommentListContextAll<'input> = IdentifierCommentListContext<'input>;


pub type IdentifierCommentListContext<'input> = BaseParserRuleContext<'input,IdentifierCommentListContextExt<'input>>;

#[derive(Clone)]
pub struct IdentifierCommentListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for IdentifierCommentListContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for IdentifierCommentListContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_identifierCommentList(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_identifierCommentList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for IdentifierCommentListContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_identifierCommentList(self);
	}
}

impl<'input> CustomRuleContext<'input> for IdentifierCommentListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identifierCommentList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identifierCommentList }
}
antlr_rust::tid!{IdentifierCommentListContextExt<'a>}

impl<'input> IdentifierCommentListContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IdentifierCommentListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IdentifierCommentListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait IdentifierCommentListContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<IdentifierCommentListContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
fn identifierComment_all(&self) ->  Vec<Rc<IdentifierCommentContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifierComment(&self, i: usize) -> Option<Rc<IdentifierCommentContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> IdentifierCommentListContextAttrs<'input> for IdentifierCommentListContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn identifierCommentList(&mut self,)
	-> Result<Rc<IdentifierCommentListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IdentifierCommentListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 282, RULE_identifierCommentList);
        let mut _localctx: Rc<IdentifierCommentListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3364);
			recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

			/*InvokeRule identifierComment*/
			recog.base.set_state(3365);
			recog.identifierComment()?;

			recog.base.set_state(3370);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(3366);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule identifierComment*/
				recog.base.set_state(3367);
				recog.identifierComment()?;

				}
				}
				recog.base.set_state(3372);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(3373);
			recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- identifierComment ----------------
pub type IdentifierCommentContextAll<'input> = IdentifierCommentContext<'input>;


pub type IdentifierCommentContext<'input> = BaseParserRuleContext<'input,IdentifierCommentContextExt<'input>>;

#[derive(Clone)]
pub struct IdentifierCommentContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for IdentifierCommentContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for IdentifierCommentContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_identifierComment(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_identifierComment(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for IdentifierCommentContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_identifierComment(self);
	}
}

impl<'input> CustomRuleContext<'input> for IdentifierCommentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identifierComment }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identifierComment }
}
antlr_rust::tid!{IdentifierCommentContextExt<'a>}

impl<'input> IdentifierCommentContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IdentifierCommentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IdentifierCommentContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait IdentifierCommentContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<IdentifierCommentContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn commentSpec(&self) -> Option<Rc<CommentSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> IdentifierCommentContextAttrs<'input> for IdentifierCommentContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn identifierComment(&mut self,)
	-> Result<Rc<IdentifierCommentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IdentifierCommentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 284, RULE_identifierComment);
        let mut _localctx: Rc<IdentifierCommentContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(3375);
			recog.identifier()?;

			recog.base.set_state(3377);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMENT {
				{
				/*InvokeRule commentSpec*/
				recog.base.set_state(3376);
				recog.commentSpec()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- relationPrimary ----------------
#[derive(Debug)]
pub enum RelationPrimaryContextAll<'input>{
	StreamRelationContext(StreamRelationContext<'input>),
	TableValuedFunctionContext(TableValuedFunctionContext<'input>),
	InlineTableDefault2Context(InlineTableDefault2Context<'input>),
	AliasedRelationContext(AliasedRelationContext<'input>),
	AliasedQueryContext(AliasedQueryContext<'input>),
	TableNameContext(TableNameContext<'input>),
Error(RelationPrimaryContext<'input>)
}
antlr_rust::tid!{RelationPrimaryContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for RelationPrimaryContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for RelationPrimaryContextAll<'input>{}

impl<'input> Deref for RelationPrimaryContextAll<'input>{
	type Target = dyn RelationPrimaryContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use RelationPrimaryContextAll::*;
		match self{
			StreamRelationContext(inner) => inner,
			TableValuedFunctionContext(inner) => inner,
			InlineTableDefault2Context(inner) => inner,
			AliasedRelationContext(inner) => inner,
			AliasedQueryContext(inner) => inner,
			TableNameContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for RelationPrimaryContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for RelationPrimaryContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type RelationPrimaryContext<'input> = BaseParserRuleContext<'input,RelationPrimaryContextExt<'input>>;

#[derive(Clone)]
pub struct RelationPrimaryContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for RelationPrimaryContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for RelationPrimaryContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for RelationPrimaryContext<'input>{
}

impl<'input> CustomRuleContext<'input> for RelationPrimaryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relationPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relationPrimary }
}
antlr_rust::tid!{RelationPrimaryContextExt<'a>}

impl<'input> RelationPrimaryContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RelationPrimaryContextAll<'input>> {
		Rc::new(
		RelationPrimaryContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RelationPrimaryContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait RelationPrimaryContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<RelationPrimaryContextExt<'input>>{


}

impl<'input> RelationPrimaryContextAttrs<'input> for RelationPrimaryContext<'input>{}

pub type StreamRelationContext<'input> = BaseParserRuleContext<'input,StreamRelationContextExt<'input>>;

pub trait StreamRelationContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn streamRelationPrimary(&self) -> Option<Rc<StreamRelationPrimaryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> StreamRelationContextAttrs<'input> for StreamRelationContext<'input>{}

pub struct StreamRelationContextExt<'input>{
	base:RelationPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{StreamRelationContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for StreamRelationContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for StreamRelationContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_streamRelation(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_streamRelation(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for StreamRelationContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_streamRelation(self);
	}
}

impl<'input> CustomRuleContext<'input> for StreamRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relationPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relationPrimary }
}

impl<'input> Borrow<RelationPrimaryContextExt<'input>> for StreamRelationContext<'input>{
	fn borrow(&self) -> &RelationPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<RelationPrimaryContextExt<'input>> for StreamRelationContext<'input>{
	fn borrow_mut(&mut self) -> &mut RelationPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> RelationPrimaryContextAttrs<'input> for StreamRelationContext<'input> {}

impl<'input> StreamRelationContextExt<'input>{
	fn new(ctx: &dyn RelationPrimaryContextAttrs<'input>) -> Rc<RelationPrimaryContextAll<'input>>  {
		Rc::new(
			RelationPrimaryContextAll::StreamRelationContext(
				BaseParserRuleContext::copy_from(ctx,StreamRelationContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TableValuedFunctionContext<'input> = BaseParserRuleContext<'input,TableValuedFunctionContextExt<'input>>;

pub trait TableValuedFunctionContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn functionTable(&self) -> Option<Rc<FunctionTableContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> TableValuedFunctionContextAttrs<'input> for TableValuedFunctionContext<'input>{}

pub struct TableValuedFunctionContextExt<'input>{
	base:RelationPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TableValuedFunctionContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for TableValuedFunctionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for TableValuedFunctionContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_tableValuedFunction(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_tableValuedFunction(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for TableValuedFunctionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_tableValuedFunction(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableValuedFunctionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relationPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relationPrimary }
}

impl<'input> Borrow<RelationPrimaryContextExt<'input>> for TableValuedFunctionContext<'input>{
	fn borrow(&self) -> &RelationPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<RelationPrimaryContextExt<'input>> for TableValuedFunctionContext<'input>{
	fn borrow_mut(&mut self) -> &mut RelationPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> RelationPrimaryContextAttrs<'input> for TableValuedFunctionContext<'input> {}

impl<'input> TableValuedFunctionContextExt<'input>{
	fn new(ctx: &dyn RelationPrimaryContextAttrs<'input>) -> Rc<RelationPrimaryContextAll<'input>>  {
		Rc::new(
			RelationPrimaryContextAll::TableValuedFunctionContext(
				BaseParserRuleContext::copy_from(ctx,TableValuedFunctionContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type InlineTableDefault2Context<'input> = BaseParserRuleContext<'input,InlineTableDefault2ContextExt<'input>>;

pub trait InlineTableDefault2ContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn inlineTable(&self) -> Option<Rc<InlineTableContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> InlineTableDefault2ContextAttrs<'input> for InlineTableDefault2Context<'input>{}

pub struct InlineTableDefault2ContextExt<'input>{
	base:RelationPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{InlineTableDefault2ContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for InlineTableDefault2Context<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for InlineTableDefault2Context<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_inlineTableDefault2(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_inlineTableDefault2(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for InlineTableDefault2Context<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_inlineTableDefault2(self);
	}
}

impl<'input> CustomRuleContext<'input> for InlineTableDefault2ContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relationPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relationPrimary }
}

impl<'input> Borrow<RelationPrimaryContextExt<'input>> for InlineTableDefault2Context<'input>{
	fn borrow(&self) -> &RelationPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<RelationPrimaryContextExt<'input>> for InlineTableDefault2Context<'input>{
	fn borrow_mut(&mut self) -> &mut RelationPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> RelationPrimaryContextAttrs<'input> for InlineTableDefault2Context<'input> {}

impl<'input> InlineTableDefault2ContextExt<'input>{
	fn new(ctx: &dyn RelationPrimaryContextAttrs<'input>) -> Rc<RelationPrimaryContextAll<'input>>  {
		Rc::new(
			RelationPrimaryContextAll::InlineTableDefault2Context(
				BaseParserRuleContext::copy_from(ctx,InlineTableDefault2ContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AliasedRelationContext<'input> = BaseParserRuleContext<'input,AliasedRelationContextExt<'input>>;

pub trait AliasedRelationContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	fn relation(&self) -> Option<Rc<RelationContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
	fn tableAlias(&self) -> Option<Rc<TableAliasContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn sample(&self) -> Option<Rc<SampleContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn watermarkClause(&self) -> Option<Rc<WatermarkClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> AliasedRelationContextAttrs<'input> for AliasedRelationContext<'input>{}

pub struct AliasedRelationContextExt<'input>{
	base:RelationPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AliasedRelationContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for AliasedRelationContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for AliasedRelationContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_aliasedRelation(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_aliasedRelation(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for AliasedRelationContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_aliasedRelation(self);
	}
}

impl<'input> CustomRuleContext<'input> for AliasedRelationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relationPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relationPrimary }
}

impl<'input> Borrow<RelationPrimaryContextExt<'input>> for AliasedRelationContext<'input>{
	fn borrow(&self) -> &RelationPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<RelationPrimaryContextExt<'input>> for AliasedRelationContext<'input>{
	fn borrow_mut(&mut self) -> &mut RelationPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> RelationPrimaryContextAttrs<'input> for AliasedRelationContext<'input> {}

impl<'input> AliasedRelationContextExt<'input>{
	fn new(ctx: &dyn RelationPrimaryContextAttrs<'input>) -> Rc<RelationPrimaryContextAll<'input>>  {
		Rc::new(
			RelationPrimaryContextAll::AliasedRelationContext(
				BaseParserRuleContext::copy_from(ctx,AliasedRelationContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type AliasedQueryContext<'input> = BaseParserRuleContext<'input,AliasedQueryContextExt<'input>>;

pub trait AliasedQueryContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
	fn tableAlias(&self) -> Option<Rc<TableAliasContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn sample(&self) -> Option<Rc<SampleContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn watermarkClause(&self) -> Option<Rc<WatermarkClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> AliasedQueryContextAttrs<'input> for AliasedQueryContext<'input>{}

pub struct AliasedQueryContextExt<'input>{
	base:RelationPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{AliasedQueryContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for AliasedQueryContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for AliasedQueryContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_aliasedQuery(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_aliasedQuery(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for AliasedQueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_aliasedQuery(self);
	}
}

impl<'input> CustomRuleContext<'input> for AliasedQueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relationPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relationPrimary }
}

impl<'input> Borrow<RelationPrimaryContextExt<'input>> for AliasedQueryContext<'input>{
	fn borrow(&self) -> &RelationPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<RelationPrimaryContextExt<'input>> for AliasedQueryContext<'input>{
	fn borrow_mut(&mut self) -> &mut RelationPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> RelationPrimaryContextAttrs<'input> for AliasedQueryContext<'input> {}

impl<'input> AliasedQueryContextExt<'input>{
	fn new(ctx: &dyn RelationPrimaryContextAttrs<'input>) -> Rc<RelationPrimaryContextAll<'input>>  {
		Rc::new(
			RelationPrimaryContextAll::AliasedQueryContext(
				BaseParserRuleContext::copy_from(ctx,AliasedQueryContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TableNameContext<'input> = BaseParserRuleContext<'input,TableNameContextExt<'input>>;

pub trait TableNameContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn tableAlias(&self) -> Option<Rc<TableAliasContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn temporalClause(&self) -> Option<Rc<TemporalClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn optionsClause(&self) -> Option<Rc<OptionsClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn sample(&self) -> Option<Rc<SampleContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn watermarkClause(&self) -> Option<Rc<WatermarkClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> TableNameContextAttrs<'input> for TableNameContext<'input>{}

pub struct TableNameContextExt<'input>{
	base:RelationPrimaryContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TableNameContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for TableNameContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for TableNameContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_tableName(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_tableName(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for TableNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_tableName(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relationPrimary }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relationPrimary }
}

impl<'input> Borrow<RelationPrimaryContextExt<'input>> for TableNameContext<'input>{
	fn borrow(&self) -> &RelationPrimaryContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<RelationPrimaryContextExt<'input>> for TableNameContext<'input>{
	fn borrow_mut(&mut self) -> &mut RelationPrimaryContextExt<'input> { &mut self.base }
}

impl<'input> RelationPrimaryContextAttrs<'input> for TableNameContext<'input> {}

impl<'input> TableNameContextExt<'input>{
	fn new(ctx: &dyn RelationPrimaryContextAttrs<'input>) -> Rc<RelationPrimaryContextAll<'input>>  {
		Rc::new(
			RelationPrimaryContextAll::TableNameContext(
				BaseParserRuleContext::copy_from(ctx,TableNameContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn relationPrimary(&mut self,)
	-> Result<Rc<RelationPrimaryContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RelationPrimaryContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 286, RULE_relationPrimary);
        let mut _localctx: Rc<RelationPrimaryContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3419);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(416,&mut recog.base)? {
				1 =>{
					let tmp = StreamRelationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule streamRelationPrimary*/
					recog.base.set_state(3379);
					recog.streamRelationPrimary()?;

					}
				}
			,
				2 =>{
					let tmp = TableNameContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule identifierReference*/
					recog.base.set_state(3380);
					recog.identifierReference()?;

					recog.base.set_state(3382);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(408,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule temporalClause*/
							recog.base.set_state(3381);
							recog.temporalClause()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(3385);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(409,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule optionsClause*/
							recog.base.set_state(3384);
							recog.optionsClause()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(3388);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(410,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule sample*/
							recog.base.set_state(3387);
							recog.sample()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(3391);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(411,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule watermarkClause*/
							recog.base.set_state(3390);
							recog.watermarkClause()?;

							}
						}

						_ => {}
					}
					/*InvokeRule tableAlias*/
					recog.base.set_state(3393);
					recog.tableAlias()?;

					}
				}
			,
				3 =>{
					let tmp = AliasedQueryContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(3395);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(3396);
					recog.query()?;

					recog.base.set_state(3397);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					recog.base.set_state(3399);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(412,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule sample*/
							recog.base.set_state(3398);
							recog.sample()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(3402);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(413,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule watermarkClause*/
							recog.base.set_state(3401);
							recog.watermarkClause()?;

							}
						}

						_ => {}
					}
					/*InvokeRule tableAlias*/
					recog.base.set_state(3404);
					recog.tableAlias()?;

					}
				}
			,
				4 =>{
					let tmp = AliasedRelationContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(3406);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule relation*/
					recog.base.set_state(3407);
					recog.relation()?;

					recog.base.set_state(3408);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					recog.base.set_state(3410);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(414,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule sample*/
							recog.base.set_state(3409);
							recog.sample()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(3413);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(415,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule watermarkClause*/
							recog.base.set_state(3412);
							recog.watermarkClause()?;

							}
						}

						_ => {}
					}
					/*InvokeRule tableAlias*/
					recog.base.set_state(3415);
					recog.tableAlias()?;

					}
				}
			,
				5 =>{
					let tmp = InlineTableDefault2ContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					/*InvokeRule inlineTable*/
					recog.base.set_state(3417);
					recog.inlineTable()?;

					}
				}
			,
				6 =>{
					let tmp = TableValuedFunctionContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 6);
					_localctx = tmp;
					{
					/*InvokeRule functionTable*/
					recog.base.set_state(3418);
					recog.functionTable()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- optionsClause ----------------
pub type OptionsClauseContextAll<'input> = OptionsClauseContext<'input>;


pub type OptionsClauseContext<'input> = BaseParserRuleContext<'input,OptionsClauseContextExt<'input>>;

#[derive(Clone)]
pub struct OptionsClauseContextExt<'input>{
	pub options: Option<Rc<PropertyListContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for OptionsClauseContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for OptionsClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_optionsClause(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_optionsClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for OptionsClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_optionsClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for OptionsClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_optionsClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_optionsClause }
}
antlr_rust::tid!{OptionsClauseContextExt<'a>}

impl<'input> OptionsClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<OptionsClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,OptionsClauseContextExt{
				options: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait OptionsClauseContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<OptionsClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
fn propertyList(&self) -> Option<Rc<PropertyListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> OptionsClauseContextAttrs<'input> for OptionsClauseContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn optionsClause(&mut self,)
	-> Result<Rc<OptionsClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = OptionsClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 288, RULE_optionsClause);
        let mut _localctx: Rc<OptionsClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3421);
			recog.base.match_token(WITH,&mut recog.err_handler)?;

			/*InvokeRule propertyList*/
			recog.base.set_state(3422);
			let tmp = recog.propertyList()?;
			 cast_mut::<_,OptionsClauseContext >(&mut _localctx).options = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- inlineTable ----------------
pub type InlineTableContextAll<'input> = InlineTableContext<'input>;


pub type InlineTableContext<'input> = BaseParserRuleContext<'input,InlineTableContextExt<'input>>;

#[derive(Clone)]
pub struct InlineTableContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for InlineTableContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for InlineTableContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_inlineTable(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_inlineTable(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for InlineTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_inlineTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for InlineTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_inlineTable }
	//fn type_rule_index() -> usize where Self: Sized { RULE_inlineTable }
}
antlr_rust::tid!{InlineTableContextExt<'a>}

impl<'input> InlineTableContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<InlineTableContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,InlineTableContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait InlineTableContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<InlineTableContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token VALUES
/// Returns `None` if there is no child corresponding to token VALUES
fn VALUES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VALUES, 0)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn tableAlias(&self) -> Option<Rc<TableAliasContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> InlineTableContextAttrs<'input> for InlineTableContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn inlineTable(&mut self,)
	-> Result<Rc<InlineTableContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = InlineTableContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 290, RULE_inlineTable);
        let mut _localctx: Rc<InlineTableContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3424);
			recog.base.match_token(VALUES,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(3425);
			recog.expression()?;

			recog.base.set_state(3430);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(417,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(3426);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(3427);
					recog.expression()?;

					}
					} 
				}
				recog.base.set_state(3432);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(417,&mut recog.base)?;
			}
			/*InvokeRule tableAlias*/
			recog.base.set_state(3433);
			recog.tableAlias()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- functionTableSubqueryArgument ----------------
pub type FunctionTableSubqueryArgumentContextAll<'input> = FunctionTableSubqueryArgumentContext<'input>;


pub type FunctionTableSubqueryArgumentContext<'input> = BaseParserRuleContext<'input,FunctionTableSubqueryArgumentContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionTableSubqueryArgumentContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for FunctionTableSubqueryArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for FunctionTableSubqueryArgumentContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionTableSubqueryArgument(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_functionTableSubqueryArgument(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for FunctionTableSubqueryArgumentContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_functionTableSubqueryArgument(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionTableSubqueryArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionTableSubqueryArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionTableSubqueryArgument }
}
antlr_rust::tid!{FunctionTableSubqueryArgumentContextExt<'a>}

impl<'input> FunctionTableSubqueryArgumentContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionTableSubqueryArgumentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionTableSubqueryArgumentContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionTableSubqueryArgumentContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<FunctionTableSubqueryArgumentContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token TABLE
/// Returns `None` if there is no child corresponding to token TABLE
fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TABLE, 0)
}
fn identifierReference(&self) -> Option<Rc<IdentifierReferenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tableArgumentPartitioning(&self) -> Option<Rc<TableArgumentPartitioningContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FunctionTableSubqueryArgumentContextAttrs<'input> for FunctionTableSubqueryArgumentContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionTableSubqueryArgument(&mut self,)
	-> Result<Rc<FunctionTableSubqueryArgumentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionTableSubqueryArgumentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 292, RULE_functionTableSubqueryArgument);
        let mut _localctx: Rc<FunctionTableSubqueryArgumentContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3454);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(421,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3435);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(3436);
					recog.identifierReference()?;

					recog.base.set_state(3438);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==DISTRIBUTE || _la==PARTITION || _la==WITH {
						{
						/*InvokeRule tableArgumentPartitioning*/
						recog.base.set_state(3437);
						recog.tableArgumentPartitioning()?;

						}
					}

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3440);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(3441);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule identifierReference*/
					recog.base.set_state(3442);
					recog.identifierReference()?;

					recog.base.set_state(3443);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					recog.base.set_state(3445);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==DISTRIBUTE || _la==PARTITION || _la==WITH {
						{
						/*InvokeRule tableArgumentPartitioning*/
						recog.base.set_state(3444);
						recog.tableArgumentPartitioning()?;

						}
					}

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(3447);
					recog.base.match_token(TABLE,&mut recog.err_handler)?;

					recog.base.set_state(3448);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(3449);
					recog.query()?;

					recog.base.set_state(3450);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					recog.base.set_state(3452);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==DISTRIBUTE || _la==PARTITION || _la==WITH {
						{
						/*InvokeRule tableArgumentPartitioning*/
						recog.base.set_state(3451);
						recog.tableArgumentPartitioning()?;

						}
					}

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableArgumentPartitioning ----------------
pub type TableArgumentPartitioningContextAll<'input> = TableArgumentPartitioningContext<'input>;


pub type TableArgumentPartitioningContext<'input> = BaseParserRuleContext<'input,TableArgumentPartitioningContextExt<'input>>;

#[derive(Clone)]
pub struct TableArgumentPartitioningContextExt<'input>{
	pub expression: Option<Rc<ExpressionContextAll<'input>>>,
	pub partition:Vec<Rc<ExpressionContextAll<'input>>>,
	pub invalidMultiPartitionExpression: Option<Rc<ExpressionContextAll<'input>>>,
	pub invalidMultiSortItem: Option<Rc<SortItemContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for TableArgumentPartitioningContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for TableArgumentPartitioningContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableArgumentPartitioning(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_tableArgumentPartitioning(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for TableArgumentPartitioningContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_tableArgumentPartitioning(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableArgumentPartitioningContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableArgumentPartitioning }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableArgumentPartitioning }
}
antlr_rust::tid!{TableArgumentPartitioningContextExt<'a>}

impl<'input> TableArgumentPartitioningContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableArgumentPartitioningContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableArgumentPartitioningContextExt{
				expression: None, invalidMultiPartitionExpression: None, invalidMultiSortItem: None, 
				partition: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait TableArgumentPartitioningContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<TableArgumentPartitioningContextExt<'input>>{

/// Retrieves all `TerminalNode`s corresponding to token BY in current rule
fn BY_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token BY, starting from 0.
/// Returns `None` if number of children corresponding to token BY is less or equal than `i`.
fn BY(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BY, i)
}
/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token SINGLE
/// Returns `None` if there is no child corresponding to token SINGLE
fn SINGLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SINGLE, 0)
}
/// Retrieves first TerminalNode corresponding to token PARTITION
/// Returns `None` if there is no child corresponding to token PARTITION
fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PARTITION, 0)
}
/// Retrieves first TerminalNode corresponding to token ORDER
/// Returns `None` if there is no child corresponding to token ORDER
fn ORDER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ORDER, 0)
}
/// Retrieves first TerminalNode corresponding to token SORT
/// Returns `None` if there is no child corresponding to token SORT
fn SORT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SORT, 0)
}
/// Retrieves first TerminalNode corresponding to token DISTRIBUTE
/// Returns `None` if there is no child corresponding to token DISTRIBUTE
fn DISTRIBUTE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DISTRIBUTE, 0)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn sortItem_all(&self) ->  Vec<Rc<SortItemContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn sortItem(&self, i: usize) -> Option<Rc<SortItemContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token LEFT_PAREN in current rule
fn LEFT_PAREN_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token LEFT_PAREN, starting from 0.
/// Returns `None` if number of children corresponding to token LEFT_PAREN is less or equal than `i`.
fn LEFT_PAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, i)
}
/// Retrieves all `TerminalNode`s corresponding to token RIGHT_PAREN in current rule
fn RIGHT_PAREN_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token RIGHT_PAREN, starting from 0.
/// Returns `None` if number of children corresponding to token RIGHT_PAREN is less or equal than `i`.
fn RIGHT_PAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> TableArgumentPartitioningContextAttrs<'input> for TableArgumentPartitioningContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableArgumentPartitioning(&mut self,)
	-> Result<Rc<TableArgumentPartitioningContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableArgumentPartitioningContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 294, RULE_tableArgumentPartitioning);
        let mut _localctx: Rc<TableArgumentPartitioningContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3482);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 WITH 
				=> {
					{
					{
					recog.base.set_state(3456);
					recog.base.match_token(WITH,&mut recog.err_handler)?;

					recog.base.set_state(3457);
					recog.base.match_token(SINGLE,&mut recog.err_handler)?;

					recog.base.set_state(3458);
					recog.base.match_token(PARTITION,&mut recog.err_handler)?;

					}
					}
				}

			 DISTRIBUTE | PARTITION 
				=> {
					{
					{
					recog.base.set_state(3459);
					_la = recog.base.input.la(1);
					if { !(_la==DISTRIBUTE || _la==PARTITION) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(3460);
					recog.base.match_token(BY,&mut recog.err_handler)?;

					recog.base.set_state(3480);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(424,&mut recog.base)? {
						1 =>{
							{
							{
							{
							recog.base.set_state(3461);
							recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

							/*InvokeRule expression*/
							recog.base.set_state(3462);
							let tmp = recog.expression()?;
							 cast_mut::<_,TableArgumentPartitioningContext >(&mut _localctx).expression = Some(tmp.clone());
							  

							let temp =  cast_mut::<_,TableArgumentPartitioningContext >(&mut _localctx).expression.clone().unwrap()
							 ;
							 cast_mut::<_,TableArgumentPartitioningContext >(&mut _localctx).partition.push(temp);
							  
							recog.base.set_state(3467);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							while _la==COMMA {
								{
								{
								recog.base.set_state(3463);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule expression*/
								recog.base.set_state(3464);
								let tmp = recog.expression()?;
								 cast_mut::<_,TableArgumentPartitioningContext >(&mut _localctx).expression = Some(tmp.clone());
								  

								let temp =  cast_mut::<_,TableArgumentPartitioningContext >(&mut _localctx).expression.clone().unwrap()
								 ;
								 cast_mut::<_,TableArgumentPartitioningContext >(&mut _localctx).partition.push(temp);
								  
								}
								}
								recog.base.set_state(3469);
								recog.err_handler.sync(&mut recog.base)?;
								_la = recog.base.input.la(1);
							}
							recog.base.set_state(3470);
							recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

							}
							}
							}
						}
					,
						2 =>{
							{
							{
							/*InvokeRule expression*/
							recog.base.set_state(3472);
							recog.expression()?;

							recog.base.set_state(3475); 
							recog.err_handler.sync(&mut recog.base)?;
							_alt = 1;
							loop {
								match _alt {
								    x if x == 1=>
									{
									{
									recog.base.set_state(3473);
									recog.base.match_token(COMMA,&mut recog.err_handler)?;

									/*InvokeRule expression*/
									recog.base.set_state(3474);
									let tmp = recog.expression()?;
									 cast_mut::<_,TableArgumentPartitioningContext >(&mut _localctx).invalidMultiPartitionExpression = Some(tmp.clone());
									  

									}
									}

								_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
								}
								recog.base.set_state(3477); 
								recog.err_handler.sync(&mut recog.base)?;
								_alt = recog.interpreter.adaptive_predict(423,&mut recog.base)?;
								if _alt==2 || _alt==INVALID_ALT { break }
							}
							}
							}
						}
					,
						3 =>{
							{
							/*InvokeRule expression*/
							recog.base.set_state(3479);
							let tmp = recog.expression()?;
							 cast_mut::<_,TableArgumentPartitioningContext >(&mut _localctx).expression = Some(tmp.clone());
							  

							let temp =  cast_mut::<_,TableArgumentPartitioningContext >(&mut _localctx).expression.clone().unwrap()
							 ;
							 cast_mut::<_,TableArgumentPartitioningContext >(&mut _localctx).partition.push(temp);
							  
							}
						}

						_ => {}
					}
					}
					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			recog.base.set_state(3507);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ORDER || _la==SORT {
				{
				recog.base.set_state(3484);
				_la = recog.base.input.la(1);
				if { !(_la==ORDER || _la==SORT) } {
					recog.err_handler.recover_inline(&mut recog.base)?;

				}
				else {
					if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
					recog.err_handler.report_match(&mut recog.base);
					recog.base.consume(&mut recog.err_handler);
				}
				recog.base.set_state(3485);
				recog.base.match_token(BY,&mut recog.err_handler)?;

				{
				recog.base.set_state(3505);
				recog.err_handler.sync(&mut recog.base)?;
				match  recog.interpreter.adaptive_predict(428,&mut recog.base)? {
					1 =>{
						{
						{
						recog.base.set_state(3486);
						recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

						/*InvokeRule sortItem*/
						recog.base.set_state(3487);
						recog.sortItem()?;

						recog.base.set_state(3492);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						while _la==COMMA {
							{
							{
							recog.base.set_state(3488);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule sortItem*/
							recog.base.set_state(3489);
							recog.sortItem()?;

							}
							}
							recog.base.set_state(3494);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
						}
						recog.base.set_state(3495);
						recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

						}
						}
					}
				,
					2 =>{
						{
						{
						/*InvokeRule sortItem*/
						recog.base.set_state(3497);
						recog.sortItem()?;

						recog.base.set_state(3500); 
						recog.err_handler.sync(&mut recog.base)?;
						_alt = 1;
						loop {
							match _alt {
							    x if x == 1=>
								{
								{
								recog.base.set_state(3498);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule sortItem*/
								recog.base.set_state(3499);
								let tmp = recog.sortItem()?;
								 cast_mut::<_,TableArgumentPartitioningContext >(&mut _localctx).invalidMultiSortItem = Some(tmp.clone());
								  

								}
								}

							_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
							}
							recog.base.set_state(3502); 
							recog.err_handler.sync(&mut recog.base)?;
							_alt = recog.interpreter.adaptive_predict(427,&mut recog.base)?;
							if _alt==2 || _alt==INVALID_ALT { break }
						}
						}
						}
					}
				,
					3 =>{
						{
						/*InvokeRule sortItem*/
						recog.base.set_state(3504);
						recog.sortItem()?;

						}
					}

					_ => {}
				}
				}
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- functionTableNamedArgumentExpression ----------------
pub type FunctionTableNamedArgumentExpressionContextAll<'input> = FunctionTableNamedArgumentExpressionContext<'input>;


pub type FunctionTableNamedArgumentExpressionContext<'input> = BaseParserRuleContext<'input,FunctionTableNamedArgumentExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionTableNamedArgumentExpressionContextExt<'input>{
	pub key: Option<Rc<IdentifierContextAll<'input>>>,
	pub table: Option<Rc<FunctionTableSubqueryArgumentContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for FunctionTableNamedArgumentExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for FunctionTableNamedArgumentExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionTableNamedArgumentExpression(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_functionTableNamedArgumentExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for FunctionTableNamedArgumentExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_functionTableNamedArgumentExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionTableNamedArgumentExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionTableNamedArgumentExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionTableNamedArgumentExpression }
}
antlr_rust::tid!{FunctionTableNamedArgumentExpressionContextExt<'a>}

impl<'input> FunctionTableNamedArgumentExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionTableNamedArgumentExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionTableNamedArgumentExpressionContextExt{
				key: None, table: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionTableNamedArgumentExpressionContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<FunctionTableNamedArgumentExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token FAT_ARROW
/// Returns `None` if there is no child corresponding to token FAT_ARROW
fn FAT_ARROW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FAT_ARROW, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn functionTableSubqueryArgument(&self) -> Option<Rc<FunctionTableSubqueryArgumentContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FunctionTableNamedArgumentExpressionContextAttrs<'input> for FunctionTableNamedArgumentExpressionContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionTableNamedArgumentExpression(&mut self,)
	-> Result<Rc<FunctionTableNamedArgumentExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionTableNamedArgumentExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 296, RULE_functionTableNamedArgumentExpression);
        let mut _localctx: Rc<FunctionTableNamedArgumentExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(3509);
			let tmp = recog.identifier()?;
			 cast_mut::<_,FunctionTableNamedArgumentExpressionContext >(&mut _localctx).key = Some(tmp.clone());
			  

			recog.base.set_state(3510);
			recog.base.match_token(FAT_ARROW,&mut recog.err_handler)?;

			/*InvokeRule functionTableSubqueryArgument*/
			recog.base.set_state(3511);
			let tmp = recog.functionTableSubqueryArgument()?;
			 cast_mut::<_,FunctionTableNamedArgumentExpressionContext >(&mut _localctx).table = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- functionTableReferenceArgument ----------------
pub type FunctionTableReferenceArgumentContextAll<'input> = FunctionTableReferenceArgumentContext<'input>;


pub type FunctionTableReferenceArgumentContext<'input> = BaseParserRuleContext<'input,FunctionTableReferenceArgumentContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionTableReferenceArgumentContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for FunctionTableReferenceArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for FunctionTableReferenceArgumentContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionTableReferenceArgument(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_functionTableReferenceArgument(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for FunctionTableReferenceArgumentContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_functionTableReferenceArgument(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionTableReferenceArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionTableReferenceArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionTableReferenceArgument }
}
antlr_rust::tid!{FunctionTableReferenceArgumentContextExt<'a>}

impl<'input> FunctionTableReferenceArgumentContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionTableReferenceArgumentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionTableReferenceArgumentContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionTableReferenceArgumentContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<FunctionTableReferenceArgumentContextExt<'input>>{

fn functionTableSubqueryArgument(&self) -> Option<Rc<FunctionTableSubqueryArgumentContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn functionTableNamedArgumentExpression(&self) -> Option<Rc<FunctionTableNamedArgumentExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FunctionTableReferenceArgumentContextAttrs<'input> for FunctionTableReferenceArgumentContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionTableReferenceArgument(&mut self,)
	-> Result<Rc<FunctionTableReferenceArgumentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionTableReferenceArgumentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 298, RULE_functionTableReferenceArgument);
        let mut _localctx: Rc<FunctionTableReferenceArgumentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3515);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(430,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule functionTableSubqueryArgument*/
					recog.base.set_state(3513);
					recog.functionTableSubqueryArgument()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule functionTableNamedArgumentExpression*/
					recog.base.set_state(3514);
					recog.functionTableNamedArgumentExpression()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- functionTableArgument ----------------
pub type FunctionTableArgumentContextAll<'input> = FunctionTableArgumentContext<'input>;


pub type FunctionTableArgumentContext<'input> = BaseParserRuleContext<'input,FunctionTableArgumentContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionTableArgumentContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for FunctionTableArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for FunctionTableArgumentContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionTableArgument(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_functionTableArgument(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for FunctionTableArgumentContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_functionTableArgument(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionTableArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionTableArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionTableArgument }
}
antlr_rust::tid!{FunctionTableArgumentContextExt<'a>}

impl<'input> FunctionTableArgumentContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionTableArgumentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionTableArgumentContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionTableArgumentContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<FunctionTableArgumentContextExt<'input>>{

fn functionTableReferenceArgument(&self) -> Option<Rc<FunctionTableReferenceArgumentContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn functionArgument(&self) -> Option<Rc<FunctionArgumentContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FunctionTableArgumentContextAttrs<'input> for FunctionTableArgumentContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionTableArgument(&mut self,)
	-> Result<Rc<FunctionTableArgumentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionTableArgumentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 300, RULE_functionTableArgument);
        let mut _localctx: Rc<FunctionTableArgumentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3519);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(431,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule functionTableReferenceArgument*/
					recog.base.set_state(3517);
					recog.functionTableReferenceArgument()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule functionArgument*/
					recog.base.set_state(3518);
					recog.functionArgument()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- functionTable ----------------
pub type FunctionTableContextAll<'input> = FunctionTableContext<'input>;


pub type FunctionTableContext<'input> = BaseParserRuleContext<'input,FunctionTableContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionTableContextExt<'input>{
	pub funcName: Option<Rc<FunctionNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for FunctionTableContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for FunctionTableContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionTable(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_functionTable(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for FunctionTableContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_functionTable(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionTableContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionTable }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionTable }
}
antlr_rust::tid!{FunctionTableContextExt<'a>}

impl<'input> FunctionTableContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionTableContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionTableContextExt{
				funcName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionTableContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<FunctionTableContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
fn tableAlias(&self) -> Option<Rc<TableAliasContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn functionName(&self) -> Option<Rc<FunctionNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn functionTableArgument_all(&self) ->  Vec<Rc<FunctionTableArgumentContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn functionTableArgument(&self, i: usize) -> Option<Rc<FunctionTableArgumentContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn watermarkClause(&self) -> Option<Rc<WatermarkClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> FunctionTableContextAttrs<'input> for FunctionTableContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionTable(&mut self,)
	-> Result<Rc<FunctionTableContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionTableContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 302, RULE_functionTable);
        let mut _localctx: Rc<FunctionTableContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule functionName*/
			recog.base.set_state(3521);
			let tmp = recog.functionName()?;
			 cast_mut::<_,FunctionTableContext >(&mut _localctx).funcName = Some(tmp.clone());
			  

			recog.base.set_state(3522);
			recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

			recog.base.set_state(3531);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(433,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule functionTableArgument*/
					recog.base.set_state(3523);
					recog.functionTableArgument()?;

					recog.base.set_state(3528);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(3524);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule functionTableArgument*/
						recog.base.set_state(3525);
						recog.functionTableArgument()?;

						}
						}
						recog.base.set_state(3530);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}

				_ => {}
			}
			recog.base.set_state(3533);
			recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

			recog.base.set_state(3535);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(434,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule watermarkClause*/
					recog.base.set_state(3534);
					recog.watermarkClause()?;

					}
				}

				_ => {}
			}
			/*InvokeRule tableAlias*/
			recog.base.set_state(3537);
			recog.tableAlias()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableAlias ----------------
pub type TableAliasContextAll<'input> = TableAliasContext<'input>;


pub type TableAliasContext<'input> = BaseParserRuleContext<'input,TableAliasContextExt<'input>>;

#[derive(Clone)]
pub struct TableAliasContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for TableAliasContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for TableAliasContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableAlias(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_tableAlias(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for TableAliasContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_tableAlias(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableAliasContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableAlias }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableAlias }
}
antlr_rust::tid!{TableAliasContextExt<'a>}

impl<'input> TableAliasContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableAliasContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableAliasContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableAliasContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<TableAliasContextExt<'input>>{

fn strictIdentifier(&self) -> Option<Rc<StrictIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
fn identifierList(&self) -> Option<Rc<IdentifierListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TableAliasContextAttrs<'input> for TableAliasContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableAlias(&mut self,)
	-> Result<Rc<TableAliasContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableAliasContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 304, RULE_tableAlias);
        let mut _localctx: Rc<TableAliasContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3546);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(437,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(3540);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(435,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3539);
							recog.base.match_token(AS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule strictIdentifier*/
					recog.base.set_state(3542);
					recog.strictIdentifier()?;

					recog.base.set_state(3544);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(436,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule identifierList*/
							recog.base.set_state(3543);
							recog.identifierList()?;

							}
						}

						_ => {}
					}
					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rowFormat ----------------
#[derive(Debug)]
pub enum RowFormatContextAll<'input>{
	RowFormatSerdeContext(RowFormatSerdeContext<'input>),
	RowFormatDelimitedContext(RowFormatDelimitedContext<'input>),
Error(RowFormatContext<'input>)
}
antlr_rust::tid!{RowFormatContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for RowFormatContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for RowFormatContextAll<'input>{}

impl<'input> Deref for RowFormatContextAll<'input>{
	type Target = dyn RowFormatContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use RowFormatContextAll::*;
		match self{
			RowFormatSerdeContext(inner) => inner,
			RowFormatDelimitedContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for RowFormatContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for RowFormatContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type RowFormatContext<'input> = BaseParserRuleContext<'input,RowFormatContextExt<'input>>;

#[derive(Clone)]
pub struct RowFormatContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for RowFormatContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for RowFormatContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for RowFormatContext<'input>{
}

impl<'input> CustomRuleContext<'input> for RowFormatContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rowFormat }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rowFormat }
}
antlr_rust::tid!{RowFormatContextExt<'a>}

impl<'input> RowFormatContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RowFormatContextAll<'input>> {
		Rc::new(
		RowFormatContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RowFormatContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait RowFormatContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<RowFormatContextExt<'input>>{


}

impl<'input> RowFormatContextAttrs<'input> for RowFormatContext<'input>{}

pub type RowFormatSerdeContext<'input> = BaseParserRuleContext<'input,RowFormatSerdeContextExt<'input>>;

pub trait RowFormatSerdeContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ROW
	/// Returns `None` if there is no child corresponding to token ROW
	fn ROW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ROW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FORMAT
	/// Returns `None` if there is no child corresponding to token FORMAT
	fn FORMAT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FORMAT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SERDE
	/// Returns `None` if there is no child corresponding to token SERDE
	fn SERDE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SERDE, 0)
	}
	fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token WITH
	/// Returns `None` if there is no child corresponding to token WITH
	fn WITH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(WITH, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SERDEPROPERTIES
	/// Returns `None` if there is no child corresponding to token SERDEPROPERTIES
	fn SERDEPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SERDEPROPERTIES, 0)
	}
	fn propertyList(&self) -> Option<Rc<PropertyListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> RowFormatSerdeContextAttrs<'input> for RowFormatSerdeContext<'input>{}

pub struct RowFormatSerdeContextExt<'input>{
	base:RowFormatContextExt<'input>,
	pub name: Option<Rc<StringLitContextAll<'input>>>,
	pub props: Option<Rc<PropertyListContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RowFormatSerdeContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for RowFormatSerdeContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for RowFormatSerdeContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_rowFormatSerde(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_rowFormatSerde(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for RowFormatSerdeContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_rowFormatSerde(self);
	}
}

impl<'input> CustomRuleContext<'input> for RowFormatSerdeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rowFormat }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rowFormat }
}

impl<'input> Borrow<RowFormatContextExt<'input>> for RowFormatSerdeContext<'input>{
	fn borrow(&self) -> &RowFormatContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<RowFormatContextExt<'input>> for RowFormatSerdeContext<'input>{
	fn borrow_mut(&mut self) -> &mut RowFormatContextExt<'input> { &mut self.base }
}

impl<'input> RowFormatContextAttrs<'input> for RowFormatSerdeContext<'input> {}

impl<'input> RowFormatSerdeContextExt<'input>{
	fn new(ctx: &dyn RowFormatContextAttrs<'input>) -> Rc<RowFormatContextAll<'input>>  {
		Rc::new(
			RowFormatContextAll::RowFormatSerdeContext(
				BaseParserRuleContext::copy_from(ctx,RowFormatSerdeContextExt{
        			name:None, props:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RowFormatDelimitedContext<'input> = BaseParserRuleContext<'input,RowFormatDelimitedContextExt<'input>>;

pub trait RowFormatDelimitedContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ROW
	/// Returns `None` if there is no child corresponding to token ROW
	fn ROW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ROW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FORMAT
	/// Returns `None` if there is no child corresponding to token FORMAT
	fn FORMAT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FORMAT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DELIMITED
	/// Returns `None` if there is no child corresponding to token DELIMITED
	fn DELIMITED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DELIMITED, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FIELDS
	/// Returns `None` if there is no child corresponding to token FIELDS
	fn FIELDS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FIELDS, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token TERMINATED in current rule
	fn TERMINATED_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token TERMINATED, starting from 0.
	/// Returns `None` if number of children corresponding to token TERMINATED is less or equal than `i`.
	fn TERMINATED(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TERMINATED, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token BY in current rule
	fn BY_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token BY, starting from 0.
	/// Returns `None` if number of children corresponding to token BY is less or equal than `i`.
	fn BY(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(BY, i)
	}
	/// Retrieves first TerminalNode corresponding to token COLLECTION
	/// Returns `None` if there is no child corresponding to token COLLECTION
	fn COLLECTION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COLLECTION, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ITEMS
	/// Returns `None` if there is no child corresponding to token ITEMS
	fn ITEMS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ITEMS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MAP
	/// Returns `None` if there is no child corresponding to token MAP
	fn MAP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(MAP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token KEYS
	/// Returns `None` if there is no child corresponding to token KEYS
	fn KEYS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(KEYS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LINES
	/// Returns `None` if there is no child corresponding to token LINES
	fn LINES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LINES, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NULL
	/// Returns `None` if there is no child corresponding to token NULL
	fn NULL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(NULL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DEFINED
	/// Returns `None` if there is no child corresponding to token DEFINED
	fn DEFINED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DEFINED, 0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	fn stringLit_all(&self) ->  Vec<Rc<StringLitContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn stringLit(&self, i: usize) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token ESCAPED
	/// Returns `None` if there is no child corresponding to token ESCAPED
	fn ESCAPED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ESCAPED, 0)
	}
}

impl<'input> RowFormatDelimitedContextAttrs<'input> for RowFormatDelimitedContext<'input>{}

pub struct RowFormatDelimitedContextExt<'input>{
	base:RowFormatContextExt<'input>,
	pub fieldsTerminatedBy: Option<Rc<StringLitContextAll<'input>>>,
	pub escapedBy: Option<Rc<StringLitContextAll<'input>>>,
	pub collectionItemsTerminatedBy: Option<Rc<StringLitContextAll<'input>>>,
	pub keysTerminatedBy: Option<Rc<StringLitContextAll<'input>>>,
	pub linesSeparatedBy: Option<Rc<StringLitContextAll<'input>>>,
	pub nullDefinedAs: Option<Rc<StringLitContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RowFormatDelimitedContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for RowFormatDelimitedContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for RowFormatDelimitedContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_rowFormatDelimited(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_rowFormatDelimited(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for RowFormatDelimitedContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_rowFormatDelimited(self);
	}
}

impl<'input> CustomRuleContext<'input> for RowFormatDelimitedContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rowFormat }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rowFormat }
}

impl<'input> Borrow<RowFormatContextExt<'input>> for RowFormatDelimitedContext<'input>{
	fn borrow(&self) -> &RowFormatContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<RowFormatContextExt<'input>> for RowFormatDelimitedContext<'input>{
	fn borrow_mut(&mut self) -> &mut RowFormatContextExt<'input> { &mut self.base }
}

impl<'input> RowFormatContextAttrs<'input> for RowFormatDelimitedContext<'input> {}

impl<'input> RowFormatDelimitedContextExt<'input>{
	fn new(ctx: &dyn RowFormatContextAttrs<'input>) -> Rc<RowFormatContextAll<'input>>  {
		Rc::new(
			RowFormatContextAll::RowFormatDelimitedContext(
				BaseParserRuleContext::copy_from(ctx,RowFormatDelimitedContextExt{
        			fieldsTerminatedBy:None, escapedBy:None, collectionItemsTerminatedBy:None, keysTerminatedBy:None, linesSeparatedBy:None, nullDefinedAs:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rowFormat(&mut self,)
	-> Result<Rc<RowFormatContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RowFormatContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 306, RULE_rowFormat);
        let mut _localctx: Rc<RowFormatContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3597);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(445,&mut recog.base)? {
				1 =>{
					let tmp = RowFormatSerdeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(3548);
					recog.base.match_token(ROW,&mut recog.err_handler)?;

					recog.base.set_state(3549);
					recog.base.match_token(FORMAT,&mut recog.err_handler)?;

					recog.base.set_state(3550);
					recog.base.match_token(SERDE,&mut recog.err_handler)?;

					/*InvokeRule stringLit*/
					recog.base.set_state(3551);
					let tmp = recog.stringLit()?;
					if let RowFormatContextAll::RowFormatSerdeContext(ctx) = cast_mut::<_,RowFormatContextAll >(&mut _localctx){
					ctx.name = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(3555);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(438,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3552);
							recog.base.match_token(WITH,&mut recog.err_handler)?;

							recog.base.set_state(3553);
							recog.base.match_token(SERDEPROPERTIES,&mut recog.err_handler)?;

							/*InvokeRule propertyList*/
							recog.base.set_state(3554);
							let tmp = recog.propertyList()?;
							if let RowFormatContextAll::RowFormatSerdeContext(ctx) = cast_mut::<_,RowFormatContextAll >(&mut _localctx){
							ctx.props = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					}
				}
			,
				2 =>{
					let tmp = RowFormatDelimitedContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(3557);
					recog.base.match_token(ROW,&mut recog.err_handler)?;

					recog.base.set_state(3558);
					recog.base.match_token(FORMAT,&mut recog.err_handler)?;

					recog.base.set_state(3559);
					recog.base.match_token(DELIMITED,&mut recog.err_handler)?;

					recog.base.set_state(3569);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(440,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3560);
							recog.base.match_token(FIELDS,&mut recog.err_handler)?;

							recog.base.set_state(3561);
							recog.base.match_token(TERMINATED,&mut recog.err_handler)?;

							recog.base.set_state(3562);
							recog.base.match_token(BY,&mut recog.err_handler)?;

							/*InvokeRule stringLit*/
							recog.base.set_state(3563);
							let tmp = recog.stringLit()?;
							if let RowFormatContextAll::RowFormatDelimitedContext(ctx) = cast_mut::<_,RowFormatContextAll >(&mut _localctx){
							ctx.fieldsTerminatedBy = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							recog.base.set_state(3567);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(439,&mut recog.base)? {
								x if x == 1=>{
									{
									recog.base.set_state(3564);
									recog.base.match_token(ESCAPED,&mut recog.err_handler)?;

									recog.base.set_state(3565);
									recog.base.match_token(BY,&mut recog.err_handler)?;

									/*InvokeRule stringLit*/
									recog.base.set_state(3566);
									let tmp = recog.stringLit()?;
									if let RowFormatContextAll::RowFormatDelimitedContext(ctx) = cast_mut::<_,RowFormatContextAll >(&mut _localctx){
									ctx.escapedBy = Some(tmp.clone()); } else {unreachable!("cant cast");}  

									}
								}

								_ => {}
							}
							}
						}

						_ => {}
					}
					recog.base.set_state(3576);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(441,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3571);
							recog.base.match_token(COLLECTION,&mut recog.err_handler)?;

							recog.base.set_state(3572);
							recog.base.match_token(ITEMS,&mut recog.err_handler)?;

							recog.base.set_state(3573);
							recog.base.match_token(TERMINATED,&mut recog.err_handler)?;

							recog.base.set_state(3574);
							recog.base.match_token(BY,&mut recog.err_handler)?;

							/*InvokeRule stringLit*/
							recog.base.set_state(3575);
							let tmp = recog.stringLit()?;
							if let RowFormatContextAll::RowFormatDelimitedContext(ctx) = cast_mut::<_,RowFormatContextAll >(&mut _localctx){
							ctx.collectionItemsTerminatedBy = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					recog.base.set_state(3583);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(442,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3578);
							recog.base.match_token(MAP,&mut recog.err_handler)?;

							recog.base.set_state(3579);
							recog.base.match_token(KEYS,&mut recog.err_handler)?;

							recog.base.set_state(3580);
							recog.base.match_token(TERMINATED,&mut recog.err_handler)?;

							recog.base.set_state(3581);
							recog.base.match_token(BY,&mut recog.err_handler)?;

							/*InvokeRule stringLit*/
							recog.base.set_state(3582);
							let tmp = recog.stringLit()?;
							if let RowFormatContextAll::RowFormatDelimitedContext(ctx) = cast_mut::<_,RowFormatContextAll >(&mut _localctx){
							ctx.keysTerminatedBy = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					recog.base.set_state(3589);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(443,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3585);
							recog.base.match_token(LINES,&mut recog.err_handler)?;

							recog.base.set_state(3586);
							recog.base.match_token(TERMINATED,&mut recog.err_handler)?;

							recog.base.set_state(3587);
							recog.base.match_token(BY,&mut recog.err_handler)?;

							/*InvokeRule stringLit*/
							recog.base.set_state(3588);
							let tmp = recog.stringLit()?;
							if let RowFormatContextAll::RowFormatDelimitedContext(ctx) = cast_mut::<_,RowFormatContextAll >(&mut _localctx){
							ctx.linesSeparatedBy = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					recog.base.set_state(3595);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(444,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3591);
							recog.base.match_token(NULL,&mut recog.err_handler)?;

							recog.base.set_state(3592);
							recog.base.match_token(DEFINED,&mut recog.err_handler)?;

							recog.base.set_state(3593);
							recog.base.match_token(AS,&mut recog.err_handler)?;

							/*InvokeRule stringLit*/
							recog.base.set_state(3594);
							let tmp = recog.stringLit()?;
							if let RowFormatContextAll::RowFormatDelimitedContext(ctx) = cast_mut::<_,RowFormatContextAll >(&mut _localctx){
							ctx.nullDefinedAs = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- multipartIdentifierList ----------------
pub type MultipartIdentifierListContextAll<'input> = MultipartIdentifierListContext<'input>;


pub type MultipartIdentifierListContext<'input> = BaseParserRuleContext<'input,MultipartIdentifierListContextExt<'input>>;

#[derive(Clone)]
pub struct MultipartIdentifierListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for MultipartIdentifierListContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for MultipartIdentifierListContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_multipartIdentifierList(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_multipartIdentifierList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for MultipartIdentifierListContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_multipartIdentifierList(self);
	}
}

impl<'input> CustomRuleContext<'input> for MultipartIdentifierListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_multipartIdentifierList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_multipartIdentifierList }
}
antlr_rust::tid!{MultipartIdentifierListContextExt<'a>}

impl<'input> MultipartIdentifierListContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MultipartIdentifierListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MultipartIdentifierListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait MultipartIdentifierListContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<MultipartIdentifierListContextExt<'input>>{

fn multipartIdentifier_all(&self) ->  Vec<Rc<MultipartIdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn multipartIdentifier(&self, i: usize) -> Option<Rc<MultipartIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> MultipartIdentifierListContextAttrs<'input> for MultipartIdentifierListContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn multipartIdentifierList(&mut self,)
	-> Result<Rc<MultipartIdentifierListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MultipartIdentifierListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 308, RULE_multipartIdentifierList);
        let mut _localctx: Rc<MultipartIdentifierListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule multipartIdentifier*/
			recog.base.set_state(3599);
			recog.multipartIdentifier()?;

			recog.base.set_state(3604);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(3600);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule multipartIdentifier*/
				recog.base.set_state(3601);
				recog.multipartIdentifier()?;

				}
				}
				recog.base.set_state(3606);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- multipartIdentifier ----------------
pub type MultipartIdentifierContextAll<'input> = MultipartIdentifierContext<'input>;


pub type MultipartIdentifierContext<'input> = BaseParserRuleContext<'input,MultipartIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct MultipartIdentifierContextExt<'input>{
	pub errorCapturingIdentifier: Option<Rc<ErrorCapturingIdentifierContextAll<'input>>>,
	pub parts:Vec<Rc<ErrorCapturingIdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for MultipartIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for MultipartIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_multipartIdentifier(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_multipartIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for MultipartIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_multipartIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for MultipartIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_multipartIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_multipartIdentifier }
}
antlr_rust::tid!{MultipartIdentifierContextExt<'a>}

impl<'input> MultipartIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MultipartIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MultipartIdentifierContextExt{
				errorCapturingIdentifier: None, 
				parts: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait MultipartIdentifierContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<MultipartIdentifierContextExt<'input>>{

fn errorCapturingIdentifier_all(&self) ->  Vec<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn errorCapturingIdentifier(&self, i: usize) -> Option<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token DOT in current rule
fn DOT_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token DOT, starting from 0.
/// Returns `None` if number of children corresponding to token DOT is less or equal than `i`.
fn DOT(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DOT, i)
}

}

impl<'input> MultipartIdentifierContextAttrs<'input> for MultipartIdentifierContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn multipartIdentifier(&mut self,)
	-> Result<Rc<MultipartIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MultipartIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 310, RULE_multipartIdentifier);
        let mut _localctx: Rc<MultipartIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule errorCapturingIdentifier*/
			recog.base.set_state(3607);
			let tmp = recog.errorCapturingIdentifier()?;
			 cast_mut::<_,MultipartIdentifierContext >(&mut _localctx).errorCapturingIdentifier = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,MultipartIdentifierContext >(&mut _localctx).errorCapturingIdentifier.clone().unwrap()
			 ;
			 cast_mut::<_,MultipartIdentifierContext >(&mut _localctx).parts.push(temp);
			  
			recog.base.set_state(3612);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(447,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(3608);
					recog.base.match_token(DOT,&mut recog.err_handler)?;

					/*InvokeRule errorCapturingIdentifier*/
					recog.base.set_state(3609);
					let tmp = recog.errorCapturingIdentifier()?;
					 cast_mut::<_,MultipartIdentifierContext >(&mut _localctx).errorCapturingIdentifier = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,MultipartIdentifierContext >(&mut _localctx).errorCapturingIdentifier.clone().unwrap()
					 ;
					 cast_mut::<_,MultipartIdentifierContext >(&mut _localctx).parts.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(3614);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(447,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- multipartIdentifierPropertyList ----------------
pub type MultipartIdentifierPropertyListContextAll<'input> = MultipartIdentifierPropertyListContext<'input>;


pub type MultipartIdentifierPropertyListContext<'input> = BaseParserRuleContext<'input,MultipartIdentifierPropertyListContextExt<'input>>;

#[derive(Clone)]
pub struct MultipartIdentifierPropertyListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for MultipartIdentifierPropertyListContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for MultipartIdentifierPropertyListContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_multipartIdentifierPropertyList(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_multipartIdentifierPropertyList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for MultipartIdentifierPropertyListContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_multipartIdentifierPropertyList(self);
	}
}

impl<'input> CustomRuleContext<'input> for MultipartIdentifierPropertyListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_multipartIdentifierPropertyList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_multipartIdentifierPropertyList }
}
antlr_rust::tid!{MultipartIdentifierPropertyListContextExt<'a>}

impl<'input> MultipartIdentifierPropertyListContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MultipartIdentifierPropertyListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MultipartIdentifierPropertyListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait MultipartIdentifierPropertyListContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<MultipartIdentifierPropertyListContextExt<'input>>{

fn multipartIdentifierProperty_all(&self) ->  Vec<Rc<MultipartIdentifierPropertyContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn multipartIdentifierProperty(&self, i: usize) -> Option<Rc<MultipartIdentifierPropertyContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> MultipartIdentifierPropertyListContextAttrs<'input> for MultipartIdentifierPropertyListContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn multipartIdentifierPropertyList(&mut self,)
	-> Result<Rc<MultipartIdentifierPropertyListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MultipartIdentifierPropertyListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 312, RULE_multipartIdentifierPropertyList);
        let mut _localctx: Rc<MultipartIdentifierPropertyListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule multipartIdentifierProperty*/
			recog.base.set_state(3615);
			recog.multipartIdentifierProperty()?;

			recog.base.set_state(3620);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(3616);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule multipartIdentifierProperty*/
				recog.base.set_state(3617);
				recog.multipartIdentifierProperty()?;

				}
				}
				recog.base.set_state(3622);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- multipartIdentifierProperty ----------------
pub type MultipartIdentifierPropertyContextAll<'input> = MultipartIdentifierPropertyContext<'input>;


pub type MultipartIdentifierPropertyContext<'input> = BaseParserRuleContext<'input,MultipartIdentifierPropertyContextExt<'input>>;

#[derive(Clone)]
pub struct MultipartIdentifierPropertyContextExt<'input>{
	pub options: Option<Rc<PropertyListContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for MultipartIdentifierPropertyContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for MultipartIdentifierPropertyContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_multipartIdentifierProperty(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_multipartIdentifierProperty(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for MultipartIdentifierPropertyContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_multipartIdentifierProperty(self);
	}
}

impl<'input> CustomRuleContext<'input> for MultipartIdentifierPropertyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_multipartIdentifierProperty }
	//fn type_rule_index() -> usize where Self: Sized { RULE_multipartIdentifierProperty }
}
antlr_rust::tid!{MultipartIdentifierPropertyContextExt<'a>}

impl<'input> MultipartIdentifierPropertyContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MultipartIdentifierPropertyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MultipartIdentifierPropertyContextExt{
				options: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait MultipartIdentifierPropertyContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<MultipartIdentifierPropertyContextExt<'input>>{

fn multipartIdentifier(&self) -> Option<Rc<MultipartIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token OPTIONS
/// Returns `None` if there is no child corresponding to token OPTIONS
fn OPTIONS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OPTIONS, 0)
}
fn propertyList(&self) -> Option<Rc<PropertyListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MultipartIdentifierPropertyContextAttrs<'input> for MultipartIdentifierPropertyContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn multipartIdentifierProperty(&mut self,)
	-> Result<Rc<MultipartIdentifierPropertyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MultipartIdentifierPropertyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 314, RULE_multipartIdentifierProperty);
        let mut _localctx: Rc<MultipartIdentifierPropertyContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule multipartIdentifier*/
			recog.base.set_state(3623);
			recog.multipartIdentifier()?;

			recog.base.set_state(3626);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==OPTIONS {
				{
				recog.base.set_state(3624);
				recog.base.match_token(OPTIONS,&mut recog.err_handler)?;

				/*InvokeRule propertyList*/
				recog.base.set_state(3625);
				let tmp = recog.propertyList()?;
				 cast_mut::<_,MultipartIdentifierPropertyContext >(&mut _localctx).options = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableIdentifier ----------------
pub type TableIdentifierContextAll<'input> = TableIdentifierContext<'input>;


pub type TableIdentifierContext<'input> = BaseParserRuleContext<'input,TableIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct TableIdentifierContextExt<'input>{
	pub db: Option<Rc<ErrorCapturingIdentifierContextAll<'input>>>,
	pub table: Option<Rc<ErrorCapturingIdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for TableIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for TableIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableIdentifier(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_tableIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for TableIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_tableIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableIdentifier }
}
antlr_rust::tid!{TableIdentifierContextExt<'a>}

impl<'input> TableIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableIdentifierContextExt{
				db: None, table: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TableIdentifierContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<TableIdentifierContextExt<'input>>{

fn errorCapturingIdentifier_all(&self) ->  Vec<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn errorCapturingIdentifier(&self, i: usize) -> Option<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token DOT
/// Returns `None` if there is no child corresponding to token DOT
fn DOT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DOT, 0)
}

}

impl<'input> TableIdentifierContextAttrs<'input> for TableIdentifierContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableIdentifier(&mut self,)
	-> Result<Rc<TableIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 316, RULE_tableIdentifier);
        let mut _localctx: Rc<TableIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3631);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(450,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule errorCapturingIdentifier*/
					recog.base.set_state(3628);
					let tmp = recog.errorCapturingIdentifier()?;
					 cast_mut::<_,TableIdentifierContext >(&mut _localctx).db = Some(tmp.clone());
					  

					recog.base.set_state(3629);
					recog.base.match_token(DOT,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			/*InvokeRule errorCapturingIdentifier*/
			recog.base.set_state(3633);
			let tmp = recog.errorCapturingIdentifier()?;
			 cast_mut::<_,TableIdentifierContext >(&mut _localctx).table = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- functionIdentifier ----------------
pub type FunctionIdentifierContextAll<'input> = FunctionIdentifierContext<'input>;


pub type FunctionIdentifierContext<'input> = BaseParserRuleContext<'input,FunctionIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionIdentifierContextExt<'input>{
	pub db: Option<Rc<ErrorCapturingIdentifierContextAll<'input>>>,
	pub function: Option<Rc<ErrorCapturingIdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for FunctionIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for FunctionIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionIdentifier(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_functionIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for FunctionIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_functionIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionIdentifier }
}
antlr_rust::tid!{FunctionIdentifierContextExt<'a>}

impl<'input> FunctionIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionIdentifierContextExt{
				db: None, function: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionIdentifierContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<FunctionIdentifierContextExt<'input>>{

fn errorCapturingIdentifier_all(&self) ->  Vec<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn errorCapturingIdentifier(&self, i: usize) -> Option<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token DOT
/// Returns `None` if there is no child corresponding to token DOT
fn DOT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DOT, 0)
}

}

impl<'input> FunctionIdentifierContextAttrs<'input> for FunctionIdentifierContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionIdentifier(&mut self,)
	-> Result<Rc<FunctionIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 318, RULE_functionIdentifier);
        let mut _localctx: Rc<FunctionIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3638);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(451,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule errorCapturingIdentifier*/
					recog.base.set_state(3635);
					let tmp = recog.errorCapturingIdentifier()?;
					 cast_mut::<_,FunctionIdentifierContext >(&mut _localctx).db = Some(tmp.clone());
					  

					recog.base.set_state(3636);
					recog.base.match_token(DOT,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			/*InvokeRule errorCapturingIdentifier*/
			recog.base.set_state(3640);
			let tmp = recog.errorCapturingIdentifier()?;
			 cast_mut::<_,FunctionIdentifierContext >(&mut _localctx).function = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- namedExpression ----------------
pub type NamedExpressionContextAll<'input> = NamedExpressionContext<'input>;


pub type NamedExpressionContext<'input> = BaseParserRuleContext<'input,NamedExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct NamedExpressionContextExt<'input>{
	pub name: Option<Rc<ErrorCapturingIdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for NamedExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for NamedExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_namedExpression(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_namedExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for NamedExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_namedExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for NamedExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_namedExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_namedExpression }
}
antlr_rust::tid!{NamedExpressionContextExt<'a>}

impl<'input> NamedExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NamedExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NamedExpressionContextExt{
				name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait NamedExpressionContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<NamedExpressionContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn identifierList(&self) -> Option<Rc<IdentifierListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
fn errorCapturingIdentifier(&self) -> Option<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> NamedExpressionContextAttrs<'input> for NamedExpressionContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn namedExpression(&mut self,)
	-> Result<Rc<NamedExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NamedExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 320, RULE_namedExpression);
        let mut _localctx: Rc<NamedExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(3642);
			recog.expression()?;

			recog.base.set_state(3650);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(454,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(3644);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(452,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3643);
							recog.base.match_token(AS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					recog.base.set_state(3648);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(453,&mut recog.base)? {
						1 =>{
							{
							/*InvokeRule errorCapturingIdentifier*/
							recog.base.set_state(3646);
							let tmp = recog.errorCapturingIdentifier()?;
							 cast_mut::<_,NamedExpressionContext >(&mut _localctx).name = Some(tmp.clone());
							  

							}
						}
					,
						2 =>{
							{
							/*InvokeRule identifierList*/
							recog.base.set_state(3647);
							recog.identifierList()?;

							}
						}

						_ => {}
					}
					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- namedExpressionSeq ----------------
pub type NamedExpressionSeqContextAll<'input> = NamedExpressionSeqContext<'input>;


pub type NamedExpressionSeqContext<'input> = BaseParserRuleContext<'input,NamedExpressionSeqContextExt<'input>>;

#[derive(Clone)]
pub struct NamedExpressionSeqContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for NamedExpressionSeqContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for NamedExpressionSeqContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_namedExpressionSeq(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_namedExpressionSeq(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for NamedExpressionSeqContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_namedExpressionSeq(self);
	}
}

impl<'input> CustomRuleContext<'input> for NamedExpressionSeqContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_namedExpressionSeq }
	//fn type_rule_index() -> usize where Self: Sized { RULE_namedExpressionSeq }
}
antlr_rust::tid!{NamedExpressionSeqContextExt<'a>}

impl<'input> NamedExpressionSeqContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NamedExpressionSeqContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NamedExpressionSeqContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait NamedExpressionSeqContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<NamedExpressionSeqContextExt<'input>>{

fn namedExpression_all(&self) ->  Vec<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn namedExpression(&self, i: usize) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> NamedExpressionSeqContextAttrs<'input> for NamedExpressionSeqContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn namedExpressionSeq(&mut self,)
	-> Result<Rc<NamedExpressionSeqContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NamedExpressionSeqContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 322, RULE_namedExpressionSeq);
        let mut _localctx: Rc<NamedExpressionSeqContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule namedExpression*/
			recog.base.set_state(3652);
			recog.namedExpression()?;

			recog.base.set_state(3657);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(455,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(3653);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule namedExpression*/
					recog.base.set_state(3654);
					recog.namedExpression()?;

					}
					} 
				}
				recog.base.set_state(3659);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(455,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionFieldList ----------------
pub type PartitionFieldListContextAll<'input> = PartitionFieldListContext<'input>;


pub type PartitionFieldListContext<'input> = BaseParserRuleContext<'input,PartitionFieldListContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionFieldListContextExt<'input>{
	pub partitionField: Option<Rc<PartitionFieldContextAll<'input>>>,
	pub fields:Vec<Rc<PartitionFieldContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for PartitionFieldListContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PartitionFieldListContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionFieldList(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_partitionFieldList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PartitionFieldListContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_partitionFieldList(self);
	}
}

impl<'input> CustomRuleContext<'input> for PartitionFieldListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionFieldList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionFieldList }
}
antlr_rust::tid!{PartitionFieldListContextExt<'a>}

impl<'input> PartitionFieldListContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionFieldListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionFieldListContextExt{
				partitionField: None, 
				fields: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionFieldListContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<PartitionFieldListContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
fn partitionField_all(&self) ->  Vec<Rc<PartitionFieldContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn partitionField(&self, i: usize) -> Option<Rc<PartitionFieldContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> PartitionFieldListContextAttrs<'input> for PartitionFieldListContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionFieldList(&mut self,)
	-> Result<Rc<PartitionFieldListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionFieldListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 324, RULE_partitionFieldList);
        let mut _localctx: Rc<PartitionFieldListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3660);
			recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

			/*InvokeRule partitionField*/
			recog.base.set_state(3661);
			let tmp = recog.partitionField()?;
			 cast_mut::<_,PartitionFieldListContext >(&mut _localctx).partitionField = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,PartitionFieldListContext >(&mut _localctx).partitionField.clone().unwrap()
			 ;
			 cast_mut::<_,PartitionFieldListContext >(&mut _localctx).fields.push(temp);
			  
			recog.base.set_state(3666);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(3662);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule partitionField*/
				recog.base.set_state(3663);
				let tmp = recog.partitionField()?;
				 cast_mut::<_,PartitionFieldListContext >(&mut _localctx).partitionField = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,PartitionFieldListContext >(&mut _localctx).partitionField.clone().unwrap()
				 ;
				 cast_mut::<_,PartitionFieldListContext >(&mut _localctx).fields.push(temp);
				  
				}
				}
				recog.base.set_state(3668);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(3669);
			recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionField ----------------
#[derive(Debug)]
pub enum PartitionFieldContextAll<'input>{
	PartitionColumnContext(PartitionColumnContext<'input>),
	PartitionTransformContext(PartitionTransformContext<'input>),
Error(PartitionFieldContext<'input>)
}
antlr_rust::tid!{PartitionFieldContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PartitionFieldContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for PartitionFieldContextAll<'input>{}

impl<'input> Deref for PartitionFieldContextAll<'input>{
	type Target = dyn PartitionFieldContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PartitionFieldContextAll::*;
		match self{
			PartitionColumnContext(inner) => inner,
			PartitionTransformContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PartitionFieldContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PartitionFieldContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PartitionFieldContext<'input> = BaseParserRuleContext<'input,PartitionFieldContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionFieldContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for PartitionFieldContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PartitionFieldContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PartitionFieldContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PartitionFieldContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionField }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionField }
}
antlr_rust::tid!{PartitionFieldContextExt<'a>}

impl<'input> PartitionFieldContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionFieldContextAll<'input>> {
		Rc::new(
		PartitionFieldContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionFieldContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PartitionFieldContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<PartitionFieldContextExt<'input>>{


}

impl<'input> PartitionFieldContextAttrs<'input> for PartitionFieldContext<'input>{}

pub type PartitionColumnContext<'input> = BaseParserRuleContext<'input,PartitionColumnContextExt<'input>>;

pub trait PartitionColumnContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn colType(&self) -> Option<Rc<ColTypeContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> PartitionColumnContextAttrs<'input> for PartitionColumnContext<'input>{}

pub struct PartitionColumnContextExt<'input>{
	base:PartitionFieldContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PartitionColumnContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for PartitionColumnContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PartitionColumnContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_partitionColumn(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_partitionColumn(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PartitionColumnContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_partitionColumn(self);
	}
}

impl<'input> CustomRuleContext<'input> for PartitionColumnContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionField }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionField }
}

impl<'input> Borrow<PartitionFieldContextExt<'input>> for PartitionColumnContext<'input>{
	fn borrow(&self) -> &PartitionFieldContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PartitionFieldContextExt<'input>> for PartitionColumnContext<'input>{
	fn borrow_mut(&mut self) -> &mut PartitionFieldContextExt<'input> { &mut self.base }
}

impl<'input> PartitionFieldContextAttrs<'input> for PartitionColumnContext<'input> {}

impl<'input> PartitionColumnContextExt<'input>{
	fn new(ctx: &dyn PartitionFieldContextAttrs<'input>) -> Rc<PartitionFieldContextAll<'input>>  {
		Rc::new(
			PartitionFieldContextAll::PartitionColumnContext(
				BaseParserRuleContext::copy_from(ctx,PartitionColumnContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PartitionTransformContext<'input> = BaseParserRuleContext<'input,PartitionTransformContextExt<'input>>;

pub trait PartitionTransformContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn transform(&self) -> Option<Rc<TransformContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> PartitionTransformContextAttrs<'input> for PartitionTransformContext<'input>{}

pub struct PartitionTransformContextExt<'input>{
	base:PartitionFieldContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PartitionTransformContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for PartitionTransformContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PartitionTransformContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_partitionTransform(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_partitionTransform(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PartitionTransformContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_partitionTransform(self);
	}
}

impl<'input> CustomRuleContext<'input> for PartitionTransformContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionField }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionField }
}

impl<'input> Borrow<PartitionFieldContextExt<'input>> for PartitionTransformContext<'input>{
	fn borrow(&self) -> &PartitionFieldContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PartitionFieldContextExt<'input>> for PartitionTransformContext<'input>{
	fn borrow_mut(&mut self) -> &mut PartitionFieldContextExt<'input> { &mut self.base }
}

impl<'input> PartitionFieldContextAttrs<'input> for PartitionTransformContext<'input> {}

impl<'input> PartitionTransformContextExt<'input>{
	fn new(ctx: &dyn PartitionFieldContextAttrs<'input>) -> Rc<PartitionFieldContextAll<'input>>  {
		Rc::new(
			PartitionFieldContextAll::PartitionTransformContext(
				BaseParserRuleContext::copy_from(ctx,PartitionTransformContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionField(&mut self,)
	-> Result<Rc<PartitionFieldContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionFieldContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 326, RULE_partitionField);
        let mut _localctx: Rc<PartitionFieldContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3673);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(457,&mut recog.base)? {
				1 =>{
					let tmp = PartitionTransformContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule transform*/
					recog.base.set_state(3671);
					recog.transform()?;

					}
				}
			,
				2 =>{
					let tmp = PartitionColumnContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule colType*/
					recog.base.set_state(3672);
					recog.colType()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- transform ----------------
#[derive(Debug)]
pub enum TransformContextAll<'input>{
	IdentityTransformContext(IdentityTransformContext<'input>),
	ApplyTransformContext(ApplyTransformContext<'input>),
Error(TransformContext<'input>)
}
antlr_rust::tid!{TransformContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for TransformContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for TransformContextAll<'input>{}

impl<'input> Deref for TransformContextAll<'input>{
	type Target = dyn TransformContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use TransformContextAll::*;
		match self{
			IdentityTransformContext(inner) => inner,
			ApplyTransformContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for TransformContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for TransformContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type TransformContext<'input> = BaseParserRuleContext<'input,TransformContextExt<'input>>;

#[derive(Clone)]
pub struct TransformContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for TransformContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for TransformContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for TransformContext<'input>{
}

impl<'input> CustomRuleContext<'input> for TransformContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_transform }
	//fn type_rule_index() -> usize where Self: Sized { RULE_transform }
}
antlr_rust::tid!{TransformContextExt<'a>}

impl<'input> TransformContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TransformContextAll<'input>> {
		Rc::new(
		TransformContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TransformContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait TransformContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<TransformContextExt<'input>>{


}

impl<'input> TransformContextAttrs<'input> for TransformContext<'input>{}

pub type IdentityTransformContext<'input> = BaseParserRuleContext<'input,IdentityTransformContextExt<'input>>;

pub trait IdentityTransformContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> IdentityTransformContextAttrs<'input> for IdentityTransformContext<'input>{}

pub struct IdentityTransformContextExt<'input>{
	base:TransformContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{IdentityTransformContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for IdentityTransformContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for IdentityTransformContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_identityTransform(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_identityTransform(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for IdentityTransformContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_identityTransform(self);
	}
}

impl<'input> CustomRuleContext<'input> for IdentityTransformContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_transform }
	//fn type_rule_index() -> usize where Self: Sized { RULE_transform }
}

impl<'input> Borrow<TransformContextExt<'input>> for IdentityTransformContext<'input>{
	fn borrow(&self) -> &TransformContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<TransformContextExt<'input>> for IdentityTransformContext<'input>{
	fn borrow_mut(&mut self) -> &mut TransformContextExt<'input> { &mut self.base }
}

impl<'input> TransformContextAttrs<'input> for IdentityTransformContext<'input> {}

impl<'input> IdentityTransformContextExt<'input>{
	fn new(ctx: &dyn TransformContextAttrs<'input>) -> Rc<TransformContextAll<'input>>  {
		Rc::new(
			TransformContextAll::IdentityTransformContext(
				BaseParserRuleContext::copy_from(ctx,IdentityTransformContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ApplyTransformContext<'input> = BaseParserRuleContext<'input,ApplyTransformContextExt<'input>>;

pub trait ApplyTransformContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn transformArgument_all(&self) ->  Vec<Rc<TransformArgumentContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn transformArgument(&self, i: usize) -> Option<Rc<TransformArgumentContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> ApplyTransformContextAttrs<'input> for ApplyTransformContext<'input>{}

pub struct ApplyTransformContextExt<'input>{
	base:TransformContextExt<'input>,
	pub transformName: Option<Rc<IdentifierContextAll<'input>>>,
	pub transformArgument: Option<Rc<TransformArgumentContextAll<'input>>>,
	pub argument:Vec<Rc<TransformArgumentContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ApplyTransformContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ApplyTransformContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ApplyTransformContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_applyTransform(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_applyTransform(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ApplyTransformContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_applyTransform(self);
	}
}

impl<'input> CustomRuleContext<'input> for ApplyTransformContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_transform }
	//fn type_rule_index() -> usize where Self: Sized { RULE_transform }
}

impl<'input> Borrow<TransformContextExt<'input>> for ApplyTransformContext<'input>{
	fn borrow(&self) -> &TransformContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<TransformContextExt<'input>> for ApplyTransformContext<'input>{
	fn borrow_mut(&mut self) -> &mut TransformContextExt<'input> { &mut self.base }
}

impl<'input> TransformContextAttrs<'input> for ApplyTransformContext<'input> {}

impl<'input> ApplyTransformContextExt<'input>{
	fn new(ctx: &dyn TransformContextAttrs<'input>) -> Rc<TransformContextAll<'input>>  {
		Rc::new(
			TransformContextAll::ApplyTransformContext(
				BaseParserRuleContext::copy_from(ctx,ApplyTransformContextExt{
        			transformName:None, transformArgument:None, 
        			argument:Vec::new(), 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn transform(&mut self,)
	-> Result<Rc<TransformContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TransformContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 328, RULE_transform);
        let mut _localctx: Rc<TransformContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3688);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(459,&mut recog.base)? {
				1 =>{
					let tmp = IdentityTransformContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule qualifiedName*/
					recog.base.set_state(3675);
					recog.qualifiedName()?;

					}
				}
			,
				2 =>{
					let tmp = ApplyTransformContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule identifier*/
					recog.base.set_state(3676);
					let tmp = recog.identifier()?;
					if let TransformContextAll::ApplyTransformContext(ctx) = cast_mut::<_,TransformContextAll >(&mut _localctx){
					ctx.transformName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(3677);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule transformArgument*/
					recog.base.set_state(3678);
					let tmp = recog.transformArgument()?;
					if let TransformContextAll::ApplyTransformContext(ctx) = cast_mut::<_,TransformContextAll >(&mut _localctx){
					ctx.transformArgument = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					let temp = if let TransformContextAll::ApplyTransformContext(ctx) = cast_mut::<_,TransformContextAll >(&mut _localctx){
					ctx.transformArgument.clone().unwrap() } else {unreachable!("cant cast");} ;
					if let TransformContextAll::ApplyTransformContext(ctx) = cast_mut::<_,TransformContextAll >(&mut _localctx){
					ctx.argument.push(temp); } else {unreachable!("cant cast");}  
					recog.base.set_state(3683);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(3679);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule transformArgument*/
						recog.base.set_state(3680);
						let tmp = recog.transformArgument()?;
						if let TransformContextAll::ApplyTransformContext(ctx) = cast_mut::<_,TransformContextAll >(&mut _localctx){
						ctx.transformArgument = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						let temp = if let TransformContextAll::ApplyTransformContext(ctx) = cast_mut::<_,TransformContextAll >(&mut _localctx){
						ctx.transformArgument.clone().unwrap() } else {unreachable!("cant cast");} ;
						if let TransformContextAll::ApplyTransformContext(ctx) = cast_mut::<_,TransformContextAll >(&mut _localctx){
						ctx.argument.push(temp); } else {unreachable!("cant cast");}  
						}
						}
						recog.base.set_state(3685);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(3686);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- transformArgument ----------------
pub type TransformArgumentContextAll<'input> = TransformArgumentContext<'input>;


pub type TransformArgumentContext<'input> = BaseParserRuleContext<'input,TransformArgumentContextExt<'input>>;

#[derive(Clone)]
pub struct TransformArgumentContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for TransformArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for TransformArgumentContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_transformArgument(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_transformArgument(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for TransformArgumentContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_transformArgument(self);
	}
}

impl<'input> CustomRuleContext<'input> for TransformArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_transformArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_transformArgument }
}
antlr_rust::tid!{TransformArgumentContextExt<'a>}

impl<'input> TransformArgumentContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TransformArgumentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TransformArgumentContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TransformArgumentContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<TransformArgumentContextExt<'input>>{

fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn constant(&self) -> Option<Rc<ConstantContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TransformArgumentContextAttrs<'input> for TransformArgumentContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn transformArgument(&mut self,)
	-> Result<Rc<TransformArgumentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TransformArgumentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 330, RULE_transformArgument);
        let mut _localctx: Rc<TransformArgumentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3692);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(460,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule qualifiedName*/
					recog.base.set_state(3690);
					recog.qualifiedName()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule constant*/
					recog.base.set_state(3691);
					recog.constant()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- expression ----------------
pub type ExpressionContextAll<'input> = ExpressionContext<'input>;


pub type ExpressionContext<'input> = BaseParserRuleContext<'input,ExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct ExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_expression(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_expression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_expression(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_expression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_expression }
}
antlr_rust::tid!{ExpressionContextExt<'a>}

impl<'input> ExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ExpressionContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ExpressionContextExt<'input>>{

fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ExpressionContextAttrs<'input> for ExpressionContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn expression(&mut self,)
	-> Result<Rc<ExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 332, RULE_expression);
        let mut _localctx: Rc<ExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule booleanExpression*/
			recog.base.set_state(3694);
			recog.booleanExpression_rec(0)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- namedArgumentExpression ----------------
pub type NamedArgumentExpressionContextAll<'input> = NamedArgumentExpressionContext<'input>;


pub type NamedArgumentExpressionContext<'input> = BaseParserRuleContext<'input,NamedArgumentExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct NamedArgumentExpressionContextExt<'input>{
	pub key: Option<Rc<IdentifierContextAll<'input>>>,
	pub value: Option<Rc<ExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for NamedArgumentExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for NamedArgumentExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_namedArgumentExpression(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_namedArgumentExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for NamedArgumentExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_namedArgumentExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for NamedArgumentExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_namedArgumentExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_namedArgumentExpression }
}
antlr_rust::tid!{NamedArgumentExpressionContextExt<'a>}

impl<'input> NamedArgumentExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NamedArgumentExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NamedArgumentExpressionContextExt{
				key: None, value: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait NamedArgumentExpressionContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<NamedArgumentExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token FAT_ARROW
/// Returns `None` if there is no child corresponding to token FAT_ARROW
fn FAT_ARROW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FAT_ARROW, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> NamedArgumentExpressionContextAttrs<'input> for NamedArgumentExpressionContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn namedArgumentExpression(&mut self,)
	-> Result<Rc<NamedArgumentExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NamedArgumentExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 334, RULE_namedArgumentExpression);
        let mut _localctx: Rc<NamedArgumentExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(3696);
			let tmp = recog.identifier()?;
			 cast_mut::<_,NamedArgumentExpressionContext >(&mut _localctx).key = Some(tmp.clone());
			  

			recog.base.set_state(3697);
			recog.base.match_token(FAT_ARROW,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(3698);
			let tmp = recog.expression()?;
			 cast_mut::<_,NamedArgumentExpressionContext >(&mut _localctx).value = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- functionArgument ----------------
pub type FunctionArgumentContextAll<'input> = FunctionArgumentContext<'input>;


pub type FunctionArgumentContext<'input> = BaseParserRuleContext<'input,FunctionArgumentContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionArgumentContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for FunctionArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for FunctionArgumentContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionArgument(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_functionArgument(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for FunctionArgumentContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_functionArgument(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionArgument }
}
antlr_rust::tid!{FunctionArgumentContextExt<'a>}

impl<'input> FunctionArgumentContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionArgumentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionArgumentContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionArgumentContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<FunctionArgumentContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn namedArgumentExpression(&self) -> Option<Rc<NamedArgumentExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FunctionArgumentContextAttrs<'input> for FunctionArgumentContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionArgument(&mut self,)
	-> Result<Rc<FunctionArgumentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionArgumentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 336, RULE_functionArgument);
        let mut _localctx: Rc<FunctionArgumentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3702);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(461,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule expression*/
					recog.base.set_state(3700);
					recog.expression()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule namedArgumentExpression*/
					recog.base.set_state(3701);
					recog.namedArgumentExpression()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- expressionSeq ----------------
pub type ExpressionSeqContextAll<'input> = ExpressionSeqContext<'input>;


pub type ExpressionSeqContext<'input> = BaseParserRuleContext<'input,ExpressionSeqContextExt<'input>>;

#[derive(Clone)]
pub struct ExpressionSeqContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ExpressionSeqContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ExpressionSeqContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_expressionSeq(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_expressionSeq(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ExpressionSeqContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_expressionSeq(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExpressionSeqContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_expressionSeq }
	//fn type_rule_index() -> usize where Self: Sized { RULE_expressionSeq }
}
antlr_rust::tid!{ExpressionSeqContextExt<'a>}

impl<'input> ExpressionSeqContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExpressionSeqContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExpressionSeqContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ExpressionSeqContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ExpressionSeqContextExt<'input>>{

fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ExpressionSeqContextAttrs<'input> for ExpressionSeqContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn expressionSeq(&mut self,)
	-> Result<Rc<ExpressionSeqContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExpressionSeqContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 338, RULE_expressionSeq);
        let mut _localctx: Rc<ExpressionSeqContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(3704);
			recog.expression()?;

			recog.base.set_state(3709);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(3705);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule expression*/
				recog.base.set_state(3706);
				recog.expression()?;

				}
				}
				recog.base.set_state(3711);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- booleanExpression ----------------
#[derive(Debug)]
pub enum BooleanExpressionContextAll<'input>{
	LogicalNotContext(LogicalNotContext<'input>),
	PredicatedContext(PredicatedContext<'input>),
	ExistsContext(ExistsContext<'input>),
	LogicalBinaryContext(LogicalBinaryContext<'input>),
Error(BooleanExpressionContext<'input>)
}
antlr_rust::tid!{BooleanExpressionContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for BooleanExpressionContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for BooleanExpressionContextAll<'input>{}

impl<'input> Deref for BooleanExpressionContextAll<'input>{
	type Target = dyn BooleanExpressionContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use BooleanExpressionContextAll::*;
		match self{
			LogicalNotContext(inner) => inner,
			PredicatedContext(inner) => inner,
			ExistsContext(inner) => inner,
			LogicalBinaryContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for BooleanExpressionContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for BooleanExpressionContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type BooleanExpressionContext<'input> = BaseParserRuleContext<'input,BooleanExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct BooleanExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for BooleanExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for BooleanExpressionContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for BooleanExpressionContext<'input>{
}

impl<'input> CustomRuleContext<'input> for BooleanExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanExpression }
}
antlr_rust::tid!{BooleanExpressionContextExt<'a>}

impl<'input> BooleanExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<BooleanExpressionContextAll<'input>> {
		Rc::new(
		BooleanExpressionContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,BooleanExpressionContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait BooleanExpressionContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<BooleanExpressionContextExt<'input>>{


}

impl<'input> BooleanExpressionContextAttrs<'input> for BooleanExpressionContext<'input>{}

pub type LogicalNotContext<'input> = BaseParserRuleContext<'input,LogicalNotContextExt<'input>>;

pub trait LogicalNotContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token NOT
	/// Returns `None` if there is no child corresponding to token NOT
	fn NOT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(NOT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token BANG
	/// Returns `None` if there is no child corresponding to token BANG
	fn BANG(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(BANG, 0)
	}
}

impl<'input> LogicalNotContextAttrs<'input> for LogicalNotContext<'input>{}

pub struct LogicalNotContextExt<'input>{
	base:BooleanExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{LogicalNotContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for LogicalNotContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for LogicalNotContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_logicalNot(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_logicalNot(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for LogicalNotContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_logicalNot(self);
	}
}

impl<'input> CustomRuleContext<'input> for LogicalNotContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanExpression }
}

impl<'input> Borrow<BooleanExpressionContextExt<'input>> for LogicalNotContext<'input>{
	fn borrow(&self) -> &BooleanExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<BooleanExpressionContextExt<'input>> for LogicalNotContext<'input>{
	fn borrow_mut(&mut self) -> &mut BooleanExpressionContextExt<'input> { &mut self.base }
}

impl<'input> BooleanExpressionContextAttrs<'input> for LogicalNotContext<'input> {}

impl<'input> LogicalNotContextExt<'input>{
	fn new(ctx: &dyn BooleanExpressionContextAttrs<'input>) -> Rc<BooleanExpressionContextAll<'input>>  {
		Rc::new(
			BooleanExpressionContextAll::LogicalNotContext(
				BaseParserRuleContext::copy_from(ctx,LogicalNotContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PredicatedContext<'input> = BaseParserRuleContext<'input,PredicatedContextExt<'input>>;

pub trait PredicatedContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn predicate(&self) -> Option<Rc<PredicateContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> PredicatedContextAttrs<'input> for PredicatedContext<'input>{}

pub struct PredicatedContextExt<'input>{
	base:BooleanExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PredicatedContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for PredicatedContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PredicatedContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_predicated(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_predicated(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PredicatedContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_predicated(self);
	}
}

impl<'input> CustomRuleContext<'input> for PredicatedContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanExpression }
}

impl<'input> Borrow<BooleanExpressionContextExt<'input>> for PredicatedContext<'input>{
	fn borrow(&self) -> &BooleanExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<BooleanExpressionContextExt<'input>> for PredicatedContext<'input>{
	fn borrow_mut(&mut self) -> &mut BooleanExpressionContextExt<'input> { &mut self.base }
}

impl<'input> BooleanExpressionContextAttrs<'input> for PredicatedContext<'input> {}

impl<'input> PredicatedContextExt<'input>{
	fn new(ctx: &dyn BooleanExpressionContextAttrs<'input>) -> Rc<BooleanExpressionContextAll<'input>>  {
		Rc::new(
			BooleanExpressionContextAll::PredicatedContext(
				BaseParserRuleContext::copy_from(ctx,PredicatedContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ExistsContext<'input> = BaseParserRuleContext<'input,ExistsContextExt<'input>>;

pub trait ExistsContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token EXISTS
	/// Returns `None` if there is no child corresponding to token EXISTS
	fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXISTS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
}

impl<'input> ExistsContextAttrs<'input> for ExistsContext<'input>{}

pub struct ExistsContextExt<'input>{
	base:BooleanExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ExistsContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ExistsContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ExistsContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_exists(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_exists(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ExistsContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_exists(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExistsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanExpression }
}

impl<'input> Borrow<BooleanExpressionContextExt<'input>> for ExistsContext<'input>{
	fn borrow(&self) -> &BooleanExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<BooleanExpressionContextExt<'input>> for ExistsContext<'input>{
	fn borrow_mut(&mut self) -> &mut BooleanExpressionContextExt<'input> { &mut self.base }
}

impl<'input> BooleanExpressionContextAttrs<'input> for ExistsContext<'input> {}

impl<'input> ExistsContextExt<'input>{
	fn new(ctx: &dyn BooleanExpressionContextAttrs<'input>) -> Rc<BooleanExpressionContextAll<'input>>  {
		Rc::new(
			BooleanExpressionContextAll::ExistsContext(
				BaseParserRuleContext::copy_from(ctx,ExistsContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type LogicalBinaryContext<'input> = BaseParserRuleContext<'input,LogicalBinaryContextExt<'input>>;

pub trait LogicalBinaryContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn booleanExpression_all(&self) ->  Vec<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn booleanExpression(&self, i: usize) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token AND
	/// Returns `None` if there is no child corresponding to token AND
	fn AND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(AND, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OR
	/// Returns `None` if there is no child corresponding to token OR
	fn OR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(OR, 0)
	}
}

impl<'input> LogicalBinaryContextAttrs<'input> for LogicalBinaryContext<'input>{}

pub struct LogicalBinaryContextExt<'input>{
	base:BooleanExpressionContextExt<'input>,
	pub left: Option<Rc<BooleanExpressionContextAll<'input>>>,
	pub operator: Option<TokenType<'input>>,
	pub right: Option<Rc<BooleanExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{LogicalBinaryContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for LogicalBinaryContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for LogicalBinaryContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_logicalBinary(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_logicalBinary(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for LogicalBinaryContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_logicalBinary(self);
	}
}

impl<'input> CustomRuleContext<'input> for LogicalBinaryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanExpression }
}

impl<'input> Borrow<BooleanExpressionContextExt<'input>> for LogicalBinaryContext<'input>{
	fn borrow(&self) -> &BooleanExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<BooleanExpressionContextExt<'input>> for LogicalBinaryContext<'input>{
	fn borrow_mut(&mut self) -> &mut BooleanExpressionContextExt<'input> { &mut self.base }
}

impl<'input> BooleanExpressionContextAttrs<'input> for LogicalBinaryContext<'input> {}

impl<'input> LogicalBinaryContextExt<'input>{
	fn new(ctx: &dyn BooleanExpressionContextAttrs<'input>) -> Rc<BooleanExpressionContextAll<'input>>  {
		Rc::new(
			BooleanExpressionContextAll::LogicalBinaryContext(
				BaseParserRuleContext::copy_from(ctx,LogicalBinaryContextExt{
					operator:None, 
        			left:None, right:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn  booleanExpression(&mut self,)
	-> Result<Rc<BooleanExpressionContextAll<'input>>,ANTLRError> {
		self.booleanExpression_rec(0)
	}

	fn booleanExpression_rec(&mut self, _p: isize)
	-> Result<Rc<BooleanExpressionContextAll<'input>>,ANTLRError> {
		let recog = self;
		let _parentctx = recog.ctx.take();
		let _parentState = recog.base.get_state();
		let mut _localctx = BooleanExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
		recog.base.enter_recursion_rule(_localctx.clone(), 340, RULE_booleanExpression, _p);
	    let mut _localctx: Rc<BooleanExpressionContextAll> = _localctx;
        let mut _prevctx = _localctx.clone();
		let _startState = 340;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {
			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3724);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(464,&mut recog.base)? {
				1 =>{
					{
					let mut tmp = LogicalNotContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();


					recog.base.set_state(3713);
					_la = recog.base.input.la(1);
					if { !(_la==BANG || _la==NOT) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					/*InvokeRule booleanExpression*/
					recog.base.set_state(3714);
					recog.booleanExpression_rec(5)?;

					}
				}
			,
				2 =>{
					{
					let mut tmp = ExistsContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3715);
					recog.base.match_token(EXISTS,&mut recog.err_handler)?;

					recog.base.set_state(3716);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(3717);
					recog.query()?;

					recog.base.set_state(3718);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					{
					let mut tmp = PredicatedContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule valueExpression*/
					recog.base.set_state(3720);
					recog.valueExpression_rec(0)?;

					recog.base.set_state(3722);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(463,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule predicate*/
							recog.base.set_state(3721);
							recog.predicate()?;

							}
						}

						_ => {}
					}
					}
				}

				_ => {}
			}

			let tmp = recog.input.lt(-1).cloned();
			recog.ctx.as_ref().unwrap().set_stop(tmp);
			recog.base.set_state(3734);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(466,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					recog.trigger_exit_rule_event();
					_prevctx = _localctx.clone();
					{
					recog.base.set_state(3732);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(465,&mut recog.base)? {
						1 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = LogicalBinaryContextExt::new(&**BooleanExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let BooleanExpressionContextAll::LogicalBinaryContext(ctx) = cast_mut::<_,BooleanExpressionContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_booleanExpression);
							_localctx = tmp;
							recog.base.set_state(3726);
							if !({recog.precpred(None, 2)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 2)".to_owned()), None))?;
							}
							recog.base.set_state(3727);
							let tmp = recog.base.match_token(AND,&mut recog.err_handler)?;
							if let BooleanExpressionContextAll::LogicalBinaryContext(ctx) = cast_mut::<_,BooleanExpressionContextAll >(&mut _localctx){
							ctx.operator = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							/*InvokeRule booleanExpression*/
							recog.base.set_state(3728);
							let tmp = recog.booleanExpression_rec(3)?;
							if let BooleanExpressionContextAll::LogicalBinaryContext(ctx) = cast_mut::<_,BooleanExpressionContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						2 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = LogicalBinaryContextExt::new(&**BooleanExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let BooleanExpressionContextAll::LogicalBinaryContext(ctx) = cast_mut::<_,BooleanExpressionContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_booleanExpression);
							_localctx = tmp;
							recog.base.set_state(3729);
							if !({recog.precpred(None, 1)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 1)".to_owned()), None))?;
							}
							recog.base.set_state(3730);
							let tmp = recog.base.match_token(OR,&mut recog.err_handler)?;
							if let BooleanExpressionContextAll::LogicalBinaryContext(ctx) = cast_mut::<_,BooleanExpressionContextAll >(&mut _localctx){
							ctx.operator = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							/*InvokeRule booleanExpression*/
							recog.base.set_state(3731);
							let tmp = recog.booleanExpression_rec(2)?;
							if let BooleanExpressionContextAll::LogicalBinaryContext(ctx) = cast_mut::<_,BooleanExpressionContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					} 
				}
				recog.base.set_state(3736);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(466,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_) => {},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re)=>{
			//_localctx.exception = re;
			recog.err_handler.report_error(&mut recog.base, re);
	        recog.err_handler.recover(&mut recog.base, re)?;}
		}
		recog.base.unroll_recursion_context(_parentctx);

		Ok(_localctx)
	}
}
//------------------- predicate ----------------
pub type PredicateContextAll<'input> = PredicateContext<'input>;


pub type PredicateContext<'input> = BaseParserRuleContext<'input,PredicateContextExt<'input>>;

#[derive(Clone)]
pub struct PredicateContextExt<'input>{
	pub kind: Option<TokenType<'input>>,
	pub lower: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub upper: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub pattern: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub quantifier: Option<TokenType<'input>>,
	pub escapeChar: Option<Rc<StringLitContextAll<'input>>>,
	pub right: Option<Rc<ValueExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for PredicateContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PredicateContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_predicate(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_predicate(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PredicateContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_predicate(self);
	}
}

impl<'input> CustomRuleContext<'input> for PredicateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicate }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicate }
}
antlr_rust::tid!{PredicateContextExt<'a>}

impl<'input> PredicateContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PredicateContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PredicateContextExt{
				kind: None, quantifier: None, 
				lower: None, upper: None, pattern: None, escapeChar: None, right: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PredicateContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<PredicateContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token AND
/// Returns `None` if there is no child corresponding to token AND
fn AND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AND, 0)
}
/// Retrieves first TerminalNode corresponding to token BETWEEN
/// Returns `None` if there is no child corresponding to token BETWEEN
fn BETWEEN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BETWEEN, 0)
}
fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn errorCapturingNot(&self) -> Option<Rc<ErrorCapturingNotContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token IN
/// Returns `None` if there is no child corresponding to token IN
fn IN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RLIKE
/// Returns `None` if there is no child corresponding to token RLIKE
fn RLIKE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RLIKE, 0)
}
/// Retrieves first TerminalNode corresponding to token LIKE
/// Returns `None` if there is no child corresponding to token LIKE
fn LIKE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LIKE, 0)
}
/// Retrieves first TerminalNode corresponding to token ILIKE
/// Returns `None` if there is no child corresponding to token ILIKE
fn ILIKE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ILIKE, 0)
}
/// Retrieves first TerminalNode corresponding to token ANY
/// Returns `None` if there is no child corresponding to token ANY
fn ANY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ANY, 0)
}
/// Retrieves first TerminalNode corresponding to token SOME
/// Returns `None` if there is no child corresponding to token SOME
fn SOME(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SOME, 0)
}
/// Retrieves first TerminalNode corresponding to token ALL
/// Returns `None` if there is no child corresponding to token ALL
fn ALL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ALL, 0)
}
/// Retrieves first TerminalNode corresponding to token ESCAPE
/// Returns `None` if there is no child corresponding to token ESCAPE
fn ESCAPE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ESCAPE, 0)
}
fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token IS
/// Returns `None` if there is no child corresponding to token IS
fn IS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IS, 0)
}
/// Retrieves first TerminalNode corresponding to token NULL
/// Returns `None` if there is no child corresponding to token NULL
fn NULL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NULL, 0)
}
/// Retrieves first TerminalNode corresponding to token TRUE
/// Returns `None` if there is no child corresponding to token TRUE
fn TRUE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TRUE, 0)
}
/// Retrieves first TerminalNode corresponding to token FALSE
/// Returns `None` if there is no child corresponding to token FALSE
fn FALSE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FALSE, 0)
}
/// Retrieves first TerminalNode corresponding to token UNKNOWN
/// Returns `None` if there is no child corresponding to token UNKNOWN
fn UNKNOWN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UNKNOWN, 0)
}
/// Retrieves first TerminalNode corresponding to token FROM
/// Returns `None` if there is no child corresponding to token FROM
fn FROM(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FROM, 0)
}
/// Retrieves first TerminalNode corresponding to token DISTINCT
/// Returns `None` if there is no child corresponding to token DISTINCT
fn DISTINCT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DISTINCT, 0)
}

}

impl<'input> PredicateContextAttrs<'input> for PredicateContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn predicate(&mut self,)
	-> Result<Rc<PredicateContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PredicateContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 342, RULE_predicate);
        let mut _localctx: Rc<PredicateContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(3819);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(480,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(3738);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==BANG || _la==NOT {
						{
						/*InvokeRule errorCapturingNot*/
						recog.base.set_state(3737);
						recog.errorCapturingNot()?;

						}
					}

					recog.base.set_state(3740);
					let tmp = recog.base.match_token(BETWEEN,&mut recog.err_handler)?;
					 cast_mut::<_,PredicateContext >(&mut _localctx).kind = Some(tmp.clone());
					  

					/*InvokeRule valueExpression*/
					recog.base.set_state(3741);
					let tmp = recog.valueExpression_rec(0)?;
					 cast_mut::<_,PredicateContext >(&mut _localctx).lower = Some(tmp.clone());
					  

					recog.base.set_state(3742);
					recog.base.match_token(AND,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(3743);
					let tmp = recog.valueExpression_rec(0)?;
					 cast_mut::<_,PredicateContext >(&mut _localctx).upper = Some(tmp.clone());
					  

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(3746);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==BANG || _la==NOT {
						{
						/*InvokeRule errorCapturingNot*/
						recog.base.set_state(3745);
						recog.errorCapturingNot()?;

						}
					}

					recog.base.set_state(3748);
					let tmp = recog.base.match_token(IN,&mut recog.err_handler)?;
					 cast_mut::<_,PredicateContext >(&mut _localctx).kind = Some(tmp.clone());
					  

					recog.base.set_state(3749);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(3750);
					recog.expression()?;

					recog.base.set_state(3755);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(3751);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule expression*/
						recog.base.set_state(3752);
						recog.expression()?;

						}
						}
						recog.base.set_state(3757);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(3758);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(3761);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==BANG || _la==NOT {
						{
						/*InvokeRule errorCapturingNot*/
						recog.base.set_state(3760);
						recog.errorCapturingNot()?;

						}
					}

					recog.base.set_state(3763);
					let tmp = recog.base.match_token(IN,&mut recog.err_handler)?;
					 cast_mut::<_,PredicateContext >(&mut _localctx).kind = Some(tmp.clone());
					  

					recog.base.set_state(3764);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(3765);
					recog.query()?;

					recog.base.set_state(3766);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(3769);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==BANG || _la==NOT {
						{
						/*InvokeRule errorCapturingNot*/
						recog.base.set_state(3768);
						recog.errorCapturingNot()?;

						}
					}

					recog.base.set_state(3771);
					let tmp = recog.base.match_token(RLIKE,&mut recog.err_handler)?;
					 cast_mut::<_,PredicateContext >(&mut _localctx).kind = Some(tmp.clone());
					  

					/*InvokeRule valueExpression*/
					recog.base.set_state(3772);
					let tmp = recog.valueExpression_rec(0)?;
					 cast_mut::<_,PredicateContext >(&mut _localctx).pattern = Some(tmp.clone());
					  

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					recog.base.set_state(3774);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==BANG || _la==NOT {
						{
						/*InvokeRule errorCapturingNot*/
						recog.base.set_state(3773);
						recog.errorCapturingNot()?;

						}
					}

					recog.base.set_state(3776);
					 cast_mut::<_,PredicateContext >(&mut _localctx).kind = recog.base.input.lt(1).cloned();
					 
					_la = recog.base.input.la(1);
					if { !(_la==LIKE || _la==ILIKE) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						 cast_mut::<_,PredicateContext >(&mut _localctx).kind = Some(tmp.clone());
						  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(3777);
					 cast_mut::<_,PredicateContext >(&mut _localctx).quantifier = recog.base.input.lt(1).cloned();
					 
					_la = recog.base.input.la(1);
					if { !(_la==ALL || _la==ANY || _la==SOME) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						 cast_mut::<_,PredicateContext >(&mut _localctx).quantifier = Some(tmp.clone());
						  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(3791);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(474,&mut recog.base)? {
						1 =>{
							{
							recog.base.set_state(3778);
							recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

							recog.base.set_state(3779);
							recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

							}
						}
					,
						2 =>{
							{
							recog.base.set_state(3780);
							recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

							/*InvokeRule expression*/
							recog.base.set_state(3781);
							recog.expression()?;

							recog.base.set_state(3786);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							while _la==COMMA {
								{
								{
								recog.base.set_state(3782);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule expression*/
								recog.base.set_state(3783);
								recog.expression()?;

								}
								}
								recog.base.set_state(3788);
								recog.err_handler.sync(&mut recog.base)?;
								_la = recog.base.input.la(1);
							}
							recog.base.set_state(3789);
							recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					recog.base.set_state(3794);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==BANG || _la==NOT {
						{
						/*InvokeRule errorCapturingNot*/
						recog.base.set_state(3793);
						recog.errorCapturingNot()?;

						}
					}

					recog.base.set_state(3796);
					 cast_mut::<_,PredicateContext >(&mut _localctx).kind = recog.base.input.lt(1).cloned();
					 
					_la = recog.base.input.la(1);
					if { !(_la==LIKE || _la==ILIKE) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						 cast_mut::<_,PredicateContext >(&mut _localctx).kind = Some(tmp.clone());
						  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					/*InvokeRule valueExpression*/
					recog.base.set_state(3797);
					let tmp = recog.valueExpression_rec(0)?;
					 cast_mut::<_,PredicateContext >(&mut _localctx).pattern = Some(tmp.clone());
					  

					recog.base.set_state(3800);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(476,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3798);
							recog.base.match_token(ESCAPE,&mut recog.err_handler)?;

							/*InvokeRule stringLit*/
							recog.base.set_state(3799);
							let tmp = recog.stringLit()?;
							 cast_mut::<_,PredicateContext >(&mut _localctx).escapeChar = Some(tmp.clone());
							  

							}
						}

						_ => {}
					}
					}
				}
			,
				7 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					recog.base.set_state(3802);
					recog.base.match_token(IS,&mut recog.err_handler)?;

					recog.base.set_state(3804);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==BANG || _la==NOT {
						{
						/*InvokeRule errorCapturingNot*/
						recog.base.set_state(3803);
						recog.errorCapturingNot()?;

						}
					}

					recog.base.set_state(3806);
					let tmp = recog.base.match_token(NULL,&mut recog.err_handler)?;
					 cast_mut::<_,PredicateContext >(&mut _localctx).kind = Some(tmp.clone());
					  

					}
				}
			,
				8 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 8);
					recog.base.enter_outer_alt(None, 8);
					{
					recog.base.set_state(3807);
					recog.base.match_token(IS,&mut recog.err_handler)?;

					recog.base.set_state(3809);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==BANG || _la==NOT {
						{
						/*InvokeRule errorCapturingNot*/
						recog.base.set_state(3808);
						recog.errorCapturingNot()?;

						}
					}

					recog.base.set_state(3811);
					 cast_mut::<_,PredicateContext >(&mut _localctx).kind = recog.base.input.lt(1).cloned();
					 
					_la = recog.base.input.la(1);
					if { !(_la==FALSE || _la==TRUE || _la==UNKNOWN) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						 cast_mut::<_,PredicateContext >(&mut _localctx).kind = Some(tmp.clone());
						  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					}
				}
			,
				9 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 9);
					recog.base.enter_outer_alt(None, 9);
					{
					recog.base.set_state(3812);
					recog.base.match_token(IS,&mut recog.err_handler)?;

					recog.base.set_state(3814);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==BANG || _la==NOT {
						{
						/*InvokeRule errorCapturingNot*/
						recog.base.set_state(3813);
						recog.errorCapturingNot()?;

						}
					}

					recog.base.set_state(3816);
					let tmp = recog.base.match_token(DISTINCT,&mut recog.err_handler)?;
					 cast_mut::<_,PredicateContext >(&mut _localctx).kind = Some(tmp.clone());
					  

					recog.base.set_state(3817);
					recog.base.match_token(FROM,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(3818);
					let tmp = recog.valueExpression_rec(0)?;
					 cast_mut::<_,PredicateContext >(&mut _localctx).right = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- errorCapturingNot ----------------
pub type ErrorCapturingNotContextAll<'input> = ErrorCapturingNotContext<'input>;


pub type ErrorCapturingNotContext<'input> = BaseParserRuleContext<'input,ErrorCapturingNotContextExt<'input>>;

#[derive(Clone)]
pub struct ErrorCapturingNotContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ErrorCapturingNotContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ErrorCapturingNotContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_errorCapturingNot(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_errorCapturingNot(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ErrorCapturingNotContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_errorCapturingNot(self);
	}
}

impl<'input> CustomRuleContext<'input> for ErrorCapturingNotContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_errorCapturingNot }
	//fn type_rule_index() -> usize where Self: Sized { RULE_errorCapturingNot }
}
antlr_rust::tid!{ErrorCapturingNotContextExt<'a>}

impl<'input> ErrorCapturingNotContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ErrorCapturingNotContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ErrorCapturingNotContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ErrorCapturingNotContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ErrorCapturingNotContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token NOT
/// Returns `None` if there is no child corresponding to token NOT
fn NOT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NOT, 0)
}
/// Retrieves first TerminalNode corresponding to token BANG
/// Returns `None` if there is no child corresponding to token BANG
fn BANG(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BANG, 0)
}

}

impl<'input> ErrorCapturingNotContextAttrs<'input> for ErrorCapturingNotContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn errorCapturingNot(&mut self,)
	-> Result<Rc<ErrorCapturingNotContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ErrorCapturingNotContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 344, RULE_errorCapturingNot);
        let mut _localctx: Rc<ErrorCapturingNotContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3821);
			_la = recog.base.input.la(1);
			if { !(_la==BANG || _la==NOT) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- valueExpression ----------------
#[derive(Debug)]
pub enum ValueExpressionContextAll<'input>{
	ValueExpressionDefaultContext(ValueExpressionDefaultContext<'input>),
	ComparisonContext(ComparisonContext<'input>),
	ShiftExpressionContext(ShiftExpressionContext<'input>),
	ArithmeticBinaryContext(ArithmeticBinaryContext<'input>),
	ArithmeticUnaryContext(ArithmeticUnaryContext<'input>),
Error(ValueExpressionContext<'input>)
}
antlr_rust::tid!{ValueExpressionContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for ValueExpressionContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for ValueExpressionContextAll<'input>{}

impl<'input> Deref for ValueExpressionContextAll<'input>{
	type Target = dyn ValueExpressionContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use ValueExpressionContextAll::*;
		match self{
			ValueExpressionDefaultContext(inner) => inner,
			ComparisonContext(inner) => inner,
			ShiftExpressionContext(inner) => inner,
			ArithmeticBinaryContext(inner) => inner,
			ArithmeticUnaryContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ValueExpressionContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ValueExpressionContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type ValueExpressionContext<'input> = BaseParserRuleContext<'input,ValueExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct ValueExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ValueExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ValueExpressionContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ValueExpressionContext<'input>{
}

impl<'input> CustomRuleContext<'input> for ValueExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valueExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valueExpression }
}
antlr_rust::tid!{ValueExpressionContextExt<'a>}

impl<'input> ValueExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ValueExpressionContextAll<'input>> {
		Rc::new(
		ValueExpressionContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ValueExpressionContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait ValueExpressionContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ValueExpressionContextExt<'input>>{


}

impl<'input> ValueExpressionContextAttrs<'input> for ValueExpressionContext<'input>{}

pub type ValueExpressionDefaultContext<'input> = BaseParserRuleContext<'input,ValueExpressionDefaultContextExt<'input>>;

pub trait ValueExpressionDefaultContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn primaryExpression(&self) -> Option<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ValueExpressionDefaultContextAttrs<'input> for ValueExpressionDefaultContext<'input>{}

pub struct ValueExpressionDefaultContextExt<'input>{
	base:ValueExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ValueExpressionDefaultContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ValueExpressionDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ValueExpressionDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_valueExpressionDefault(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_valueExpressionDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ValueExpressionDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_valueExpressionDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for ValueExpressionDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valueExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valueExpression }
}

impl<'input> Borrow<ValueExpressionContextExt<'input>> for ValueExpressionDefaultContext<'input>{
	fn borrow(&self) -> &ValueExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ValueExpressionContextExt<'input>> for ValueExpressionDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut ValueExpressionContextExt<'input> { &mut self.base }
}

impl<'input> ValueExpressionContextAttrs<'input> for ValueExpressionDefaultContext<'input> {}

impl<'input> ValueExpressionDefaultContextExt<'input>{
	fn new(ctx: &dyn ValueExpressionContextAttrs<'input>) -> Rc<ValueExpressionContextAll<'input>>  {
		Rc::new(
			ValueExpressionContextAll::ValueExpressionDefaultContext(
				BaseParserRuleContext::copy_from(ctx,ValueExpressionDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ComparisonContext<'input> = BaseParserRuleContext<'input,ComparisonContextExt<'input>>;

pub trait ComparisonContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn comparisonOperator(&self) -> Option<Rc<ComparisonOperatorContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> ComparisonContextAttrs<'input> for ComparisonContext<'input>{}

pub struct ComparisonContextExt<'input>{
	base:ValueExpressionContextExt<'input>,
	pub left: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub right: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ComparisonContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ComparisonContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ComparisonContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_comparison(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_comparison(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ComparisonContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_comparison(self);
	}
}

impl<'input> CustomRuleContext<'input> for ComparisonContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valueExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valueExpression }
}

impl<'input> Borrow<ValueExpressionContextExt<'input>> for ComparisonContext<'input>{
	fn borrow(&self) -> &ValueExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ValueExpressionContextExt<'input>> for ComparisonContext<'input>{
	fn borrow_mut(&mut self) -> &mut ValueExpressionContextExt<'input> { &mut self.base }
}

impl<'input> ValueExpressionContextAttrs<'input> for ComparisonContext<'input> {}

impl<'input> ComparisonContextExt<'input>{
	fn new(ctx: &dyn ValueExpressionContextAttrs<'input>) -> Rc<ValueExpressionContextAll<'input>>  {
		Rc::new(
			ValueExpressionContextAll::ComparisonContext(
				BaseParserRuleContext::copy_from(ctx,ComparisonContextExt{
        			left:None, right:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ShiftExpressionContext<'input> = BaseParserRuleContext<'input,ShiftExpressionContextExt<'input>>;

pub trait ShiftExpressionContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn shiftOperator(&self) -> Option<Rc<ShiftOperatorContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> ShiftExpressionContextAttrs<'input> for ShiftExpressionContext<'input>{}

pub struct ShiftExpressionContextExt<'input>{
	base:ValueExpressionContextExt<'input>,
	pub left: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub right: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ShiftExpressionContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ShiftExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ShiftExpressionContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_shiftExpression(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_shiftExpression(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ShiftExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_shiftExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for ShiftExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valueExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valueExpression }
}

impl<'input> Borrow<ValueExpressionContextExt<'input>> for ShiftExpressionContext<'input>{
	fn borrow(&self) -> &ValueExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ValueExpressionContextExt<'input>> for ShiftExpressionContext<'input>{
	fn borrow_mut(&mut self) -> &mut ValueExpressionContextExt<'input> { &mut self.base }
}

impl<'input> ValueExpressionContextAttrs<'input> for ShiftExpressionContext<'input> {}

impl<'input> ShiftExpressionContextExt<'input>{
	fn new(ctx: &dyn ValueExpressionContextAttrs<'input>) -> Rc<ValueExpressionContextAll<'input>>  {
		Rc::new(
			ValueExpressionContextAll::ShiftExpressionContext(
				BaseParserRuleContext::copy_from(ctx,ShiftExpressionContextExt{
        			left:None, right:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ArithmeticBinaryContext<'input> = BaseParserRuleContext<'input,ArithmeticBinaryContextExt<'input>>;

pub trait ArithmeticBinaryContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token ASTERISK
	/// Returns `None` if there is no child corresponding to token ASTERISK
	fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ASTERISK, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SLASH
	/// Returns `None` if there is no child corresponding to token SLASH
	fn SLASH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SLASH, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PERCENT
	/// Returns `None` if there is no child corresponding to token PERCENT
	fn PERCENT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(PERCENT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DIV
	/// Returns `None` if there is no child corresponding to token DIV
	fn DIV(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DIV, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PLUS
	/// Returns `None` if there is no child corresponding to token PLUS
	fn PLUS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(PLUS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token CONCAT_PIPE
	/// Returns `None` if there is no child corresponding to token CONCAT_PIPE
	fn CONCAT_PIPE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CONCAT_PIPE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token AMPERSAND
	/// Returns `None` if there is no child corresponding to token AMPERSAND
	fn AMPERSAND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(AMPERSAND, 0)
	}
	/// Retrieves first TerminalNode corresponding to token HAT
	/// Returns `None` if there is no child corresponding to token HAT
	fn HAT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(HAT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PIPE
	/// Returns `None` if there is no child corresponding to token PIPE
	fn PIPE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(PIPE, 0)
	}
}

impl<'input> ArithmeticBinaryContextAttrs<'input> for ArithmeticBinaryContext<'input>{}

pub struct ArithmeticBinaryContextExt<'input>{
	base:ValueExpressionContextExt<'input>,
	pub left: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub operator: Option<TokenType<'input>>,
	pub right: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ArithmeticBinaryContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ArithmeticBinaryContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ArithmeticBinaryContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_arithmeticBinary(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_arithmeticBinary(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ArithmeticBinaryContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_arithmeticBinary(self);
	}
}

impl<'input> CustomRuleContext<'input> for ArithmeticBinaryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valueExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valueExpression }
}

impl<'input> Borrow<ValueExpressionContextExt<'input>> for ArithmeticBinaryContext<'input>{
	fn borrow(&self) -> &ValueExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ValueExpressionContextExt<'input>> for ArithmeticBinaryContext<'input>{
	fn borrow_mut(&mut self) -> &mut ValueExpressionContextExt<'input> { &mut self.base }
}

impl<'input> ValueExpressionContextAttrs<'input> for ArithmeticBinaryContext<'input> {}

impl<'input> ArithmeticBinaryContextExt<'input>{
	fn new(ctx: &dyn ValueExpressionContextAttrs<'input>) -> Rc<ValueExpressionContextAll<'input>>  {
		Rc::new(
			ValueExpressionContextAll::ArithmeticBinaryContext(
				BaseParserRuleContext::copy_from(ctx,ArithmeticBinaryContextExt{
					operator:None, 
        			left:None, right:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ArithmeticUnaryContext<'input> = BaseParserRuleContext<'input,ArithmeticUnaryContextExt<'input>>;

pub trait ArithmeticUnaryContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PLUS
	/// Returns `None` if there is no child corresponding to token PLUS
	fn PLUS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(PLUS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TILDE
	/// Returns `None` if there is no child corresponding to token TILDE
	fn TILDE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TILDE, 0)
	}
}

impl<'input> ArithmeticUnaryContextAttrs<'input> for ArithmeticUnaryContext<'input>{}

pub struct ArithmeticUnaryContextExt<'input>{
	base:ValueExpressionContextExt<'input>,
	pub operator: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ArithmeticUnaryContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ArithmeticUnaryContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ArithmeticUnaryContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_arithmeticUnary(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_arithmeticUnary(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ArithmeticUnaryContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_arithmeticUnary(self);
	}
}

impl<'input> CustomRuleContext<'input> for ArithmeticUnaryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_valueExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_valueExpression }
}

impl<'input> Borrow<ValueExpressionContextExt<'input>> for ArithmeticUnaryContext<'input>{
	fn borrow(&self) -> &ValueExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ValueExpressionContextExt<'input>> for ArithmeticUnaryContext<'input>{
	fn borrow_mut(&mut self) -> &mut ValueExpressionContextExt<'input> { &mut self.base }
}

impl<'input> ValueExpressionContextAttrs<'input> for ArithmeticUnaryContext<'input> {}

impl<'input> ArithmeticUnaryContextExt<'input>{
	fn new(ctx: &dyn ValueExpressionContextAttrs<'input>) -> Rc<ValueExpressionContextAll<'input>>  {
		Rc::new(
			ValueExpressionContextAll::ArithmeticUnaryContext(
				BaseParserRuleContext::copy_from(ctx,ArithmeticUnaryContextExt{
					operator:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn  valueExpression(&mut self,)
	-> Result<Rc<ValueExpressionContextAll<'input>>,ANTLRError> {
		self.valueExpression_rec(0)
	}

	fn valueExpression_rec(&mut self, _p: isize)
	-> Result<Rc<ValueExpressionContextAll<'input>>,ANTLRError> {
		let recog = self;
		let _parentctx = recog.ctx.take();
		let _parentState = recog.base.get_state();
		let mut _localctx = ValueExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
		recog.base.enter_recursion_rule(_localctx.clone(), 346, RULE_valueExpression, _p);
	    let mut _localctx: Rc<ValueExpressionContextAll> = _localctx;
        let mut _prevctx = _localctx.clone();
		let _startState = 346;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {
			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3827);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(481,&mut recog.base)? {
				1 =>{
					{
					let mut tmp = ValueExpressionDefaultContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();


					/*InvokeRule primaryExpression*/
					recog.base.set_state(3824);
					recog.primaryExpression_rec(0)?;

					}
				}
			,
				2 =>{
					{
					let mut tmp = ArithmeticUnaryContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3825);
					if let ValueExpressionContextAll::ArithmeticUnaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
					ctx.operator = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
					_la = recog.base.input.la(1);
					if { !(((((_la - 419)) & !0x3f) == 0 && ((1usize << (_la - 419)) & ((1usize << (PLUS - 419)) | (1usize << (MINUS - 419)) | (1usize << (TILDE - 419)))) != 0)) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						if let ValueExpressionContextAll::ArithmeticUnaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
						ctx.operator = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					/*InvokeRule valueExpression*/
					recog.base.set_state(3826);
					recog.valueExpression_rec(8)?;

					}
				}

				_ => {}
			}

			let tmp = recog.input.lt(-1).cloned();
			recog.ctx.as_ref().unwrap().set_stop(tmp);
			recog.base.set_state(3855);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(483,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					recog.trigger_exit_rule_event();
					_prevctx = _localctx.clone();
					{
					recog.base.set_state(3853);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(482,&mut recog.base)? {
						1 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = ArithmeticBinaryContextExt::new(&**ValueExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_valueExpression);
							_localctx = tmp;
							recog.base.set_state(3829);
							if !({recog.precpred(None, 7)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 7)".to_owned()), None))?;
							}
							recog.base.set_state(3830);
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.operator = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
							_la = recog.base.input.la(1);
							if { !(_la==DIV || ((((_la - 421)) & !0x3f) == 0 && ((1usize << (_la - 421)) & ((1usize << (ASTERISK - 421)) | (1usize << (SLASH - 421)) | (1usize << (PERCENT - 421)))) != 0)) } {
								let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
								if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
								ctx.operator = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
							else {
								if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
								recog.err_handler.report_match(&mut recog.base);
								recog.base.consume(&mut recog.err_handler);
							}
							/*InvokeRule valueExpression*/
							recog.base.set_state(3831);
							let tmp = recog.valueExpression_rec(8)?;
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						2 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = ArithmeticBinaryContextExt::new(&**ValueExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_valueExpression);
							_localctx = tmp;
							recog.base.set_state(3832);
							if !({recog.precpred(None, 6)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 6)".to_owned()), None))?;
							}
							recog.base.set_state(3833);
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.operator = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
							_la = recog.base.input.la(1);
							if { !(((((_la - 419)) & !0x3f) == 0 && ((1usize << (_la - 419)) & ((1usize << (PLUS - 419)) | (1usize << (MINUS - 419)) | (1usize << (CONCAT_PIPE - 419)))) != 0)) } {
								let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
								if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
								ctx.operator = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
							else {
								if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
								recog.err_handler.report_match(&mut recog.base);
								recog.base.consume(&mut recog.err_handler);
							}
							/*InvokeRule valueExpression*/
							recog.base.set_state(3834);
							let tmp = recog.valueExpression_rec(7)?;
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						3 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = ShiftExpressionContextExt::new(&**ValueExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let ValueExpressionContextAll::ShiftExpressionContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_valueExpression);
							_localctx = tmp;
							recog.base.set_state(3835);
							if !({recog.precpred(None, 5)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 5)".to_owned()), None))?;
							}
							/*InvokeRule shiftOperator*/
							recog.base.set_state(3836);
							recog.shiftOperator()?;

							/*InvokeRule valueExpression*/
							recog.base.set_state(3837);
							let tmp = recog.valueExpression_rec(6)?;
							if let ValueExpressionContextAll::ShiftExpressionContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						4 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = ArithmeticBinaryContextExt::new(&**ValueExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_valueExpression);
							_localctx = tmp;
							recog.base.set_state(3839);
							if !({recog.precpred(None, 4)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 4)".to_owned()), None))?;
							}
							recog.base.set_state(3840);
							let tmp = recog.base.match_token(AMPERSAND,&mut recog.err_handler)?;
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.operator = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							/*InvokeRule valueExpression*/
							recog.base.set_state(3841);
							let tmp = recog.valueExpression_rec(5)?;
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						5 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = ArithmeticBinaryContextExt::new(&**ValueExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_valueExpression);
							_localctx = tmp;
							recog.base.set_state(3842);
							if !({recog.precpred(None, 3)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 3)".to_owned()), None))?;
							}
							recog.base.set_state(3843);
							let tmp = recog.base.match_token(HAT,&mut recog.err_handler)?;
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.operator = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							/*InvokeRule valueExpression*/
							recog.base.set_state(3844);
							let tmp = recog.valueExpression_rec(4)?;
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						6 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = ArithmeticBinaryContextExt::new(&**ValueExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_valueExpression);
							_localctx = tmp;
							recog.base.set_state(3845);
							if !({recog.precpred(None, 2)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 2)".to_owned()), None))?;
							}
							recog.base.set_state(3846);
							if !({!isOperatorPipeStart()}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("!isOperatorPipeStart()".to_owned()), None))?;
							}
							recog.base.set_state(3847);
							let tmp = recog.base.match_token(PIPE,&mut recog.err_handler)?;
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.operator = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							/*InvokeRule valueExpression*/
							recog.base.set_state(3848);
							let tmp = recog.valueExpression_rec(3)?;
							if let ValueExpressionContextAll::ArithmeticBinaryContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						7 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = ComparisonContextExt::new(&**ValueExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let ValueExpressionContextAll::ComparisonContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut tmp){
								ctx.left = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_valueExpression);
							_localctx = tmp;
							recog.base.set_state(3849);
							if !({recog.precpred(None, 1)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 1)".to_owned()), None))?;
							}
							/*InvokeRule comparisonOperator*/
							recog.base.set_state(3850);
							recog.comparisonOperator()?;

							/*InvokeRule valueExpression*/
							recog.base.set_state(3851);
							let tmp = recog.valueExpression_rec(2)?;
							if let ValueExpressionContextAll::ComparisonContext(ctx) = cast_mut::<_,ValueExpressionContextAll >(&mut _localctx){
							ctx.right = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					} 
				}
				recog.base.set_state(3857);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(483,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_) => {},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re)=>{
			//_localctx.exception = re;
			recog.err_handler.report_error(&mut recog.base, re);
	        recog.err_handler.recover(&mut recog.base, re)?;}
		}
		recog.base.unroll_recursion_context(_parentctx);

		Ok(_localctx)
	}
}
//------------------- shiftOperator ----------------
pub type ShiftOperatorContextAll<'input> = ShiftOperatorContext<'input>;


pub type ShiftOperatorContext<'input> = BaseParserRuleContext<'input,ShiftOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct ShiftOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ShiftOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ShiftOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_shiftOperator(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_shiftOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ShiftOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_shiftOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for ShiftOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_shiftOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_shiftOperator }
}
antlr_rust::tid!{ShiftOperatorContextExt<'a>}

impl<'input> ShiftOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ShiftOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ShiftOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ShiftOperatorContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ShiftOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token SHIFT_LEFT
/// Returns `None` if there is no child corresponding to token SHIFT_LEFT
fn SHIFT_LEFT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SHIFT_LEFT, 0)
}
/// Retrieves first TerminalNode corresponding to token SHIFT_RIGHT
/// Returns `None` if there is no child corresponding to token SHIFT_RIGHT
fn SHIFT_RIGHT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SHIFT_RIGHT, 0)
}
/// Retrieves first TerminalNode corresponding to token SHIFT_RIGHT_UNSIGNED
/// Returns `None` if there is no child corresponding to token SHIFT_RIGHT_UNSIGNED
fn SHIFT_RIGHT_UNSIGNED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SHIFT_RIGHT_UNSIGNED, 0)
}

}

impl<'input> ShiftOperatorContextAttrs<'input> for ShiftOperatorContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn shiftOperator(&mut self,)
	-> Result<Rc<ShiftOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ShiftOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 348, RULE_shiftOperator);
        let mut _localctx: Rc<ShiftOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3858);
			_la = recog.base.input.la(1);
			if { !(((((_la - 416)) & !0x3f) == 0 && ((1usize << (_la - 416)) & ((1usize << (SHIFT_LEFT - 416)) | (1usize << (SHIFT_RIGHT - 416)) | (1usize << (SHIFT_RIGHT_UNSIGNED - 416)))) != 0)) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- datetimeUnit ----------------
pub type DatetimeUnitContextAll<'input> = DatetimeUnitContext<'input>;


pub type DatetimeUnitContext<'input> = BaseParserRuleContext<'input,DatetimeUnitContextExt<'input>>;

#[derive(Clone)]
pub struct DatetimeUnitContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for DatetimeUnitContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DatetimeUnitContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_datetimeUnit(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_datetimeUnit(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DatetimeUnitContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_datetimeUnit(self);
	}
}

impl<'input> CustomRuleContext<'input> for DatetimeUnitContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_datetimeUnit }
	//fn type_rule_index() -> usize where Self: Sized { RULE_datetimeUnit }
}
antlr_rust::tid!{DatetimeUnitContextExt<'a>}

impl<'input> DatetimeUnitContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DatetimeUnitContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DatetimeUnitContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DatetimeUnitContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<DatetimeUnitContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token YEAR
/// Returns `None` if there is no child corresponding to token YEAR
fn YEAR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(YEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token QUARTER
/// Returns `None` if there is no child corresponding to token QUARTER
fn QUARTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(QUARTER, 0)
}
/// Retrieves first TerminalNode corresponding to token MONTH
/// Returns `None` if there is no child corresponding to token MONTH
fn MONTH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MONTH, 0)
}
/// Retrieves first TerminalNode corresponding to token WEEK
/// Returns `None` if there is no child corresponding to token WEEK
fn WEEK(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WEEK, 0)
}
/// Retrieves first TerminalNode corresponding to token DAY
/// Returns `None` if there is no child corresponding to token DAY
fn DAY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DAY, 0)
}
/// Retrieves first TerminalNode corresponding to token DAYOFYEAR
/// Returns `None` if there is no child corresponding to token DAYOFYEAR
fn DAYOFYEAR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DAYOFYEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token HOUR
/// Returns `None` if there is no child corresponding to token HOUR
fn HOUR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(HOUR, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUTE
/// Returns `None` if there is no child corresponding to token MINUTE
fn MINUTE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MINUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token SECOND
/// Returns `None` if there is no child corresponding to token SECOND
fn SECOND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token MILLISECOND
/// Returns `None` if there is no child corresponding to token MILLISECOND
fn MILLISECOND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MILLISECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token MICROSECOND
/// Returns `None` if there is no child corresponding to token MICROSECOND
fn MICROSECOND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MICROSECOND, 0)
}

}

impl<'input> DatetimeUnitContextAttrs<'input> for DatetimeUnitContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn datetimeUnit(&mut self,)
	-> Result<Rc<DatetimeUnitContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DatetimeUnitContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 350, RULE_datetimeUnit);
        let mut _localctx: Rc<DatetimeUnitContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(3860);
			_la = recog.base.input.la(1);
			if { !(_la==DAY || _la==DAYOFYEAR || _la==HOUR || ((((_la - 218)) & !0x3f) == 0 && ((1usize << (_la - 218)) & ((1usize << (MICROSECOND - 218)) | (1usize << (MILLISECOND - 218)) | (1usize << (MINUTE - 218)) | (1usize << (MONTH - 218)))) != 0) || _la==QUARTER || _la==SECOND || _la==WEEK || _la==YEAR) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- primaryExpression ----------------
#[derive(Debug)]
pub enum PrimaryExpressionContextAll<'input>{
	StructContext(StructContext<'input>),
	DereferenceContext(DereferenceContext<'input>),
	CastByColonContext(CastByColonContext<'input>),
	TimestampaddContext(TimestampaddContext<'input>),
	SubstringContext(SubstringContext<'input>),
	CastContext(CastContext<'input>),
	LambdaContext(LambdaContext<'input>),
	ParenthesizedExpressionContext(ParenthesizedExpressionContext<'input>),
	Any_valueContext(Any_valueContext<'input>),
	TrimContext(TrimContext<'input>),
	SemiStructuredExtractContext(SemiStructuredExtractContext<'input>),
	SimpleCaseContext(SimpleCaseContext<'input>),
	CurrentLikeContext(CurrentLikeContext<'input>),
	ColumnReferenceContext(ColumnReferenceContext<'input>),
	RowConstructorContext(RowConstructorContext<'input>),
	LastContext(LastContext<'input>),
	StarContext(StarContext<'input>),
	OverlayContext(OverlayContext<'input>),
	SubscriptContext(SubscriptContext<'input>),
	TimestampdiffContext(TimestampdiffContext<'input>),
	SubqueryExpressionContext(SubqueryExpressionContext<'input>),
	CollateContext(CollateContext<'input>),
	ConstantDefaultContext(ConstantDefaultContext<'input>),
	ExtractContext(ExtractContext<'input>),
	FunctionCallContext(FunctionCallContext<'input>),
	SearchedCaseContext(SearchedCaseContext<'input>),
	PositionContext(PositionContext<'input>),
	FirstContext(FirstContext<'input>),
Error(PrimaryExpressionContext<'input>)
}
antlr_rust::tid!{PrimaryExpressionContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for PrimaryExpressionContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for PrimaryExpressionContextAll<'input>{}

impl<'input> Deref for PrimaryExpressionContextAll<'input>{
	type Target = dyn PrimaryExpressionContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use PrimaryExpressionContextAll::*;
		match self{
			StructContext(inner) => inner,
			DereferenceContext(inner) => inner,
			CastByColonContext(inner) => inner,
			TimestampaddContext(inner) => inner,
			SubstringContext(inner) => inner,
			CastContext(inner) => inner,
			LambdaContext(inner) => inner,
			ParenthesizedExpressionContext(inner) => inner,
			Any_valueContext(inner) => inner,
			TrimContext(inner) => inner,
			SemiStructuredExtractContext(inner) => inner,
			SimpleCaseContext(inner) => inner,
			CurrentLikeContext(inner) => inner,
			ColumnReferenceContext(inner) => inner,
			RowConstructorContext(inner) => inner,
			LastContext(inner) => inner,
			StarContext(inner) => inner,
			OverlayContext(inner) => inner,
			SubscriptContext(inner) => inner,
			TimestampdiffContext(inner) => inner,
			SubqueryExpressionContext(inner) => inner,
			CollateContext(inner) => inner,
			ConstantDefaultContext(inner) => inner,
			ExtractContext(inner) => inner,
			FunctionCallContext(inner) => inner,
			SearchedCaseContext(inner) => inner,
			PositionContext(inner) => inner,
			FirstContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PrimaryExpressionContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PrimaryExpressionContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type PrimaryExpressionContext<'input> = BaseParserRuleContext<'input,PrimaryExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct PrimaryExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for PrimaryExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PrimaryExpressionContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PrimaryExpressionContext<'input>{
}

impl<'input> CustomRuleContext<'input> for PrimaryExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}
antlr_rust::tid!{PrimaryExpressionContextExt<'a>}

impl<'input> PrimaryExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrimaryExpressionContextAll<'input>> {
		Rc::new(
		PrimaryExpressionContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrimaryExpressionContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait PrimaryExpressionContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<PrimaryExpressionContextExt<'input>>{


}

impl<'input> PrimaryExpressionContextAttrs<'input> for PrimaryExpressionContext<'input>{}

pub type StructContext<'input> = BaseParserRuleContext<'input,StructContextExt<'input>>;

pub trait StructContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token STRUCT
	/// Returns `None` if there is no child corresponding to token STRUCT
	fn STRUCT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(STRUCT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
	fn namedExpression_all(&self) ->  Vec<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn namedExpression(&self, i: usize) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> StructContextAttrs<'input> for StructContext<'input>{}

pub struct StructContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub namedExpression: Option<Rc<NamedExpressionContextAll<'input>>>,
	pub argument:Vec<Rc<NamedExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{StructContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for StructContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for StructContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_struct(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_struct(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for StructContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_struct(self);
	}
}

impl<'input> CustomRuleContext<'input> for StructContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for StructContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for StructContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for StructContext<'input> {}

impl<'input> StructContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::StructContext(
				BaseParserRuleContext::copy_from(ctx,StructContextExt{
        			namedExpression:None, 
        			argument:Vec::new(), 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DereferenceContext<'input> = BaseParserRuleContext<'input,DereferenceContextExt<'input>>;

pub trait DereferenceContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DOT
	/// Returns `None` if there is no child corresponding to token DOT
	fn DOT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DOT, 0)
	}
	fn primaryExpression(&self) -> Option<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> DereferenceContextAttrs<'input> for DereferenceContext<'input>{}

pub struct DereferenceContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub base: Option<Rc<PrimaryExpressionContextAll<'input>>>,
	pub fieldName: Option<Rc<IdentifierContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DereferenceContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for DereferenceContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DereferenceContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_dereference(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_dereference(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DereferenceContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_dereference(self);
	}
}

impl<'input> CustomRuleContext<'input> for DereferenceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for DereferenceContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for DereferenceContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for DereferenceContext<'input> {}

impl<'input> DereferenceContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::DereferenceContext(
				BaseParserRuleContext::copy_from(ctx,DereferenceContextExt{
        			base:None, fieldName:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CastByColonContext<'input> = BaseParserRuleContext<'input,CastByColonContextExt<'input>>;

pub trait CastByColonContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn primaryExpression(&self) -> Option<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token DOUBLE_COLON
	/// Returns `None` if there is no child corresponding to token DOUBLE_COLON
	fn DOUBLE_COLON(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DOUBLE_COLON, 0)
	}
	fn dataType(&self) -> Option<Rc<DataTypeContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> CastByColonContextAttrs<'input> for CastByColonContext<'input>{}

pub struct CastByColonContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CastByColonContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for CastByColonContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CastByColonContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_castByColon(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_castByColon(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CastByColonContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_castByColon(self);
	}
}

impl<'input> CustomRuleContext<'input> for CastByColonContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for CastByColonContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for CastByColonContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for CastByColonContext<'input> {}

impl<'input> CastByColonContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::CastByColonContext(
				BaseParserRuleContext::copy_from(ctx,CastByColonContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TimestampaddContext<'input> = BaseParserRuleContext<'input,TimestampaddContextExt<'input>>;

pub trait TimestampaddContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token TIMESTAMPADD
	/// Returns `None` if there is no child corresponding to token TIMESTAMPADD
	fn TIMESTAMPADD(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TIMESTAMPADD, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DATEADD
	/// Returns `None` if there is no child corresponding to token DATEADD
	fn DATEADD(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DATEADD, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DATE_ADD
	/// Returns `None` if there is no child corresponding to token DATE_ADD
	fn DATE_ADD(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DATE_ADD, 0)
	}
	fn datetimeUnit(&self) -> Option<Rc<DatetimeUnitContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> TimestampaddContextAttrs<'input> for TimestampaddContext<'input>{}

pub struct TimestampaddContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub name: Option<TokenType<'input>>,
	pub unit: Option<Rc<DatetimeUnitContextAll<'input>>>,
	pub invalidUnit: Option<Rc<StringLitContextAll<'input>>>,
	pub unitsAmount: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub timestamp: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TimestampaddContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for TimestampaddContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for TimestampaddContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_timestampadd(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_timestampadd(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for TimestampaddContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_timestampadd(self);
	}
}

impl<'input> CustomRuleContext<'input> for TimestampaddContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for TimestampaddContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for TimestampaddContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for TimestampaddContext<'input> {}

impl<'input> TimestampaddContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::TimestampaddContext(
				BaseParserRuleContext::copy_from(ctx,TimestampaddContextExt{
					name:None, 
        			unit:None, invalidUnit:None, unitsAmount:None, timestamp:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SubstringContext<'input> = BaseParserRuleContext<'input,SubstringContextExt<'input>>;

pub trait SubstringContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SUBSTR
	/// Returns `None` if there is no child corresponding to token SUBSTR
	fn SUBSTR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SUBSTR, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SUBSTRING
	/// Returns `None` if there is no child corresponding to token SUBSTRING
	fn SUBSTRING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SUBSTRING, 0)
	}
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
	/// Retrieves first TerminalNode corresponding to token FOR
	/// Returns `None` if there is no child corresponding to token FOR
	fn FOR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FOR, 0)
	}
}

impl<'input> SubstringContextAttrs<'input> for SubstringContext<'input>{}

pub struct SubstringContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub str: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub pos: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub len: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SubstringContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SubstringContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SubstringContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_substring(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_substring(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SubstringContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_substring(self);
	}
}

impl<'input> CustomRuleContext<'input> for SubstringContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for SubstringContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for SubstringContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for SubstringContext<'input> {}

impl<'input> SubstringContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::SubstringContext(
				BaseParserRuleContext::copy_from(ctx,SubstringContextExt{
        			str:None, pos:None, len:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CastContext<'input> = BaseParserRuleContext<'input,CastContextExt<'input>>;

pub trait CastContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	fn dataType(&self) -> Option<Rc<DataTypeContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token CAST
	/// Returns `None` if there is no child corresponding to token CAST
	fn CAST(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CAST, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TRY_CAST
	/// Returns `None` if there is no child corresponding to token TRY_CAST
	fn TRY_CAST(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TRY_CAST, 0)
	}
}

impl<'input> CastContextAttrs<'input> for CastContext<'input>{}

pub struct CastContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub name: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CastContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for CastContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CastContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_cast(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_cast(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CastContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_cast(self);
	}
}

impl<'input> CustomRuleContext<'input> for CastContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for CastContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for CastContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for CastContext<'input> {}

impl<'input> CastContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::CastContext(
				BaseParserRuleContext::copy_from(ctx,CastContextExt{
					name:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type LambdaContext<'input> = BaseParserRuleContext<'input,LambdaContextExt<'input>>;

pub trait LambdaContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token ARROW
	/// Returns `None` if there is no child corresponding to token ARROW
	fn ARROW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ARROW, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> LambdaContextAttrs<'input> for LambdaContext<'input>{}

pub struct LambdaContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{LambdaContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for LambdaContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for LambdaContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_lambda(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_lambda(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for LambdaContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_lambda(self);
	}
}

impl<'input> CustomRuleContext<'input> for LambdaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for LambdaContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for LambdaContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for LambdaContext<'input> {}

impl<'input> LambdaContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::LambdaContext(
				BaseParserRuleContext::copy_from(ctx,LambdaContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ParenthesizedExpressionContext<'input> = BaseParserRuleContext<'input,ParenthesizedExpressionContextExt<'input>>;

pub trait ParenthesizedExpressionContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
}

impl<'input> ParenthesizedExpressionContextAttrs<'input> for ParenthesizedExpressionContext<'input>{}

pub struct ParenthesizedExpressionContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ParenthesizedExpressionContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ParenthesizedExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ParenthesizedExpressionContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_parenthesizedExpression(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_parenthesizedExpression(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ParenthesizedExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_parenthesizedExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for ParenthesizedExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for ParenthesizedExpressionContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for ParenthesizedExpressionContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for ParenthesizedExpressionContext<'input> {}

impl<'input> ParenthesizedExpressionContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::ParenthesizedExpressionContext(
				BaseParserRuleContext::copy_from(ctx,ParenthesizedExpressionContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type Any_valueContext<'input> = BaseParserRuleContext<'input,Any_valueContextExt<'input>>;

pub trait Any_valueContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ANY_VALUE
	/// Returns `None` if there is no child corresponding to token ANY_VALUE
	fn ANY_VALUE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ANY_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IGNORE
	/// Returns `None` if there is no child corresponding to token IGNORE
	fn IGNORE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IGNORE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NULLS
	/// Returns `None` if there is no child corresponding to token NULLS
	fn NULLS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(NULLS, 0)
	}
}

impl<'input> Any_valueContextAttrs<'input> for Any_valueContext<'input>{}

pub struct Any_valueContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{Any_valueContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for Any_valueContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for Any_valueContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_any_value(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_any_value(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for Any_valueContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_any_value(self);
	}
}

impl<'input> CustomRuleContext<'input> for Any_valueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for Any_valueContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for Any_valueContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for Any_valueContext<'input> {}

impl<'input> Any_valueContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::Any_valueContext(
				BaseParserRuleContext::copy_from(ctx,Any_valueContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TrimContext<'input> = BaseParserRuleContext<'input,TrimContextExt<'input>>;

pub trait TrimContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token TRIM
	/// Returns `None` if there is no child corresponding to token TRIM
	fn TRIM(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TRIM, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token BOTH
	/// Returns `None` if there is no child corresponding to token BOTH
	fn BOTH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(BOTH, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LEADING
	/// Returns `None` if there is no child corresponding to token LEADING
	fn LEADING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEADING, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TRAILING
	/// Returns `None` if there is no child corresponding to token TRAILING
	fn TRAILING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TRAILING, 0)
	}
}

impl<'input> TrimContextAttrs<'input> for TrimContext<'input>{}

pub struct TrimContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub trimOption: Option<TokenType<'input>>,
	pub trimStr: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub srcStr: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TrimContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for TrimContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for TrimContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_trim(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_trim(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for TrimContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_trim(self);
	}
}

impl<'input> CustomRuleContext<'input> for TrimContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for TrimContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for TrimContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for TrimContext<'input> {}

impl<'input> TrimContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::TrimContext(
				BaseParserRuleContext::copy_from(ctx,TrimContextExt{
					trimOption:None, 
        			trimStr:None, srcStr:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SemiStructuredExtractContext<'input> = BaseParserRuleContext<'input,SemiStructuredExtractContextExt<'input>>;

pub trait SemiStructuredExtractContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token COLON
	/// Returns `None` if there is no child corresponding to token COLON
	fn COLON(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COLON, 0)
	}
	fn primaryExpression(&self) -> Option<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn semiStructuredExtractionPath(&self) -> Option<Rc<SemiStructuredExtractionPathContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SemiStructuredExtractContextAttrs<'input> for SemiStructuredExtractContext<'input>{}

pub struct SemiStructuredExtractContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub col: Option<Rc<PrimaryExpressionContextAll<'input>>>,
	pub path: Option<Rc<SemiStructuredExtractionPathContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SemiStructuredExtractContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SemiStructuredExtractContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SemiStructuredExtractContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_semiStructuredExtract(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_semiStructuredExtract(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SemiStructuredExtractContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_semiStructuredExtract(self);
	}
}

impl<'input> CustomRuleContext<'input> for SemiStructuredExtractContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for SemiStructuredExtractContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for SemiStructuredExtractContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for SemiStructuredExtractContext<'input> {}

impl<'input> SemiStructuredExtractContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::SemiStructuredExtractContext(
				BaseParserRuleContext::copy_from(ctx,SemiStructuredExtractContextExt{
        			col:None, path:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SimpleCaseContext<'input> = BaseParserRuleContext<'input,SimpleCaseContextExt<'input>>;

pub trait SimpleCaseContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CASE
	/// Returns `None` if there is no child corresponding to token CASE
	fn CASE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CASE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token END
	/// Returns `None` if there is no child corresponding to token END
	fn END(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(END, 0)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn whenClause_all(&self) ->  Vec<Rc<WhenClauseContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn whenClause(&self, i: usize) -> Option<Rc<WhenClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token ELSE
	/// Returns `None` if there is no child corresponding to token ELSE
	fn ELSE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ELSE, 0)
	}
}

impl<'input> SimpleCaseContextAttrs<'input> for SimpleCaseContext<'input>{}

pub struct SimpleCaseContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub value: Option<Rc<ExpressionContextAll<'input>>>,
	pub elseExpression: Option<Rc<ExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SimpleCaseContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SimpleCaseContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SimpleCaseContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_simpleCase(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_simpleCase(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SimpleCaseContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_simpleCase(self);
	}
}

impl<'input> CustomRuleContext<'input> for SimpleCaseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for SimpleCaseContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for SimpleCaseContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for SimpleCaseContext<'input> {}

impl<'input> SimpleCaseContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::SimpleCaseContext(
				BaseParserRuleContext::copy_from(ctx,SimpleCaseContextExt{
        			value:None, elseExpression:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CurrentLikeContext<'input> = BaseParserRuleContext<'input,CurrentLikeContextExt<'input>>;

pub trait CurrentLikeContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CURRENT_DATE
	/// Returns `None` if there is no child corresponding to token CURRENT_DATE
	fn CURRENT_DATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CURRENT_DATE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token CURRENT_TIMESTAMP
	/// Returns `None` if there is no child corresponding to token CURRENT_TIMESTAMP
	fn CURRENT_TIMESTAMP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CURRENT_TIMESTAMP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token CURRENT_USER
	/// Returns `None` if there is no child corresponding to token CURRENT_USER
	fn CURRENT_USER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CURRENT_USER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token USER
	/// Returns `None` if there is no child corresponding to token USER
	fn USER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(USER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SESSION_USER
	/// Returns `None` if there is no child corresponding to token SESSION_USER
	fn SESSION_USER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SESSION_USER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token CURRENT_TIME
	/// Returns `None` if there is no child corresponding to token CURRENT_TIME
	fn CURRENT_TIME(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CURRENT_TIME, 0)
	}
}

impl<'input> CurrentLikeContextAttrs<'input> for CurrentLikeContext<'input>{}

pub struct CurrentLikeContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub name: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CurrentLikeContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for CurrentLikeContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CurrentLikeContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_currentLike(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_currentLike(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CurrentLikeContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_currentLike(self);
	}
}

impl<'input> CustomRuleContext<'input> for CurrentLikeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for CurrentLikeContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for CurrentLikeContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for CurrentLikeContext<'input> {}

impl<'input> CurrentLikeContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::CurrentLikeContext(
				BaseParserRuleContext::copy_from(ctx,CurrentLikeContextExt{
					name:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ColumnReferenceContext<'input> = BaseParserRuleContext<'input,ColumnReferenceContextExt<'input>>;

pub trait ColumnReferenceContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ColumnReferenceContextAttrs<'input> for ColumnReferenceContext<'input>{}

pub struct ColumnReferenceContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ColumnReferenceContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ColumnReferenceContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ColumnReferenceContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_columnReference(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_columnReference(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ColumnReferenceContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_columnReference(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnReferenceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for ColumnReferenceContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for ColumnReferenceContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for ColumnReferenceContext<'input> {}

impl<'input> ColumnReferenceContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::ColumnReferenceContext(
				BaseParserRuleContext::copy_from(ctx,ColumnReferenceContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RowConstructorContext<'input> = BaseParserRuleContext<'input,RowConstructorContextExt<'input>>;

pub trait RowConstructorContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	fn namedExpression_all(&self) ->  Vec<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn namedExpression(&self, i: usize) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> RowConstructorContextAttrs<'input> for RowConstructorContext<'input>{}

pub struct RowConstructorContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RowConstructorContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for RowConstructorContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for RowConstructorContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_rowConstructor(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_rowConstructor(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for RowConstructorContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_rowConstructor(self);
	}
}

impl<'input> CustomRuleContext<'input> for RowConstructorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for RowConstructorContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for RowConstructorContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for RowConstructorContext<'input> {}

impl<'input> RowConstructorContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::RowConstructorContext(
				BaseParserRuleContext::copy_from(ctx,RowConstructorContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type LastContext<'input> = BaseParserRuleContext<'input,LastContextExt<'input>>;

pub trait LastContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LAST
	/// Returns `None` if there is no child corresponding to token LAST
	fn LAST(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LAST, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IGNORE
	/// Returns `None` if there is no child corresponding to token IGNORE
	fn IGNORE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IGNORE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NULLS
	/// Returns `None` if there is no child corresponding to token NULLS
	fn NULLS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(NULLS, 0)
	}
}

impl<'input> LastContextAttrs<'input> for LastContext<'input>{}

pub struct LastContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{LastContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for LastContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for LastContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_last(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_last(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for LastContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_last(self);
	}
}

impl<'input> CustomRuleContext<'input> for LastContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for LastContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for LastContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for LastContext<'input> {}

impl<'input> LastContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::LastContext(
				BaseParserRuleContext::copy_from(ctx,LastContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type StarContext<'input> = BaseParserRuleContext<'input,StarContextExt<'input>>;

pub trait StarContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ASTERISK
	/// Returns `None` if there is no child corresponding to token ASTERISK
	fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ASTERISK, 0)
	}
	fn exceptClause(&self) -> Option<Rc<ExceptClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token DOT
	/// Returns `None` if there is no child corresponding to token DOT
	fn DOT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DOT, 0)
	}
}

impl<'input> StarContextAttrs<'input> for StarContext<'input>{}

pub struct StarContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{StarContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for StarContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for StarContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_star(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_star(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for StarContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_star(self);
	}
}

impl<'input> CustomRuleContext<'input> for StarContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for StarContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for StarContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for StarContext<'input> {}

impl<'input> StarContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::StarContext(
				BaseParserRuleContext::copy_from(ctx,StarContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type OverlayContext<'input> = BaseParserRuleContext<'input,OverlayContextExt<'input>>;

pub trait OverlayContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token OVERLAY
	/// Returns `None` if there is no child corresponding to token OVERLAY
	fn OVERLAY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(OVERLAY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token PLACING
	/// Returns `None` if there is no child corresponding to token PLACING
	fn PLACING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(PLACING, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token FOR
	/// Returns `None` if there is no child corresponding to token FOR
	fn FOR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FOR, 0)
	}
}

impl<'input> OverlayContextAttrs<'input> for OverlayContext<'input>{}

pub struct OverlayContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub input: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub replace: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub position: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub length: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{OverlayContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for OverlayContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for OverlayContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_overlay(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_overlay(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for OverlayContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_overlay(self);
	}
}

impl<'input> CustomRuleContext<'input> for OverlayContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for OverlayContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for OverlayContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for OverlayContext<'input> {}

impl<'input> OverlayContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::OverlayContext(
				BaseParserRuleContext::copy_from(ctx,OverlayContextExt{
        			input:None, replace:None, position:None, length:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SubscriptContext<'input> = BaseParserRuleContext<'input,SubscriptContextExt<'input>>;

pub trait SubscriptContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LEFT_BRACKET
	/// Returns `None` if there is no child corresponding to token LEFT_BRACKET
	fn LEFT_BRACKET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_BRACKET, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_BRACKET
	/// Returns `None` if there is no child corresponding to token RIGHT_BRACKET
	fn RIGHT_BRACKET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_BRACKET, 0)
	}
	fn primaryExpression(&self) -> Option<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SubscriptContextAttrs<'input> for SubscriptContext<'input>{}

pub struct SubscriptContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub value: Option<Rc<PrimaryExpressionContextAll<'input>>>,
	pub index: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SubscriptContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SubscriptContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SubscriptContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_subscript(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_subscript(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SubscriptContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_subscript(self);
	}
}

impl<'input> CustomRuleContext<'input> for SubscriptContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for SubscriptContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for SubscriptContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for SubscriptContext<'input> {}

impl<'input> SubscriptContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::SubscriptContext(
				BaseParserRuleContext::copy_from(ctx,SubscriptContextExt{
        			value:None, index:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TimestampdiffContext<'input> = BaseParserRuleContext<'input,TimestampdiffContextExt<'input>>;

pub trait TimestampdiffContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token TIMESTAMPDIFF
	/// Returns `None` if there is no child corresponding to token TIMESTAMPDIFF
	fn TIMESTAMPDIFF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TIMESTAMPDIFF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DATEDIFF
	/// Returns `None` if there is no child corresponding to token DATEDIFF
	fn DATEDIFF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DATEDIFF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DATE_DIFF
	/// Returns `None` if there is no child corresponding to token DATE_DIFF
	fn DATE_DIFF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DATE_DIFF, 0)
	}
	/// Retrieves first TerminalNode corresponding to token TIMEDIFF
	/// Returns `None` if there is no child corresponding to token TIMEDIFF
	fn TIMEDIFF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TIMEDIFF, 0)
	}
	fn datetimeUnit(&self) -> Option<Rc<DatetimeUnitContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> TimestampdiffContextAttrs<'input> for TimestampdiffContext<'input>{}

pub struct TimestampdiffContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub name: Option<TokenType<'input>>,
	pub unit: Option<Rc<DatetimeUnitContextAll<'input>>>,
	pub invalidUnit: Option<Rc<StringLitContextAll<'input>>>,
	pub startTimestamp: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub endTimestamp: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TimestampdiffContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for TimestampdiffContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for TimestampdiffContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_timestampdiff(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_timestampdiff(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for TimestampdiffContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_timestampdiff(self);
	}
}

impl<'input> CustomRuleContext<'input> for TimestampdiffContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for TimestampdiffContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for TimestampdiffContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for TimestampdiffContext<'input> {}

impl<'input> TimestampdiffContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::TimestampdiffContext(
				BaseParserRuleContext::copy_from(ctx,TimestampdiffContextExt{
					name:None, 
        			unit:None, invalidUnit:None, startTimestamp:None, endTimestamp:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SubqueryExpressionContext<'input> = BaseParserRuleContext<'input,SubqueryExpressionContextExt<'input>>;

pub trait SubqueryExpressionContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
}

impl<'input> SubqueryExpressionContextAttrs<'input> for SubqueryExpressionContext<'input>{}

pub struct SubqueryExpressionContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SubqueryExpressionContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SubqueryExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SubqueryExpressionContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_subqueryExpression(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_subqueryExpression(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SubqueryExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_subqueryExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for SubqueryExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for SubqueryExpressionContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for SubqueryExpressionContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for SubqueryExpressionContext<'input> {}

impl<'input> SubqueryExpressionContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::SubqueryExpressionContext(
				BaseParserRuleContext::copy_from(ctx,SubqueryExpressionContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type CollateContext<'input> = BaseParserRuleContext<'input,CollateContextExt<'input>>;

pub trait CollateContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn primaryExpression(&self) -> Option<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn collateClause(&self) -> Option<Rc<CollateClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> CollateContextAttrs<'input> for CollateContext<'input>{}

pub struct CollateContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{CollateContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for CollateContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CollateContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_collate(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_collate(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CollateContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_collate(self);
	}
}

impl<'input> CustomRuleContext<'input> for CollateContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for CollateContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for CollateContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for CollateContext<'input> {}

impl<'input> CollateContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::CollateContext(
				BaseParserRuleContext::copy_from(ctx,CollateContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ConstantDefaultContext<'input> = BaseParserRuleContext<'input,ConstantDefaultContextExt<'input>>;

pub trait ConstantDefaultContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn constant(&self) -> Option<Rc<ConstantContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ConstantDefaultContextAttrs<'input> for ConstantDefaultContext<'input>{}

pub struct ConstantDefaultContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ConstantDefaultContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ConstantDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ConstantDefaultContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_constantDefault(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_constantDefault(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ConstantDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_constantDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for ConstantDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for ConstantDefaultContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for ConstantDefaultContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for ConstantDefaultContext<'input> {}

impl<'input> ConstantDefaultContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::ConstantDefaultContext(
				BaseParserRuleContext::copy_from(ctx,ConstantDefaultContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ExtractContext<'input> = BaseParserRuleContext<'input,ExtractContextExt<'input>>;

pub trait ExtractContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token EXTRACT
	/// Returns `None` if there is no child corresponding to token EXTRACT
	fn EXTRACT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXTRACT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token FROM
	/// Returns `None` if there is no child corresponding to token FROM
	fn FROM(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FROM, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
	fn simpleIdentifier(&self) -> Option<Rc<SimpleIdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn valueExpression(&self) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ExtractContextAttrs<'input> for ExtractContext<'input>{}

pub struct ExtractContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub field: Option<Rc<SimpleIdentifierContextAll<'input>>>,
	pub source: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ExtractContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ExtractContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ExtractContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_extract(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_extract(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ExtractContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_extract(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExtractContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for ExtractContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for ExtractContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for ExtractContext<'input> {}

impl<'input> ExtractContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::ExtractContext(
				BaseParserRuleContext::copy_from(ctx,ExtractContextExt{
        			field:None, source:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type FunctionCallContext<'input> = BaseParserRuleContext<'input,FunctionCallContextExt<'input>>;

pub trait FunctionCallContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn functionName(&self) -> Option<Rc<FunctionNameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token LEFT_PAREN in current rule
	fn LEFT_PAREN_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token LEFT_PAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token LEFT_PAREN is less or equal than `i`.
	fn LEFT_PAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, i)
	}
	/// Retrieves all `TerminalNode`s corresponding to token RIGHT_PAREN in current rule
	fn RIGHT_PAREN_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token RIGHT_PAREN, starting from 0.
	/// Returns `None` if number of children corresponding to token RIGHT_PAREN is less or equal than `i`.
	fn RIGHT_PAREN(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, i)
	}
	/// Retrieves first TerminalNode corresponding to token WITHIN
	/// Returns `None` if there is no child corresponding to token WITHIN
	fn WITHIN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(WITHIN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token GROUP
	/// Returns `None` if there is no child corresponding to token GROUP
	fn GROUP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(GROUP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ORDER
	/// Returns `None` if there is no child corresponding to token ORDER
	fn ORDER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ORDER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token BY
	/// Returns `None` if there is no child corresponding to token BY
	fn BY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(BY, 0)
	}
	fn sortItem_all(&self) ->  Vec<Rc<SortItemContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn sortItem(&self, i: usize) -> Option<Rc<SortItemContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token FILTER
	/// Returns `None` if there is no child corresponding to token FILTER
	fn FILTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FILTER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token WHERE
	/// Returns `None` if there is no child corresponding to token WHERE
	fn WHERE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(WHERE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NULLS
	/// Returns `None` if there is no child corresponding to token NULLS
	fn NULLS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(NULLS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token OVER
	/// Returns `None` if there is no child corresponding to token OVER
	fn OVER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(OVER, 0)
	}
	fn windowSpec(&self) -> Option<Rc<WindowSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn functionArgument_all(&self) ->  Vec<Rc<FunctionArgumentContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn functionArgument(&self, i: usize) -> Option<Rc<FunctionArgumentContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token IGNORE
	/// Returns `None` if there is no child corresponding to token IGNORE
	fn IGNORE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IGNORE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RESPECT
	/// Returns `None` if there is no child corresponding to token RESPECT
	fn RESPECT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RESPECT, 0)
	}
	fn setQuantifier(&self) -> Option<Rc<SetQuantifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
}

impl<'input> FunctionCallContextAttrs<'input> for FunctionCallContext<'input>{}

pub struct FunctionCallContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub functionArgument: Option<Rc<FunctionArgumentContextAll<'input>>>,
	pub argument:Vec<Rc<FunctionArgumentContextAll<'input>>>,
	pub whereExpr: Option<Rc<BooleanExpressionContextAll<'input>>>,
	pub nullsOption: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FunctionCallContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for FunctionCallContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for FunctionCallContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_functionCall(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_functionCall(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for FunctionCallContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_functionCall(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionCallContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for FunctionCallContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for FunctionCallContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for FunctionCallContext<'input> {}

impl<'input> FunctionCallContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::FunctionCallContext(
				BaseParserRuleContext::copy_from(ctx,FunctionCallContextExt{
					nullsOption:None, 
        			functionArgument:None, whereExpr:None, 
        			argument:Vec::new(), 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SearchedCaseContext<'input> = BaseParserRuleContext<'input,SearchedCaseContextExt<'input>>;

pub trait SearchedCaseContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token CASE
	/// Returns `None` if there is no child corresponding to token CASE
	fn CASE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CASE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token END
	/// Returns `None` if there is no child corresponding to token END
	fn END(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(END, 0)
	}
	fn whenClause_all(&self) ->  Vec<Rc<WhenClauseContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn whenClause(&self, i: usize) -> Option<Rc<WhenClauseContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token ELSE
	/// Returns `None` if there is no child corresponding to token ELSE
	fn ELSE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ELSE, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SearchedCaseContextAttrs<'input> for SearchedCaseContext<'input>{}

pub struct SearchedCaseContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub elseExpression: Option<Rc<ExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SearchedCaseContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SearchedCaseContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SearchedCaseContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_searchedCase(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_searchedCase(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SearchedCaseContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_searchedCase(self);
	}
}

impl<'input> CustomRuleContext<'input> for SearchedCaseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for SearchedCaseContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for SearchedCaseContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for SearchedCaseContext<'input> {}

impl<'input> SearchedCaseContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::SearchedCaseContext(
				BaseParserRuleContext::copy_from(ctx,SearchedCaseContextExt{
        			elseExpression:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PositionContext<'input> = BaseParserRuleContext<'input,PositionContextExt<'input>>;

pub trait PositionContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token POSITION
	/// Returns `None` if there is no child corresponding to token POSITION
	fn POSITION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(POSITION, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IN
	/// Returns `None` if there is no child corresponding to token IN
	fn IN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
	fn valueExpression_all(&self) ->  Vec<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn valueExpression(&self, i: usize) -> Option<Rc<ValueExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> PositionContextAttrs<'input> for PositionContext<'input>{}

pub struct PositionContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	pub substr: Option<Rc<ValueExpressionContextAll<'input>>>,
	pub str: Option<Rc<ValueExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PositionContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for PositionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PositionContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_position(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_position(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PositionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_position(self);
	}
}

impl<'input> CustomRuleContext<'input> for PositionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for PositionContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for PositionContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for PositionContext<'input> {}

impl<'input> PositionContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::PositionContext(
				BaseParserRuleContext::copy_from(ctx,PositionContextExt{
        			substr:None, str:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type FirstContext<'input> = BaseParserRuleContext<'input,FirstContextExt<'input>>;

pub trait FirstContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token FIRST
	/// Returns `None` if there is no child corresponding to token FIRST
	fn FIRST(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FIRST, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IGNORE
	/// Returns `None` if there is no child corresponding to token IGNORE
	fn IGNORE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IGNORE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NULLS
	/// Returns `None` if there is no child corresponding to token NULLS
	fn NULLS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(NULLS, 0)
	}
}

impl<'input> FirstContextAttrs<'input> for FirstContext<'input>{}

pub struct FirstContextExt<'input>{
	base:PrimaryExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FirstContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for FirstContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for FirstContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_first(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_first(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for FirstContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_first(self);
	}
}

impl<'input> CustomRuleContext<'input> for FirstContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}

impl<'input> Borrow<PrimaryExpressionContextExt<'input>> for FirstContext<'input>{
	fn borrow(&self) -> &PrimaryExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<PrimaryExpressionContextExt<'input>> for FirstContext<'input>{
	fn borrow_mut(&mut self) -> &mut PrimaryExpressionContextExt<'input> { &mut self.base }
}

impl<'input> PrimaryExpressionContextAttrs<'input> for FirstContext<'input> {}

impl<'input> FirstContextExt<'input>{
	fn new(ctx: &dyn PrimaryExpressionContextAttrs<'input>) -> Rc<PrimaryExpressionContextAll<'input>>  {
		Rc::new(
			PrimaryExpressionContextAll::FirstContext(
				BaseParserRuleContext::copy_from(ctx,FirstContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn  primaryExpression(&mut self,)
	-> Result<Rc<PrimaryExpressionContextAll<'input>>,ANTLRError> {
		self.primaryExpression_rec(0)
	}

	fn primaryExpression_rec(&mut self, _p: isize)
	-> Result<Rc<PrimaryExpressionContextAll<'input>>,ANTLRError> {
		let recog = self;
		let _parentctx = recog.ctx.take();
		let _parentState = recog.base.get_state();
		let mut _localctx = PrimaryExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
		recog.base.enter_recursion_rule(_localctx.clone(), 352, RULE_primaryExpression, _p);
	    let mut _localctx: Rc<PrimaryExpressionContextAll> = _localctx;
        let mut _prevctx = _localctx.clone();
		let _startState = 352;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {
			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4105);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(511,&mut recog.base)? {
				1 =>{
					{
					let mut tmp = CurrentLikeContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();


					recog.base.set_state(3863);
					if let PrimaryExpressionContextAll::CurrentLikeContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.name = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
					_la = recog.base.input.la(1);
					if { !(((((_la - 75)) & !0x3f) == 0 && ((1usize << (_la - 75)) & ((1usize << (CURRENT_DATE - 75)) | (1usize << (CURRENT_TIME - 75)) | (1usize << (CURRENT_TIMESTAMP - 75)) | (1usize << (CURRENT_USER - 75)))) != 0) || _la==SESSION_USER || _la==USER) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						if let PrimaryExpressionContextAll::CurrentLikeContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.name = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					}
				}
			,
				2 =>{
					{
					let mut tmp = TimestampaddContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3864);
					if let PrimaryExpressionContextAll::TimestampaddContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.name = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
					_la = recog.base.input.la(1);
					if { !(_la==DATEADD || _la==DATE_ADD || _la==TIMESTAMPADD) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						if let PrimaryExpressionContextAll::TimestampaddContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.name = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(3865);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					recog.base.set_state(3868);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(484,&mut recog.base)? {
						1 =>{
							{
							/*InvokeRule datetimeUnit*/
							recog.base.set_state(3866);
							let tmp = recog.datetimeUnit()?;
							if let PrimaryExpressionContextAll::TimestampaddContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.unit = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						2 =>{
							{
							/*InvokeRule stringLit*/
							recog.base.set_state(3867);
							let tmp = recog.stringLit()?;
							if let PrimaryExpressionContextAll::TimestampaddContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.invalidUnit = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					recog.base.set_state(3870);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(3871);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::TimestampaddContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.unitsAmount = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(3872);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(3873);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::TimestampaddContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.timestamp = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(3874);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					{
					let mut tmp = TimestampdiffContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3876);
					if let PrimaryExpressionContextAll::TimestampdiffContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.name = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
					_la = recog.base.input.la(1);
					if { !(_la==DATEDIFF || _la==DATE_DIFF || _la==TIMEDIFF || _la==TIMESTAMPDIFF) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						if let PrimaryExpressionContextAll::TimestampdiffContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.name = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(3877);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					recog.base.set_state(3880);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(485,&mut recog.base)? {
						1 =>{
							{
							/*InvokeRule datetimeUnit*/
							recog.base.set_state(3878);
							let tmp = recog.datetimeUnit()?;
							if let PrimaryExpressionContextAll::TimestampdiffContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.unit = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						2 =>{
							{
							/*InvokeRule stringLit*/
							recog.base.set_state(3879);
							let tmp = recog.stringLit()?;
							if let PrimaryExpressionContextAll::TimestampdiffContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.invalidUnit = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					recog.base.set_state(3882);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(3883);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::TimestampdiffContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.startTimestamp = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(3884);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(3885);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::TimestampdiffContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.endTimestamp = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(3886);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					{
					let mut tmp = SearchedCaseContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3888);
					recog.base.match_token(CASE,&mut recog.err_handler)?;

					recog.base.set_state(3890); 
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					loop {
						{
						{
						/*InvokeRule whenClause*/
						recog.base.set_state(3889);
						recog.whenClause()?;

						}
						}
						recog.base.set_state(3892); 
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if !(_la==WHEN) {break}
					}
					recog.base.set_state(3896);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ELSE {
						{
						recog.base.set_state(3894);
						recog.base.match_token(ELSE,&mut recog.err_handler)?;

						/*InvokeRule expression*/
						recog.base.set_state(3895);
						let tmp = recog.expression()?;
						if let PrimaryExpressionContextAll::SearchedCaseContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.elseExpression = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(3898);
					recog.base.match_token(END,&mut recog.err_handler)?;

					}
				}
			,
				5 =>{
					{
					let mut tmp = SimpleCaseContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3900);
					recog.base.match_token(CASE,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(3901);
					let tmp = recog.expression()?;
					if let PrimaryExpressionContextAll::SimpleCaseContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.value = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(3903); 
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					loop {
						{
						{
						/*InvokeRule whenClause*/
						recog.base.set_state(3902);
						recog.whenClause()?;

						}
						}
						recog.base.set_state(3905); 
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if !(_la==WHEN) {break}
					}
					recog.base.set_state(3909);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ELSE {
						{
						recog.base.set_state(3907);
						recog.base.match_token(ELSE,&mut recog.err_handler)?;

						/*InvokeRule expression*/
						recog.base.set_state(3908);
						let tmp = recog.expression()?;
						if let PrimaryExpressionContextAll::SimpleCaseContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.elseExpression = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(3911);
					recog.base.match_token(END,&mut recog.err_handler)?;

					}
				}
			,
				6 =>{
					{
					let mut tmp = CastContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3913);
					if let PrimaryExpressionContextAll::CastContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.name = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
					_la = recog.base.input.la(1);
					if { !(_la==CAST || _la==TRY_CAST) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						if let PrimaryExpressionContextAll::CastContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.name = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(3914);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(3915);
					recog.expression()?;

					recog.base.set_state(3916);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					/*InvokeRule dataType*/
					recog.base.set_state(3917);
					recog.dataType()?;

					recog.base.set_state(3918);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				7 =>{
					{
					let mut tmp = StructContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3920);
					recog.base.match_token(STRUCT,&mut recog.err_handler)?;

					recog.base.set_state(3921);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					recog.base.set_state(3930);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(491,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule namedExpression*/
							recog.base.set_state(3922);
							let tmp = recog.namedExpression()?;
							if let PrimaryExpressionContextAll::StructContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.namedExpression = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							let temp = if let PrimaryExpressionContextAll::StructContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.namedExpression.clone().unwrap() } else {unreachable!("cant cast");} ;
							if let PrimaryExpressionContextAll::StructContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.argument.push(temp); } else {unreachable!("cant cast");}  
							recog.base.set_state(3927);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							while _la==COMMA {
								{
								{
								recog.base.set_state(3923);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule namedExpression*/
								recog.base.set_state(3924);
								let tmp = recog.namedExpression()?;
								if let PrimaryExpressionContextAll::StructContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
								ctx.namedExpression = Some(tmp.clone()); } else {unreachable!("cant cast");}  

								let temp = if let PrimaryExpressionContextAll::StructContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
								ctx.namedExpression.clone().unwrap() } else {unreachable!("cant cast");} ;
								if let PrimaryExpressionContextAll::StructContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
								ctx.argument.push(temp); } else {unreachable!("cant cast");}  
								}
								}
								recog.base.set_state(3929);
								recog.err_handler.sync(&mut recog.base)?;
								_la = recog.base.input.la(1);
							}
							}
						}

						_ => {}
					}
					recog.base.set_state(3932);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				8 =>{
					{
					let mut tmp = FirstContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3933);
					recog.base.match_token(FIRST,&mut recog.err_handler)?;

					recog.base.set_state(3934);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(3935);
					recog.expression()?;

					recog.base.set_state(3938);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IGNORE {
						{
						recog.base.set_state(3936);
						recog.base.match_token(IGNORE,&mut recog.err_handler)?;

						recog.base.set_state(3937);
						recog.base.match_token(NULLS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3940);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				9 =>{
					{
					let mut tmp = Any_valueContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3942);
					recog.base.match_token(ANY_VALUE,&mut recog.err_handler)?;

					recog.base.set_state(3943);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(3944);
					recog.expression()?;

					recog.base.set_state(3947);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IGNORE {
						{
						recog.base.set_state(3945);
						recog.base.match_token(IGNORE,&mut recog.err_handler)?;

						recog.base.set_state(3946);
						recog.base.match_token(NULLS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3949);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				10 =>{
					{
					let mut tmp = LastContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3951);
					recog.base.match_token(LAST,&mut recog.err_handler)?;

					recog.base.set_state(3952);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(3953);
					recog.expression()?;

					recog.base.set_state(3956);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==IGNORE {
						{
						recog.base.set_state(3954);
						recog.base.match_token(IGNORE,&mut recog.err_handler)?;

						recog.base.set_state(3955);
						recog.base.match_token(NULLS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(3958);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				11 =>{
					{
					let mut tmp = PositionContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3960);
					recog.base.match_token(POSITION,&mut recog.err_handler)?;

					recog.base.set_state(3961);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(3962);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::PositionContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.substr = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(3963);
					recog.base.match_token(IN,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(3964);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::PositionContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.str = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(3965);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				12 =>{
					{
					let mut tmp = ConstantDefaultContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule constant*/
					recog.base.set_state(3967);
					recog.constant()?;

					}
				}
			,
				13 =>{
					{
					let mut tmp = StarContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3968);
					recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

					recog.base.set_state(3970);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(495,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule exceptClause*/
							recog.base.set_state(3969);
							recog.exceptClause()?;

							}
						}

						_ => {}
					}
					}
				}
			,
				14 =>{
					{
					let mut tmp = StarContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule qualifiedName*/
					recog.base.set_state(3972);
					recog.qualifiedName()?;

					recog.base.set_state(3973);
					recog.base.match_token(DOT,&mut recog.err_handler)?;

					recog.base.set_state(3974);
					recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

					recog.base.set_state(3976);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(496,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule exceptClause*/
							recog.base.set_state(3975);
							recog.exceptClause()?;

							}
						}

						_ => {}
					}
					}
				}
			,
				15 =>{
					{
					let mut tmp = RowConstructorContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3978);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule namedExpression*/
					recog.base.set_state(3979);
					recog.namedExpression()?;

					recog.base.set_state(3982); 
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					loop {
						{
						{
						recog.base.set_state(3980);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule namedExpression*/
						recog.base.set_state(3981);
						recog.namedExpression()?;

						}
						}
						recog.base.set_state(3984); 
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if !(_la==COMMA) {break}
					}
					recog.base.set_state(3986);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				16 =>{
					{
					let mut tmp = SubqueryExpressionContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(3988);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule query*/
					recog.base.set_state(3989);
					recog.query()?;

					recog.base.set_state(3990);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				17 =>{
					{
					let mut tmp = FunctionCallContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule functionName*/
					recog.base.set_state(3992);
					recog.functionName()?;

					recog.base.set_state(3993);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					recog.base.set_state(4005);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(500,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(3995);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(498,&mut recog.base)? {
								x if x == 1=>{
									{
									/*InvokeRule setQuantifier*/
									recog.base.set_state(3994);
									recog.setQuantifier()?;

									}
								}

								_ => {}
							}
							/*InvokeRule functionArgument*/
							recog.base.set_state(3997);
							let tmp = recog.functionArgument()?;
							if let PrimaryExpressionContextAll::FunctionCallContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.functionArgument = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							let temp = if let PrimaryExpressionContextAll::FunctionCallContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.functionArgument.clone().unwrap() } else {unreachable!("cant cast");} ;
							if let PrimaryExpressionContextAll::FunctionCallContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.argument.push(temp); } else {unreachable!("cant cast");}  
							recog.base.set_state(4002);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							while _la==COMMA {
								{
								{
								recog.base.set_state(3998);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule functionArgument*/
								recog.base.set_state(3999);
								let tmp = recog.functionArgument()?;
								if let PrimaryExpressionContextAll::FunctionCallContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
								ctx.functionArgument = Some(tmp.clone()); } else {unreachable!("cant cast");}  

								let temp = if let PrimaryExpressionContextAll::FunctionCallContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
								ctx.functionArgument.clone().unwrap() } else {unreachable!("cant cast");} ;
								if let PrimaryExpressionContextAll::FunctionCallContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
								ctx.argument.push(temp); } else {unreachable!("cant cast");}  
								}
								}
								recog.base.set_state(4004);
								recog.err_handler.sync(&mut recog.base)?;
								_la = recog.base.input.la(1);
							}
							}
						}

						_ => {}
					}
					recog.base.set_state(4007);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					recog.base.set_state(4023);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(502,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(4008);
							recog.base.match_token(WITHIN,&mut recog.err_handler)?;

							recog.base.set_state(4009);
							recog.base.match_token(GROUP,&mut recog.err_handler)?;

							recog.base.set_state(4010);
							recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

							recog.base.set_state(4011);
							recog.base.match_token(ORDER,&mut recog.err_handler)?;

							recog.base.set_state(4012);
							recog.base.match_token(BY,&mut recog.err_handler)?;

							/*InvokeRule sortItem*/
							recog.base.set_state(4013);
							recog.sortItem()?;

							recog.base.set_state(4018);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							while _la==COMMA {
								{
								{
								recog.base.set_state(4014);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule sortItem*/
								recog.base.set_state(4015);
								recog.sortItem()?;

								}
								}
								recog.base.set_state(4020);
								recog.err_handler.sync(&mut recog.base)?;
								_la = recog.base.input.la(1);
							}
							recog.base.set_state(4021);
							recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					recog.base.set_state(4031);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(503,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(4025);
							recog.base.match_token(FILTER,&mut recog.err_handler)?;

							recog.base.set_state(4026);
							recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

							recog.base.set_state(4027);
							recog.base.match_token(WHERE,&mut recog.err_handler)?;

							/*InvokeRule booleanExpression*/
							recog.base.set_state(4028);
							let tmp = recog.booleanExpression_rec(0)?;
							if let PrimaryExpressionContextAll::FunctionCallContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.whereExpr = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							recog.base.set_state(4029);
							recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					recog.base.set_state(4035);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(504,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(4033);
							if let PrimaryExpressionContextAll::FunctionCallContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.nullsOption = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
							_la = recog.base.input.la(1);
							if { !(_la==IGNORE || _la==RESPECT) } {
								let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
								if let PrimaryExpressionContextAll::FunctionCallContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
								ctx.nullsOption = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
							else {
								if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
								recog.err_handler.report_match(&mut recog.base);
								recog.base.consume(&mut recog.err_handler);
							}
							recog.base.set_state(4034);
							recog.base.match_token(NULLS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					recog.base.set_state(4039);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(505,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(4037);
							recog.base.match_token(OVER,&mut recog.err_handler)?;

							/*InvokeRule windowSpec*/
							recog.base.set_state(4038);
							recog.windowSpec()?;

							}
						}

						_ => {}
					}
					}
				}
			,
				18 =>{
					{
					let mut tmp = LambdaContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule identifier*/
					recog.base.set_state(4041);
					recog.identifier()?;

					recog.base.set_state(4042);
					recog.base.match_token(ARROW,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(4043);
					recog.expression()?;

					}
				}
			,
				19 =>{
					{
					let mut tmp = LambdaContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(4045);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(4046);
					recog.identifier()?;

					recog.base.set_state(4049); 
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					loop {
						{
						{
						recog.base.set_state(4047);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule identifier*/
						recog.base.set_state(4048);
						recog.identifier()?;

						}
						}
						recog.base.set_state(4051); 
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
						if !(_la==COMMA) {break}
					}
					recog.base.set_state(4053);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					recog.base.set_state(4054);
					recog.base.match_token(ARROW,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(4055);
					recog.expression()?;

					}
				}
			,
				20 =>{
					{
					let mut tmp = ColumnReferenceContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					/*InvokeRule identifier*/
					recog.base.set_state(4057);
					recog.identifier()?;

					}
				}
			,
				21 =>{
					{
					let mut tmp = ParenthesizedExpressionContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(4058);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(4059);
					recog.expression()?;

					recog.base.set_state(4060);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				22 =>{
					{
					let mut tmp = ExtractContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(4062);
					recog.base.match_token(EXTRACT,&mut recog.err_handler)?;

					recog.base.set_state(4063);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule simpleIdentifier*/
					recog.base.set_state(4064);
					let tmp = recog.simpleIdentifier()?;
					if let PrimaryExpressionContextAll::ExtractContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.field = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(4065);
					recog.base.match_token(FROM,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(4066);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::ExtractContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.source = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(4067);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				23 =>{
					{
					let mut tmp = SubstringContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(4069);
					_la = recog.base.input.la(1);
					if { !(_la==SUBSTR || _la==SUBSTRING) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(4070);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(4071);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::SubstringContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.str = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(4072);
					_la = recog.base.input.la(1);
					if { !(_la==COMMA || _la==FROM) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					/*InvokeRule valueExpression*/
					recog.base.set_state(4073);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::SubstringContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.pos = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(4076);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==COMMA || _la==FOR {
						{
						recog.base.set_state(4074);
						_la = recog.base.input.la(1);
						if { !(_la==COMMA || _la==FOR) } {
							recog.err_handler.recover_inline(&mut recog.base)?;

						}
						else {
							if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
							recog.err_handler.report_match(&mut recog.base);
							recog.base.consume(&mut recog.err_handler);
						}
						/*InvokeRule valueExpression*/
						recog.base.set_state(4075);
						let tmp = recog.valueExpression_rec(0)?;
						if let PrimaryExpressionContextAll::SubstringContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.len = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(4078);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				24 =>{
					{
					let mut tmp = TrimContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(4080);
					recog.base.match_token(TRIM,&mut recog.err_handler)?;

					recog.base.set_state(4081);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					recog.base.set_state(4083);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(508,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(4082);
							if let PrimaryExpressionContextAll::TrimContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.trimOption = recog.base.input.lt(1).cloned(); } else {unreachable!("cant cast");} 
							_la = recog.base.input.la(1);
							if { !(_la==BOTH || _la==LEADING || _la==TRAILING) } {
								let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
								if let PrimaryExpressionContextAll::TrimContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
								ctx.trimOption = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
							else {
								if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
								recog.err_handler.report_match(&mut recog.base);
								recog.base.consume(&mut recog.err_handler);
							}
							}
						}

						_ => {}
					}
					recog.base.set_state(4086);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(509,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule valueExpression*/
							recog.base.set_state(4085);
							let tmp = recog.valueExpression_rec(0)?;
							if let PrimaryExpressionContextAll::TrimContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.trimStr = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					recog.base.set_state(4088);
					recog.base.match_token(FROM,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(4089);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::TrimContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.srcStr = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(4090);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				25 =>{
					{
					let mut tmp = OverlayContextExt::new(&**_localctx);
					recog.ctx = Some(tmp.clone());
					_localctx = tmp;
					_prevctx = _localctx.clone();
					recog.base.set_state(4092);
					recog.base.match_token(OVERLAY,&mut recog.err_handler)?;

					recog.base.set_state(4093);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(4094);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::OverlayContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.input = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(4095);
					recog.base.match_token(PLACING,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(4096);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::OverlayContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.replace = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(4097);
					recog.base.match_token(FROM,&mut recog.err_handler)?;

					/*InvokeRule valueExpression*/
					recog.base.set_state(4098);
					let tmp = recog.valueExpression_rec(0)?;
					if let PrimaryExpressionContextAll::OverlayContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
					ctx.position = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(4101);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==FOR {
						{
						recog.base.set_state(4099);
						recog.base.match_token(FOR,&mut recog.err_handler)?;

						/*InvokeRule valueExpression*/
						recog.base.set_state(4100);
						let tmp = recog.valueExpression_rec(0)?;
						if let PrimaryExpressionContextAll::OverlayContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
						ctx.length = Some(tmp.clone()); } else {unreachable!("cant cast");}  

						}
					}

					recog.base.set_state(4103);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}

			let tmp = recog.input.lt(-1).cloned();
			recog.ctx.as_ref().unwrap().set_stop(tmp);
			recog.base.set_state(4125);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(513,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					recog.trigger_exit_rule_event();
					_prevctx = _localctx.clone();
					{
					recog.base.set_state(4123);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(512,&mut recog.base)? {
						1 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = CollateContextExt::new(&**PrimaryExpressionContextExt::new(_parentctx.clone(), _parentState));
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_primaryExpression);
							_localctx = tmp;
							recog.base.set_state(4107);
							if !({recog.precpred(None, 24)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 24)".to_owned()), None))?;
							}
							/*InvokeRule collateClause*/
							recog.base.set_state(4108);
							recog.collateClause()?;

							}
						}
					,
						2 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = CastByColonContextExt::new(&**PrimaryExpressionContextExt::new(_parentctx.clone(), _parentState));
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_primaryExpression);
							_localctx = tmp;
							recog.base.set_state(4109);
							if !({recog.precpred(None, 23)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 23)".to_owned()), None))?;
							}
							recog.base.set_state(4110);
							recog.base.match_token(DOUBLE_COLON,&mut recog.err_handler)?;

							/*InvokeRule dataType*/
							recog.base.set_state(4111);
							recog.dataType()?;

							}
						}
					,
						3 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = SemiStructuredExtractContextExt::new(&**PrimaryExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let PrimaryExpressionContextAll::SemiStructuredExtractContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut tmp){
								ctx.col = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_primaryExpression);
							_localctx = tmp;
							recog.base.set_state(4112);
							if !({recog.precpred(None, 14)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 14)".to_owned()), None))?;
							}
							recog.base.set_state(4113);
							recog.base.match_token(COLON,&mut recog.err_handler)?;

							/*InvokeRule semiStructuredExtractionPath*/
							recog.base.set_state(4114);
							let tmp = recog.semiStructuredExtractionPath()?;
							if let PrimaryExpressionContextAll::SemiStructuredExtractContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.path = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}
					,
						4 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = SubscriptContextExt::new(&**PrimaryExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let PrimaryExpressionContextAll::SubscriptContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut tmp){
								ctx.value = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_primaryExpression);
							_localctx = tmp;
							recog.base.set_state(4115);
							if !({recog.precpred(None, 8)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 8)".to_owned()), None))?;
							}
							recog.base.set_state(4116);
							recog.base.match_token(LEFT_BRACKET,&mut recog.err_handler)?;

							/*InvokeRule valueExpression*/
							recog.base.set_state(4117);
							let tmp = recog.valueExpression_rec(0)?;
							if let PrimaryExpressionContextAll::SubscriptContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.index = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							recog.base.set_state(4118);
							recog.base.match_token(RIGHT_BRACKET,&mut recog.err_handler)?;

							}
						}
					,
						5 =>{
							{
							/*recRuleLabeledAltStartAction*/
							let mut tmp = DereferenceContextExt::new(&**PrimaryExpressionContextExt::new(_parentctx.clone(), _parentState));
							if let PrimaryExpressionContextAll::DereferenceContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut tmp){
								ctx.base = Some(_prevctx.clone());
							} else {unreachable!("cant cast");}
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_primaryExpression);
							_localctx = tmp;
							recog.base.set_state(4120);
							if !({recog.precpred(None, 6)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 6)".to_owned()), None))?;
							}
							recog.base.set_state(4121);
							recog.base.match_token(DOT,&mut recog.err_handler)?;

							/*InvokeRule identifier*/
							recog.base.set_state(4122);
							let tmp = recog.identifier()?;
							if let PrimaryExpressionContextAll::DereferenceContext(ctx) = cast_mut::<_,PrimaryExpressionContextAll >(&mut _localctx){
							ctx.fieldName = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							}
						}

						_ => {}
					}
					} 
				}
				recog.base.set_state(4127);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(513,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_) => {},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re)=>{
			//_localctx.exception = re;
			recog.err_handler.report_error(&mut recog.base, re);
	        recog.err_handler.recover(&mut recog.base, re)?;}
		}
		recog.base.unroll_recursion_context(_parentctx);

		Ok(_localctx)
	}
}
//------------------- semiStructuredExtractionPath ----------------
pub type SemiStructuredExtractionPathContextAll<'input> = SemiStructuredExtractionPathContext<'input>;


pub type SemiStructuredExtractionPathContext<'input> = BaseParserRuleContext<'input,SemiStructuredExtractionPathContextExt<'input>>;

#[derive(Clone)]
pub struct SemiStructuredExtractionPathContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SemiStructuredExtractionPathContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SemiStructuredExtractionPathContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_semiStructuredExtractionPath(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_semiStructuredExtractionPath(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SemiStructuredExtractionPathContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_semiStructuredExtractionPath(self);
	}
}

impl<'input> CustomRuleContext<'input> for SemiStructuredExtractionPathContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_semiStructuredExtractionPath }
	//fn type_rule_index() -> usize where Self: Sized { RULE_semiStructuredExtractionPath }
}
antlr_rust::tid!{SemiStructuredExtractionPathContextExt<'a>}

impl<'input> SemiStructuredExtractionPathContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SemiStructuredExtractionPathContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SemiStructuredExtractionPathContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SemiStructuredExtractionPathContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SemiStructuredExtractionPathContextExt<'input>>{

fn jsonPathFirstPart(&self) -> Option<Rc<JsonPathFirstPartContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn jsonPathParts_all(&self) ->  Vec<Rc<JsonPathPartsContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn jsonPathParts(&self, i: usize) -> Option<Rc<JsonPathPartsContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> SemiStructuredExtractionPathContextAttrs<'input> for SemiStructuredExtractionPathContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn semiStructuredExtractionPath(&mut self,)
	-> Result<Rc<SemiStructuredExtractionPathContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SemiStructuredExtractionPathContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 354, RULE_semiStructuredExtractionPath);
        let mut _localctx: Rc<SemiStructuredExtractionPathContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule jsonPathFirstPart*/
			recog.base.set_state(4128);
			recog.jsonPathFirstPart()?;

			recog.base.set_state(4132);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(514,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					/*InvokeRule jsonPathParts*/
					recog.base.set_state(4129);
					recog.jsonPathParts()?;

					}
					} 
				}
				recog.base.set_state(4134);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(514,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- jsonPathIdentifier ----------------
pub type JsonPathIdentifierContextAll<'input> = JsonPathIdentifierContext<'input>;


pub type JsonPathIdentifierContext<'input> = BaseParserRuleContext<'input,JsonPathIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct JsonPathIdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for JsonPathIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for JsonPathIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_jsonPathIdentifier(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_jsonPathIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for JsonPathIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_jsonPathIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonPathIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_jsonPathIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_jsonPathIdentifier }
}
antlr_rust::tid!{JsonPathIdentifierContextExt<'a>}

impl<'input> JsonPathIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JsonPathIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JsonPathIdentifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait JsonPathIdentifierContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<JsonPathIdentifierContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token BACKQUOTED_IDENTIFIER
/// Returns `None` if there is no child corresponding to token BACKQUOTED_IDENTIFIER
fn BACKQUOTED_IDENTIFIER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BACKQUOTED_IDENTIFIER, 0)
}

}

impl<'input> JsonPathIdentifierContextAttrs<'input> for JsonPathIdentifierContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn jsonPathIdentifier(&mut self,)
	-> Result<Rc<JsonPathIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JsonPathIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 356, RULE_jsonPathIdentifier);
        let mut _localctx: Rc<JsonPathIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4137);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(515,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule identifier*/
					recog.base.set_state(4135);
					recog.identifier()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4136);
					recog.base.match_token(BACKQUOTED_IDENTIFIER,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- jsonPathBracketedIdentifier ----------------
pub type JsonPathBracketedIdentifierContextAll<'input> = JsonPathBracketedIdentifierContext<'input>;


pub type JsonPathBracketedIdentifierContext<'input> = BaseParserRuleContext<'input,JsonPathBracketedIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct JsonPathBracketedIdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for JsonPathBracketedIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for JsonPathBracketedIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_jsonPathBracketedIdentifier(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_jsonPathBracketedIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for JsonPathBracketedIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_jsonPathBracketedIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonPathBracketedIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_jsonPathBracketedIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_jsonPathBracketedIdentifier }
}
antlr_rust::tid!{JsonPathBracketedIdentifierContextExt<'a>}

impl<'input> JsonPathBracketedIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JsonPathBracketedIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JsonPathBracketedIdentifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait JsonPathBracketedIdentifierContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<JsonPathBracketedIdentifierContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LEFT_BRACKET
/// Returns `None` if there is no child corresponding to token LEFT_BRACKET
fn LEFT_BRACKET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_BRACKET, 0)
}
fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_BRACKET
/// Returns `None` if there is no child corresponding to token RIGHT_BRACKET
fn RIGHT_BRACKET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_BRACKET, 0)
}

}

impl<'input> JsonPathBracketedIdentifierContextAttrs<'input> for JsonPathBracketedIdentifierContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn jsonPathBracketedIdentifier(&mut self,)
	-> Result<Rc<JsonPathBracketedIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JsonPathBracketedIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 358, RULE_jsonPathBracketedIdentifier);
        let mut _localctx: Rc<JsonPathBracketedIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4139);
			recog.base.match_token(LEFT_BRACKET,&mut recog.err_handler)?;

			/*InvokeRule stringLit*/
			recog.base.set_state(4140);
			recog.stringLit()?;

			recog.base.set_state(4141);
			recog.base.match_token(RIGHT_BRACKET,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- jsonPathFirstPart ----------------
pub type JsonPathFirstPartContextAll<'input> = JsonPathFirstPartContext<'input>;


pub type JsonPathFirstPartContext<'input> = BaseParserRuleContext<'input,JsonPathFirstPartContextExt<'input>>;

#[derive(Clone)]
pub struct JsonPathFirstPartContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for JsonPathFirstPartContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for JsonPathFirstPartContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_jsonPathFirstPart(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_jsonPathFirstPart(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for JsonPathFirstPartContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_jsonPathFirstPart(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonPathFirstPartContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_jsonPathFirstPart }
	//fn type_rule_index() -> usize where Self: Sized { RULE_jsonPathFirstPart }
}
antlr_rust::tid!{JsonPathFirstPartContextExt<'a>}

impl<'input> JsonPathFirstPartContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JsonPathFirstPartContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JsonPathFirstPartContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait JsonPathFirstPartContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<JsonPathFirstPartContextExt<'input>>{

fn jsonPathIdentifier(&self) -> Option<Rc<JsonPathIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn jsonPathBracketedIdentifier(&self) -> Option<Rc<JsonPathBracketedIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LEFT_BRACKET
/// Returns `None` if there is no child corresponding to token LEFT_BRACKET
fn LEFT_BRACKET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_BRACKET, 0)
}
fn integerValue(&self) -> Option<Rc<IntegerValueContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_BRACKET
/// Returns `None` if there is no child corresponding to token RIGHT_BRACKET
fn RIGHT_BRACKET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_BRACKET, 0)
}

}

impl<'input> JsonPathFirstPartContextAttrs<'input> for JsonPathFirstPartContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn jsonPathFirstPart(&mut self,)
	-> Result<Rc<JsonPathFirstPartContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JsonPathFirstPartContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 360, RULE_jsonPathFirstPart);
        let mut _localctx: Rc<JsonPathFirstPartContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4149);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(516,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule jsonPathIdentifier*/
					recog.base.set_state(4143);
					recog.jsonPathIdentifier()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule jsonPathBracketedIdentifier*/
					recog.base.set_state(4144);
					recog.jsonPathBracketedIdentifier()?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(4145);
					recog.base.match_token(LEFT_BRACKET,&mut recog.err_handler)?;

					/*InvokeRule integerValue*/
					recog.base.set_state(4146);
					recog.integerValue()?;

					recog.base.set_state(4147);
					recog.base.match_token(RIGHT_BRACKET,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- jsonPathParts ----------------
pub type JsonPathPartsContextAll<'input> = JsonPathPartsContext<'input>;


pub type JsonPathPartsContext<'input> = BaseParserRuleContext<'input,JsonPathPartsContextExt<'input>>;

#[derive(Clone)]
pub struct JsonPathPartsContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for JsonPathPartsContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for JsonPathPartsContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_jsonPathParts(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_jsonPathParts(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for JsonPathPartsContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_jsonPathParts(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonPathPartsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_jsonPathParts }
	//fn type_rule_index() -> usize where Self: Sized { RULE_jsonPathParts }
}
antlr_rust::tid!{JsonPathPartsContextExt<'a>}

impl<'input> JsonPathPartsContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JsonPathPartsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JsonPathPartsContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait JsonPathPartsContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<JsonPathPartsContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DOT
/// Returns `None` if there is no child corresponding to token DOT
fn DOT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DOT, 0)
}
fn jsonPathIdentifier(&self) -> Option<Rc<JsonPathIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn jsonPathBracketedIdentifier(&self) -> Option<Rc<JsonPathBracketedIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LEFT_BRACKET
/// Returns `None` if there is no child corresponding to token LEFT_BRACKET
fn LEFT_BRACKET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_BRACKET, 0)
}
fn integerValue(&self) -> Option<Rc<IntegerValueContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_BRACKET
/// Returns `None` if there is no child corresponding to token RIGHT_BRACKET
fn RIGHT_BRACKET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_BRACKET, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> JsonPathPartsContextAttrs<'input> for JsonPathPartsContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn jsonPathParts(&mut self,)
	-> Result<Rc<JsonPathPartsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JsonPathPartsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 362, RULE_jsonPathParts);
        let mut _localctx: Rc<JsonPathPartsContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4162);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(517,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4151);
					recog.base.match_token(DOT,&mut recog.err_handler)?;

					/*InvokeRule jsonPathIdentifier*/
					recog.base.set_state(4152);
					recog.jsonPathIdentifier()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule jsonPathBracketedIdentifier*/
					recog.base.set_state(4153);
					recog.jsonPathBracketedIdentifier()?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(4154);
					recog.base.match_token(LEFT_BRACKET,&mut recog.err_handler)?;

					/*InvokeRule integerValue*/
					recog.base.set_state(4155);
					recog.integerValue()?;

					recog.base.set_state(4156);
					recog.base.match_token(RIGHT_BRACKET,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(4158);
					recog.base.match_token(LEFT_BRACKET,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(4159);
					recog.identifier()?;

					recog.base.set_state(4160);
					recog.base.match_token(RIGHT_BRACKET,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- literalType ----------------
pub type LiteralTypeContextAll<'input> = LiteralTypeContext<'input>;


pub type LiteralTypeContext<'input> = BaseParserRuleContext<'input,LiteralTypeContextExt<'input>>;

#[derive(Clone)]
pub struct LiteralTypeContextExt<'input>{
	pub unsupportedType: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for LiteralTypeContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for LiteralTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_literalType(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_literalType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for LiteralTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_literalType(self);
	}
}

impl<'input> CustomRuleContext<'input> for LiteralTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_literalType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_literalType }
}
antlr_rust::tid!{LiteralTypeContextExt<'a>}

impl<'input> LiteralTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LiteralTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LiteralTypeContextExt{
				unsupportedType: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait LiteralTypeContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<LiteralTypeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DATE
/// Returns `None` if there is no child corresponding to token DATE
fn DATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DATE, 0)
}
/// Retrieves first TerminalNode corresponding to token TIME
/// Returns `None` if there is no child corresponding to token TIME
fn TIME(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TIME, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMP
/// Returns `None` if there is no child corresponding to token TIMESTAMP
fn TIMESTAMP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMP_LTZ
/// Returns `None` if there is no child corresponding to token TIMESTAMP_LTZ
fn TIMESTAMP_LTZ(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP_LTZ, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMP_NTZ
/// Returns `None` if there is no child corresponding to token TIMESTAMP_NTZ
fn TIMESTAMP_NTZ(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP_NTZ, 0)
}
/// Retrieves first TerminalNode corresponding to token INTERVAL
/// Returns `None` if there is no child corresponding to token INTERVAL
fn INTERVAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INTERVAL, 0)
}
/// Retrieves first TerminalNode corresponding to token BINARY_HEX
/// Returns `None` if there is no child corresponding to token BINARY_HEX
fn BINARY_HEX(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BINARY_HEX, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LiteralTypeContextAttrs<'input> for LiteralTypeContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn literalType(&mut self,)
	-> Result<Rc<LiteralTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LiteralTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 364, RULE_literalType);
        let mut _localctx: Rc<LiteralTypeContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4172);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(518,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4164);
					recog.base.match_token(DATE,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4165);
					recog.base.match_token(TIME,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(4166);
					recog.base.match_token(TIMESTAMP,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(4167);
					recog.base.match_token(TIMESTAMP_LTZ,&mut recog.err_handler)?;

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					recog.base.set_state(4168);
					recog.base.match_token(TIMESTAMP_NTZ,&mut recog.err_handler)?;

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					recog.base.set_state(4169);
					recog.base.match_token(INTERVAL,&mut recog.err_handler)?;

					}
				}
			,
				7 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					recog.base.set_state(4170);
					recog.base.match_token(BINARY_HEX,&mut recog.err_handler)?;

					}
				}
			,
				8 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 8);
					recog.base.enter_outer_alt(None, 8);
					{
					/*InvokeRule identifier*/
					recog.base.set_state(4171);
					let tmp = recog.identifier()?;
					 cast_mut::<_,LiteralTypeContext >(&mut _localctx).unsupportedType = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- constant ----------------
#[derive(Debug)]
pub enum ConstantContextAll<'input>{
	NullLiteralContext(NullLiteralContext<'input>),
	StringLiteralContext(StringLiteralContext<'input>),
	TypeConstructorContext(TypeConstructorContext<'input>),
	PosParameterLiteralContext(PosParameterLiteralContext<'input>),
	NamedParameterLiteralContext(NamedParameterLiteralContext<'input>),
	IntervalLiteralContext(IntervalLiteralContext<'input>),
	NumericLiteralContext(NumericLiteralContext<'input>),
	BooleanLiteralContext(BooleanLiteralContext<'input>),
Error(ConstantContext<'input>)
}
antlr_rust::tid!{ConstantContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for ConstantContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for ConstantContextAll<'input>{}

impl<'input> Deref for ConstantContextAll<'input>{
	type Target = dyn ConstantContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use ConstantContextAll::*;
		match self{
			NullLiteralContext(inner) => inner,
			StringLiteralContext(inner) => inner,
			TypeConstructorContext(inner) => inner,
			PosParameterLiteralContext(inner) => inner,
			NamedParameterLiteralContext(inner) => inner,
			IntervalLiteralContext(inner) => inner,
			NumericLiteralContext(inner) => inner,
			BooleanLiteralContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ConstantContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ConstantContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type ConstantContext<'input> = BaseParserRuleContext<'input,ConstantContextExt<'input>>;

#[derive(Clone)]
pub struct ConstantContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ConstantContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ConstantContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ConstantContext<'input>{
}

impl<'input> CustomRuleContext<'input> for ConstantContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_constant }
	//fn type_rule_index() -> usize where Self: Sized { RULE_constant }
}
antlr_rust::tid!{ConstantContextExt<'a>}

impl<'input> ConstantContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ConstantContextAll<'input>> {
		Rc::new(
		ConstantContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ConstantContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait ConstantContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ConstantContextExt<'input>>{


}

impl<'input> ConstantContextAttrs<'input> for ConstantContext<'input>{}

pub type NullLiteralContext<'input> = BaseParserRuleContext<'input,NullLiteralContextExt<'input>>;

pub trait NullLiteralContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token NULL
	/// Returns `None` if there is no child corresponding to token NULL
	fn NULL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(NULL, 0)
	}
}

impl<'input> NullLiteralContextAttrs<'input> for NullLiteralContext<'input>{}

pub struct NullLiteralContextExt<'input>{
	base:ConstantContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{NullLiteralContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for NullLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for NullLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_nullLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_nullLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for NullLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_nullLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for NullLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_constant }
	//fn type_rule_index() -> usize where Self: Sized { RULE_constant }
}

impl<'input> Borrow<ConstantContextExt<'input>> for NullLiteralContext<'input>{
	fn borrow(&self) -> &ConstantContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ConstantContextExt<'input>> for NullLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut ConstantContextExt<'input> { &mut self.base }
}

impl<'input> ConstantContextAttrs<'input> for NullLiteralContext<'input> {}

impl<'input> NullLiteralContextExt<'input>{
	fn new(ctx: &dyn ConstantContextAttrs<'input>) -> Rc<ConstantContextAll<'input>>  {
		Rc::new(
			ConstantContextAll::NullLiteralContext(
				BaseParserRuleContext::copy_from(ctx,NullLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type StringLiteralContext<'input> = BaseParserRuleContext<'input,StringLiteralContextExt<'input>>;

pub trait StringLiteralContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> StringLiteralContextAttrs<'input> for StringLiteralContext<'input>{}

pub struct StringLiteralContextExt<'input>{
	base:ConstantContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{StringLiteralContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for StringLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for StringLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_stringLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_stringLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for StringLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_stringLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for StringLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_constant }
	//fn type_rule_index() -> usize where Self: Sized { RULE_constant }
}

impl<'input> Borrow<ConstantContextExt<'input>> for StringLiteralContext<'input>{
	fn borrow(&self) -> &ConstantContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ConstantContextExt<'input>> for StringLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut ConstantContextExt<'input> { &mut self.base }
}

impl<'input> ConstantContextAttrs<'input> for StringLiteralContext<'input> {}

impl<'input> StringLiteralContextExt<'input>{
	fn new(ctx: &dyn ConstantContextAttrs<'input>) -> Rc<ConstantContextAll<'input>>  {
		Rc::new(
			ConstantContextAll::StringLiteralContext(
				BaseParserRuleContext::copy_from(ctx,StringLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TypeConstructorContext<'input> = BaseParserRuleContext<'input,TypeConstructorContextExt<'input>>;

pub trait TypeConstructorContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn literalType(&self) -> Option<Rc<LiteralTypeContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn singleStringLitWithoutMarker(&self) -> Option<Rc<SingleStringLitWithoutMarkerContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> TypeConstructorContextAttrs<'input> for TypeConstructorContext<'input>{}

pub struct TypeConstructorContextExt<'input>{
	base:ConstantContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TypeConstructorContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for TypeConstructorContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for TypeConstructorContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_typeConstructor(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_typeConstructor(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for TypeConstructorContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_typeConstructor(self);
	}
}

impl<'input> CustomRuleContext<'input> for TypeConstructorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_constant }
	//fn type_rule_index() -> usize where Self: Sized { RULE_constant }
}

impl<'input> Borrow<ConstantContextExt<'input>> for TypeConstructorContext<'input>{
	fn borrow(&self) -> &ConstantContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ConstantContextExt<'input>> for TypeConstructorContext<'input>{
	fn borrow_mut(&mut self) -> &mut ConstantContextExt<'input> { &mut self.base }
}

impl<'input> ConstantContextAttrs<'input> for TypeConstructorContext<'input> {}

impl<'input> TypeConstructorContextExt<'input>{
	fn new(ctx: &dyn ConstantContextAttrs<'input>) -> Rc<ConstantContextAll<'input>>  {
		Rc::new(
			ConstantContextAll::TypeConstructorContext(
				BaseParserRuleContext::copy_from(ctx,TypeConstructorContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PosParameterLiteralContext<'input> = BaseParserRuleContext<'input,PosParameterLiteralContextExt<'input>>;

pub trait PosParameterLiteralContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token QUESTION
	/// Returns `None` if there is no child corresponding to token QUESTION
	fn QUESTION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(QUESTION, 0)
	}
}

impl<'input> PosParameterLiteralContextAttrs<'input> for PosParameterLiteralContext<'input>{}

pub struct PosParameterLiteralContextExt<'input>{
	base:ConstantContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PosParameterLiteralContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for PosParameterLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PosParameterLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_posParameterLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_posParameterLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PosParameterLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_posParameterLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for PosParameterLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_constant }
	//fn type_rule_index() -> usize where Self: Sized { RULE_constant }
}

impl<'input> Borrow<ConstantContextExt<'input>> for PosParameterLiteralContext<'input>{
	fn borrow(&self) -> &ConstantContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ConstantContextExt<'input>> for PosParameterLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut ConstantContextExt<'input> { &mut self.base }
}

impl<'input> ConstantContextAttrs<'input> for PosParameterLiteralContext<'input> {}

impl<'input> PosParameterLiteralContextExt<'input>{
	fn new(ctx: &dyn ConstantContextAttrs<'input>) -> Rc<ConstantContextAll<'input>>  {
		Rc::new(
			ConstantContextAll::PosParameterLiteralContext(
				BaseParserRuleContext::copy_from(ctx,PosParameterLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type NamedParameterLiteralContext<'input> = BaseParserRuleContext<'input,NamedParameterLiteralContextExt<'input>>;

pub trait NamedParameterLiteralContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn namedParameterMarker(&self) -> Option<Rc<NamedParameterMarkerContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> NamedParameterLiteralContextAttrs<'input> for NamedParameterLiteralContext<'input>{}

pub struct NamedParameterLiteralContextExt<'input>{
	base:ConstantContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{NamedParameterLiteralContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for NamedParameterLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for NamedParameterLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_namedParameterLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_namedParameterLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for NamedParameterLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_namedParameterLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for NamedParameterLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_constant }
	//fn type_rule_index() -> usize where Self: Sized { RULE_constant }
}

impl<'input> Borrow<ConstantContextExt<'input>> for NamedParameterLiteralContext<'input>{
	fn borrow(&self) -> &ConstantContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ConstantContextExt<'input>> for NamedParameterLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut ConstantContextExt<'input> { &mut self.base }
}

impl<'input> ConstantContextAttrs<'input> for NamedParameterLiteralContext<'input> {}

impl<'input> NamedParameterLiteralContextExt<'input>{
	fn new(ctx: &dyn ConstantContextAttrs<'input>) -> Rc<ConstantContextAll<'input>>  {
		Rc::new(
			ConstantContextAll::NamedParameterLiteralContext(
				BaseParserRuleContext::copy_from(ctx,NamedParameterLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type IntervalLiteralContext<'input> = BaseParserRuleContext<'input,IntervalLiteralContextExt<'input>>;

pub trait IntervalLiteralContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn interval(&self) -> Option<Rc<IntervalContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> IntervalLiteralContextAttrs<'input> for IntervalLiteralContext<'input>{}

pub struct IntervalLiteralContextExt<'input>{
	base:ConstantContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{IntervalLiteralContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for IntervalLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for IntervalLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_intervalLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_intervalLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for IntervalLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_intervalLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for IntervalLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_constant }
	//fn type_rule_index() -> usize where Self: Sized { RULE_constant }
}

impl<'input> Borrow<ConstantContextExt<'input>> for IntervalLiteralContext<'input>{
	fn borrow(&self) -> &ConstantContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ConstantContextExt<'input>> for IntervalLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut ConstantContextExt<'input> { &mut self.base }
}

impl<'input> ConstantContextAttrs<'input> for IntervalLiteralContext<'input> {}

impl<'input> IntervalLiteralContextExt<'input>{
	fn new(ctx: &dyn ConstantContextAttrs<'input>) -> Rc<ConstantContextAll<'input>>  {
		Rc::new(
			ConstantContextAll::IntervalLiteralContext(
				BaseParserRuleContext::copy_from(ctx,IntervalLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type NumericLiteralContext<'input> = BaseParserRuleContext<'input,NumericLiteralContextExt<'input>>;

pub trait NumericLiteralContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn number(&self) -> Option<Rc<NumberContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> NumericLiteralContextAttrs<'input> for NumericLiteralContext<'input>{}

pub struct NumericLiteralContextExt<'input>{
	base:ConstantContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{NumericLiteralContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for NumericLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for NumericLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_numericLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_numericLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for NumericLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_numericLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for NumericLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_constant }
	//fn type_rule_index() -> usize where Self: Sized { RULE_constant }
}

impl<'input> Borrow<ConstantContextExt<'input>> for NumericLiteralContext<'input>{
	fn borrow(&self) -> &ConstantContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ConstantContextExt<'input>> for NumericLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut ConstantContextExt<'input> { &mut self.base }
}

impl<'input> ConstantContextAttrs<'input> for NumericLiteralContext<'input> {}

impl<'input> NumericLiteralContextExt<'input>{
	fn new(ctx: &dyn ConstantContextAttrs<'input>) -> Rc<ConstantContextAll<'input>>  {
		Rc::new(
			ConstantContextAll::NumericLiteralContext(
				BaseParserRuleContext::copy_from(ctx,NumericLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BooleanLiteralContext<'input> = BaseParserRuleContext<'input,BooleanLiteralContextExt<'input>>;

pub trait BooleanLiteralContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn booleanValue(&self) -> Option<Rc<BooleanValueContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> BooleanLiteralContextAttrs<'input> for BooleanLiteralContext<'input>{}

pub struct BooleanLiteralContextExt<'input>{
	base:ConstantContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BooleanLiteralContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for BooleanLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for BooleanLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_booleanLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_booleanLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for BooleanLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_booleanLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for BooleanLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_constant }
	//fn type_rule_index() -> usize where Self: Sized { RULE_constant }
}

impl<'input> Borrow<ConstantContextExt<'input>> for BooleanLiteralContext<'input>{
	fn borrow(&self) -> &ConstantContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ConstantContextExt<'input>> for BooleanLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut ConstantContextExt<'input> { &mut self.base }
}

impl<'input> ConstantContextAttrs<'input> for BooleanLiteralContext<'input> {}

impl<'input> BooleanLiteralContextExt<'input>{
	fn new(ctx: &dyn ConstantContextAttrs<'input>) -> Rc<ConstantContextAll<'input>>  {
		Rc::new(
			ConstantContextAll::BooleanLiteralContext(
				BaseParserRuleContext::copy_from(ctx,BooleanLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn constant(&mut self,)
	-> Result<Rc<ConstantContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ConstantContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 366, RULE_constant);
        let mut _localctx: Rc<ConstantContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4184);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(519,&mut recog.base)? {
				1 =>{
					let tmp = NullLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(4174);
					recog.base.match_token(NULL,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = PosParameterLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(4175);
					recog.base.match_token(QUESTION,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					let tmp = NamedParameterLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					/*InvokeRule namedParameterMarker*/
					recog.base.set_state(4176);
					recog.namedParameterMarker()?;

					}
				}
			,
				4 =>{
					let tmp = IntervalLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					/*InvokeRule interval*/
					recog.base.set_state(4177);
					recog.interval()?;

					}
				}
			,
				5 =>{
					let tmp = TypeConstructorContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					/*InvokeRule literalType*/
					recog.base.set_state(4178);
					recog.literalType()?;

					/*InvokeRule singleStringLitWithoutMarker*/
					recog.base.set_state(4179);
					recog.singleStringLitWithoutMarker()?;

					}
				}
			,
				6 =>{
					let tmp = NumericLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 6);
					_localctx = tmp;
					{
					/*InvokeRule number*/
					recog.base.set_state(4181);
					recog.number()?;

					}
				}
			,
				7 =>{
					let tmp = BooleanLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 7);
					_localctx = tmp;
					{
					/*InvokeRule booleanValue*/
					recog.base.set_state(4182);
					recog.booleanValue()?;

					}
				}
			,
				8 =>{
					let tmp = StringLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 8);
					_localctx = tmp;
					{
					/*InvokeRule stringLit*/
					recog.base.set_state(4183);
					recog.stringLit()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- namedParameterMarker ----------------
pub type NamedParameterMarkerContextAll<'input> = NamedParameterMarkerContext<'input>;


pub type NamedParameterMarkerContext<'input> = BaseParserRuleContext<'input,NamedParameterMarkerContextExt<'input>>;

#[derive(Clone)]
pub struct NamedParameterMarkerContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for NamedParameterMarkerContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for NamedParameterMarkerContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_namedParameterMarker(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_namedParameterMarker(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for NamedParameterMarkerContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_namedParameterMarker(self);
	}
}

impl<'input> CustomRuleContext<'input> for NamedParameterMarkerContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_namedParameterMarker }
	//fn type_rule_index() -> usize where Self: Sized { RULE_namedParameterMarker }
}
antlr_rust::tid!{NamedParameterMarkerContextExt<'a>}

impl<'input> NamedParameterMarkerContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NamedParameterMarkerContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NamedParameterMarkerContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait NamedParameterMarkerContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<NamedParameterMarkerContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token COLON
/// Returns `None` if there is no child corresponding to token COLON
fn COLON(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COLON, 0)
}
fn simpleIdentifier(&self) -> Option<Rc<SimpleIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> NamedParameterMarkerContextAttrs<'input> for NamedParameterMarkerContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn namedParameterMarker(&mut self,)
	-> Result<Rc<NamedParameterMarkerContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NamedParameterMarkerContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 368, RULE_namedParameterMarker);
        let mut _localctx: Rc<NamedParameterMarkerContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4186);
			recog.base.match_token(COLON,&mut recog.err_handler)?;

			/*InvokeRule simpleIdentifier*/
			recog.base.set_state(4187);
			recog.simpleIdentifier()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- comparisonOperator ----------------
pub type ComparisonOperatorContextAll<'input> = ComparisonOperatorContext<'input>;


pub type ComparisonOperatorContext<'input> = BaseParserRuleContext<'input,ComparisonOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct ComparisonOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ComparisonOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ComparisonOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_comparisonOperator(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_comparisonOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ComparisonOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_comparisonOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for ComparisonOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_comparisonOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_comparisonOperator }
}
antlr_rust::tid!{ComparisonOperatorContextExt<'a>}

impl<'input> ComparisonOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ComparisonOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ComparisonOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ComparisonOperatorContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ComparisonOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EQ
/// Returns `None` if there is no child corresponding to token EQ
fn EQ(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EQ, 0)
}
/// Retrieves first TerminalNode corresponding to token NEQ
/// Returns `None` if there is no child corresponding to token NEQ
fn NEQ(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NEQ, 0)
}
/// Retrieves first TerminalNode corresponding to token NEQJ
/// Returns `None` if there is no child corresponding to token NEQJ
fn NEQJ(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NEQJ, 0)
}
/// Retrieves first TerminalNode corresponding to token LT
/// Returns `None` if there is no child corresponding to token LT
fn LT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LT, 0)
}
/// Retrieves first TerminalNode corresponding to token LTE
/// Returns `None` if there is no child corresponding to token LTE
fn LTE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LTE, 0)
}
/// Retrieves first TerminalNode corresponding to token GT
/// Returns `None` if there is no child corresponding to token GT
fn GT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(GT, 0)
}
/// Retrieves first TerminalNode corresponding to token GTE
/// Returns `None` if there is no child corresponding to token GTE
fn GTE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(GTE, 0)
}
/// Retrieves first TerminalNode corresponding to token NSEQ
/// Returns `None` if there is no child corresponding to token NSEQ
fn NSEQ(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NSEQ, 0)
}

}

impl<'input> ComparisonOperatorContextAttrs<'input> for ComparisonOperatorContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn comparisonOperator(&mut self,)
	-> Result<Rc<ComparisonOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ComparisonOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 370, RULE_comparisonOperator);
        let mut _localctx: Rc<ComparisonOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4189);
			_la = recog.base.input.la(1);
			if { !(((((_la - 408)) & !0x3f) == 0 && ((1usize << (_la - 408)) & ((1usize << (EQ - 408)) | (1usize << (NSEQ - 408)) | (1usize << (NEQ - 408)) | (1usize << (NEQJ - 408)) | (1usize << (LT - 408)) | (1usize << (LTE - 408)) | (1usize << (GT - 408)) | (1usize << (GTE - 408)))) != 0)) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- arithmeticOperator ----------------
pub type ArithmeticOperatorContextAll<'input> = ArithmeticOperatorContext<'input>;


pub type ArithmeticOperatorContext<'input> = BaseParserRuleContext<'input,ArithmeticOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct ArithmeticOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ArithmeticOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ArithmeticOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_arithmeticOperator(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_arithmeticOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ArithmeticOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_arithmeticOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for ArithmeticOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_arithmeticOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_arithmeticOperator }
}
antlr_rust::tid!{ArithmeticOperatorContextExt<'a>}

impl<'input> ArithmeticOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ArithmeticOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ArithmeticOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ArithmeticOperatorContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ArithmeticOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PLUS
/// Returns `None` if there is no child corresponding to token PLUS
fn PLUS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PLUS, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUS
/// Returns `None` if there is no child corresponding to token MINUS
fn MINUS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MINUS, 0)
}
/// Retrieves first TerminalNode corresponding to token ASTERISK
/// Returns `None` if there is no child corresponding to token ASTERISK
fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ASTERISK, 0)
}
/// Retrieves first TerminalNode corresponding to token SLASH
/// Returns `None` if there is no child corresponding to token SLASH
fn SLASH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SLASH, 0)
}
/// Retrieves first TerminalNode corresponding to token PERCENT
/// Returns `None` if there is no child corresponding to token PERCENT
fn PERCENT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PERCENT, 0)
}
/// Retrieves first TerminalNode corresponding to token DIV
/// Returns `None` if there is no child corresponding to token DIV
fn DIV(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DIV, 0)
}
/// Retrieves first TerminalNode corresponding to token TILDE
/// Returns `None` if there is no child corresponding to token TILDE
fn TILDE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TILDE, 0)
}
/// Retrieves first TerminalNode corresponding to token AMPERSAND
/// Returns `None` if there is no child corresponding to token AMPERSAND
fn AMPERSAND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AMPERSAND, 0)
}
/// Retrieves first TerminalNode corresponding to token PIPE
/// Returns `None` if there is no child corresponding to token PIPE
fn PIPE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PIPE, 0)
}
/// Retrieves first TerminalNode corresponding to token CONCAT_PIPE
/// Returns `None` if there is no child corresponding to token CONCAT_PIPE
fn CONCAT_PIPE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CONCAT_PIPE, 0)
}
/// Retrieves first TerminalNode corresponding to token HAT
/// Returns `None` if there is no child corresponding to token HAT
fn HAT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(HAT, 0)
}

}

impl<'input> ArithmeticOperatorContextAttrs<'input> for ArithmeticOperatorContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn arithmeticOperator(&mut self,)
	-> Result<Rc<ArithmeticOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ArithmeticOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 372, RULE_arithmeticOperator);
        let mut _localctx: Rc<ArithmeticOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4191);
			_la = recog.base.input.la(1);
			if { !(_la==DIV || ((((_la - 419)) & !0x3f) == 0 && ((1usize << (_la - 419)) & ((1usize << (PLUS - 419)) | (1usize << (MINUS - 419)) | (1usize << (ASTERISK - 419)) | (1usize << (SLASH - 419)) | (1usize << (PERCENT - 419)) | (1usize << (TILDE - 419)) | (1usize << (AMPERSAND - 419)) | (1usize << (PIPE - 419)) | (1usize << (CONCAT_PIPE - 419)) | (1usize << (HAT - 419)))) != 0)) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- predicateOperator ----------------
pub type PredicateOperatorContextAll<'input> = PredicateOperatorContext<'input>;


pub type PredicateOperatorContext<'input> = BaseParserRuleContext<'input,PredicateOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct PredicateOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for PredicateOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PredicateOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_predicateOperator(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_predicateOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PredicateOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_predicateOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for PredicateOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_predicateOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_predicateOperator }
}
antlr_rust::tid!{PredicateOperatorContextExt<'a>}

impl<'input> PredicateOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PredicateOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PredicateOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PredicateOperatorContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<PredicateOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OR
/// Returns `None` if there is no child corresponding to token OR
fn OR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OR, 0)
}
/// Retrieves first TerminalNode corresponding to token AND
/// Returns `None` if there is no child corresponding to token AND
fn AND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AND, 0)
}
/// Retrieves first TerminalNode corresponding to token IN
/// Returns `None` if there is no child corresponding to token IN
fn IN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IN, 0)
}
/// Retrieves first TerminalNode corresponding to token NOT
/// Returns `None` if there is no child corresponding to token NOT
fn NOT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NOT, 0)
}

}

impl<'input> PredicateOperatorContextAttrs<'input> for PredicateOperatorContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn predicateOperator(&mut self,)
	-> Result<Rc<PredicateOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PredicateOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 374, RULE_predicateOperator);
        let mut _localctx: Rc<PredicateOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4193);
			_la = recog.base.input.la(1);
			if { !(_la==AND || _la==IN || _la==NOT || _la==OR) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- booleanValue ----------------
pub type BooleanValueContextAll<'input> = BooleanValueContext<'input>;


pub type BooleanValueContext<'input> = BaseParserRuleContext<'input,BooleanValueContextExt<'input>>;

#[derive(Clone)]
pub struct BooleanValueContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for BooleanValueContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for BooleanValueContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_booleanValue(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_booleanValue(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for BooleanValueContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_booleanValue(self);
	}
}

impl<'input> CustomRuleContext<'input> for BooleanValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanValue }
}
antlr_rust::tid!{BooleanValueContextExt<'a>}

impl<'input> BooleanValueContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<BooleanValueContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,BooleanValueContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait BooleanValueContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<BooleanValueContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token TRUE
/// Returns `None` if there is no child corresponding to token TRUE
fn TRUE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TRUE, 0)
}
/// Retrieves first TerminalNode corresponding to token FALSE
/// Returns `None` if there is no child corresponding to token FALSE
fn FALSE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FALSE, 0)
}

}

impl<'input> BooleanValueContextAttrs<'input> for BooleanValueContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn booleanValue(&mut self,)
	-> Result<Rc<BooleanValueContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = BooleanValueContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 376, RULE_booleanValue);
        let mut _localctx: Rc<BooleanValueContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4195);
			_la = recog.base.input.la(1);
			if { !(_la==FALSE || _la==TRUE) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- interval ----------------
pub type IntervalContextAll<'input> = IntervalContext<'input>;


pub type IntervalContext<'input> = BaseParserRuleContext<'input,IntervalContextExt<'input>>;

#[derive(Clone)]
pub struct IntervalContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for IntervalContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for IntervalContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_interval(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_interval(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for IntervalContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_interval(self);
	}
}

impl<'input> CustomRuleContext<'input> for IntervalContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_interval }
	//fn type_rule_index() -> usize where Self: Sized { RULE_interval }
}
antlr_rust::tid!{IntervalContextExt<'a>}

impl<'input> IntervalContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IntervalContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IntervalContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait IntervalContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<IntervalContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token INTERVAL
/// Returns `None` if there is no child corresponding to token INTERVAL
fn INTERVAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INTERVAL, 0)
}
fn errorCapturingMultiUnitsInterval(&self) -> Option<Rc<ErrorCapturingMultiUnitsIntervalContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn errorCapturingUnitToUnitInterval(&self) -> Option<Rc<ErrorCapturingUnitToUnitIntervalContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> IntervalContextAttrs<'input> for IntervalContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn interval(&mut self,)
	-> Result<Rc<IntervalContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IntervalContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 378, RULE_interval);
        let mut _localctx: Rc<IntervalContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4197);
			recog.base.match_token(INTERVAL,&mut recog.err_handler)?;

			recog.base.set_state(4200);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(520,&mut recog.base)? {
				1 =>{
					{
					/*InvokeRule errorCapturingMultiUnitsInterval*/
					recog.base.set_state(4198);
					recog.errorCapturingMultiUnitsInterval()?;

					}
				}
			,
				2 =>{
					{
					/*InvokeRule errorCapturingUnitToUnitInterval*/
					recog.base.set_state(4199);
					recog.errorCapturingUnitToUnitInterval()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- errorCapturingMultiUnitsInterval ----------------
pub type ErrorCapturingMultiUnitsIntervalContextAll<'input> = ErrorCapturingMultiUnitsIntervalContext<'input>;


pub type ErrorCapturingMultiUnitsIntervalContext<'input> = BaseParserRuleContext<'input,ErrorCapturingMultiUnitsIntervalContextExt<'input>>;

#[derive(Clone)]
pub struct ErrorCapturingMultiUnitsIntervalContextExt<'input>{
	pub body: Option<Rc<MultiUnitsIntervalContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ErrorCapturingMultiUnitsIntervalContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ErrorCapturingMultiUnitsIntervalContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_errorCapturingMultiUnitsInterval(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_errorCapturingMultiUnitsInterval(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ErrorCapturingMultiUnitsIntervalContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_errorCapturingMultiUnitsInterval(self);
	}
}

impl<'input> CustomRuleContext<'input> for ErrorCapturingMultiUnitsIntervalContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_errorCapturingMultiUnitsInterval }
	//fn type_rule_index() -> usize where Self: Sized { RULE_errorCapturingMultiUnitsInterval }
}
antlr_rust::tid!{ErrorCapturingMultiUnitsIntervalContextExt<'a>}

impl<'input> ErrorCapturingMultiUnitsIntervalContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ErrorCapturingMultiUnitsIntervalContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ErrorCapturingMultiUnitsIntervalContextExt{
				body: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ErrorCapturingMultiUnitsIntervalContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ErrorCapturingMultiUnitsIntervalContextExt<'input>>{

fn multiUnitsInterval(&self) -> Option<Rc<MultiUnitsIntervalContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn unitToUnitInterval(&self) -> Option<Rc<UnitToUnitIntervalContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ErrorCapturingMultiUnitsIntervalContextAttrs<'input> for ErrorCapturingMultiUnitsIntervalContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn errorCapturingMultiUnitsInterval(&mut self,)
	-> Result<Rc<ErrorCapturingMultiUnitsIntervalContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ErrorCapturingMultiUnitsIntervalContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 380, RULE_errorCapturingMultiUnitsInterval);
        let mut _localctx: Rc<ErrorCapturingMultiUnitsIntervalContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule multiUnitsInterval*/
			recog.base.set_state(4202);
			let tmp = recog.multiUnitsInterval()?;
			 cast_mut::<_,ErrorCapturingMultiUnitsIntervalContext >(&mut _localctx).body = Some(tmp.clone());
			  

			recog.base.set_state(4204);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(521,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule unitToUnitInterval*/
					recog.base.set_state(4203);
					recog.unitToUnitInterval()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- multiUnitsInterval ----------------
pub type MultiUnitsIntervalContextAll<'input> = MultiUnitsIntervalContext<'input>;


pub type MultiUnitsIntervalContext<'input> = BaseParserRuleContext<'input,MultiUnitsIntervalContextExt<'input>>;

#[derive(Clone)]
pub struct MultiUnitsIntervalContextExt<'input>{
	pub unitInMultiUnits: Option<Rc<UnitInMultiUnitsContextAll<'input>>>,
	pub unit:Vec<Rc<UnitInMultiUnitsContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for MultiUnitsIntervalContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for MultiUnitsIntervalContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_multiUnitsInterval(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_multiUnitsInterval(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for MultiUnitsIntervalContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_multiUnitsInterval(self);
	}
}

impl<'input> CustomRuleContext<'input> for MultiUnitsIntervalContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_multiUnitsInterval }
	//fn type_rule_index() -> usize where Self: Sized { RULE_multiUnitsInterval }
}
antlr_rust::tid!{MultiUnitsIntervalContextExt<'a>}

impl<'input> MultiUnitsIntervalContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MultiUnitsIntervalContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MultiUnitsIntervalContextExt{
				unitInMultiUnits: None, 
				unit: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait MultiUnitsIntervalContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<MultiUnitsIntervalContextExt<'input>>{

fn intervalValue_all(&self) ->  Vec<Rc<IntervalValueContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn intervalValue(&self, i: usize) -> Option<Rc<IntervalValueContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn unitInMultiUnits_all(&self) ->  Vec<Rc<UnitInMultiUnitsContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn unitInMultiUnits(&self, i: usize) -> Option<Rc<UnitInMultiUnitsContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> MultiUnitsIntervalContextAttrs<'input> for MultiUnitsIntervalContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn multiUnitsInterval(&mut self,)
	-> Result<Rc<MultiUnitsIntervalContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MultiUnitsIntervalContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 382, RULE_multiUnitsInterval);
        let mut _localctx: Rc<MultiUnitsIntervalContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4209); 
			recog.err_handler.sync(&mut recog.base)?;
			_alt = 1;
			loop {
				match _alt {
				    x if x == 1=>
					{
					{
					/*InvokeRule intervalValue*/
					recog.base.set_state(4206);
					recog.intervalValue()?;

					/*InvokeRule unitInMultiUnits*/
					recog.base.set_state(4207);
					let tmp = recog.unitInMultiUnits()?;
					 cast_mut::<_,MultiUnitsIntervalContext >(&mut _localctx).unitInMultiUnits = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,MultiUnitsIntervalContext >(&mut _localctx).unitInMultiUnits.clone().unwrap()
					 ;
					 cast_mut::<_,MultiUnitsIntervalContext >(&mut _localctx).unit.push(temp);
					  
					}
					}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
				}
				recog.base.set_state(4211); 
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(522,&mut recog.base)?;
				if _alt==2 || _alt==INVALID_ALT { break }
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- errorCapturingUnitToUnitInterval ----------------
pub type ErrorCapturingUnitToUnitIntervalContextAll<'input> = ErrorCapturingUnitToUnitIntervalContext<'input>;


pub type ErrorCapturingUnitToUnitIntervalContext<'input> = BaseParserRuleContext<'input,ErrorCapturingUnitToUnitIntervalContextExt<'input>>;

#[derive(Clone)]
pub struct ErrorCapturingUnitToUnitIntervalContextExt<'input>{
	pub body: Option<Rc<UnitToUnitIntervalContextAll<'input>>>,
	pub error1: Option<Rc<MultiUnitsIntervalContextAll<'input>>>,
	pub error2: Option<Rc<UnitToUnitIntervalContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ErrorCapturingUnitToUnitIntervalContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ErrorCapturingUnitToUnitIntervalContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_errorCapturingUnitToUnitInterval(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_errorCapturingUnitToUnitInterval(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ErrorCapturingUnitToUnitIntervalContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_errorCapturingUnitToUnitInterval(self);
	}
}

impl<'input> CustomRuleContext<'input> for ErrorCapturingUnitToUnitIntervalContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_errorCapturingUnitToUnitInterval }
	//fn type_rule_index() -> usize where Self: Sized { RULE_errorCapturingUnitToUnitInterval }
}
antlr_rust::tid!{ErrorCapturingUnitToUnitIntervalContextExt<'a>}

impl<'input> ErrorCapturingUnitToUnitIntervalContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ErrorCapturingUnitToUnitIntervalContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ErrorCapturingUnitToUnitIntervalContextExt{
				body: None, error1: None, error2: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ErrorCapturingUnitToUnitIntervalContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ErrorCapturingUnitToUnitIntervalContextExt<'input>>{

fn unitToUnitInterval_all(&self) ->  Vec<Rc<UnitToUnitIntervalContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn unitToUnitInterval(&self, i: usize) -> Option<Rc<UnitToUnitIntervalContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn multiUnitsInterval(&self) -> Option<Rc<MultiUnitsIntervalContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ErrorCapturingUnitToUnitIntervalContextAttrs<'input> for ErrorCapturingUnitToUnitIntervalContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn errorCapturingUnitToUnitInterval(&mut self,)
	-> Result<Rc<ErrorCapturingUnitToUnitIntervalContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ErrorCapturingUnitToUnitIntervalContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 384, RULE_errorCapturingUnitToUnitInterval);
        let mut _localctx: Rc<ErrorCapturingUnitToUnitIntervalContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule unitToUnitInterval*/
			recog.base.set_state(4213);
			let tmp = recog.unitToUnitInterval()?;
			 cast_mut::<_,ErrorCapturingUnitToUnitIntervalContext >(&mut _localctx).body = Some(tmp.clone());
			  

			recog.base.set_state(4216);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(523,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule multiUnitsInterval*/
					recog.base.set_state(4214);
					let tmp = recog.multiUnitsInterval()?;
					 cast_mut::<_,ErrorCapturingUnitToUnitIntervalContext >(&mut _localctx).error1 = Some(tmp.clone());
					  

					}
				}

				x if x == 2=>{
					{
					/*InvokeRule unitToUnitInterval*/
					recog.base.set_state(4215);
					let tmp = recog.unitToUnitInterval()?;
					 cast_mut::<_,ErrorCapturingUnitToUnitIntervalContext >(&mut _localctx).error2 = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unitToUnitInterval ----------------
pub type UnitToUnitIntervalContextAll<'input> = UnitToUnitIntervalContext<'input>;


pub type UnitToUnitIntervalContext<'input> = BaseParserRuleContext<'input,UnitToUnitIntervalContextExt<'input>>;

#[derive(Clone)]
pub struct UnitToUnitIntervalContextExt<'input>{
	pub value: Option<Rc<IntervalValueContextAll<'input>>>,
	pub from: Option<Rc<UnitInUnitToUnitContextAll<'input>>>,
	pub to: Option<Rc<UnitInUnitToUnitContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for UnitToUnitIntervalContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for UnitToUnitIntervalContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unitToUnitInterval(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_unitToUnitInterval(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for UnitToUnitIntervalContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_unitToUnitInterval(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnitToUnitIntervalContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unitToUnitInterval }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unitToUnitInterval }
}
antlr_rust::tid!{UnitToUnitIntervalContextExt<'a>}

impl<'input> UnitToUnitIntervalContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnitToUnitIntervalContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnitToUnitIntervalContextExt{
				value: None, from: None, to: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait UnitToUnitIntervalContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<UnitToUnitIntervalContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token TO
/// Returns `None` if there is no child corresponding to token TO
fn TO(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TO, 0)
}
fn intervalValue(&self) -> Option<Rc<IntervalValueContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn unitInUnitToUnit_all(&self) ->  Vec<Rc<UnitInUnitToUnitContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn unitInUnitToUnit(&self, i: usize) -> Option<Rc<UnitInUnitToUnitContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> UnitToUnitIntervalContextAttrs<'input> for UnitToUnitIntervalContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unitToUnitInterval(&mut self,)
	-> Result<Rc<UnitToUnitIntervalContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnitToUnitIntervalContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 386, RULE_unitToUnitInterval);
        let mut _localctx: Rc<UnitToUnitIntervalContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule intervalValue*/
			recog.base.set_state(4218);
			let tmp = recog.intervalValue()?;
			 cast_mut::<_,UnitToUnitIntervalContext >(&mut _localctx).value = Some(tmp.clone());
			  

			/*InvokeRule unitInUnitToUnit*/
			recog.base.set_state(4219);
			let tmp = recog.unitInUnitToUnit()?;
			 cast_mut::<_,UnitToUnitIntervalContext >(&mut _localctx).from = Some(tmp.clone());
			  

			recog.base.set_state(4220);
			recog.base.match_token(TO,&mut recog.err_handler)?;

			/*InvokeRule unitInUnitToUnit*/
			recog.base.set_state(4221);
			let tmp = recog.unitInUnitToUnit()?;
			 cast_mut::<_,UnitToUnitIntervalContext >(&mut _localctx).to = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- intervalValue ----------------
pub type IntervalValueContextAll<'input> = IntervalValueContext<'input>;


pub type IntervalValueContext<'input> = BaseParserRuleContext<'input,IntervalValueContextExt<'input>>;

#[derive(Clone)]
pub struct IntervalValueContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for IntervalValueContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for IntervalValueContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_intervalValue(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_intervalValue(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for IntervalValueContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_intervalValue(self);
	}
}

impl<'input> CustomRuleContext<'input> for IntervalValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_intervalValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_intervalValue }
}
antlr_rust::tid!{IntervalValueContextExt<'a>}

impl<'input> IntervalValueContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IntervalValueContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IntervalValueContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait IntervalValueContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<IntervalValueContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INTEGER_VALUE, 0)
}
/// Retrieves first TerminalNode corresponding to token DECIMAL_VALUE
/// Returns `None` if there is no child corresponding to token DECIMAL_VALUE
fn DECIMAL_VALUE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DECIMAL_VALUE, 0)
}
fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token PLUS
/// Returns `None` if there is no child corresponding to token PLUS
fn PLUS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PLUS, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUS
/// Returns `None` if there is no child corresponding to token MINUS
fn MINUS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MINUS, 0)
}

}

impl<'input> IntervalValueContextAttrs<'input> for IntervalValueContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn intervalValue(&mut self,)
	-> Result<Rc<IntervalValueContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IntervalValueContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 388, RULE_intervalValue);
        let mut _localctx: Rc<IntervalValueContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4224);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(524,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(4223);
					_la = recog.base.input.la(1);
					if { !(_la==PLUS || _la==MINUS) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					}
				}

				_ => {}
			}
			recog.base.set_state(4229);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(525,&mut recog.base)? {
				1 =>{
					{
					recog.base.set_state(4226);
					recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					{
					recog.base.set_state(4227);
					recog.base.match_token(DECIMAL_VALUE,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					{
					/*InvokeRule stringLit*/
					recog.base.set_state(4228);
					recog.stringLit()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unitInMultiUnits ----------------
pub type UnitInMultiUnitsContextAll<'input> = UnitInMultiUnitsContext<'input>;


pub type UnitInMultiUnitsContext<'input> = BaseParserRuleContext<'input,UnitInMultiUnitsContextExt<'input>>;

#[derive(Clone)]
pub struct UnitInMultiUnitsContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for UnitInMultiUnitsContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for UnitInMultiUnitsContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unitInMultiUnits(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_unitInMultiUnits(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for UnitInMultiUnitsContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_unitInMultiUnits(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnitInMultiUnitsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unitInMultiUnits }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unitInMultiUnits }
}
antlr_rust::tid!{UnitInMultiUnitsContextExt<'a>}

impl<'input> UnitInMultiUnitsContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnitInMultiUnitsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnitInMultiUnitsContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait UnitInMultiUnitsContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<UnitInMultiUnitsContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token NANOSECOND
/// Returns `None` if there is no child corresponding to token NANOSECOND
fn NANOSECOND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NANOSECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token NANOSECONDS
/// Returns `None` if there is no child corresponding to token NANOSECONDS
fn NANOSECONDS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NANOSECONDS, 0)
}
/// Retrieves first TerminalNode corresponding to token MICROSECOND
/// Returns `None` if there is no child corresponding to token MICROSECOND
fn MICROSECOND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MICROSECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token MICROSECONDS
/// Returns `None` if there is no child corresponding to token MICROSECONDS
fn MICROSECONDS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MICROSECONDS, 0)
}
/// Retrieves first TerminalNode corresponding to token MILLISECOND
/// Returns `None` if there is no child corresponding to token MILLISECOND
fn MILLISECOND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MILLISECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token MILLISECONDS
/// Returns `None` if there is no child corresponding to token MILLISECONDS
fn MILLISECONDS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MILLISECONDS, 0)
}
/// Retrieves first TerminalNode corresponding to token SECOND
/// Returns `None` if there is no child corresponding to token SECOND
fn SECOND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token SECONDS
/// Returns `None` if there is no child corresponding to token SECONDS
fn SECONDS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SECONDS, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUTE
/// Returns `None` if there is no child corresponding to token MINUTE
fn MINUTE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MINUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUTES
/// Returns `None` if there is no child corresponding to token MINUTES
fn MINUTES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MINUTES, 0)
}
/// Retrieves first TerminalNode corresponding to token HOUR
/// Returns `None` if there is no child corresponding to token HOUR
fn HOUR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(HOUR, 0)
}
/// Retrieves first TerminalNode corresponding to token HOURS
/// Returns `None` if there is no child corresponding to token HOURS
fn HOURS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(HOURS, 0)
}
/// Retrieves first TerminalNode corresponding to token DAY
/// Returns `None` if there is no child corresponding to token DAY
fn DAY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DAY, 0)
}
/// Retrieves first TerminalNode corresponding to token DAYS
/// Returns `None` if there is no child corresponding to token DAYS
fn DAYS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DAYS, 0)
}
/// Retrieves first TerminalNode corresponding to token WEEK
/// Returns `None` if there is no child corresponding to token WEEK
fn WEEK(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WEEK, 0)
}
/// Retrieves first TerminalNode corresponding to token WEEKS
/// Returns `None` if there is no child corresponding to token WEEKS
fn WEEKS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WEEKS, 0)
}
/// Retrieves first TerminalNode corresponding to token MONTH
/// Returns `None` if there is no child corresponding to token MONTH
fn MONTH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MONTH, 0)
}
/// Retrieves first TerminalNode corresponding to token MONTHS
/// Returns `None` if there is no child corresponding to token MONTHS
fn MONTHS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MONTHS, 0)
}
/// Retrieves first TerminalNode corresponding to token YEAR
/// Returns `None` if there is no child corresponding to token YEAR
fn YEAR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(YEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token YEARS
/// Returns `None` if there is no child corresponding to token YEARS
fn YEARS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(YEARS, 0)
}

}

impl<'input> UnitInMultiUnitsContextAttrs<'input> for UnitInMultiUnitsContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unitInMultiUnits(&mut self,)
	-> Result<Rc<UnitInMultiUnitsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnitInMultiUnitsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 390, RULE_unitInMultiUnits);
        let mut _localctx: Rc<UnitInMultiUnitsContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4231);
			_la = recog.base.input.la(1);
			if { !(_la==DAY || _la==DAYS || _la==HOUR || _la==HOURS || ((((_la - 218)) & !0x3f) == 0 && ((1usize << (_la - 218)) & ((1usize << (MICROSECOND - 218)) | (1usize << (MICROSECONDS - 218)) | (1usize << (MILLISECOND - 218)) | (1usize << (MILLISECONDS - 218)) | (1usize << (MINUTE - 218)) | (1usize << (MINUTES - 218)) | (1usize << (MONTH - 218)) | (1usize << (MONTHS - 218)) | (1usize << (NANOSECOND - 218)) | (1usize << (NANOSECONDS - 218)))) != 0) || _la==SECOND || _la==SECONDS || ((((_la - 396)) & !0x3f) == 0 && ((1usize << (_la - 396)) & ((1usize << (WEEK - 396)) | (1usize << (WEEKS - 396)) | (1usize << (YEAR - 396)) | (1usize << (YEARS - 396)))) != 0)) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unitInUnitToUnit ----------------
pub type UnitInUnitToUnitContextAll<'input> = UnitInUnitToUnitContext<'input>;


pub type UnitInUnitToUnitContext<'input> = BaseParserRuleContext<'input,UnitInUnitToUnitContextExt<'input>>;

#[derive(Clone)]
pub struct UnitInUnitToUnitContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for UnitInUnitToUnitContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for UnitInUnitToUnitContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unitInUnitToUnit(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_unitInUnitToUnit(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for UnitInUnitToUnitContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_unitInUnitToUnit(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnitInUnitToUnitContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unitInUnitToUnit }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unitInUnitToUnit }
}
antlr_rust::tid!{UnitInUnitToUnitContextExt<'a>}

impl<'input> UnitInUnitToUnitContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnitInUnitToUnitContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnitInUnitToUnitContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait UnitInUnitToUnitContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<UnitInUnitToUnitContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token SECOND
/// Returns `None` if there is no child corresponding to token SECOND
fn SECOND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUTE
/// Returns `None` if there is no child corresponding to token MINUTE
fn MINUTE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MINUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token HOUR
/// Returns `None` if there is no child corresponding to token HOUR
fn HOUR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(HOUR, 0)
}
/// Retrieves first TerminalNode corresponding to token DAY
/// Returns `None` if there is no child corresponding to token DAY
fn DAY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DAY, 0)
}
/// Retrieves first TerminalNode corresponding to token MONTH
/// Returns `None` if there is no child corresponding to token MONTH
fn MONTH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MONTH, 0)
}
/// Retrieves first TerminalNode corresponding to token YEAR
/// Returns `None` if there is no child corresponding to token YEAR
fn YEAR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(YEAR, 0)
}

}

impl<'input> UnitInUnitToUnitContextAttrs<'input> for UnitInUnitToUnitContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unitInUnitToUnit(&mut self,)
	-> Result<Rc<UnitInUnitToUnitContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnitInUnitToUnitContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 392, RULE_unitInUnitToUnit);
        let mut _localctx: Rc<UnitInUnitToUnitContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4233);
			_la = recog.base.input.la(1);
			if { !(_la==DAY || _la==HOUR || _la==MINUTE || _la==MONTH || _la==SECOND || _la==YEAR) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- colPosition ----------------
pub type ColPositionContextAll<'input> = ColPositionContext<'input>;


pub type ColPositionContext<'input> = BaseParserRuleContext<'input,ColPositionContextExt<'input>>;

#[derive(Clone)]
pub struct ColPositionContextExt<'input>{
	pub position: Option<TokenType<'input>>,
	pub afterCol: Option<Rc<ErrorCapturingIdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ColPositionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ColPositionContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_colPosition(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_colPosition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ColPositionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_colPosition(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColPositionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_colPosition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_colPosition }
}
antlr_rust::tid!{ColPositionContextExt<'a>}

impl<'input> ColPositionContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColPositionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColPositionContextExt{
				position: None, 
				afterCol: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ColPositionContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ColPositionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token FIRST
/// Returns `None` if there is no child corresponding to token FIRST
fn FIRST(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FIRST, 0)
}
/// Retrieves first TerminalNode corresponding to token AFTER
/// Returns `None` if there is no child corresponding to token AFTER
fn AFTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AFTER, 0)
}
fn errorCapturingIdentifier(&self) -> Option<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColPositionContextAttrs<'input> for ColPositionContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn colPosition(&mut self,)
	-> Result<Rc<ColPositionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColPositionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 394, RULE_colPosition);
        let mut _localctx: Rc<ColPositionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4238);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 FIRST 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4235);
					let tmp = recog.base.match_token(FIRST,&mut recog.err_handler)?;
					 cast_mut::<_,ColPositionContext >(&mut _localctx).position = Some(tmp.clone());
					  

					}
				}

			 AFTER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4236);
					let tmp = recog.base.match_token(AFTER,&mut recog.err_handler)?;
					 cast_mut::<_,ColPositionContext >(&mut _localctx).position = Some(tmp.clone());
					  

					/*InvokeRule errorCapturingIdentifier*/
					recog.base.set_state(4237);
					let tmp = recog.errorCapturingIdentifier()?;
					 cast_mut::<_,ColPositionContext >(&mut _localctx).afterCol = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- collationSpec ----------------
pub type CollationSpecContextAll<'input> = CollationSpecContext<'input>;


pub type CollationSpecContext<'input> = BaseParserRuleContext<'input,CollationSpecContextExt<'input>>;

#[derive(Clone)]
pub struct CollationSpecContextExt<'input>{
	pub collationName: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for CollationSpecContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CollationSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_collationSpec(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_collationSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CollationSpecContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_collationSpec(self);
	}
}

impl<'input> CustomRuleContext<'input> for CollationSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_collationSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_collationSpec }
}
antlr_rust::tid!{CollationSpecContextExt<'a>}

impl<'input> CollationSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CollationSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CollationSpecContextExt{
				collationName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CollationSpecContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<CollationSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DEFAULT
/// Returns `None` if there is no child corresponding to token DEFAULT
fn DEFAULT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DEFAULT, 0)
}
/// Retrieves first TerminalNode corresponding to token COLLATION
/// Returns `None` if there is no child corresponding to token COLLATION
fn COLLATION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COLLATION, 0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CollationSpecContextAttrs<'input> for CollationSpecContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn collationSpec(&mut self,)
	-> Result<Rc<CollationSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CollationSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 396, RULE_collationSpec);
        let mut _localctx: Rc<CollationSpecContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4240);
			recog.base.match_token(DEFAULT,&mut recog.err_handler)?;

			recog.base.set_state(4241);
			recog.base.match_token(COLLATION,&mut recog.err_handler)?;

			/*InvokeRule identifier*/
			recog.base.set_state(4242);
			let tmp = recog.identifier()?;
			 cast_mut::<_,CollationSpecContext >(&mut _localctx).collationName = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- collateClause ----------------
pub type CollateClauseContextAll<'input> = CollateClauseContext<'input>;


pub type CollateClauseContext<'input> = BaseParserRuleContext<'input,CollateClauseContextExt<'input>>;

#[derive(Clone)]
pub struct CollateClauseContextExt<'input>{
	pub collationName: Option<Rc<MultipartIdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for CollateClauseContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CollateClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_collateClause(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_collateClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CollateClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_collateClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for CollateClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_collateClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_collateClause }
}
antlr_rust::tid!{CollateClauseContextExt<'a>}

impl<'input> CollateClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CollateClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CollateClauseContextExt{
				collationName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CollateClauseContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<CollateClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token COLLATE
/// Returns `None` if there is no child corresponding to token COLLATE
fn COLLATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COLLATE, 0)
}
fn multipartIdentifier(&self) -> Option<Rc<MultipartIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CollateClauseContextAttrs<'input> for CollateClauseContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn collateClause(&mut self,)
	-> Result<Rc<CollateClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CollateClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 398, RULE_collateClause);
        let mut _localctx: Rc<CollateClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4244);
			recog.base.match_token(COLLATE,&mut recog.err_handler)?;

			/*InvokeRule multipartIdentifier*/
			recog.base.set_state(4245);
			let tmp = recog.multipartIdentifier()?;
			 cast_mut::<_,CollateClauseContext >(&mut _localctx).collationName = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- nonTrivialPrimitiveType ----------------
pub type NonTrivialPrimitiveTypeContextAll<'input> = NonTrivialPrimitiveTypeContext<'input>;


pub type NonTrivialPrimitiveTypeContext<'input> = BaseParserRuleContext<'input,NonTrivialPrimitiveTypeContextExt<'input>>;

#[derive(Clone)]
pub struct NonTrivialPrimitiveTypeContextExt<'input>{
	pub length: Option<Rc<IntegerValueContextAll<'input>>>,
	pub precision: Option<Rc<IntegerValueContextAll<'input>>>,
	pub scale: Option<Rc<IntegerValueContextAll<'input>>>,
	pub fromYearMonth: Option<TokenType<'input>>,
	pub to: Option<TokenType<'input>>,
	pub fromDayTime: Option<TokenType<'input>>,
	pub srid: Option<Rc<IntegerValueContextAll<'input>>>,
	pub any: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for NonTrivialPrimitiveTypeContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for NonTrivialPrimitiveTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_nonTrivialPrimitiveType(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_nonTrivialPrimitiveType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for NonTrivialPrimitiveTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_nonTrivialPrimitiveType(self);
	}
}

impl<'input> CustomRuleContext<'input> for NonTrivialPrimitiveTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nonTrivialPrimitiveType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nonTrivialPrimitiveType }
}
antlr_rust::tid!{NonTrivialPrimitiveTypeContextExt<'a>}

impl<'input> NonTrivialPrimitiveTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NonTrivialPrimitiveTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NonTrivialPrimitiveTypeContextExt{
				fromYearMonth: None, to: None, fromDayTime: None, any: None, 
				length: None, precision: None, scale: None, srid: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait NonTrivialPrimitiveTypeContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<NonTrivialPrimitiveTypeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token STRING
/// Returns `None` if there is no child corresponding to token STRING
fn STRING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(STRING, 0)
}
fn collateClause(&self) -> Option<Rc<CollateClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token CHARACTER
/// Returns `None` if there is no child corresponding to token CHARACTER
fn CHARACTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CHARACTER, 0)
}
/// Retrieves first TerminalNode corresponding to token CHAR
/// Returns `None` if there is no child corresponding to token CHAR
fn CHAR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CHAR, 0)
}
/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
fn integerValue_all(&self) ->  Vec<Rc<IntegerValueContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn integerValue(&self, i: usize) -> Option<Rc<IntegerValueContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token VARCHAR
/// Returns `None` if there is no child corresponding to token VARCHAR
fn VARCHAR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VARCHAR, 0)
}
/// Retrieves first TerminalNode corresponding to token DECIMAL
/// Returns `None` if there is no child corresponding to token DECIMAL
fn DECIMAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DECIMAL, 0)
}
/// Retrieves first TerminalNode corresponding to token DEC
/// Returns `None` if there is no child corresponding to token DEC
fn DEC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DEC, 0)
}
/// Retrieves first TerminalNode corresponding to token NUMERIC
/// Returns `None` if there is no child corresponding to token NUMERIC
fn NUMERIC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NUMERIC, 0)
}
/// Retrieves first TerminalNode corresponding to token COMMA
/// Returns `None` if there is no child corresponding to token COMMA
fn COMMA(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, 0)
}
/// Retrieves first TerminalNode corresponding to token INTERVAL
/// Returns `None` if there is no child corresponding to token INTERVAL
fn INTERVAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INTERVAL, 0)
}
/// Retrieves first TerminalNode corresponding to token YEAR
/// Returns `None` if there is no child corresponding to token YEAR
fn YEAR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(YEAR, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token MONTH in current rule
fn MONTH_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token MONTH, starting from 0.
/// Returns `None` if number of children corresponding to token MONTH is less or equal than `i`.
fn MONTH(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MONTH, i)
}
/// Retrieves first TerminalNode corresponding to token DAY
/// Returns `None` if there is no child corresponding to token DAY
fn DAY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DAY, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token HOUR in current rule
fn HOUR_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token HOUR, starting from 0.
/// Returns `None` if number of children corresponding to token HOUR is less or equal than `i`.
fn HOUR(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(HOUR, i)
}
/// Retrieves all `TerminalNode`s corresponding to token MINUTE in current rule
fn MINUTE_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token MINUTE, starting from 0.
/// Returns `None` if number of children corresponding to token MINUTE is less or equal than `i`.
fn MINUTE(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MINUTE, i)
}
/// Retrieves all `TerminalNode`s corresponding to token SECOND in current rule
fn SECOND_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token SECOND, starting from 0.
/// Returns `None` if number of children corresponding to token SECOND is less or equal than `i`.
fn SECOND(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SECOND, i)
}
/// Retrieves first TerminalNode corresponding to token TO
/// Returns `None` if there is no child corresponding to token TO
fn TO(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TO, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMP
/// Returns `None` if there is no child corresponding to token TIMESTAMP
fn TIMESTAMP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP, 0)
}
/// Retrieves first TerminalNode corresponding to token WITHOUT
/// Returns `None` if there is no child corresponding to token WITHOUT
fn WITHOUT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WITHOUT, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token TIME in current rule
fn TIME_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token TIME, starting from 0.
/// Returns `None` if number of children corresponding to token TIME is less or equal than `i`.
fn TIME(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TIME, i)
}
/// Retrieves first TerminalNode corresponding to token ZONE
/// Returns `None` if there is no child corresponding to token ZONE
fn ZONE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ZONE, 0)
}
/// Retrieves first TerminalNode corresponding to token GEOGRAPHY
/// Returns `None` if there is no child corresponding to token GEOGRAPHY
fn GEOGRAPHY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(GEOGRAPHY, 0)
}
/// Retrieves first TerminalNode corresponding to token ANY
/// Returns `None` if there is no child corresponding to token ANY
fn ANY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ANY, 0)
}
/// Retrieves first TerminalNode corresponding to token GEOMETRY
/// Returns `None` if there is no child corresponding to token GEOMETRY
fn GEOMETRY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(GEOMETRY, 0)
}

}

impl<'input> NonTrivialPrimitiveTypeContextAttrs<'input> for NonTrivialPrimitiveTypeContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn nonTrivialPrimitiveType(&mut self,)
	-> Result<Rc<NonTrivialPrimitiveTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NonTrivialPrimitiveTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 400, RULE_nonTrivialPrimitiveType);
        let mut _localctx: Rc<NonTrivialPrimitiveTypeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4321);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 STRING 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4247);
					recog.base.match_token(STRING,&mut recog.err_handler)?;

					recog.base.set_state(4249);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(527,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule collateClause*/
							recog.base.set_state(4248);
							recog.collateClause()?;

							}
						}

						_ => {}
					}
					}
				}

			 CHAR | CHARACTER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4251);
					_la = recog.base.input.la(1);
					if { !(_la==CHAR || _la==CHARACTER) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(4256);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(528,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(4252);
							recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

							/*InvokeRule integerValue*/
							recog.base.set_state(4253);
							let tmp = recog.integerValue()?;
							 cast_mut::<_,NonTrivialPrimitiveTypeContext >(&mut _localctx).length = Some(tmp.clone());
							  

							recog.base.set_state(4254);
							recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}

			 VARCHAR 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(4258);
					recog.base.match_token(VARCHAR,&mut recog.err_handler)?;

					recog.base.set_state(4263);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(529,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(4259);
							recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

							/*InvokeRule integerValue*/
							recog.base.set_state(4260);
							let tmp = recog.integerValue()?;
							 cast_mut::<_,NonTrivialPrimitiveTypeContext >(&mut _localctx).length = Some(tmp.clone());
							  

							recog.base.set_state(4261);
							recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}

			 DEC | DECIMAL | NUMERIC 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(4265);
					_la = recog.base.input.la(1);
					if { !(_la==DEC || _la==DECIMAL || _la==NUMERIC) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(4274);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(531,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(4266);
							recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

							/*InvokeRule integerValue*/
							recog.base.set_state(4267);
							let tmp = recog.integerValue()?;
							 cast_mut::<_,NonTrivialPrimitiveTypeContext >(&mut _localctx).precision = Some(tmp.clone());
							  

							recog.base.set_state(4270);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==COMMA {
								{
								recog.base.set_state(4268);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule integerValue*/
								recog.base.set_state(4269);
								let tmp = recog.integerValue()?;
								 cast_mut::<_,NonTrivialPrimitiveTypeContext >(&mut _localctx).scale = Some(tmp.clone());
								  

								}
							}

							recog.base.set_state(4272);
							recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}

			 INTERVAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					recog.base.set_state(4276);
					recog.base.match_token(INTERVAL,&mut recog.err_handler)?;

					recog.base.set_state(4287);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(534,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(4277);
							 cast_mut::<_,NonTrivialPrimitiveTypeContext >(&mut _localctx).fromYearMonth = recog.base.input.lt(1).cloned();
							 
							_la = recog.base.input.la(1);
							if { !(_la==MONTH || _la==YEAR) } {
								let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
								 cast_mut::<_,NonTrivialPrimitiveTypeContext >(&mut _localctx).fromYearMonth = Some(tmp.clone());
								  

							}
							else {
								if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
								recog.err_handler.report_match(&mut recog.base);
								recog.base.consume(&mut recog.err_handler);
							}
							recog.base.set_state(4280);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(532,&mut recog.base)? {
								x if x == 1=>{
									{
									recog.base.set_state(4278);
									recog.base.match_token(TO,&mut recog.err_handler)?;

									recog.base.set_state(4279);
									let tmp = recog.base.match_token(MONTH,&mut recog.err_handler)?;
									 cast_mut::<_,NonTrivialPrimitiveTypeContext >(&mut _localctx).to = Some(tmp.clone());
									  

									}
								}

								_ => {}
							}
							}
						}

						x if x == 2=>{
							{
							recog.base.set_state(4282);
							 cast_mut::<_,NonTrivialPrimitiveTypeContext >(&mut _localctx).fromDayTime = recog.base.input.lt(1).cloned();
							 
							_la = recog.base.input.la(1);
							if { !(_la==DAY || _la==HOUR || _la==MINUTE || _la==SECOND) } {
								let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
								 cast_mut::<_,NonTrivialPrimitiveTypeContext >(&mut _localctx).fromDayTime = Some(tmp.clone());
								  

							}
							else {
								if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
								recog.err_handler.report_match(&mut recog.base);
								recog.base.consume(&mut recog.err_handler);
							}
							recog.base.set_state(4285);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(533,&mut recog.base)? {
								x if x == 1=>{
									{
									recog.base.set_state(4283);
									recog.base.match_token(TO,&mut recog.err_handler)?;

									recog.base.set_state(4284);
									 cast_mut::<_,NonTrivialPrimitiveTypeContext >(&mut _localctx).to = recog.base.input.lt(1).cloned();
									 
									_la = recog.base.input.la(1);
									if { !(_la==HOUR || _la==MINUTE || _la==SECOND) } {
										let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
										 cast_mut::<_,NonTrivialPrimitiveTypeContext >(&mut _localctx).to = Some(tmp.clone());
										  

									}
									else {
										if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
										recog.err_handler.report_match(&mut recog.base);
										recog.base.consume(&mut recog.err_handler);
									}
									}
								}

								_ => {}
							}
							}
						}

						_ => {}
					}
					}
				}

			 TIMESTAMP 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					recog.base.set_state(4289);
					recog.base.match_token(TIMESTAMP,&mut recog.err_handler)?;

					recog.base.set_state(4293);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(535,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(4290);
							recog.base.match_token(WITHOUT,&mut recog.err_handler)?;

							recog.base.set_state(4291);
							recog.base.match_token(TIME,&mut recog.err_handler)?;

							recog.base.set_state(4292);
							recog.base.match_token(ZONE,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}

			 TIME 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					recog.base.set_state(4295);
					recog.base.match_token(TIME,&mut recog.err_handler)?;

					recog.base.set_state(4300);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(536,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(4296);
							recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

							/*InvokeRule integerValue*/
							recog.base.set_state(4297);
							let tmp = recog.integerValue()?;
							 cast_mut::<_,NonTrivialPrimitiveTypeContext >(&mut _localctx).precision = Some(tmp.clone());
							  

							recog.base.set_state(4298);
							recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					recog.base.set_state(4305);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(537,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(4302);
							recog.base.match_token(WITHOUT,&mut recog.err_handler)?;

							recog.base.set_state(4303);
							recog.base.match_token(TIME,&mut recog.err_handler)?;

							recog.base.set_state(4304);
							recog.base.match_token(ZONE,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}

			 GEOGRAPHY 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 8);
					recog.base.enter_outer_alt(None, 8);
					{
					recog.base.set_state(4307);
					recog.base.match_token(GEOGRAPHY,&mut recog.err_handler)?;

					recog.base.set_state(4308);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					recog.base.set_state(4311);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(538,&mut recog.base)? {
						1 =>{
							{
							/*InvokeRule integerValue*/
							recog.base.set_state(4309);
							let tmp = recog.integerValue()?;
							 cast_mut::<_,NonTrivialPrimitiveTypeContext >(&mut _localctx).srid = Some(tmp.clone());
							  

							}
						}
					,
						2 =>{
							{
							recog.base.set_state(4310);
							let tmp = recog.base.match_token(ANY,&mut recog.err_handler)?;
							 cast_mut::<_,NonTrivialPrimitiveTypeContext >(&mut _localctx).any = Some(tmp.clone());
							  

							}
						}

						_ => {}
					}
					recog.base.set_state(4313);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}

			 GEOMETRY 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 9);
					recog.base.enter_outer_alt(None, 9);
					{
					recog.base.set_state(4314);
					recog.base.match_token(GEOMETRY,&mut recog.err_handler)?;

					recog.base.set_state(4315);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					recog.base.set_state(4318);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(539,&mut recog.base)? {
						1 =>{
							{
							/*InvokeRule integerValue*/
							recog.base.set_state(4316);
							let tmp = recog.integerValue()?;
							 cast_mut::<_,NonTrivialPrimitiveTypeContext >(&mut _localctx).srid = Some(tmp.clone());
							  

							}
						}
					,
						2 =>{
							{
							recog.base.set_state(4317);
							let tmp = recog.base.match_token(ANY,&mut recog.err_handler)?;
							 cast_mut::<_,NonTrivialPrimitiveTypeContext >(&mut _localctx).any = Some(tmp.clone());
							  

							}
						}

						_ => {}
					}
					recog.base.set_state(4320);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- trivialPrimitiveType ----------------
pub type TrivialPrimitiveTypeContextAll<'input> = TrivialPrimitiveTypeContext<'input>;


pub type TrivialPrimitiveTypeContext<'input> = BaseParserRuleContext<'input,TrivialPrimitiveTypeContextExt<'input>>;

#[derive(Clone)]
pub struct TrivialPrimitiveTypeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for TrivialPrimitiveTypeContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for TrivialPrimitiveTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_trivialPrimitiveType(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_trivialPrimitiveType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for TrivialPrimitiveTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_trivialPrimitiveType(self);
	}
}

impl<'input> CustomRuleContext<'input> for TrivialPrimitiveTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_trivialPrimitiveType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_trivialPrimitiveType }
}
antlr_rust::tid!{TrivialPrimitiveTypeContextExt<'a>}

impl<'input> TrivialPrimitiveTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TrivialPrimitiveTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TrivialPrimitiveTypeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TrivialPrimitiveTypeContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<TrivialPrimitiveTypeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token BOOLEAN
/// Returns `None` if there is no child corresponding to token BOOLEAN
fn BOOLEAN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BOOLEAN, 0)
}
/// Retrieves first TerminalNode corresponding to token TINYINT
/// Returns `None` if there is no child corresponding to token TINYINT
fn TINYINT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TINYINT, 0)
}
/// Retrieves first TerminalNode corresponding to token BYTE
/// Returns `None` if there is no child corresponding to token BYTE
fn BYTE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BYTE, 0)
}
/// Retrieves first TerminalNode corresponding to token SMALLINT
/// Returns `None` if there is no child corresponding to token SMALLINT
fn SMALLINT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SMALLINT, 0)
}
/// Retrieves first TerminalNode corresponding to token SHORT
/// Returns `None` if there is no child corresponding to token SHORT
fn SHORT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SHORT, 0)
}
/// Retrieves first TerminalNode corresponding to token INT
/// Returns `None` if there is no child corresponding to token INT
fn INT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INT, 0)
}
/// Retrieves first TerminalNode corresponding to token INTEGER
/// Returns `None` if there is no child corresponding to token INTEGER
fn INTEGER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INTEGER, 0)
}
/// Retrieves first TerminalNode corresponding to token BIGINT
/// Returns `None` if there is no child corresponding to token BIGINT
fn BIGINT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BIGINT, 0)
}
/// Retrieves first TerminalNode corresponding to token LONG
/// Returns `None` if there is no child corresponding to token LONG
fn LONG(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LONG, 0)
}
/// Retrieves first TerminalNode corresponding to token FLOAT
/// Returns `None` if there is no child corresponding to token FLOAT
fn FLOAT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FLOAT, 0)
}
/// Retrieves first TerminalNode corresponding to token REAL
/// Returns `None` if there is no child corresponding to token REAL
fn REAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(REAL, 0)
}
/// Retrieves first TerminalNode corresponding to token DOUBLE
/// Returns `None` if there is no child corresponding to token DOUBLE
fn DOUBLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DOUBLE, 0)
}
/// Retrieves first TerminalNode corresponding to token DATE
/// Returns `None` if there is no child corresponding to token DATE
fn DATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DATE, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMP_LTZ
/// Returns `None` if there is no child corresponding to token TIMESTAMP_LTZ
fn TIMESTAMP_LTZ(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP_LTZ, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMP_NTZ
/// Returns `None` if there is no child corresponding to token TIMESTAMP_NTZ
fn TIMESTAMP_NTZ(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP_NTZ, 0)
}
/// Retrieves first TerminalNode corresponding to token BINARY
/// Returns `None` if there is no child corresponding to token BINARY
fn BINARY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BINARY, 0)
}
/// Retrieves first TerminalNode corresponding to token VOID
/// Returns `None` if there is no child corresponding to token VOID
fn VOID(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VOID, 0)
}
/// Retrieves first TerminalNode corresponding to token VARIANT
/// Returns `None` if there is no child corresponding to token VARIANT
fn VARIANT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VARIANT, 0)
}

}

impl<'input> TrivialPrimitiveTypeContextAttrs<'input> for TrivialPrimitiveTypeContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn trivialPrimitiveType(&mut self,)
	-> Result<Rc<TrivialPrimitiveTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TrivialPrimitiveTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 402, RULE_trivialPrimitiveType);
        let mut _localctx: Rc<TrivialPrimitiveTypeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4323);
			_la = recog.base.input.la(1);
			if { !(((((_la - 29)) & !0x3f) == 0 && ((1usize << (_la - 29)) & ((1usize << (BIGINT - 29)) | (1usize << (BINARY - 29)) | (1usize << (BOOLEAN - 29)) | (1usize << (BYTE - 29)))) != 0) || _la==DATE || _la==DOUBLE || _la==FLOAT || ((((_la - 178)) & !0x3f) == 0 && ((1usize << (_la - 178)) & ((1usize << (INT - 178)) | (1usize << (INTEGER - 178)) | (1usize << (LONG - 178)))) != 0) || _la==REAL || _la==SHORT || _la==SMALLINT || ((((_la - 354)) & !0x3f) == 0 && ((1usize << (_la - 354)) & ((1usize << (TIMESTAMP_LTZ - 354)) | (1usize << (TIMESTAMP_NTZ - 354)) | (1usize << (TINYINT - 354)))) != 0) || _la==VARIANT || _la==VOID) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- primitiveType ----------------
pub type PrimitiveTypeContextAll<'input> = PrimitiveTypeContext<'input>;


pub type PrimitiveTypeContext<'input> = BaseParserRuleContext<'input,PrimitiveTypeContextExt<'input>>;

#[derive(Clone)]
pub struct PrimitiveTypeContextExt<'input>{
	pub unsupportedType: Option<Rc<IdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for PrimitiveTypeContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PrimitiveTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_primitiveType(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_primitiveType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PrimitiveTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_primitiveType(self);
	}
}

impl<'input> CustomRuleContext<'input> for PrimitiveTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primitiveType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primitiveType }
}
antlr_rust::tid!{PrimitiveTypeContextExt<'a>}

impl<'input> PrimitiveTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrimitiveTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrimitiveTypeContextExt{
				unsupportedType: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PrimitiveTypeContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<PrimitiveTypeContextExt<'input>>{

fn nonTrivialPrimitiveType(&self) -> Option<Rc<NonTrivialPrimitiveTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn trivialPrimitiveType(&self) -> Option<Rc<TrivialPrimitiveTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
fn integerValue_all(&self) ->  Vec<Rc<IntegerValueContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn integerValue(&self, i: usize) -> Option<Rc<IntegerValueContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> PrimitiveTypeContextAttrs<'input> for PrimitiveTypeContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn primitiveType(&mut self,)
	-> Result<Rc<PrimitiveTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrimitiveTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 404, RULE_primitiveType);
        let mut _localctx: Rc<PrimitiveTypeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4341);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(543,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule nonTrivialPrimitiveType*/
					recog.base.set_state(4325);
					recog.nonTrivialPrimitiveType()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule trivialPrimitiveType*/
					recog.base.set_state(4326);
					recog.trivialPrimitiveType()?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule identifier*/
					recog.base.set_state(4327);
					let tmp = recog.identifier()?;
					 cast_mut::<_,PrimitiveTypeContext >(&mut _localctx).unsupportedType = Some(tmp.clone());
					  

					recog.base.set_state(4339);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(542,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(4328);
							recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

							/*InvokeRule integerValue*/
							recog.base.set_state(4329);
							recog.integerValue()?;

							recog.base.set_state(4334);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							while _la==COMMA {
								{
								{
								recog.base.set_state(4330);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule integerValue*/
								recog.base.set_state(4331);
								recog.integerValue()?;

								}
								}
								recog.base.set_state(4336);
								recog.err_handler.sync(&mut recog.base)?;
								_la = recog.base.input.la(1);
							}
							recog.base.set_state(4337);
							recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dataType ----------------
#[derive(Debug)]
pub enum DataTypeContextAll<'input>{
	ComplexDataTypeContext(ComplexDataTypeContext<'input>),
	PrimitiveDataTypeContext(PrimitiveDataTypeContext<'input>),
Error(DataTypeContext<'input>)
}
antlr_rust::tid!{DataTypeContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for DataTypeContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for DataTypeContextAll<'input>{}

impl<'input> Deref for DataTypeContextAll<'input>{
	type Target = dyn DataTypeContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use DataTypeContextAll::*;
		match self{
			ComplexDataTypeContext(inner) => inner,
			PrimitiveDataTypeContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DataTypeContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DataTypeContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type DataTypeContext<'input> = BaseParserRuleContext<'input,DataTypeContextExt<'input>>;

#[derive(Clone)]
pub struct DataTypeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for DataTypeContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DataTypeContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DataTypeContext<'input>{
}

impl<'input> CustomRuleContext<'input> for DataTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dataType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dataType }
}
antlr_rust::tid!{DataTypeContextExt<'a>}

impl<'input> DataTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DataTypeContextAll<'input>> {
		Rc::new(
		DataTypeContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DataTypeContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait DataTypeContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<DataTypeContextExt<'input>>{


}

impl<'input> DataTypeContextAttrs<'input> for DataTypeContext<'input>{}

pub type ComplexDataTypeContext<'input> = BaseParserRuleContext<'input,ComplexDataTypeContextExt<'input>>;

pub trait ComplexDataTypeContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token ARRAY
	/// Returns `None` if there is no child corresponding to token ARRAY
	fn ARRAY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ARRAY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LT
	/// Returns `None` if there is no child corresponding to token LT
	fn LT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LT, 0)
	}
	fn dataType_all(&self) ->  Vec<Rc<DataTypeContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn dataType(&self, i: usize) -> Option<Rc<DataTypeContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token GT
	/// Returns `None` if there is no child corresponding to token GT
	fn GT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(GT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MAP
	/// Returns `None` if there is no child corresponding to token MAP
	fn MAP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(MAP, 0)
	}
	/// Retrieves first TerminalNode corresponding to token COMMA
	/// Returns `None` if there is no child corresponding to token COMMA
	fn COMMA(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COMMA, 0)
	}
	/// Retrieves first TerminalNode corresponding to token STRUCT
	/// Returns `None` if there is no child corresponding to token STRUCT
	fn STRUCT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(STRUCT, 0)
	}
	/// Retrieves first TerminalNode corresponding to token NEQ
	/// Returns `None` if there is no child corresponding to token NEQ
	fn NEQ(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(NEQ, 0)
	}
	fn complexColTypeList(&self) -> Option<Rc<ComplexColTypeListContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ComplexDataTypeContextAttrs<'input> for ComplexDataTypeContext<'input>{}

pub struct ComplexDataTypeContextExt<'input>{
	base:DataTypeContextExt<'input>,
	pub complex: Option<TokenType<'input>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ComplexDataTypeContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ComplexDataTypeContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ComplexDataTypeContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_complexDataType(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_complexDataType(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ComplexDataTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_complexDataType(self);
	}
}

impl<'input> CustomRuleContext<'input> for ComplexDataTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dataType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dataType }
}

impl<'input> Borrow<DataTypeContextExt<'input>> for ComplexDataTypeContext<'input>{
	fn borrow(&self) -> &DataTypeContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<DataTypeContextExt<'input>> for ComplexDataTypeContext<'input>{
	fn borrow_mut(&mut self) -> &mut DataTypeContextExt<'input> { &mut self.base }
}

impl<'input> DataTypeContextAttrs<'input> for ComplexDataTypeContext<'input> {}

impl<'input> ComplexDataTypeContextExt<'input>{
	fn new(ctx: &dyn DataTypeContextAttrs<'input>) -> Rc<DataTypeContextAll<'input>>  {
		Rc::new(
			DataTypeContextAll::ComplexDataTypeContext(
				BaseParserRuleContext::copy_from(ctx,ComplexDataTypeContextExt{
					complex:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type PrimitiveDataTypeContext<'input> = BaseParserRuleContext<'input,PrimitiveDataTypeContextExt<'input>>;

pub trait PrimitiveDataTypeContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn primitiveType(&self) -> Option<Rc<PrimitiveTypeContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> PrimitiveDataTypeContextAttrs<'input> for PrimitiveDataTypeContext<'input>{}

pub struct PrimitiveDataTypeContextExt<'input>{
	base:DataTypeContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PrimitiveDataTypeContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for PrimitiveDataTypeContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PrimitiveDataTypeContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_primitiveDataType(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_primitiveDataType(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PrimitiveDataTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_primitiveDataType(self);
	}
}

impl<'input> CustomRuleContext<'input> for PrimitiveDataTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dataType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dataType }
}

impl<'input> Borrow<DataTypeContextExt<'input>> for PrimitiveDataTypeContext<'input>{
	fn borrow(&self) -> &DataTypeContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<DataTypeContextExt<'input>> for PrimitiveDataTypeContext<'input>{
	fn borrow_mut(&mut self) -> &mut DataTypeContextExt<'input> { &mut self.base }
}

impl<'input> DataTypeContextAttrs<'input> for PrimitiveDataTypeContext<'input> {}

impl<'input> PrimitiveDataTypeContextExt<'input>{
	fn new(ctx: &dyn DataTypeContextAttrs<'input>) -> Rc<DataTypeContextAll<'input>>  {
		Rc::new(
			DataTypeContextAll::PrimitiveDataTypeContext(
				BaseParserRuleContext::copy_from(ctx,PrimitiveDataTypeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dataType(&mut self,)
	-> Result<Rc<DataTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DataTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 406, RULE_dataType);
        let mut _localctx: Rc<DataTypeContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4369);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(548,&mut recog.base)? {
				1 =>{
					let tmp = ComplexDataTypeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(4343);
					let tmp = recog.base.match_token(ARRAY,&mut recog.err_handler)?;
					if let DataTypeContextAll::ComplexDataTypeContext(ctx) = cast_mut::<_,DataTypeContextAll >(&mut _localctx){
					ctx.complex = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(4348);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(544,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(4344);
							recog.base.match_token(LT,&mut recog.err_handler)?;

							/*InvokeRule dataType*/
							recog.base.set_state(4345);
							recog.dataType()?;

							recog.base.set_state(4346);
							recog.base.match_token(GT,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}
			,
				2 =>{
					let tmp = ComplexDataTypeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(4350);
					let tmp = recog.base.match_token(MAP,&mut recog.err_handler)?;
					if let DataTypeContextAll::ComplexDataTypeContext(ctx) = cast_mut::<_,DataTypeContextAll >(&mut _localctx){
					ctx.complex = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(4357);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(545,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(4351);
							recog.base.match_token(LT,&mut recog.err_handler)?;

							/*InvokeRule dataType*/
							recog.base.set_state(4352);
							recog.dataType()?;

							recog.base.set_state(4353);
							recog.base.match_token(COMMA,&mut recog.err_handler)?;

							/*InvokeRule dataType*/
							recog.base.set_state(4354);
							recog.dataType()?;

							recog.base.set_state(4355);
							recog.base.match_token(GT,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}
			,
				3 =>{
					let tmp = ComplexDataTypeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(4359);
					let tmp = recog.base.match_token(STRUCT,&mut recog.err_handler)?;
					if let DataTypeContextAll::ComplexDataTypeContext(ctx) = cast_mut::<_,DataTypeContextAll >(&mut _localctx){
					ctx.complex = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(4366);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(547,&mut recog.base)? {
						x if x == 1=>{
							{
							{
							recog.base.set_state(4360);
							recog.base.match_token(LT,&mut recog.err_handler)?;

							recog.base.set_state(4362);
							recog.err_handler.sync(&mut recog.base)?;
							match  recog.interpreter.adaptive_predict(546,&mut recog.base)? {
								x if x == 1=>{
									{
									/*InvokeRule complexColTypeList*/
									recog.base.set_state(4361);
									recog.complexColTypeList()?;

									}
								}

								_ => {}
							}
							recog.base.set_state(4364);
							recog.base.match_token(GT,&mut recog.err_handler)?;

							}
							}
						}

						x if x == 2=>{
							{
							recog.base.set_state(4365);
							recog.base.match_token(NEQ,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					}
				}
			,
				4 =>{
					let tmp = PrimitiveDataTypeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					/*InvokeRule primitiveType*/
					recog.base.set_state(4368);
					recog.primitiveType()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- qualifiedColTypeWithPositionList ----------------
pub type QualifiedColTypeWithPositionListContextAll<'input> = QualifiedColTypeWithPositionListContext<'input>;


pub type QualifiedColTypeWithPositionListContext<'input> = BaseParserRuleContext<'input,QualifiedColTypeWithPositionListContextExt<'input>>;

#[derive(Clone)]
pub struct QualifiedColTypeWithPositionListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for QualifiedColTypeWithPositionListContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for QualifiedColTypeWithPositionListContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_qualifiedColTypeWithPositionList(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_qualifiedColTypeWithPositionList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for QualifiedColTypeWithPositionListContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_qualifiedColTypeWithPositionList(self);
	}
}

impl<'input> CustomRuleContext<'input> for QualifiedColTypeWithPositionListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_qualifiedColTypeWithPositionList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_qualifiedColTypeWithPositionList }
}
antlr_rust::tid!{QualifiedColTypeWithPositionListContextExt<'a>}

impl<'input> QualifiedColTypeWithPositionListContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QualifiedColTypeWithPositionListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QualifiedColTypeWithPositionListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait QualifiedColTypeWithPositionListContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<QualifiedColTypeWithPositionListContextExt<'input>>{

fn qualifiedColTypeWithPosition_all(&self) ->  Vec<Rc<QualifiedColTypeWithPositionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn qualifiedColTypeWithPosition(&self, i: usize) -> Option<Rc<QualifiedColTypeWithPositionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> QualifiedColTypeWithPositionListContextAttrs<'input> for QualifiedColTypeWithPositionListContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn qualifiedColTypeWithPositionList(&mut self,)
	-> Result<Rc<QualifiedColTypeWithPositionListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QualifiedColTypeWithPositionListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 408, RULE_qualifiedColTypeWithPositionList);
        let mut _localctx: Rc<QualifiedColTypeWithPositionListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule qualifiedColTypeWithPosition*/
			recog.base.set_state(4371);
			recog.qualifiedColTypeWithPosition()?;

			recog.base.set_state(4376);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(4372);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule qualifiedColTypeWithPosition*/
				recog.base.set_state(4373);
				recog.qualifiedColTypeWithPosition()?;

				}
				}
				recog.base.set_state(4378);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- qualifiedColTypeWithPosition ----------------
pub type QualifiedColTypeWithPositionContextAll<'input> = QualifiedColTypeWithPositionContext<'input>;


pub type QualifiedColTypeWithPositionContext<'input> = BaseParserRuleContext<'input,QualifiedColTypeWithPositionContextExt<'input>>;

#[derive(Clone)]
pub struct QualifiedColTypeWithPositionContextExt<'input>{
	pub name: Option<Rc<MultipartIdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for QualifiedColTypeWithPositionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for QualifiedColTypeWithPositionContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_qualifiedColTypeWithPosition(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_qualifiedColTypeWithPosition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for QualifiedColTypeWithPositionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_qualifiedColTypeWithPosition(self);
	}
}

impl<'input> CustomRuleContext<'input> for QualifiedColTypeWithPositionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_qualifiedColTypeWithPosition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_qualifiedColTypeWithPosition }
}
antlr_rust::tid!{QualifiedColTypeWithPositionContextExt<'a>}

impl<'input> QualifiedColTypeWithPositionContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QualifiedColTypeWithPositionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QualifiedColTypeWithPositionContextExt{
				name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait QualifiedColTypeWithPositionContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<QualifiedColTypeWithPositionContextExt<'input>>{

fn dataType(&self) -> Option<Rc<DataTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn multipartIdentifier(&self) -> Option<Rc<MultipartIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn colDefinitionDescriptorWithPosition_all(&self) ->  Vec<Rc<ColDefinitionDescriptorWithPositionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn colDefinitionDescriptorWithPosition(&self, i: usize) -> Option<Rc<ColDefinitionDescriptorWithPositionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> QualifiedColTypeWithPositionContextAttrs<'input> for QualifiedColTypeWithPositionContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn qualifiedColTypeWithPosition(&mut self,)
	-> Result<Rc<QualifiedColTypeWithPositionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QualifiedColTypeWithPositionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 410, RULE_qualifiedColTypeWithPosition);
        let mut _localctx: Rc<QualifiedColTypeWithPositionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule multipartIdentifier*/
			recog.base.set_state(4379);
			let tmp = recog.multipartIdentifier()?;
			 cast_mut::<_,QualifiedColTypeWithPositionContext >(&mut _localctx).name = Some(tmp.clone());
			  

			/*InvokeRule dataType*/
			recog.base.set_state(4380);
			recog.dataType()?;

			recog.base.set_state(4384);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==BANG || _la==AFTER || _la==COMMENT || _la==DEFAULT || _la==FIRST || _la==NOT {
				{
				{
				/*InvokeRule colDefinitionDescriptorWithPosition*/
				recog.base.set_state(4381);
				recog.colDefinitionDescriptorWithPosition()?;

				}
				}
				recog.base.set_state(4386);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- colDefinitionDescriptorWithPosition ----------------
pub type ColDefinitionDescriptorWithPositionContextAll<'input> = ColDefinitionDescriptorWithPositionContext<'input>;


pub type ColDefinitionDescriptorWithPositionContext<'input> = BaseParserRuleContext<'input,ColDefinitionDescriptorWithPositionContextExt<'input>>;

#[derive(Clone)]
pub struct ColDefinitionDescriptorWithPositionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ColDefinitionDescriptorWithPositionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ColDefinitionDescriptorWithPositionContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_colDefinitionDescriptorWithPosition(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_colDefinitionDescriptorWithPosition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ColDefinitionDescriptorWithPositionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_colDefinitionDescriptorWithPosition(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColDefinitionDescriptorWithPositionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_colDefinitionDescriptorWithPosition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_colDefinitionDescriptorWithPosition }
}
antlr_rust::tid!{ColDefinitionDescriptorWithPositionContextExt<'a>}

impl<'input> ColDefinitionDescriptorWithPositionContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColDefinitionDescriptorWithPositionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColDefinitionDescriptorWithPositionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColDefinitionDescriptorWithPositionContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ColDefinitionDescriptorWithPositionContextExt<'input>>{

fn errorCapturingNot(&self) -> Option<Rc<ErrorCapturingNotContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token NULL
/// Returns `None` if there is no child corresponding to token NULL
fn NULL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NULL, 0)
}
fn defaultExpression(&self) -> Option<Rc<DefaultExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn commentSpec(&self) -> Option<Rc<CommentSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn colPosition(&self) -> Option<Rc<ColPositionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColDefinitionDescriptorWithPositionContextAttrs<'input> for ColDefinitionDescriptorWithPositionContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn colDefinitionDescriptorWithPosition(&mut self,)
	-> Result<Rc<ColDefinitionDescriptorWithPositionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColDefinitionDescriptorWithPositionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 412, RULE_colDefinitionDescriptorWithPosition);
        let mut _localctx: Rc<ColDefinitionDescriptorWithPositionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4393);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 BANG | NOT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule errorCapturingNot*/
					recog.base.set_state(4387);
					recog.errorCapturingNot()?;

					recog.base.set_state(4388);
					recog.base.match_token(NULL,&mut recog.err_handler)?;

					}
				}

			 DEFAULT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule defaultExpression*/
					recog.base.set_state(4390);
					recog.defaultExpression()?;

					}
				}

			 COMMENT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule commentSpec*/
					recog.base.set_state(4391);
					recog.commentSpec()?;

					}
				}

			 AFTER | FIRST 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule colPosition*/
					recog.base.set_state(4392);
					recog.colPosition()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- defaultExpression ----------------
pub type DefaultExpressionContextAll<'input> = DefaultExpressionContext<'input>;


pub type DefaultExpressionContext<'input> = BaseParserRuleContext<'input,DefaultExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct DefaultExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for DefaultExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DefaultExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_defaultExpression(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_defaultExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DefaultExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_defaultExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for DefaultExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_defaultExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_defaultExpression }
}
antlr_rust::tid!{DefaultExpressionContextExt<'a>}

impl<'input> DefaultExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DefaultExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DefaultExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DefaultExpressionContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<DefaultExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DEFAULT
/// Returns `None` if there is no child corresponding to token DEFAULT
fn DEFAULT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DEFAULT, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DefaultExpressionContextAttrs<'input> for DefaultExpressionContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn defaultExpression(&mut self,)
	-> Result<Rc<DefaultExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DefaultExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 414, RULE_defaultExpression);
        let mut _localctx: Rc<DefaultExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4395);
			recog.base.match_token(DEFAULT,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(4396);
			recog.expression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- variableDefaultExpression ----------------
pub type VariableDefaultExpressionContextAll<'input> = VariableDefaultExpressionContext<'input>;


pub type VariableDefaultExpressionContext<'input> = BaseParserRuleContext<'input,VariableDefaultExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct VariableDefaultExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for VariableDefaultExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for VariableDefaultExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_variableDefaultExpression(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_variableDefaultExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for VariableDefaultExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_variableDefaultExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for VariableDefaultExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_variableDefaultExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_variableDefaultExpression }
}
antlr_rust::tid!{VariableDefaultExpressionContextExt<'a>}

impl<'input> VariableDefaultExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<VariableDefaultExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,VariableDefaultExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait VariableDefaultExpressionContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<VariableDefaultExpressionContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token DEFAULT
/// Returns `None` if there is no child corresponding to token DEFAULT
fn DEFAULT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DEFAULT, 0)
}
/// Retrieves first TerminalNode corresponding to token EQ
/// Returns `None` if there is no child corresponding to token EQ
fn EQ(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EQ, 0)
}

}

impl<'input> VariableDefaultExpressionContextAttrs<'input> for VariableDefaultExpressionContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn variableDefaultExpression(&mut self,)
	-> Result<Rc<VariableDefaultExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = VariableDefaultExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 416, RULE_variableDefaultExpression);
        let mut _localctx: Rc<VariableDefaultExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4398);
			_la = recog.base.input.la(1);
			if { !(_la==DEFAULT || _la==EQ) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			/*InvokeRule expression*/
			recog.base.set_state(4399);
			recog.expression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- colTypeList ----------------
pub type ColTypeListContextAll<'input> = ColTypeListContext<'input>;


pub type ColTypeListContext<'input> = BaseParserRuleContext<'input,ColTypeListContextExt<'input>>;

#[derive(Clone)]
pub struct ColTypeListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ColTypeListContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ColTypeListContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_colTypeList(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_colTypeList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ColTypeListContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_colTypeList(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColTypeListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_colTypeList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_colTypeList }
}
antlr_rust::tid!{ColTypeListContextExt<'a>}

impl<'input> ColTypeListContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColTypeListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColTypeListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColTypeListContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ColTypeListContextExt<'input>>{

fn colType_all(&self) ->  Vec<Rc<ColTypeContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn colType(&self, i: usize) -> Option<Rc<ColTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ColTypeListContextAttrs<'input> for ColTypeListContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn colTypeList(&mut self,)
	-> Result<Rc<ColTypeListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColTypeListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 418, RULE_colTypeList);
        let mut _localctx: Rc<ColTypeListContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule colType*/
			recog.base.set_state(4401);
			recog.colType()?;

			recog.base.set_state(4406);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(552,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(4402);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule colType*/
					recog.base.set_state(4403);
					recog.colType()?;

					}
					} 
				}
				recog.base.set_state(4408);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(552,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- colType ----------------
pub type ColTypeContextAll<'input> = ColTypeContext<'input>;


pub type ColTypeContext<'input> = BaseParserRuleContext<'input,ColTypeContextExt<'input>>;

#[derive(Clone)]
pub struct ColTypeContextExt<'input>{
	pub colName: Option<Rc<ErrorCapturingIdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ColTypeContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ColTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_colType(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_colType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ColTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_colType(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_colType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_colType }
}
antlr_rust::tid!{ColTypeContextExt<'a>}

impl<'input> ColTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColTypeContextExt{
				colName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ColTypeContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ColTypeContextExt<'input>>{

fn dataType(&self) -> Option<Rc<DataTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn errorCapturingIdentifier(&self) -> Option<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn errorCapturingNot(&self) -> Option<Rc<ErrorCapturingNotContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token NULL
/// Returns `None` if there is no child corresponding to token NULL
fn NULL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NULL, 0)
}
fn commentSpec(&self) -> Option<Rc<CommentSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColTypeContextAttrs<'input> for ColTypeContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn colType(&mut self,)
	-> Result<Rc<ColTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 420, RULE_colType);
        let mut _localctx: Rc<ColTypeContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule errorCapturingIdentifier*/
			recog.base.set_state(4409);
			let tmp = recog.errorCapturingIdentifier()?;
			 cast_mut::<_,ColTypeContext >(&mut _localctx).colName = Some(tmp.clone());
			  

			/*InvokeRule dataType*/
			recog.base.set_state(4410);
			recog.dataType()?;

			recog.base.set_state(4414);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(553,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule errorCapturingNot*/
					recog.base.set_state(4411);
					recog.errorCapturingNot()?;

					recog.base.set_state(4412);
					recog.base.match_token(NULL,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			recog.base.set_state(4417);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(554,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule commentSpec*/
					recog.base.set_state(4416);
					recog.commentSpec()?;

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableElementList ----------------
pub type TableElementListContextAll<'input> = TableElementListContext<'input>;


pub type TableElementListContext<'input> = BaseParserRuleContext<'input,TableElementListContextExt<'input>>;

#[derive(Clone)]
pub struct TableElementListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for TableElementListContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for TableElementListContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableElementList(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_tableElementList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for TableElementListContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_tableElementList(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableElementListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableElementList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableElementList }
}
antlr_rust::tid!{TableElementListContextExt<'a>}

impl<'input> TableElementListContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableElementListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableElementListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableElementListContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<TableElementListContextExt<'input>>{

fn tableElement_all(&self) ->  Vec<Rc<TableElementContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn tableElement(&self, i: usize) -> Option<Rc<TableElementContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> TableElementListContextAttrs<'input> for TableElementListContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableElementList(&mut self,)
	-> Result<Rc<TableElementListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableElementListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 422, RULE_tableElementList);
        let mut _localctx: Rc<TableElementListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule tableElement*/
			recog.base.set_state(4419);
			recog.tableElement()?;

			recog.base.set_state(4424);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(4420);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule tableElement*/
				recog.base.set_state(4421);
				recog.tableElement()?;

				}
				}
				recog.base.set_state(4426);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableElement ----------------
pub type TableElementContextAll<'input> = TableElementContext<'input>;


pub type TableElementContext<'input> = BaseParserRuleContext<'input,TableElementContextExt<'input>>;

#[derive(Clone)]
pub struct TableElementContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for TableElementContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for TableElementContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableElement(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_tableElement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for TableElementContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_tableElement(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableElementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableElement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableElement }
}
antlr_rust::tid!{TableElementContextExt<'a>}

impl<'input> TableElementContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableElementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableElementContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableElementContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<TableElementContextExt<'input>>{

fn tableConstraintDefinition(&self) -> Option<Rc<TableConstraintDefinitionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn colDefinition(&self) -> Option<Rc<ColDefinitionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TableElementContextAttrs<'input> for TableElementContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableElement(&mut self,)
	-> Result<Rc<TableElementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableElementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 424, RULE_tableElement);
        let mut _localctx: Rc<TableElementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4429);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(556,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule tableConstraintDefinition*/
					recog.base.set_state(4427);
					recog.tableConstraintDefinition()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule colDefinition*/
					recog.base.set_state(4428);
					recog.colDefinition()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- colDefinitionList ----------------
pub type ColDefinitionListContextAll<'input> = ColDefinitionListContext<'input>;


pub type ColDefinitionListContext<'input> = BaseParserRuleContext<'input,ColDefinitionListContextExt<'input>>;

#[derive(Clone)]
pub struct ColDefinitionListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ColDefinitionListContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ColDefinitionListContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_colDefinitionList(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_colDefinitionList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ColDefinitionListContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_colDefinitionList(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColDefinitionListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_colDefinitionList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_colDefinitionList }
}
antlr_rust::tid!{ColDefinitionListContextExt<'a>}

impl<'input> ColDefinitionListContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColDefinitionListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColDefinitionListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColDefinitionListContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ColDefinitionListContextExt<'input>>{

fn colDefinition_all(&self) ->  Vec<Rc<ColDefinitionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn colDefinition(&self, i: usize) -> Option<Rc<ColDefinitionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ColDefinitionListContextAttrs<'input> for ColDefinitionListContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn colDefinitionList(&mut self,)
	-> Result<Rc<ColDefinitionListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColDefinitionListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 426, RULE_colDefinitionList);
        let mut _localctx: Rc<ColDefinitionListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule colDefinition*/
			recog.base.set_state(4431);
			recog.colDefinition()?;

			recog.base.set_state(4436);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(4432);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule colDefinition*/
				recog.base.set_state(4433);
				recog.colDefinition()?;

				}
				}
				recog.base.set_state(4438);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- colDefinition ----------------
pub type ColDefinitionContextAll<'input> = ColDefinitionContext<'input>;


pub type ColDefinitionContext<'input> = BaseParserRuleContext<'input,ColDefinitionContextExt<'input>>;

#[derive(Clone)]
pub struct ColDefinitionContextExt<'input>{
	pub colName: Option<Rc<ErrorCapturingIdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ColDefinitionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ColDefinitionContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_colDefinition(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_colDefinition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ColDefinitionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_colDefinition(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColDefinitionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_colDefinition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_colDefinition }
}
antlr_rust::tid!{ColDefinitionContextExt<'a>}

impl<'input> ColDefinitionContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColDefinitionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColDefinitionContextExt{
				colName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ColDefinitionContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ColDefinitionContextExt<'input>>{

fn dataType(&self) -> Option<Rc<DataTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn errorCapturingIdentifier(&self) -> Option<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn colDefinitionOption_all(&self) ->  Vec<Rc<ColDefinitionOptionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn colDefinitionOption(&self, i: usize) -> Option<Rc<ColDefinitionOptionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> ColDefinitionContextAttrs<'input> for ColDefinitionContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn colDefinition(&mut self,)
	-> Result<Rc<ColDefinitionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColDefinitionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 428, RULE_colDefinition);
        let mut _localctx: Rc<ColDefinitionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule errorCapturingIdentifier*/
			recog.base.set_state(4439);
			let tmp = recog.errorCapturingIdentifier()?;
			 cast_mut::<_,ColDefinitionContext >(&mut _localctx).colName = Some(tmp.clone());
			  

			/*InvokeRule dataType*/
			recog.base.set_state(4440);
			recog.dataType()?;

			recog.base.set_state(4444);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==BANG || ((((_la - 49)) & !0x3f) == 0 && ((1usize << (_la - 49)) & ((1usize << (CHECK - 49)) | (1usize << (COMMENT - 49)) | (1usize << (CONSTRAINT - 49)))) != 0) || _la==DEFAULT || _la==GENERATED || _la==NOT || _la==PRIMARY || _la==REFERENCES || _la==UNIQUE {
				{
				{
				/*InvokeRule colDefinitionOption*/
				recog.base.set_state(4441);
				recog.colDefinitionOption()?;

				}
				}
				recog.base.set_state(4446);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- colDefinitionOption ----------------
pub type ColDefinitionOptionContextAll<'input> = ColDefinitionOptionContext<'input>;


pub type ColDefinitionOptionContext<'input> = BaseParserRuleContext<'input,ColDefinitionOptionContextExt<'input>>;

#[derive(Clone)]
pub struct ColDefinitionOptionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ColDefinitionOptionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ColDefinitionOptionContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_colDefinitionOption(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_colDefinitionOption(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ColDefinitionOptionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_colDefinitionOption(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColDefinitionOptionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_colDefinitionOption }
	//fn type_rule_index() -> usize where Self: Sized { RULE_colDefinitionOption }
}
antlr_rust::tid!{ColDefinitionOptionContextExt<'a>}

impl<'input> ColDefinitionOptionContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColDefinitionOptionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColDefinitionOptionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColDefinitionOptionContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ColDefinitionOptionContextExt<'input>>{

fn errorCapturingNot(&self) -> Option<Rc<ErrorCapturingNotContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token NULL
/// Returns `None` if there is no child corresponding to token NULL
fn NULL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NULL, 0)
}
fn defaultExpression(&self) -> Option<Rc<DefaultExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn generationExpression(&self) -> Option<Rc<GenerationExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn commentSpec(&self) -> Option<Rc<CommentSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn columnConstraintDefinition(&self) -> Option<Rc<ColumnConstraintDefinitionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColDefinitionOptionContextAttrs<'input> for ColDefinitionOptionContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn colDefinitionOption(&mut self,)
	-> Result<Rc<ColDefinitionOptionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColDefinitionOptionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 430, RULE_colDefinitionOption);
        let mut _localctx: Rc<ColDefinitionOptionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4454);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 BANG | NOT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule errorCapturingNot*/
					recog.base.set_state(4447);
					recog.errorCapturingNot()?;

					recog.base.set_state(4448);
					recog.base.match_token(NULL,&mut recog.err_handler)?;

					}
				}

			 DEFAULT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule defaultExpression*/
					recog.base.set_state(4450);
					recog.defaultExpression()?;

					}
				}

			 GENERATED 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule generationExpression*/
					recog.base.set_state(4451);
					recog.generationExpression()?;

					}
				}

			 COMMENT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule commentSpec*/
					recog.base.set_state(4452);
					recog.commentSpec()?;

					}
				}

			 CHECK | CONSTRAINT | PRIMARY | REFERENCES | UNIQUE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					/*InvokeRule columnConstraintDefinition*/
					recog.base.set_state(4453);
					recog.columnConstraintDefinition()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- generationExpression ----------------
#[derive(Debug)]
pub enum GenerationExpressionContextAll<'input>{
	GeneratedColumnContext(GeneratedColumnContext<'input>),
	IdentityColumnContext(IdentityColumnContext<'input>),
Error(GenerationExpressionContext<'input>)
}
antlr_rust::tid!{GenerationExpressionContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for GenerationExpressionContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for GenerationExpressionContextAll<'input>{}

impl<'input> Deref for GenerationExpressionContextAll<'input>{
	type Target = dyn GenerationExpressionContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use GenerationExpressionContextAll::*;
		match self{
			GeneratedColumnContext(inner) => inner,
			IdentityColumnContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for GenerationExpressionContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for GenerationExpressionContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type GenerationExpressionContext<'input> = BaseParserRuleContext<'input,GenerationExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct GenerationExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for GenerationExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for GenerationExpressionContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for GenerationExpressionContext<'input>{
}

impl<'input> CustomRuleContext<'input> for GenerationExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_generationExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_generationExpression }
}
antlr_rust::tid!{GenerationExpressionContextExt<'a>}

impl<'input> GenerationExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GenerationExpressionContextAll<'input>> {
		Rc::new(
		GenerationExpressionContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GenerationExpressionContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait GenerationExpressionContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<GenerationExpressionContextExt<'input>>{


}

impl<'input> GenerationExpressionContextAttrs<'input> for GenerationExpressionContext<'input>{}

pub type GeneratedColumnContext<'input> = BaseParserRuleContext<'input,GeneratedColumnContextExt<'input>>;

pub trait GeneratedColumnContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token GENERATED
	/// Returns `None` if there is no child corresponding to token GENERATED
	fn GENERATED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(GENERATED, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ALWAYS
	/// Returns `None` if there is no child corresponding to token ALWAYS
	fn ALWAYS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ALWAYS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
}

impl<'input> GeneratedColumnContextAttrs<'input> for GeneratedColumnContext<'input>{}

pub struct GeneratedColumnContextExt<'input>{
	base:GenerationExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{GeneratedColumnContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for GeneratedColumnContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for GeneratedColumnContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_generatedColumn(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_generatedColumn(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for GeneratedColumnContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_generatedColumn(self);
	}
}

impl<'input> CustomRuleContext<'input> for GeneratedColumnContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_generationExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_generationExpression }
}

impl<'input> Borrow<GenerationExpressionContextExt<'input>> for GeneratedColumnContext<'input>{
	fn borrow(&self) -> &GenerationExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<GenerationExpressionContextExt<'input>> for GeneratedColumnContext<'input>{
	fn borrow_mut(&mut self) -> &mut GenerationExpressionContextExt<'input> { &mut self.base }
}

impl<'input> GenerationExpressionContextAttrs<'input> for GeneratedColumnContext<'input> {}

impl<'input> GeneratedColumnContextExt<'input>{
	fn new(ctx: &dyn GenerationExpressionContextAttrs<'input>) -> Rc<GenerationExpressionContextAll<'input>>  {
		Rc::new(
			GenerationExpressionContextAll::GeneratedColumnContext(
				BaseParserRuleContext::copy_from(ctx,GeneratedColumnContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type IdentityColumnContext<'input> = BaseParserRuleContext<'input,IdentityColumnContextExt<'input>>;

pub trait IdentityColumnContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token GENERATED
	/// Returns `None` if there is no child corresponding to token GENERATED
	fn GENERATED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(GENERATED, 0)
	}
	/// Retrieves first TerminalNode corresponding to token AS
	/// Returns `None` if there is no child corresponding to token AS
	fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(AS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token IDENTITY
	/// Returns `None` if there is no child corresponding to token IDENTITY
	fn IDENTITY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IDENTITY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ALWAYS
	/// Returns `None` if there is no child corresponding to token ALWAYS
	fn ALWAYS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ALWAYS, 0)
	}
	/// Retrieves first TerminalNode corresponding to token BY
	/// Returns `None` if there is no child corresponding to token BY
	fn BY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(BY, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DEFAULT
	/// Returns `None` if there is no child corresponding to token DEFAULT
	fn DEFAULT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DEFAULT, 0)
	}
	fn identityColSpec(&self) -> Option<Rc<IdentityColSpecContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> IdentityColumnContextAttrs<'input> for IdentityColumnContext<'input>{}

pub struct IdentityColumnContextExt<'input>{
	base:GenerationExpressionContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{IdentityColumnContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for IdentityColumnContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for IdentityColumnContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_identityColumn(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_identityColumn(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for IdentityColumnContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_identityColumn(self);
	}
}

impl<'input> CustomRuleContext<'input> for IdentityColumnContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_generationExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_generationExpression }
}

impl<'input> Borrow<GenerationExpressionContextExt<'input>> for IdentityColumnContext<'input>{
	fn borrow(&self) -> &GenerationExpressionContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<GenerationExpressionContextExt<'input>> for IdentityColumnContext<'input>{
	fn borrow_mut(&mut self) -> &mut GenerationExpressionContextExt<'input> { &mut self.base }
}

impl<'input> GenerationExpressionContextAttrs<'input> for IdentityColumnContext<'input> {}

impl<'input> IdentityColumnContextExt<'input>{
	fn new(ctx: &dyn GenerationExpressionContextAttrs<'input>) -> Rc<GenerationExpressionContextAll<'input>>  {
		Rc::new(
			GenerationExpressionContextAll::IdentityColumnContext(
				BaseParserRuleContext::copy_from(ctx,IdentityColumnContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn generationExpression(&mut self,)
	-> Result<Rc<GenerationExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GenerationExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 432, RULE_generationExpression);
        let mut _localctx: Rc<GenerationExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4474);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(562,&mut recog.base)? {
				1 =>{
					let tmp = GeneratedColumnContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(4456);
					recog.base.match_token(GENERATED,&mut recog.err_handler)?;

					recog.base.set_state(4457);
					recog.base.match_token(ALWAYS,&mut recog.err_handler)?;

					recog.base.set_state(4458);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					recog.base.set_state(4459);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(4460);
					recog.expression()?;

					recog.base.set_state(4461);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = IdentityColumnContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(4463);
					recog.base.match_token(GENERATED,&mut recog.err_handler)?;

					recog.base.set_state(4467);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 ALWAYS 
						=> {
							{
							recog.base.set_state(4464);
							recog.base.match_token(ALWAYS,&mut recog.err_handler)?;

							}
						}

					 BY 
						=> {
							{
							recog.base.set_state(4465);
							recog.base.match_token(BY,&mut recog.err_handler)?;

							recog.base.set_state(4466);
							recog.base.match_token(DEFAULT,&mut recog.err_handler)?;

							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					recog.base.set_state(4469);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					recog.base.set_state(4470);
					recog.base.match_token(IDENTITY,&mut recog.err_handler)?;

					recog.base.set_state(4472);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==LEFT_PAREN {
						{
						/*InvokeRule identityColSpec*/
						recog.base.set_state(4471);
						recog.identityColSpec()?;

						}
					}

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- identityColSpec ----------------
pub type IdentityColSpecContextAll<'input> = IdentityColSpecContext<'input>;


pub type IdentityColSpecContext<'input> = BaseParserRuleContext<'input,IdentityColSpecContextExt<'input>>;

#[derive(Clone)]
pub struct IdentityColSpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for IdentityColSpecContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for IdentityColSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_identityColSpec(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_identityColSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for IdentityColSpecContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_identityColSpec(self);
	}
}

impl<'input> CustomRuleContext<'input> for IdentityColSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identityColSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identityColSpec }
}
antlr_rust::tid!{IdentityColSpecContextExt<'a>}

impl<'input> IdentityColSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IdentityColSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IdentityColSpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait IdentityColSpecContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<IdentityColSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
fn sequenceGeneratorOption_all(&self) ->  Vec<Rc<SequenceGeneratorOptionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn sequenceGeneratorOption(&self, i: usize) -> Option<Rc<SequenceGeneratorOptionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> IdentityColSpecContextAttrs<'input> for IdentityColSpecContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn identityColSpec(&mut self,)
	-> Result<Rc<IdentityColSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IdentityColSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 434, RULE_identityColSpec);
        let mut _localctx: Rc<IdentityColSpecContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4476);
			recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

			recog.base.set_state(4480);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==INCREMENT || _la==START {
				{
				{
				/*InvokeRule sequenceGeneratorOption*/
				recog.base.set_state(4477);
				recog.sequenceGeneratorOption()?;

				}
				}
				recog.base.set_state(4482);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(4483);
			recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- sequenceGeneratorOption ----------------
pub type SequenceGeneratorOptionContextAll<'input> = SequenceGeneratorOptionContext<'input>;


pub type SequenceGeneratorOptionContext<'input> = BaseParserRuleContext<'input,SequenceGeneratorOptionContextExt<'input>>;

#[derive(Clone)]
pub struct SequenceGeneratorOptionContextExt<'input>{
	pub start: Option<Rc<SequenceGeneratorStartOrStepContextAll<'input>>>,
	pub step: Option<Rc<SequenceGeneratorStartOrStepContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SequenceGeneratorOptionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SequenceGeneratorOptionContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_sequenceGeneratorOption(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_sequenceGeneratorOption(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SequenceGeneratorOptionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_sequenceGeneratorOption(self);
	}
}

impl<'input> CustomRuleContext<'input> for SequenceGeneratorOptionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sequenceGeneratorOption }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sequenceGeneratorOption }
}
antlr_rust::tid!{SequenceGeneratorOptionContextExt<'a>}

impl<'input> SequenceGeneratorOptionContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SequenceGeneratorOptionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SequenceGeneratorOptionContextExt{
				start: None, step: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SequenceGeneratorOptionContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SequenceGeneratorOptionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token START
/// Returns `None` if there is no child corresponding to token START
fn START(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(START, 0)
}
/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
fn sequenceGeneratorStartOrStep(&self) -> Option<Rc<SequenceGeneratorStartOrStepContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token INCREMENT
/// Returns `None` if there is no child corresponding to token INCREMENT
fn INCREMENT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INCREMENT, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}

}

impl<'input> SequenceGeneratorOptionContextAttrs<'input> for SequenceGeneratorOptionContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn sequenceGeneratorOption(&mut self,)
	-> Result<Rc<SequenceGeneratorOptionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SequenceGeneratorOptionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 436, RULE_sequenceGeneratorOption);
        let mut _localctx: Rc<SequenceGeneratorOptionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4491);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 START 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4485);
					recog.base.match_token(START,&mut recog.err_handler)?;

					recog.base.set_state(4486);
					recog.base.match_token(WITH,&mut recog.err_handler)?;

					/*InvokeRule sequenceGeneratorStartOrStep*/
					recog.base.set_state(4487);
					let tmp = recog.sequenceGeneratorStartOrStep()?;
					 cast_mut::<_,SequenceGeneratorOptionContext >(&mut _localctx).start = Some(tmp.clone());
					  

					}
				}

			 INCREMENT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4488);
					recog.base.match_token(INCREMENT,&mut recog.err_handler)?;

					recog.base.set_state(4489);
					recog.base.match_token(BY,&mut recog.err_handler)?;

					/*InvokeRule sequenceGeneratorStartOrStep*/
					recog.base.set_state(4490);
					let tmp = recog.sequenceGeneratorStartOrStep()?;
					 cast_mut::<_,SequenceGeneratorOptionContext >(&mut _localctx).step = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- sequenceGeneratorStartOrStep ----------------
pub type SequenceGeneratorStartOrStepContextAll<'input> = SequenceGeneratorStartOrStepContext<'input>;


pub type SequenceGeneratorStartOrStepContext<'input> = BaseParserRuleContext<'input,SequenceGeneratorStartOrStepContextExt<'input>>;

#[derive(Clone)]
pub struct SequenceGeneratorStartOrStepContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SequenceGeneratorStartOrStepContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SequenceGeneratorStartOrStepContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_sequenceGeneratorStartOrStep(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_sequenceGeneratorStartOrStep(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SequenceGeneratorStartOrStepContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_sequenceGeneratorStartOrStep(self);
	}
}

impl<'input> CustomRuleContext<'input> for SequenceGeneratorStartOrStepContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sequenceGeneratorStartOrStep }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sequenceGeneratorStartOrStep }
}
antlr_rust::tid!{SequenceGeneratorStartOrStepContextExt<'a>}

impl<'input> SequenceGeneratorStartOrStepContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SequenceGeneratorStartOrStepContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SequenceGeneratorStartOrStepContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SequenceGeneratorStartOrStepContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SequenceGeneratorStartOrStepContextExt<'input>>{

fn integerValue(&self) -> Option<Rc<IntegerValueContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token MINUS
/// Returns `None` if there is no child corresponding to token MINUS
fn MINUS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MINUS, 0)
}
/// Retrieves first TerminalNode corresponding to token BIGINT_LITERAL
/// Returns `None` if there is no child corresponding to token BIGINT_LITERAL
fn BIGINT_LITERAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BIGINT_LITERAL, 0)
}

}

impl<'input> SequenceGeneratorStartOrStepContextAttrs<'input> for SequenceGeneratorStartOrStepContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn sequenceGeneratorStartOrStep(&mut self,)
	-> Result<Rc<SequenceGeneratorStartOrStepContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SequenceGeneratorStartOrStepContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 438, RULE_sequenceGeneratorStartOrStep);
        let mut _localctx: Rc<SequenceGeneratorStartOrStepContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4501);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(567,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4494);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(565,&mut recog.base)? {
						x if x == 1=>{
							{
							recog.base.set_state(4493);
							recog.base.match_token(MINUS,&mut recog.err_handler)?;

							}
						}

						_ => {}
					}
					/*InvokeRule integerValue*/
					recog.base.set_state(4496);
					recog.integerValue()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4498);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MINUS {
						{
						recog.base.set_state(4497);
						recog.base.match_token(MINUS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(4500);
					recog.base.match_token(BIGINT_LITERAL,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- complexColTypeList ----------------
pub type ComplexColTypeListContextAll<'input> = ComplexColTypeListContext<'input>;


pub type ComplexColTypeListContext<'input> = BaseParserRuleContext<'input,ComplexColTypeListContextExt<'input>>;

#[derive(Clone)]
pub struct ComplexColTypeListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ComplexColTypeListContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ComplexColTypeListContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_complexColTypeList(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_complexColTypeList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ComplexColTypeListContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_complexColTypeList(self);
	}
}

impl<'input> CustomRuleContext<'input> for ComplexColTypeListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_complexColTypeList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_complexColTypeList }
}
antlr_rust::tid!{ComplexColTypeListContextExt<'a>}

impl<'input> ComplexColTypeListContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ComplexColTypeListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ComplexColTypeListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ComplexColTypeListContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ComplexColTypeListContextExt<'input>>{

fn complexColType_all(&self) ->  Vec<Rc<ComplexColTypeContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn complexColType(&self, i: usize) -> Option<Rc<ComplexColTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ComplexColTypeListContextAttrs<'input> for ComplexColTypeListContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn complexColTypeList(&mut self,)
	-> Result<Rc<ComplexColTypeListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ComplexColTypeListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 440, RULE_complexColTypeList);
        let mut _localctx: Rc<ComplexColTypeListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule complexColType*/
			recog.base.set_state(4503);
			recog.complexColType()?;

			recog.base.set_state(4508);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(4504);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule complexColType*/
				recog.base.set_state(4505);
				recog.complexColType()?;

				}
				}
				recog.base.set_state(4510);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- complexColType ----------------
pub type ComplexColTypeContextAll<'input> = ComplexColTypeContext<'input>;


pub type ComplexColTypeContext<'input> = BaseParserRuleContext<'input,ComplexColTypeContextExt<'input>>;

#[derive(Clone)]
pub struct ComplexColTypeContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ComplexColTypeContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ComplexColTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_complexColType(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_complexColType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ComplexColTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_complexColType(self);
	}
}

impl<'input> CustomRuleContext<'input> for ComplexColTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_complexColType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_complexColType }
}
antlr_rust::tid!{ComplexColTypeContextExt<'a>}

impl<'input> ComplexColTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ComplexColTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ComplexColTypeContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ComplexColTypeContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ComplexColTypeContextExt<'input>>{

fn errorCapturingIdentifier(&self) -> Option<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dataType(&self) -> Option<Rc<DataTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token COLON
/// Returns `None` if there is no child corresponding to token COLON
fn COLON(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COLON, 0)
}
fn errorCapturingNot(&self) -> Option<Rc<ErrorCapturingNotContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token NULL
/// Returns `None` if there is no child corresponding to token NULL
fn NULL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NULL, 0)
}
fn commentSpec(&self) -> Option<Rc<CommentSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ComplexColTypeContextAttrs<'input> for ComplexColTypeContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn complexColType(&mut self,)
	-> Result<Rc<ComplexColTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ComplexColTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 442, RULE_complexColType);
        let mut _localctx: Rc<ComplexColTypeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule errorCapturingIdentifier*/
			recog.base.set_state(4511);
			recog.errorCapturingIdentifier()?;

			recog.base.set_state(4513);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(569,&mut recog.base)? {
				x if x == 1=>{
					{
					recog.base.set_state(4512);
					recog.base.match_token(COLON,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			/*InvokeRule dataType*/
			recog.base.set_state(4515);
			recog.dataType()?;

			recog.base.set_state(4519);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==BANG || _la==NOT {
				{
				/*InvokeRule errorCapturingNot*/
				recog.base.set_state(4516);
				recog.errorCapturingNot()?;

				recog.base.set_state(4517);
				recog.base.match_token(NULL,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(4522);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMENT {
				{
				/*InvokeRule commentSpec*/
				recog.base.set_state(4521);
				recog.commentSpec()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- codeLiteral ----------------
pub type CodeLiteralContextAll<'input> = CodeLiteralContext<'input>;


pub type CodeLiteralContext<'input> = BaseParserRuleContext<'input,CodeLiteralContextExt<'input>>;

#[derive(Clone)]
pub struct CodeLiteralContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for CodeLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CodeLiteralContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_codeLiteral(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_codeLiteral(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CodeLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_codeLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for CodeLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_codeLiteral }
	//fn type_rule_index() -> usize where Self: Sized { RULE_codeLiteral }
}
antlr_rust::tid!{CodeLiteralContextExt<'a>}

impl<'input> CodeLiteralContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CodeLiteralContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CodeLiteralContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait CodeLiteralContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<CodeLiteralContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token BEGIN_DOLLAR_QUOTED_STRING
/// Returns `None` if there is no child corresponding to token BEGIN_DOLLAR_QUOTED_STRING
fn BEGIN_DOLLAR_QUOTED_STRING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BEGIN_DOLLAR_QUOTED_STRING, 0)
}
/// Retrieves first TerminalNode corresponding to token END_DOLLAR_QUOTED_STRING
/// Returns `None` if there is no child corresponding to token END_DOLLAR_QUOTED_STRING
fn END_DOLLAR_QUOTED_STRING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(END_DOLLAR_QUOTED_STRING, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token DOLLAR_QUOTED_STRING_BODY in current rule
fn DOLLAR_QUOTED_STRING_BODY_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token DOLLAR_QUOTED_STRING_BODY, starting from 0.
/// Returns `None` if number of children corresponding to token DOLLAR_QUOTED_STRING_BODY is less or equal than `i`.
fn DOLLAR_QUOTED_STRING_BODY(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DOLLAR_QUOTED_STRING_BODY, i)
}

}

impl<'input> CodeLiteralContextAttrs<'input> for CodeLiteralContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn codeLiteral(&mut self,)
	-> Result<Rc<CodeLiteralContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CodeLiteralContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 444, RULE_codeLiteral);
        let mut _localctx: Rc<CodeLiteralContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4524);
			recog.base.match_token(BEGIN_DOLLAR_QUOTED_STRING,&mut recog.err_handler)?;

			recog.base.set_state(4526); 
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			loop {
				{
				{
				recog.base.set_state(4525);
				recog.base.match_token(DOLLAR_QUOTED_STRING_BODY,&mut recog.err_handler)?;

				}
				}
				recog.base.set_state(4528); 
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if !(_la==DOLLAR_QUOTED_STRING_BODY) {break}
			}
			recog.base.set_state(4530);
			recog.base.match_token(END_DOLLAR_QUOTED_STRING,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- routineCharacteristics ----------------
pub type RoutineCharacteristicsContextAll<'input> = RoutineCharacteristicsContext<'input>;


pub type RoutineCharacteristicsContext<'input> = BaseParserRuleContext<'input,RoutineCharacteristicsContextExt<'input>>;

#[derive(Clone)]
pub struct RoutineCharacteristicsContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for RoutineCharacteristicsContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for RoutineCharacteristicsContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_routineCharacteristics(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_routineCharacteristics(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for RoutineCharacteristicsContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_routineCharacteristics(self);
	}
}

impl<'input> CustomRuleContext<'input> for RoutineCharacteristicsContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_routineCharacteristics }
	//fn type_rule_index() -> usize where Self: Sized { RULE_routineCharacteristics }
}
antlr_rust::tid!{RoutineCharacteristicsContextExt<'a>}

impl<'input> RoutineCharacteristicsContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RoutineCharacteristicsContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RoutineCharacteristicsContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RoutineCharacteristicsContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<RoutineCharacteristicsContextExt<'input>>{

fn routineLanguage_all(&self) ->  Vec<Rc<RoutineLanguageContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn routineLanguage(&self, i: usize) -> Option<Rc<RoutineLanguageContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn specificName_all(&self) ->  Vec<Rc<SpecificNameContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn specificName(&self, i: usize) -> Option<Rc<SpecificNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn deterministic_all(&self) ->  Vec<Rc<DeterministicContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn deterministic(&self, i: usize) -> Option<Rc<DeterministicContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn sqlDataAccess_all(&self) ->  Vec<Rc<SqlDataAccessContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn sqlDataAccess(&self, i: usize) -> Option<Rc<SqlDataAccessContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn nullCall_all(&self) ->  Vec<Rc<NullCallContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn nullCall(&self, i: usize) -> Option<Rc<NullCallContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn commentSpec_all(&self) ->  Vec<Rc<CommentSpecContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn commentSpec(&self, i: usize) -> Option<Rc<CommentSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn rightsClause_all(&self) ->  Vec<Rc<RightsClauseContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn rightsClause(&self, i: usize) -> Option<Rc<RightsClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> RoutineCharacteristicsContextAttrs<'input> for RoutineCharacteristicsContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn routineCharacteristics(&mut self,)
	-> Result<Rc<RoutineCharacteristicsContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RoutineCharacteristicsContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 446, RULE_routineCharacteristics);
        let mut _localctx: Rc<RoutineCharacteristicsContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4541);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==BANG || ((((_la - 40)) & !0x3f) == 0 && ((1usize << (_la - 40)) & ((1usize << (CALLED - 40)) | (1usize << (COMMENT - 40)) | (1usize << (CONTAINS - 40)))) != 0) || _la==DETERMINISTIC || _la==LANGUAGE || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (MODIFIES - 224)) | (1usize << (NO - 224)) | (1usize << (NOT - 224)))) != 0) || _la==READS || _la==RETURNS || _la==SPECIFIC || _la==SQL {
				{
				recog.base.set_state(4539);
				recog.err_handler.sync(&mut recog.base)?;
				match recog.base.input.la(1) {
				 LANGUAGE 
					=> {
						{
						/*InvokeRule routineLanguage*/
						recog.base.set_state(4532);
						recog.routineLanguage()?;

						}
					}

				 SPECIFIC 
					=> {
						{
						/*InvokeRule specificName*/
						recog.base.set_state(4533);
						recog.specificName()?;

						}
					}

				 BANG | DETERMINISTIC | NOT 
					=> {
						{
						/*InvokeRule deterministic*/
						recog.base.set_state(4534);
						recog.deterministic()?;

						}
					}

				 CONTAINS | MODIFIES | NO | READS 
					=> {
						{
						/*InvokeRule sqlDataAccess*/
						recog.base.set_state(4535);
						recog.sqlDataAccess()?;

						}
					}

				 CALLED | RETURNS 
					=> {
						{
						/*InvokeRule nullCall*/
						recog.base.set_state(4536);
						recog.nullCall()?;

						}
					}

				 COMMENT 
					=> {
						{
						/*InvokeRule commentSpec*/
						recog.base.set_state(4537);
						recog.commentSpec()?;

						}
					}

				 SQL 
					=> {
						{
						/*InvokeRule rightsClause*/
						recog.base.set_state(4538);
						recog.rightsClause()?;

						}
					}

					_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
				}
				}
				recog.base.set_state(4543);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- routineLanguage ----------------
pub type RoutineLanguageContextAll<'input> = RoutineLanguageContext<'input>;


pub type RoutineLanguageContext<'input> = BaseParserRuleContext<'input,RoutineLanguageContextExt<'input>>;

#[derive(Clone)]
pub struct RoutineLanguageContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for RoutineLanguageContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for RoutineLanguageContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_routineLanguage(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_routineLanguage(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for RoutineLanguageContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_routineLanguage(self);
	}
}

impl<'input> CustomRuleContext<'input> for RoutineLanguageContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_routineLanguage }
	//fn type_rule_index() -> usize where Self: Sized { RULE_routineLanguage }
}
antlr_rust::tid!{RoutineLanguageContextExt<'a>}

impl<'input> RoutineLanguageContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RoutineLanguageContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RoutineLanguageContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RoutineLanguageContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<RoutineLanguageContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LANGUAGE
/// Returns `None` if there is no child corresponding to token LANGUAGE
fn LANGUAGE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LANGUAGE, 0)
}
/// Retrieves first TerminalNode corresponding to token SQL
/// Returns `None` if there is no child corresponding to token SQL
fn SQL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SQL, 0)
}
/// Retrieves first TerminalNode corresponding to token IDENTIFIER
/// Returns `None` if there is no child corresponding to token IDENTIFIER
fn IDENTIFIER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IDENTIFIER, 0)
}

}

impl<'input> RoutineLanguageContextAttrs<'input> for RoutineLanguageContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn routineLanguage(&mut self,)
	-> Result<Rc<RoutineLanguageContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RoutineLanguageContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 448, RULE_routineLanguage);
        let mut _localctx: Rc<RoutineLanguageContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4544);
			recog.base.match_token(LANGUAGE,&mut recog.err_handler)?;

			recog.base.set_state(4545);
			_la = recog.base.input.la(1);
			if { !(_la==SQL || _la==IDENTIFIER) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- specificName ----------------
pub type SpecificNameContextAll<'input> = SpecificNameContext<'input>;


pub type SpecificNameContext<'input> = BaseParserRuleContext<'input,SpecificNameContextExt<'input>>;

#[derive(Clone)]
pub struct SpecificNameContextExt<'input>{
	pub specific: Option<Rc<ErrorCapturingIdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SpecificNameContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SpecificNameContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_specificName(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_specificName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SpecificNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_specificName(self);
	}
}

impl<'input> CustomRuleContext<'input> for SpecificNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_specificName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_specificName }
}
antlr_rust::tid!{SpecificNameContextExt<'a>}

impl<'input> SpecificNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SpecificNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SpecificNameContextExt{
				specific: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SpecificNameContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SpecificNameContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token SPECIFIC
/// Returns `None` if there is no child corresponding to token SPECIFIC
fn SPECIFIC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SPECIFIC, 0)
}
fn errorCapturingIdentifier(&self) -> Option<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SpecificNameContextAttrs<'input> for SpecificNameContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn specificName(&mut self,)
	-> Result<Rc<SpecificNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SpecificNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 450, RULE_specificName);
        let mut _localctx: Rc<SpecificNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4547);
			recog.base.match_token(SPECIFIC,&mut recog.err_handler)?;

			/*InvokeRule errorCapturingIdentifier*/
			recog.base.set_state(4548);
			let tmp = recog.errorCapturingIdentifier()?;
			 cast_mut::<_,SpecificNameContext >(&mut _localctx).specific = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- deterministic ----------------
pub type DeterministicContextAll<'input> = DeterministicContext<'input>;


pub type DeterministicContext<'input> = BaseParserRuleContext<'input,DeterministicContextExt<'input>>;

#[derive(Clone)]
pub struct DeterministicContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for DeterministicContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DeterministicContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_deterministic(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_deterministic(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DeterministicContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_deterministic(self);
	}
}

impl<'input> CustomRuleContext<'input> for DeterministicContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_deterministic }
	//fn type_rule_index() -> usize where Self: Sized { RULE_deterministic }
}
antlr_rust::tid!{DeterministicContextExt<'a>}

impl<'input> DeterministicContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DeterministicContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DeterministicContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DeterministicContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<DeterministicContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DETERMINISTIC
/// Returns `None` if there is no child corresponding to token DETERMINISTIC
fn DETERMINISTIC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DETERMINISTIC, 0)
}
fn errorCapturingNot(&self) -> Option<Rc<ErrorCapturingNotContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DeterministicContextAttrs<'input> for DeterministicContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn deterministic(&mut self,)
	-> Result<Rc<DeterministicContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DeterministicContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 452, RULE_deterministic);
        let mut _localctx: Rc<DeterministicContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4554);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 DETERMINISTIC 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4550);
					recog.base.match_token(DETERMINISTIC,&mut recog.err_handler)?;

					}
				}

			 BANG | NOT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule errorCapturingNot*/
					recog.base.set_state(4551);
					recog.errorCapturingNot()?;

					recog.base.set_state(4552);
					recog.base.match_token(DETERMINISTIC,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- sqlDataAccess ----------------
pub type SqlDataAccessContextAll<'input> = SqlDataAccessContext<'input>;


pub type SqlDataAccessContext<'input> = BaseParserRuleContext<'input,SqlDataAccessContextExt<'input>>;

#[derive(Clone)]
pub struct SqlDataAccessContextExt<'input>{
	pub access: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SqlDataAccessContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SqlDataAccessContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_sqlDataAccess(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_sqlDataAccess(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SqlDataAccessContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_sqlDataAccess(self);
	}
}

impl<'input> CustomRuleContext<'input> for SqlDataAccessContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sqlDataAccess }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sqlDataAccess }
}
antlr_rust::tid!{SqlDataAccessContextExt<'a>}

impl<'input> SqlDataAccessContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SqlDataAccessContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SqlDataAccessContextExt{
				access: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SqlDataAccessContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SqlDataAccessContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token SQL
/// Returns `None` if there is no child corresponding to token SQL
fn SQL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SQL, 0)
}
/// Retrieves first TerminalNode corresponding to token NO
/// Returns `None` if there is no child corresponding to token NO
fn NO(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NO, 0)
}
/// Retrieves first TerminalNode corresponding to token CONTAINS
/// Returns `None` if there is no child corresponding to token CONTAINS
fn CONTAINS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CONTAINS, 0)
}
/// Retrieves first TerminalNode corresponding to token DATA
/// Returns `None` if there is no child corresponding to token DATA
fn DATA(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DATA, 0)
}
/// Retrieves first TerminalNode corresponding to token READS
/// Returns `None` if there is no child corresponding to token READS
fn READS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(READS, 0)
}
/// Retrieves first TerminalNode corresponding to token MODIFIES
/// Returns `None` if there is no child corresponding to token MODIFIES
fn MODIFIES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MODIFIES, 0)
}

}

impl<'input> SqlDataAccessContextAttrs<'input> for SqlDataAccessContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn sqlDataAccess(&mut self,)
	-> Result<Rc<SqlDataAccessContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SqlDataAccessContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 454, RULE_sqlDataAccess);
        let mut _localctx: Rc<SqlDataAccessContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4566);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 NO 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4556);
					let tmp = recog.base.match_token(NO,&mut recog.err_handler)?;
					 cast_mut::<_,SqlDataAccessContext >(&mut _localctx).access = Some(tmp.clone());
					  

					recog.base.set_state(4557);
					recog.base.match_token(SQL,&mut recog.err_handler)?;

					}
				}

			 CONTAINS 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4558);
					let tmp = recog.base.match_token(CONTAINS,&mut recog.err_handler)?;
					 cast_mut::<_,SqlDataAccessContext >(&mut _localctx).access = Some(tmp.clone());
					  

					recog.base.set_state(4559);
					recog.base.match_token(SQL,&mut recog.err_handler)?;

					}
				}

			 READS 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(4560);
					let tmp = recog.base.match_token(READS,&mut recog.err_handler)?;
					 cast_mut::<_,SqlDataAccessContext >(&mut _localctx).access = Some(tmp.clone());
					  

					recog.base.set_state(4561);
					recog.base.match_token(SQL,&mut recog.err_handler)?;

					recog.base.set_state(4562);
					recog.base.match_token(DATA,&mut recog.err_handler)?;

					}
				}

			 MODIFIES 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(4563);
					let tmp = recog.base.match_token(MODIFIES,&mut recog.err_handler)?;
					 cast_mut::<_,SqlDataAccessContext >(&mut _localctx).access = Some(tmp.clone());
					  

					recog.base.set_state(4564);
					recog.base.match_token(SQL,&mut recog.err_handler)?;

					recog.base.set_state(4565);
					recog.base.match_token(DATA,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- nullCall ----------------
pub type NullCallContextAll<'input> = NullCallContext<'input>;


pub type NullCallContext<'input> = BaseParserRuleContext<'input,NullCallContextExt<'input>>;

#[derive(Clone)]
pub struct NullCallContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for NullCallContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for NullCallContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_nullCall(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_nullCall(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for NullCallContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_nullCall(self);
	}
}

impl<'input> CustomRuleContext<'input> for NullCallContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nullCall }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nullCall }
}
antlr_rust::tid!{NullCallContextExt<'a>}

impl<'input> NullCallContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NullCallContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NullCallContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait NullCallContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<NullCallContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token RETURNS
/// Returns `None` if there is no child corresponding to token RETURNS
fn RETURNS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RETURNS, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token NULL in current rule
fn NULL_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token NULL, starting from 0.
/// Returns `None` if number of children corresponding to token NULL is less or equal than `i`.
fn NULL(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NULL, i)
}
/// Retrieves first TerminalNode corresponding to token ON
/// Returns `None` if there is no child corresponding to token ON
fn ON(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ON, 0)
}
/// Retrieves first TerminalNode corresponding to token INPUT
/// Returns `None` if there is no child corresponding to token INPUT
fn INPUT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INPUT, 0)
}
/// Retrieves first TerminalNode corresponding to token CALLED
/// Returns `None` if there is no child corresponding to token CALLED
fn CALLED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CALLED, 0)
}

}

impl<'input> NullCallContextAttrs<'input> for NullCallContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn nullCall(&mut self,)
	-> Result<Rc<NullCallContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NullCallContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 456, RULE_nullCall);
        let mut _localctx: Rc<NullCallContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4577);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 RETURNS 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4568);
					recog.base.match_token(RETURNS,&mut recog.err_handler)?;

					recog.base.set_state(4569);
					recog.base.match_token(NULL,&mut recog.err_handler)?;

					recog.base.set_state(4570);
					recog.base.match_token(ON,&mut recog.err_handler)?;

					recog.base.set_state(4571);
					recog.base.match_token(NULL,&mut recog.err_handler)?;

					recog.base.set_state(4572);
					recog.base.match_token(INPUT,&mut recog.err_handler)?;

					}
				}

			 CALLED 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4573);
					recog.base.match_token(CALLED,&mut recog.err_handler)?;

					recog.base.set_state(4574);
					recog.base.match_token(ON,&mut recog.err_handler)?;

					recog.base.set_state(4575);
					recog.base.match_token(NULL,&mut recog.err_handler)?;

					recog.base.set_state(4576);
					recog.base.match_token(INPUT,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rightsClause ----------------
pub type RightsClauseContextAll<'input> = RightsClauseContext<'input>;


pub type RightsClauseContext<'input> = BaseParserRuleContext<'input,RightsClauseContextExt<'input>>;

#[derive(Clone)]
pub struct RightsClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for RightsClauseContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for RightsClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_rightsClause(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_rightsClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for RightsClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_rightsClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for RightsClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rightsClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rightsClause }
}
antlr_rust::tid!{RightsClauseContextExt<'a>}

impl<'input> RightsClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RightsClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RightsClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RightsClauseContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<RightsClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token SQL
/// Returns `None` if there is no child corresponding to token SQL
fn SQL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SQL, 0)
}
/// Retrieves first TerminalNode corresponding to token SECURITY
/// Returns `None` if there is no child corresponding to token SECURITY
fn SECURITY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SECURITY, 0)
}
/// Retrieves first TerminalNode corresponding to token INVOKER
/// Returns `None` if there is no child corresponding to token INVOKER
fn INVOKER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INVOKER, 0)
}
/// Retrieves first TerminalNode corresponding to token DEFINER
/// Returns `None` if there is no child corresponding to token DEFINER
fn DEFINER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DEFINER, 0)
}

}

impl<'input> RightsClauseContextAttrs<'input> for RightsClauseContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rightsClause(&mut self,)
	-> Result<Rc<RightsClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RightsClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 458, RULE_rightsClause);
        let mut _localctx: Rc<RightsClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4585);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(578,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4579);
					recog.base.match_token(SQL,&mut recog.err_handler)?;

					recog.base.set_state(4580);
					recog.base.match_token(SECURITY,&mut recog.err_handler)?;

					recog.base.set_state(4581);
					recog.base.match_token(INVOKER,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4582);
					recog.base.match_token(SQL,&mut recog.err_handler)?;

					recog.base.set_state(4583);
					recog.base.match_token(SECURITY,&mut recog.err_handler)?;

					recog.base.set_state(4584);
					recog.base.match_token(DEFINER,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- whenClause ----------------
pub type WhenClauseContextAll<'input> = WhenClauseContext<'input>;


pub type WhenClauseContext<'input> = BaseParserRuleContext<'input,WhenClauseContextExt<'input>>;

#[derive(Clone)]
pub struct WhenClauseContextExt<'input>{
	pub condition: Option<Rc<ExpressionContextAll<'input>>>,
	pub result: Option<Rc<ExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for WhenClauseContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for WhenClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_whenClause(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_whenClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for WhenClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_whenClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for WhenClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_whenClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_whenClause }
}
antlr_rust::tid!{WhenClauseContextExt<'a>}

impl<'input> WhenClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WhenClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WhenClauseContextExt{
				condition: None, result: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait WhenClauseContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<WhenClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WHEN
/// Returns `None` if there is no child corresponding to token WHEN
fn WHEN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WHEN, 0)
}
/// Retrieves first TerminalNode corresponding to token THEN
/// Returns `None` if there is no child corresponding to token THEN
fn THEN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(THEN, 0)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> WhenClauseContextAttrs<'input> for WhenClauseContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn whenClause(&mut self,)
	-> Result<Rc<WhenClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WhenClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 460, RULE_whenClause);
        let mut _localctx: Rc<WhenClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4587);
			recog.base.match_token(WHEN,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(4588);
			let tmp = recog.expression()?;
			 cast_mut::<_,WhenClauseContext >(&mut _localctx).condition = Some(tmp.clone());
			  

			recog.base.set_state(4589);
			recog.base.match_token(THEN,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(4590);
			let tmp = recog.expression()?;
			 cast_mut::<_,WhenClauseContext >(&mut _localctx).result = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- windowClause ----------------
pub type WindowClauseContextAll<'input> = WindowClauseContext<'input>;


pub type WindowClauseContext<'input> = BaseParserRuleContext<'input,WindowClauseContextExt<'input>>;

#[derive(Clone)]
pub struct WindowClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for WindowClauseContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for WindowClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_windowClause(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_windowClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for WindowClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_windowClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for WindowClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_windowClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_windowClause }
}
antlr_rust::tid!{WindowClauseContextExt<'a>}

impl<'input> WindowClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WindowClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WindowClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait WindowClauseContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<WindowClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WINDOW
/// Returns `None` if there is no child corresponding to token WINDOW
fn WINDOW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WINDOW, 0)
}
fn namedWindow_all(&self) ->  Vec<Rc<NamedWindowContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn namedWindow(&self, i: usize) -> Option<Rc<NamedWindowContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> WindowClauseContextAttrs<'input> for WindowClauseContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn windowClause(&mut self,)
	-> Result<Rc<WindowClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WindowClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 462, RULE_windowClause);
        let mut _localctx: Rc<WindowClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4592);
			recog.base.match_token(WINDOW,&mut recog.err_handler)?;

			/*InvokeRule namedWindow*/
			recog.base.set_state(4593);
			recog.namedWindow()?;

			recog.base.set_state(4598);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(579,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(4594);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule namedWindow*/
					recog.base.set_state(4595);
					recog.namedWindow()?;

					}
					} 
				}
				recog.base.set_state(4600);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(579,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- namedWindow ----------------
pub type NamedWindowContextAll<'input> = NamedWindowContext<'input>;


pub type NamedWindowContext<'input> = BaseParserRuleContext<'input,NamedWindowContextExt<'input>>;

#[derive(Clone)]
pub struct NamedWindowContextExt<'input>{
	pub name: Option<Rc<ErrorCapturingIdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for NamedWindowContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for NamedWindowContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_namedWindow(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_namedWindow(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for NamedWindowContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_namedWindow(self);
	}
}

impl<'input> CustomRuleContext<'input> for NamedWindowContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_namedWindow }
	//fn type_rule_index() -> usize where Self: Sized { RULE_namedWindow }
}
antlr_rust::tid!{NamedWindowContextExt<'a>}

impl<'input> NamedWindowContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NamedWindowContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NamedWindowContextExt{
				name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait NamedWindowContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<NamedWindowContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
fn windowSpec(&self) -> Option<Rc<WindowSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn errorCapturingIdentifier(&self) -> Option<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> NamedWindowContextAttrs<'input> for NamedWindowContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn namedWindow(&mut self,)
	-> Result<Rc<NamedWindowContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NamedWindowContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 464, RULE_namedWindow);
        let mut _localctx: Rc<NamedWindowContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule errorCapturingIdentifier*/
			recog.base.set_state(4601);
			let tmp = recog.errorCapturingIdentifier()?;
			 cast_mut::<_,NamedWindowContext >(&mut _localctx).name = Some(tmp.clone());
			  

			recog.base.set_state(4602);
			recog.base.match_token(AS,&mut recog.err_handler)?;

			/*InvokeRule windowSpec*/
			recog.base.set_state(4603);
			recog.windowSpec()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- windowSpec ----------------
#[derive(Debug)]
pub enum WindowSpecContextAll<'input>{
	WindowRefContext(WindowRefContext<'input>),
	WindowDefContext(WindowDefContext<'input>),
Error(WindowSpecContext<'input>)
}
antlr_rust::tid!{WindowSpecContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for WindowSpecContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for WindowSpecContextAll<'input>{}

impl<'input> Deref for WindowSpecContextAll<'input>{
	type Target = dyn WindowSpecContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use WindowSpecContextAll::*;
		match self{
			WindowRefContext(inner) => inner,
			WindowDefContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for WindowSpecContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for WindowSpecContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type WindowSpecContext<'input> = BaseParserRuleContext<'input,WindowSpecContextExt<'input>>;

#[derive(Clone)]
pub struct WindowSpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for WindowSpecContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for WindowSpecContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for WindowSpecContext<'input>{
}

impl<'input> CustomRuleContext<'input> for WindowSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_windowSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_windowSpec }
}
antlr_rust::tid!{WindowSpecContextExt<'a>}

impl<'input> WindowSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WindowSpecContextAll<'input>> {
		Rc::new(
		WindowSpecContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WindowSpecContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait WindowSpecContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<WindowSpecContextExt<'input>>{


}

impl<'input> WindowSpecContextAttrs<'input> for WindowSpecContext<'input>{}

pub type WindowRefContext<'input> = BaseParserRuleContext<'input,WindowRefContextExt<'input>>;

pub trait WindowRefContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn errorCapturingIdentifier(&self) -> Option<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
}

impl<'input> WindowRefContextAttrs<'input> for WindowRefContext<'input>{}

pub struct WindowRefContextExt<'input>{
	base:WindowSpecContextExt<'input>,
	pub name: Option<Rc<ErrorCapturingIdentifierContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{WindowRefContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for WindowRefContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for WindowRefContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_windowRef(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_windowRef(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for WindowRefContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_windowRef(self);
	}
}

impl<'input> CustomRuleContext<'input> for WindowRefContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_windowSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_windowSpec }
}

impl<'input> Borrow<WindowSpecContextExt<'input>> for WindowRefContext<'input>{
	fn borrow(&self) -> &WindowSpecContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<WindowSpecContextExt<'input>> for WindowRefContext<'input>{
	fn borrow_mut(&mut self) -> &mut WindowSpecContextExt<'input> { &mut self.base }
}

impl<'input> WindowSpecContextAttrs<'input> for WindowRefContext<'input> {}

impl<'input> WindowRefContextExt<'input>{
	fn new(ctx: &dyn WindowSpecContextAttrs<'input>) -> Rc<WindowSpecContextAll<'input>>  {
		Rc::new(
			WindowSpecContextAll::WindowRefContext(
				BaseParserRuleContext::copy_from(ctx,WindowRefContextExt{
        			name:None, 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type WindowDefContext<'input> = BaseParserRuleContext<'input,WindowDefContextExt<'input>>;

pub trait WindowDefContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
	/// Retrieves first TerminalNode corresponding to token CLUSTER
	/// Returns `None` if there is no child corresponding to token CLUSTER
	fn CLUSTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(CLUSTER, 0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token BY in current rule
	fn BY_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token BY, starting from 0.
	/// Returns `None` if number of children corresponding to token BY is less or equal than `i`.
	fn BY(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(BY, i)
	}
	fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	fn windowFrame(&self) -> Option<Rc<WindowFrameContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
	fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
	/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
	fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(COMMA, i)
	}
	fn sortItem_all(&self) ->  Vec<Rc<SortItemContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn sortItem(&self, i: usize) -> Option<Rc<SortItemContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
	/// Retrieves first TerminalNode corresponding to token PARTITION
	/// Returns `None` if there is no child corresponding to token PARTITION
	fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(PARTITION, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DISTRIBUTE
	/// Returns `None` if there is no child corresponding to token DISTRIBUTE
	fn DISTRIBUTE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DISTRIBUTE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token ORDER
	/// Returns `None` if there is no child corresponding to token ORDER
	fn ORDER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(ORDER, 0)
	}
	/// Retrieves first TerminalNode corresponding to token SORT
	/// Returns `None` if there is no child corresponding to token SORT
	fn SORT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SORT, 0)
	}
}

impl<'input> WindowDefContextAttrs<'input> for WindowDefContext<'input>{}

pub struct WindowDefContextExt<'input>{
	base:WindowSpecContextExt<'input>,
	pub expression: Option<Rc<ExpressionContextAll<'input>>>,
	pub partition:Vec<Rc<ExpressionContextAll<'input>>>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{WindowDefContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for WindowDefContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for WindowDefContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_windowDef(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_windowDef(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for WindowDefContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_windowDef(self);
	}
}

impl<'input> CustomRuleContext<'input> for WindowDefContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_windowSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_windowSpec }
}

impl<'input> Borrow<WindowSpecContextExt<'input>> for WindowDefContext<'input>{
	fn borrow(&self) -> &WindowSpecContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<WindowSpecContextExt<'input>> for WindowDefContext<'input>{
	fn borrow_mut(&mut self) -> &mut WindowSpecContextExt<'input> { &mut self.base }
}

impl<'input> WindowSpecContextAttrs<'input> for WindowDefContext<'input> {}

impl<'input> WindowDefContextExt<'input>{
	fn new(ctx: &dyn WindowSpecContextAttrs<'input>) -> Rc<WindowSpecContextAll<'input>>  {
		Rc::new(
			WindowSpecContextAll::WindowDefContext(
				BaseParserRuleContext::copy_from(ctx,WindowDefContextExt{
        			expression:None, 
        			partition:Vec::new(), 
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn windowSpec(&mut self,)
	-> Result<Rc<WindowSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WindowSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 466, RULE_windowSpec);
        let mut _localctx: Rc<WindowSpecContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4651);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(587,&mut recog.base)? {
				1 =>{
					let tmp = WindowRefContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					/*InvokeRule errorCapturingIdentifier*/
					recog.base.set_state(4605);
					let tmp = recog.errorCapturingIdentifier()?;
					if let WindowSpecContextAll::WindowRefContext(ctx) = cast_mut::<_,WindowSpecContextAll >(&mut _localctx){
					ctx.name = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					}
				}
			,
				2 =>{
					let tmp = WindowRefContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(4606);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule errorCapturingIdentifier*/
					recog.base.set_state(4607);
					let tmp = recog.errorCapturingIdentifier()?;
					if let WindowSpecContextAll::WindowRefContext(ctx) = cast_mut::<_,WindowSpecContextAll >(&mut _localctx){
					ctx.name = Some(tmp.clone()); } else {unreachable!("cant cast");}  

					recog.base.set_state(4608);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					let tmp = WindowDefContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(4610);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					recog.base.set_state(4645);
					recog.err_handler.sync(&mut recog.base)?;
					match recog.base.input.la(1) {
					 CLUSTER 
						=> {
							{
							recog.base.set_state(4611);
							recog.base.match_token(CLUSTER,&mut recog.err_handler)?;

							recog.base.set_state(4612);
							recog.base.match_token(BY,&mut recog.err_handler)?;

							/*InvokeRule expression*/
							recog.base.set_state(4613);
							let tmp = recog.expression()?;
							if let WindowSpecContextAll::WindowDefContext(ctx) = cast_mut::<_,WindowSpecContextAll >(&mut _localctx){
							ctx.expression = Some(tmp.clone()); } else {unreachable!("cant cast");}  

							let temp = if let WindowSpecContextAll::WindowDefContext(ctx) = cast_mut::<_,WindowSpecContextAll >(&mut _localctx){
							ctx.expression.clone().unwrap() } else {unreachable!("cant cast");} ;
							if let WindowSpecContextAll::WindowDefContext(ctx) = cast_mut::<_,WindowSpecContextAll >(&mut _localctx){
							ctx.partition.push(temp); } else {unreachable!("cant cast");}  
							recog.base.set_state(4618);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							while _la==COMMA {
								{
								{
								recog.base.set_state(4614);
								recog.base.match_token(COMMA,&mut recog.err_handler)?;

								/*InvokeRule expression*/
								recog.base.set_state(4615);
								let tmp = recog.expression()?;
								if let WindowSpecContextAll::WindowDefContext(ctx) = cast_mut::<_,WindowSpecContextAll >(&mut _localctx){
								ctx.expression = Some(tmp.clone()); } else {unreachable!("cant cast");}  

								let temp = if let WindowSpecContextAll::WindowDefContext(ctx) = cast_mut::<_,WindowSpecContextAll >(&mut _localctx){
								ctx.expression.clone().unwrap() } else {unreachable!("cant cast");} ;
								if let WindowSpecContextAll::WindowDefContext(ctx) = cast_mut::<_,WindowSpecContextAll >(&mut _localctx){
								ctx.partition.push(temp); } else {unreachable!("cant cast");}  
								}
								}
								recog.base.set_state(4620);
								recog.err_handler.sync(&mut recog.base)?;
								_la = recog.base.input.la(1);
							}
							}
						}

					 RIGHT_PAREN | DISTRIBUTE | ORDER | PARTITION | RANGE | ROWS | SORT 
						=> {
							{
							recog.base.set_state(4631);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==DISTRIBUTE || _la==PARTITION {
								{
								recog.base.set_state(4621);
								_la = recog.base.input.la(1);
								if { !(_la==DISTRIBUTE || _la==PARTITION) } {
									recog.err_handler.recover_inline(&mut recog.base)?;

								}
								else {
									if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
									recog.err_handler.report_match(&mut recog.base);
									recog.base.consume(&mut recog.err_handler);
								}
								recog.base.set_state(4622);
								recog.base.match_token(BY,&mut recog.err_handler)?;

								/*InvokeRule expression*/
								recog.base.set_state(4623);
								let tmp = recog.expression()?;
								if let WindowSpecContextAll::WindowDefContext(ctx) = cast_mut::<_,WindowSpecContextAll >(&mut _localctx){
								ctx.expression = Some(tmp.clone()); } else {unreachable!("cant cast");}  

								let temp = if let WindowSpecContextAll::WindowDefContext(ctx) = cast_mut::<_,WindowSpecContextAll >(&mut _localctx){
								ctx.expression.clone().unwrap() } else {unreachable!("cant cast");} ;
								if let WindowSpecContextAll::WindowDefContext(ctx) = cast_mut::<_,WindowSpecContextAll >(&mut _localctx){
								ctx.partition.push(temp); } else {unreachable!("cant cast");}  
								recog.base.set_state(4628);
								recog.err_handler.sync(&mut recog.base)?;
								_la = recog.base.input.la(1);
								while _la==COMMA {
									{
									{
									recog.base.set_state(4624);
									recog.base.match_token(COMMA,&mut recog.err_handler)?;

									/*InvokeRule expression*/
									recog.base.set_state(4625);
									let tmp = recog.expression()?;
									if let WindowSpecContextAll::WindowDefContext(ctx) = cast_mut::<_,WindowSpecContextAll >(&mut _localctx){
									ctx.expression = Some(tmp.clone()); } else {unreachable!("cant cast");}  

									let temp = if let WindowSpecContextAll::WindowDefContext(ctx) = cast_mut::<_,WindowSpecContextAll >(&mut _localctx){
									ctx.expression.clone().unwrap() } else {unreachable!("cant cast");} ;
									if let WindowSpecContextAll::WindowDefContext(ctx) = cast_mut::<_,WindowSpecContextAll >(&mut _localctx){
									ctx.partition.push(temp); } else {unreachable!("cant cast");}  
									}
									}
									recog.base.set_state(4630);
									recog.err_handler.sync(&mut recog.base)?;
									_la = recog.base.input.la(1);
								}
								}
							}

							recog.base.set_state(4643);
							recog.err_handler.sync(&mut recog.base)?;
							_la = recog.base.input.la(1);
							if _la==ORDER || _la==SORT {
								{
								recog.base.set_state(4633);
								_la = recog.base.input.la(1);
								if { !(_la==ORDER || _la==SORT) } {
									recog.err_handler.recover_inline(&mut recog.base)?;

								}
								else {
									if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
									recog.err_handler.report_match(&mut recog.base);
									recog.base.consume(&mut recog.err_handler);
								}
								recog.base.set_state(4634);
								recog.base.match_token(BY,&mut recog.err_handler)?;

								/*InvokeRule sortItem*/
								recog.base.set_state(4635);
								recog.sortItem()?;

								recog.base.set_state(4640);
								recog.err_handler.sync(&mut recog.base)?;
								_la = recog.base.input.la(1);
								while _la==COMMA {
									{
									{
									recog.base.set_state(4636);
									recog.base.match_token(COMMA,&mut recog.err_handler)?;

									/*InvokeRule sortItem*/
									recog.base.set_state(4637);
									recog.sortItem()?;

									}
									}
									recog.base.set_state(4642);
									recog.err_handler.sync(&mut recog.base)?;
									_la = recog.base.input.la(1);
								}
								}
							}

							}
						}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
					}
					recog.base.set_state(4648);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==RANGE || _la==ROWS {
						{
						/*InvokeRule windowFrame*/
						recog.base.set_state(4647);
						recog.windowFrame()?;

						}
					}

					recog.base.set_state(4650);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- windowFrame ----------------
pub type WindowFrameContextAll<'input> = WindowFrameContext<'input>;


pub type WindowFrameContext<'input> = BaseParserRuleContext<'input,WindowFrameContextExt<'input>>;

#[derive(Clone)]
pub struct WindowFrameContextExt<'input>{
	pub frameType: Option<TokenType<'input>>,
	pub start: Option<Rc<FrameBoundContextAll<'input>>>,
	pub end: Option<Rc<FrameBoundContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for WindowFrameContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for WindowFrameContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_windowFrame(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_windowFrame(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for WindowFrameContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_windowFrame(self);
	}
}

impl<'input> CustomRuleContext<'input> for WindowFrameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_windowFrame }
	//fn type_rule_index() -> usize where Self: Sized { RULE_windowFrame }
}
antlr_rust::tid!{WindowFrameContextExt<'a>}

impl<'input> WindowFrameContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WindowFrameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WindowFrameContextExt{
				frameType: None, 
				start: None, end: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait WindowFrameContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<WindowFrameContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token RANGE
/// Returns `None` if there is no child corresponding to token RANGE
fn RANGE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RANGE, 0)
}
fn frameBound_all(&self) ->  Vec<Rc<FrameBoundContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn frameBound(&self, i: usize) -> Option<Rc<FrameBoundContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token ROWS
/// Returns `None` if there is no child corresponding to token ROWS
fn ROWS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ROWS, 0)
}
/// Retrieves first TerminalNode corresponding to token BETWEEN
/// Returns `None` if there is no child corresponding to token BETWEEN
fn BETWEEN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BETWEEN, 0)
}
/// Retrieves first TerminalNode corresponding to token AND
/// Returns `None` if there is no child corresponding to token AND
fn AND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AND, 0)
}

}

impl<'input> WindowFrameContextAttrs<'input> for WindowFrameContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn windowFrame(&mut self,)
	-> Result<Rc<WindowFrameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WindowFrameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 468, RULE_windowFrame);
        let mut _localctx: Rc<WindowFrameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4669);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(588,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4653);
					let tmp = recog.base.match_token(RANGE,&mut recog.err_handler)?;
					 cast_mut::<_,WindowFrameContext >(&mut _localctx).frameType = Some(tmp.clone());
					  

					/*InvokeRule frameBound*/
					recog.base.set_state(4654);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,WindowFrameContext >(&mut _localctx).start = Some(tmp.clone());
					  

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4655);
					let tmp = recog.base.match_token(ROWS,&mut recog.err_handler)?;
					 cast_mut::<_,WindowFrameContext >(&mut _localctx).frameType = Some(tmp.clone());
					  

					/*InvokeRule frameBound*/
					recog.base.set_state(4656);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,WindowFrameContext >(&mut _localctx).start = Some(tmp.clone());
					  

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(4657);
					let tmp = recog.base.match_token(RANGE,&mut recog.err_handler)?;
					 cast_mut::<_,WindowFrameContext >(&mut _localctx).frameType = Some(tmp.clone());
					  

					recog.base.set_state(4658);
					recog.base.match_token(BETWEEN,&mut recog.err_handler)?;

					/*InvokeRule frameBound*/
					recog.base.set_state(4659);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,WindowFrameContext >(&mut _localctx).start = Some(tmp.clone());
					  

					recog.base.set_state(4660);
					recog.base.match_token(AND,&mut recog.err_handler)?;

					/*InvokeRule frameBound*/
					recog.base.set_state(4661);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,WindowFrameContext >(&mut _localctx).end = Some(tmp.clone());
					  

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(4663);
					let tmp = recog.base.match_token(ROWS,&mut recog.err_handler)?;
					 cast_mut::<_,WindowFrameContext >(&mut _localctx).frameType = Some(tmp.clone());
					  

					recog.base.set_state(4664);
					recog.base.match_token(BETWEEN,&mut recog.err_handler)?;

					/*InvokeRule frameBound*/
					recog.base.set_state(4665);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,WindowFrameContext >(&mut _localctx).start = Some(tmp.clone());
					  

					recog.base.set_state(4666);
					recog.base.match_token(AND,&mut recog.err_handler)?;

					/*InvokeRule frameBound*/
					recog.base.set_state(4667);
					let tmp = recog.frameBound()?;
					 cast_mut::<_,WindowFrameContext >(&mut _localctx).end = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- frameBound ----------------
pub type FrameBoundContextAll<'input> = FrameBoundContext<'input>;


pub type FrameBoundContext<'input> = BaseParserRuleContext<'input,FrameBoundContextExt<'input>>;

#[derive(Clone)]
pub struct FrameBoundContextExt<'input>{
	pub boundType: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for FrameBoundContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for FrameBoundContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_frameBound(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_frameBound(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for FrameBoundContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_frameBound(self);
	}
}

impl<'input> CustomRuleContext<'input> for FrameBoundContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_frameBound }
	//fn type_rule_index() -> usize where Self: Sized { RULE_frameBound }
}
antlr_rust::tid!{FrameBoundContextExt<'a>}

impl<'input> FrameBoundContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FrameBoundContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FrameBoundContextExt{
				boundType: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait FrameBoundContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<FrameBoundContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token UNBOUNDED
/// Returns `None` if there is no child corresponding to token UNBOUNDED
fn UNBOUNDED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UNBOUNDED, 0)
}
/// Retrieves first TerminalNode corresponding to token PRECEDING
/// Returns `None` if there is no child corresponding to token PRECEDING
fn PRECEDING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PRECEDING, 0)
}
/// Retrieves first TerminalNode corresponding to token FOLLOWING
/// Returns `None` if there is no child corresponding to token FOLLOWING
fn FOLLOWING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FOLLOWING, 0)
}
/// Retrieves first TerminalNode corresponding to token ROW
/// Returns `None` if there is no child corresponding to token ROW
fn ROW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ROW, 0)
}
/// Retrieves first TerminalNode corresponding to token CURRENT
/// Returns `None` if there is no child corresponding to token CURRENT
fn CURRENT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CURRENT, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FrameBoundContextAttrs<'input> for FrameBoundContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn frameBound(&mut self,)
	-> Result<Rc<FrameBoundContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FrameBoundContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 470, RULE_frameBound);
        let mut _localctx: Rc<FrameBoundContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4678);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(589,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4671);
					recog.base.match_token(UNBOUNDED,&mut recog.err_handler)?;

					recog.base.set_state(4672);
					 cast_mut::<_,FrameBoundContext >(&mut _localctx).boundType = recog.base.input.lt(1).cloned();
					 
					_la = recog.base.input.la(1);
					if { !(_la==FOLLOWING || _la==PRECEDING) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						 cast_mut::<_,FrameBoundContext >(&mut _localctx).boundType = Some(tmp.clone());
						  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4673);
					let tmp = recog.base.match_token(CURRENT,&mut recog.err_handler)?;
					 cast_mut::<_,FrameBoundContext >(&mut _localctx).boundType = Some(tmp.clone());
					  

					recog.base.set_state(4674);
					recog.base.match_token(ROW,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule expression*/
					recog.base.set_state(4675);
					recog.expression()?;

					recog.base.set_state(4676);
					 cast_mut::<_,FrameBoundContext >(&mut _localctx).boundType = recog.base.input.lt(1).cloned();
					 
					_la = recog.base.input.la(1);
					if { !(_la==FOLLOWING || _la==PRECEDING) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						 cast_mut::<_,FrameBoundContext >(&mut _localctx).boundType = Some(tmp.clone());
						  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- qualifiedNameList ----------------
pub type QualifiedNameListContextAll<'input> = QualifiedNameListContext<'input>;


pub type QualifiedNameListContext<'input> = BaseParserRuleContext<'input,QualifiedNameListContextExt<'input>>;

#[derive(Clone)]
pub struct QualifiedNameListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for QualifiedNameListContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for QualifiedNameListContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_qualifiedNameList(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_qualifiedNameList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for QualifiedNameListContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_qualifiedNameList(self);
	}
}

impl<'input> CustomRuleContext<'input> for QualifiedNameListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_qualifiedNameList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_qualifiedNameList }
}
antlr_rust::tid!{QualifiedNameListContextExt<'a>}

impl<'input> QualifiedNameListContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QualifiedNameListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QualifiedNameListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait QualifiedNameListContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<QualifiedNameListContextExt<'input>>{

fn qualifiedName_all(&self) ->  Vec<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn qualifiedName(&self, i: usize) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> QualifiedNameListContextAttrs<'input> for QualifiedNameListContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn qualifiedNameList(&mut self,)
	-> Result<Rc<QualifiedNameListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QualifiedNameListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 472, RULE_qualifiedNameList);
        let mut _localctx: Rc<QualifiedNameListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule qualifiedName*/
			recog.base.set_state(4680);
			recog.qualifiedName()?;

			recog.base.set_state(4685);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(4681);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule qualifiedName*/
				recog.base.set_state(4682);
				recog.qualifiedName()?;

				}
				}
				recog.base.set_state(4687);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- functionName ----------------
pub type FunctionNameContextAll<'input> = FunctionNameContext<'input>;


pub type FunctionNameContext<'input> = BaseParserRuleContext<'input,FunctionNameContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionNameContextExt<'input>{
	pub identFunc: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for FunctionNameContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for FunctionNameContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionName(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_functionName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for FunctionNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_functionName(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionName }
}
antlr_rust::tid!{FunctionNameContextExt<'a>}

impl<'input> FunctionNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionNameContextExt{
				identFunc: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionNameContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<FunctionNameContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token IDENTIFIER_KW
/// Returns `None` if there is no child corresponding to token IDENTIFIER_KW
fn IDENTIFIER_KW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IDENTIFIER_KW, 0)
}
/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
fn qualifiedName(&self) -> Option<Rc<QualifiedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token FILTER
/// Returns `None` if there is no child corresponding to token FILTER
fn FILTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FILTER, 0)
}
/// Retrieves first TerminalNode corresponding to token LEFT
/// Returns `None` if there is no child corresponding to token LEFT
fn LEFT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT, 0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT
/// Returns `None` if there is no child corresponding to token RIGHT
fn RIGHT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT, 0)
}

}

impl<'input> FunctionNameContextAttrs<'input> for FunctionNameContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionName(&mut self,)
	-> Result<Rc<FunctionNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 474, RULE_functionName);
        let mut _localctx: Rc<FunctionNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4698);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(591,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4688);
					recog.base.match_token(IDENTIFIER_KW,&mut recog.err_handler)?;

					recog.base.set_state(4689);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(4690);
					recog.expression()?;

					recog.base.set_state(4691);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4693);
					let tmp = recog.base.match_token(IDENTIFIER_KW,&mut recog.err_handler)?;
					 cast_mut::<_,FunctionNameContext >(&mut _localctx).identFunc = Some(tmp.clone());
					  

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule qualifiedName*/
					recog.base.set_state(4694);
					recog.qualifiedName()?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(4695);
					recog.base.match_token(FILTER,&mut recog.err_handler)?;

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					recog.base.set_state(4696);
					recog.base.match_token(LEFT,&mut recog.err_handler)?;

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					recog.base.set_state(4697);
					recog.base.match_token(RIGHT,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- qualifiedName ----------------
pub type QualifiedNameContextAll<'input> = QualifiedNameContext<'input>;


pub type QualifiedNameContext<'input> = BaseParserRuleContext<'input,QualifiedNameContextExt<'input>>;

#[derive(Clone)]
pub struct QualifiedNameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for QualifiedNameContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for QualifiedNameContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_qualifiedName(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_qualifiedName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for QualifiedNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_qualifiedName(self);
	}
}

impl<'input> CustomRuleContext<'input> for QualifiedNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_qualifiedName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_qualifiedName }
}
antlr_rust::tid!{QualifiedNameContextExt<'a>}

impl<'input> QualifiedNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QualifiedNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QualifiedNameContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait QualifiedNameContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<QualifiedNameContextExt<'input>>{

fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token DOT in current rule
fn DOT_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token DOT, starting from 0.
/// Returns `None` if number of children corresponding to token DOT is less or equal than `i`.
fn DOT(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DOT, i)
}

}

impl<'input> QualifiedNameContextAttrs<'input> for QualifiedNameContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn qualifiedName(&mut self,)
	-> Result<Rc<QualifiedNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QualifiedNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 476, RULE_qualifiedName);
        let mut _localctx: Rc<QualifiedNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(4700);
			recog.identifier()?;

			recog.base.set_state(4705);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(592,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(4701);
					recog.base.match_token(DOT,&mut recog.err_handler)?;

					/*InvokeRule identifier*/
					recog.base.set_state(4702);
					recog.identifier()?;

					}
					} 
				}
				recog.base.set_state(4707);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(592,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- errorCapturingIdentifier ----------------
pub type ErrorCapturingIdentifierContextAll<'input> = ErrorCapturingIdentifierContext<'input>;


pub type ErrorCapturingIdentifierContext<'input> = BaseParserRuleContext<'input,ErrorCapturingIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct ErrorCapturingIdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ErrorCapturingIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ErrorCapturingIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_errorCapturingIdentifier(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_errorCapturingIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ErrorCapturingIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_errorCapturingIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for ErrorCapturingIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_errorCapturingIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_errorCapturingIdentifier }
}
antlr_rust::tid!{ErrorCapturingIdentifierContextExt<'a>}

impl<'input> ErrorCapturingIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ErrorCapturingIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ErrorCapturingIdentifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ErrorCapturingIdentifierContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ErrorCapturingIdentifierContextExt<'input>>{

fn identifier(&self) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn errorCapturingIdentifierExtra(&self) -> Option<Rc<ErrorCapturingIdentifierExtraContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ErrorCapturingIdentifierContextAttrs<'input> for ErrorCapturingIdentifierContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn errorCapturingIdentifier(&mut self,)
	-> Result<Rc<ErrorCapturingIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ErrorCapturingIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 478, RULE_errorCapturingIdentifier);
        let mut _localctx: Rc<ErrorCapturingIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifier*/
			recog.base.set_state(4708);
			recog.identifier()?;

			/*InvokeRule errorCapturingIdentifierExtra*/
			recog.base.set_state(4709);
			recog.errorCapturingIdentifierExtra()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- errorCapturingIdentifierExtra ----------------
#[derive(Debug)]
pub enum ErrorCapturingIdentifierExtraContextAll<'input>{
	ErrorIdentContext(ErrorIdentContext<'input>),
	RealIdentContext(RealIdentContext<'input>),
Error(ErrorCapturingIdentifierExtraContext<'input>)
}
antlr_rust::tid!{ErrorCapturingIdentifierExtraContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for ErrorCapturingIdentifierExtraContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for ErrorCapturingIdentifierExtraContextAll<'input>{}

impl<'input> Deref for ErrorCapturingIdentifierExtraContextAll<'input>{
	type Target = dyn ErrorCapturingIdentifierExtraContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use ErrorCapturingIdentifierExtraContextAll::*;
		match self{
			ErrorIdentContext(inner) => inner,
			RealIdentContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ErrorCapturingIdentifierExtraContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ErrorCapturingIdentifierExtraContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type ErrorCapturingIdentifierExtraContext<'input> = BaseParserRuleContext<'input,ErrorCapturingIdentifierExtraContextExt<'input>>;

#[derive(Clone)]
pub struct ErrorCapturingIdentifierExtraContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ErrorCapturingIdentifierExtraContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ErrorCapturingIdentifierExtraContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ErrorCapturingIdentifierExtraContext<'input>{
}

impl<'input> CustomRuleContext<'input> for ErrorCapturingIdentifierExtraContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_errorCapturingIdentifierExtra }
	//fn type_rule_index() -> usize where Self: Sized { RULE_errorCapturingIdentifierExtra }
}
antlr_rust::tid!{ErrorCapturingIdentifierExtraContextExt<'a>}

impl<'input> ErrorCapturingIdentifierExtraContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ErrorCapturingIdentifierExtraContextAll<'input>> {
		Rc::new(
		ErrorCapturingIdentifierExtraContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ErrorCapturingIdentifierExtraContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait ErrorCapturingIdentifierExtraContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ErrorCapturingIdentifierExtraContextExt<'input>>{


}

impl<'input> ErrorCapturingIdentifierExtraContextAttrs<'input> for ErrorCapturingIdentifierExtraContext<'input>{}

pub type ErrorIdentContext<'input> = BaseParserRuleContext<'input,ErrorIdentContextExt<'input>>;

pub trait ErrorIdentContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves all `TerminalNode`s corresponding to token MINUS in current rule
	fn MINUS_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
		self.children_of_type()
	}
	/// Retrieves 'i's TerminalNode corresponding to token MINUS, starting from 0.
	/// Returns `None` if number of children corresponding to token MINUS is less or equal than `i`.
	fn MINUS(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(MINUS, i)
	}
	fn identifier_all(&self) ->  Vec<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.children_of_type()
	}
	fn identifier(&self, i: usize) -> Option<Rc<IdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(i)
	}
}

impl<'input> ErrorIdentContextAttrs<'input> for ErrorIdentContext<'input>{}

pub struct ErrorIdentContextExt<'input>{
	base:ErrorCapturingIdentifierExtraContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ErrorIdentContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ErrorIdentContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ErrorIdentContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_errorIdent(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_errorIdent(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ErrorIdentContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_errorIdent(self);
	}
}

impl<'input> CustomRuleContext<'input> for ErrorIdentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_errorCapturingIdentifierExtra }
	//fn type_rule_index() -> usize where Self: Sized { RULE_errorCapturingIdentifierExtra }
}

impl<'input> Borrow<ErrorCapturingIdentifierExtraContextExt<'input>> for ErrorIdentContext<'input>{
	fn borrow(&self) -> &ErrorCapturingIdentifierExtraContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ErrorCapturingIdentifierExtraContextExt<'input>> for ErrorIdentContext<'input>{
	fn borrow_mut(&mut self) -> &mut ErrorCapturingIdentifierExtraContextExt<'input> { &mut self.base }
}

impl<'input> ErrorCapturingIdentifierExtraContextAttrs<'input> for ErrorIdentContext<'input> {}

impl<'input> ErrorIdentContextExt<'input>{
	fn new(ctx: &dyn ErrorCapturingIdentifierExtraContextAttrs<'input>) -> Rc<ErrorCapturingIdentifierExtraContextAll<'input>>  {
		Rc::new(
			ErrorCapturingIdentifierExtraContextAll::ErrorIdentContext(
				BaseParserRuleContext::copy_from(ctx,ErrorIdentContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type RealIdentContext<'input> = BaseParserRuleContext<'input,RealIdentContextExt<'input>>;

pub trait RealIdentContextAttrs<'input>: SqlBaseParserContext<'input>{
}

impl<'input> RealIdentContextAttrs<'input> for RealIdentContext<'input>{}

pub struct RealIdentContextExt<'input>{
	base:ErrorCapturingIdentifierExtraContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{RealIdentContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for RealIdentContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for RealIdentContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_realIdent(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_realIdent(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for RealIdentContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_realIdent(self);
	}
}

impl<'input> CustomRuleContext<'input> for RealIdentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_errorCapturingIdentifierExtra }
	//fn type_rule_index() -> usize where Self: Sized { RULE_errorCapturingIdentifierExtra }
}

impl<'input> Borrow<ErrorCapturingIdentifierExtraContextExt<'input>> for RealIdentContext<'input>{
	fn borrow(&self) -> &ErrorCapturingIdentifierExtraContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ErrorCapturingIdentifierExtraContextExt<'input>> for RealIdentContext<'input>{
	fn borrow_mut(&mut self) -> &mut ErrorCapturingIdentifierExtraContextExt<'input> { &mut self.base }
}

impl<'input> ErrorCapturingIdentifierExtraContextAttrs<'input> for RealIdentContext<'input> {}

impl<'input> RealIdentContextExt<'input>{
	fn new(ctx: &dyn ErrorCapturingIdentifierExtraContextAttrs<'input>) -> Rc<ErrorCapturingIdentifierExtraContextAll<'input>>  {
		Rc::new(
			ErrorCapturingIdentifierExtraContextAll::RealIdentContext(
				BaseParserRuleContext::copy_from(ctx,RealIdentContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn errorCapturingIdentifierExtra(&mut self,)
	-> Result<Rc<ErrorCapturingIdentifierExtraContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ErrorCapturingIdentifierExtraContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 480, RULE_errorCapturingIdentifierExtra);
        let mut _localctx: Rc<ErrorCapturingIdentifierExtraContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			recog.base.set_state(4718);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(594,&mut recog.base)? {
				1 =>{
					let tmp = ErrorIdentContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(4713); 
					recog.err_handler.sync(&mut recog.base)?;
					_alt = 1;
					loop {
						match _alt {
						    x if x == 1=>
							{
							{
							recog.base.set_state(4711);
							recog.base.match_token(MINUS,&mut recog.err_handler)?;

							/*InvokeRule identifier*/
							recog.base.set_state(4712);
							recog.identifier()?;

							}
							}

						_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
						}
						recog.base.set_state(4715); 
						recog.err_handler.sync(&mut recog.base)?;
						_alt = recog.interpreter.adaptive_predict(593,&mut recog.base)?;
						if _alt==2 || _alt==INVALID_ALT { break }
					}
					}
				}
			,
				2 =>{
					let tmp = RealIdentContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- identifier ----------------
pub type IdentifierContextAll<'input> = IdentifierContext<'input>;


pub type IdentifierContext<'input> = BaseParserRuleContext<'input,IdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct IdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for IdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for IdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_identifier(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_identifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for IdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_identifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for IdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identifier }
}
antlr_rust::tid!{IdentifierContextExt<'a>}

impl<'input> IdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IdentifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait IdentifierContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<IdentifierContextExt<'input>>{

fn strictIdentifier(&self) -> Option<Rc<StrictIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn strictNonReserved(&self) -> Option<Rc<StrictNonReservedContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> IdentifierContextAttrs<'input> for IdentifierContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn identifier(&mut self,)
	-> Result<Rc<IdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 482, RULE_identifier);
        let mut _localctx: Rc<IdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4723);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(595,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule strictIdentifier*/
					recog.base.set_state(4720);
					recog.strictIdentifier()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4721);
					if !({!SQL_standard_keyword_behavior}) {
						Err(FailedPredicateError::new(&mut recog.base, Some("!SQL_standard_keyword_behavior".to_owned()), None))?;
					}
					/*InvokeRule strictNonReserved*/
					recog.base.set_state(4722);
					recog.strictNonReserved()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- simpleIdentifier ----------------
pub type SimpleIdentifierContextAll<'input> = SimpleIdentifierContext<'input>;


pub type SimpleIdentifierContext<'input> = BaseParserRuleContext<'input,SimpleIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct SimpleIdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SimpleIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SimpleIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_simpleIdentifier(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_simpleIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SimpleIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_simpleIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for SimpleIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_simpleIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_simpleIdentifier }
}
antlr_rust::tid!{SimpleIdentifierContextExt<'a>}

impl<'input> SimpleIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SimpleIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SimpleIdentifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SimpleIdentifierContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SimpleIdentifierContextExt<'input>>{

fn simpleStrictIdentifier(&self) -> Option<Rc<SimpleStrictIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn strictNonReserved(&self) -> Option<Rc<StrictNonReservedContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SimpleIdentifierContextAttrs<'input> for SimpleIdentifierContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn simpleIdentifier(&mut self,)
	-> Result<Rc<SimpleIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SimpleIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 484, RULE_simpleIdentifier);
        let mut _localctx: Rc<SimpleIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4728);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(596,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule simpleStrictIdentifier*/
					recog.base.set_state(4725);
					recog.simpleStrictIdentifier()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4726);
					if !({!SQL_standard_keyword_behavior}) {
						Err(FailedPredicateError::new(&mut recog.base, Some("!SQL_standard_keyword_behavior".to_owned()), None))?;
					}
					/*InvokeRule strictNonReserved*/
					recog.base.set_state(4727);
					recog.strictNonReserved()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- strictIdentifier ----------------
#[derive(Debug)]
pub enum StrictIdentifierContextAll<'input>{
	QuotedIdentifierAlternativeContext(QuotedIdentifierAlternativeContext<'input>),
	IdentifierLiteralContext(IdentifierLiteralContext<'input>),
	UnquotedIdentifierContext(UnquotedIdentifierContext<'input>),
Error(StrictIdentifierContext<'input>)
}
antlr_rust::tid!{StrictIdentifierContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for StrictIdentifierContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for StrictIdentifierContextAll<'input>{}

impl<'input> Deref for StrictIdentifierContextAll<'input>{
	type Target = dyn StrictIdentifierContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use StrictIdentifierContextAll::*;
		match self{
			QuotedIdentifierAlternativeContext(inner) => inner,
			IdentifierLiteralContext(inner) => inner,
			UnquotedIdentifierContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for StrictIdentifierContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for StrictIdentifierContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type StrictIdentifierContext<'input> = BaseParserRuleContext<'input,StrictIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct StrictIdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for StrictIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for StrictIdentifierContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for StrictIdentifierContext<'input>{
}

impl<'input> CustomRuleContext<'input> for StrictIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_strictIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_strictIdentifier }
}
antlr_rust::tid!{StrictIdentifierContextExt<'a>}

impl<'input> StrictIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StrictIdentifierContextAll<'input>> {
		Rc::new(
		StrictIdentifierContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StrictIdentifierContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait StrictIdentifierContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<StrictIdentifierContextExt<'input>>{


}

impl<'input> StrictIdentifierContextAttrs<'input> for StrictIdentifierContext<'input>{}

pub type QuotedIdentifierAlternativeContext<'input> = BaseParserRuleContext<'input,QuotedIdentifierAlternativeContextExt<'input>>;

pub trait QuotedIdentifierAlternativeContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn quotedIdentifier(&self) -> Option<Rc<QuotedIdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> QuotedIdentifierAlternativeContextAttrs<'input> for QuotedIdentifierAlternativeContext<'input>{}

pub struct QuotedIdentifierAlternativeContextExt<'input>{
	base:StrictIdentifierContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{QuotedIdentifierAlternativeContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for QuotedIdentifierAlternativeContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for QuotedIdentifierAlternativeContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_quotedIdentifierAlternative(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_quotedIdentifierAlternative(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for QuotedIdentifierAlternativeContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_quotedIdentifierAlternative(self);
	}
}

impl<'input> CustomRuleContext<'input> for QuotedIdentifierAlternativeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_strictIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_strictIdentifier }
}

impl<'input> Borrow<StrictIdentifierContextExt<'input>> for QuotedIdentifierAlternativeContext<'input>{
	fn borrow(&self) -> &StrictIdentifierContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StrictIdentifierContextExt<'input>> for QuotedIdentifierAlternativeContext<'input>{
	fn borrow_mut(&mut self) -> &mut StrictIdentifierContextExt<'input> { &mut self.base }
}

impl<'input> StrictIdentifierContextAttrs<'input> for QuotedIdentifierAlternativeContext<'input> {}

impl<'input> QuotedIdentifierAlternativeContextExt<'input>{
	fn new(ctx: &dyn StrictIdentifierContextAttrs<'input>) -> Rc<StrictIdentifierContextAll<'input>>  {
		Rc::new(
			StrictIdentifierContextAll::QuotedIdentifierAlternativeContext(
				BaseParserRuleContext::copy_from(ctx,QuotedIdentifierAlternativeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type IdentifierLiteralContext<'input> = BaseParserRuleContext<'input,IdentifierLiteralContextExt<'input>>;

pub trait IdentifierLiteralContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IDENTIFIER_KW
	/// Returns `None` if there is no child corresponding to token IDENTIFIER_KW
	fn IDENTIFIER_KW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IDENTIFIER_KW, 0)
	}
	/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
	/// Returns `None` if there is no child corresponding to token LEFT_PAREN
	fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(LEFT_PAREN, 0)
	}
	fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
	/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
	fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(RIGHT_PAREN, 0)
	}
}

impl<'input> IdentifierLiteralContextAttrs<'input> for IdentifierLiteralContext<'input>{}

pub struct IdentifierLiteralContextExt<'input>{
	base:StrictIdentifierContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{IdentifierLiteralContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for IdentifierLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for IdentifierLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_identifierLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_identifierLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for IdentifierLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_identifierLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for IdentifierLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_strictIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_strictIdentifier }
}

impl<'input> Borrow<StrictIdentifierContextExt<'input>> for IdentifierLiteralContext<'input>{
	fn borrow(&self) -> &StrictIdentifierContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StrictIdentifierContextExt<'input>> for IdentifierLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut StrictIdentifierContextExt<'input> { &mut self.base }
}

impl<'input> StrictIdentifierContextAttrs<'input> for IdentifierLiteralContext<'input> {}

impl<'input> IdentifierLiteralContextExt<'input>{
	fn new(ctx: &dyn StrictIdentifierContextAttrs<'input>) -> Rc<StrictIdentifierContextAll<'input>>  {
		Rc::new(
			StrictIdentifierContextAll::IdentifierLiteralContext(
				BaseParserRuleContext::copy_from(ctx,IdentifierLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type UnquotedIdentifierContext<'input> = BaseParserRuleContext<'input,UnquotedIdentifierContextExt<'input>>;

pub trait UnquotedIdentifierContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IDENTIFIER
	/// Returns `None` if there is no child corresponding to token IDENTIFIER
	fn IDENTIFIER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IDENTIFIER, 0)
	}
	fn ansiNonReserved(&self) -> Option<Rc<AnsiNonReservedContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn nonReserved(&self) -> Option<Rc<NonReservedContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> UnquotedIdentifierContextAttrs<'input> for UnquotedIdentifierContext<'input>{}

pub struct UnquotedIdentifierContextExt<'input>{
	base:StrictIdentifierContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{UnquotedIdentifierContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for UnquotedIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for UnquotedIdentifierContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_unquotedIdentifier(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_unquotedIdentifier(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for UnquotedIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_unquotedIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnquotedIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_strictIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_strictIdentifier }
}

impl<'input> Borrow<StrictIdentifierContextExt<'input>> for UnquotedIdentifierContext<'input>{
	fn borrow(&self) -> &StrictIdentifierContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<StrictIdentifierContextExt<'input>> for UnquotedIdentifierContext<'input>{
	fn borrow_mut(&mut self) -> &mut StrictIdentifierContextExt<'input> { &mut self.base }
}

impl<'input> StrictIdentifierContextAttrs<'input> for UnquotedIdentifierContext<'input> {}

impl<'input> UnquotedIdentifierContextExt<'input>{
	fn new(ctx: &dyn StrictIdentifierContextAttrs<'input>) -> Rc<StrictIdentifierContextAll<'input>>  {
		Rc::new(
			StrictIdentifierContextAll::UnquotedIdentifierContext(
				BaseParserRuleContext::copy_from(ctx,UnquotedIdentifierContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn strictIdentifier(&mut self,)
	-> Result<Rc<StrictIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StrictIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 486, RULE_strictIdentifier);
        let mut _localctx: Rc<StrictIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4742);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(597,&mut recog.base)? {
				1 =>{
					let tmp = UnquotedIdentifierContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(4730);
					recog.base.match_token(IDENTIFIER,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = QuotedIdentifierAlternativeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule quotedIdentifier*/
					recog.base.set_state(4731);
					recog.quotedIdentifier()?;

					}
				}
			,
				3 =>{
					let tmp = IdentifierLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(4732);
					if !({!legacy_identifier_clause_only}) {
						Err(FailedPredicateError::new(&mut recog.base, Some("!legacy_identifier_clause_only".to_owned()), None))?;
					}
					recog.base.set_state(4733);
					recog.base.match_token(IDENTIFIER_KW,&mut recog.err_handler)?;

					recog.base.set_state(4734);
					recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

					/*InvokeRule stringLit*/
					recog.base.set_state(4735);
					recog.stringLit()?;

					recog.base.set_state(4736);
					recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

					}
				}
			,
				4 =>{
					let tmp = UnquotedIdentifierContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(4738);
					if !({SQL_standard_keyword_behavior}) {
						Err(FailedPredicateError::new(&mut recog.base, Some("SQL_standard_keyword_behavior".to_owned()), None))?;
					}
					/*InvokeRule ansiNonReserved*/
					recog.base.set_state(4739);
					recog.ansiNonReserved()?;

					}
				}
			,
				5 =>{
					let tmp = UnquotedIdentifierContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					recog.base.set_state(4740);
					if !({!SQL_standard_keyword_behavior}) {
						Err(FailedPredicateError::new(&mut recog.base, Some("!SQL_standard_keyword_behavior".to_owned()), None))?;
					}
					/*InvokeRule nonReserved*/
					recog.base.set_state(4741);
					recog.nonReserved()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- simpleStrictIdentifier ----------------
#[derive(Debug)]
pub enum SimpleStrictIdentifierContextAll<'input>{
	SimpleUnquotedIdentifierContext(SimpleUnquotedIdentifierContext<'input>),
	SimpleQuotedIdentifierAlternativeContext(SimpleQuotedIdentifierAlternativeContext<'input>),
Error(SimpleStrictIdentifierContext<'input>)
}
antlr_rust::tid!{SimpleStrictIdentifierContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for SimpleStrictIdentifierContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for SimpleStrictIdentifierContextAll<'input>{}

impl<'input> Deref for SimpleStrictIdentifierContextAll<'input>{
	type Target = dyn SimpleStrictIdentifierContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use SimpleStrictIdentifierContextAll::*;
		match self{
			SimpleUnquotedIdentifierContext(inner) => inner,
			SimpleQuotedIdentifierAlternativeContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SimpleStrictIdentifierContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SimpleStrictIdentifierContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type SimpleStrictIdentifierContext<'input> = BaseParserRuleContext<'input,SimpleStrictIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct SimpleStrictIdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SimpleStrictIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SimpleStrictIdentifierContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SimpleStrictIdentifierContext<'input>{
}

impl<'input> CustomRuleContext<'input> for SimpleStrictIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_simpleStrictIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_simpleStrictIdentifier }
}
antlr_rust::tid!{SimpleStrictIdentifierContextExt<'a>}

impl<'input> SimpleStrictIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SimpleStrictIdentifierContextAll<'input>> {
		Rc::new(
		SimpleStrictIdentifierContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SimpleStrictIdentifierContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait SimpleStrictIdentifierContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SimpleStrictIdentifierContextExt<'input>>{


}

impl<'input> SimpleStrictIdentifierContextAttrs<'input> for SimpleStrictIdentifierContext<'input>{}

pub type SimpleUnquotedIdentifierContext<'input> = BaseParserRuleContext<'input,SimpleUnquotedIdentifierContextExt<'input>>;

pub trait SimpleUnquotedIdentifierContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token IDENTIFIER
	/// Returns `None` if there is no child corresponding to token IDENTIFIER
	fn IDENTIFIER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(IDENTIFIER, 0)
	}
	fn ansiNonReserved(&self) -> Option<Rc<AnsiNonReservedContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
	fn nonReserved(&self) -> Option<Rc<NonReservedContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SimpleUnquotedIdentifierContextAttrs<'input> for SimpleUnquotedIdentifierContext<'input>{}

pub struct SimpleUnquotedIdentifierContextExt<'input>{
	base:SimpleStrictIdentifierContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SimpleUnquotedIdentifierContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SimpleUnquotedIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SimpleUnquotedIdentifierContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_simpleUnquotedIdentifier(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_simpleUnquotedIdentifier(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SimpleUnquotedIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_simpleUnquotedIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for SimpleUnquotedIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_simpleStrictIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_simpleStrictIdentifier }
}

impl<'input> Borrow<SimpleStrictIdentifierContextExt<'input>> for SimpleUnquotedIdentifierContext<'input>{
	fn borrow(&self) -> &SimpleStrictIdentifierContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<SimpleStrictIdentifierContextExt<'input>> for SimpleUnquotedIdentifierContext<'input>{
	fn borrow_mut(&mut self) -> &mut SimpleStrictIdentifierContextExt<'input> { &mut self.base }
}

impl<'input> SimpleStrictIdentifierContextAttrs<'input> for SimpleUnquotedIdentifierContext<'input> {}

impl<'input> SimpleUnquotedIdentifierContextExt<'input>{
	fn new(ctx: &dyn SimpleStrictIdentifierContextAttrs<'input>) -> Rc<SimpleStrictIdentifierContextAll<'input>>  {
		Rc::new(
			SimpleStrictIdentifierContextAll::SimpleUnquotedIdentifierContext(
				BaseParserRuleContext::copy_from(ctx,SimpleUnquotedIdentifierContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SimpleQuotedIdentifierAlternativeContext<'input> = BaseParserRuleContext<'input,SimpleQuotedIdentifierAlternativeContextExt<'input>>;

pub trait SimpleQuotedIdentifierAlternativeContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn quotedIdentifier(&self) -> Option<Rc<QuotedIdentifierContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> SimpleQuotedIdentifierAlternativeContextAttrs<'input> for SimpleQuotedIdentifierAlternativeContext<'input>{}

pub struct SimpleQuotedIdentifierAlternativeContextExt<'input>{
	base:SimpleStrictIdentifierContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SimpleQuotedIdentifierAlternativeContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SimpleQuotedIdentifierAlternativeContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SimpleQuotedIdentifierAlternativeContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_simpleQuotedIdentifierAlternative(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_simpleQuotedIdentifierAlternative(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SimpleQuotedIdentifierAlternativeContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_simpleQuotedIdentifierAlternative(self);
	}
}

impl<'input> CustomRuleContext<'input> for SimpleQuotedIdentifierAlternativeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_simpleStrictIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_simpleStrictIdentifier }
}

impl<'input> Borrow<SimpleStrictIdentifierContextExt<'input>> for SimpleQuotedIdentifierAlternativeContext<'input>{
	fn borrow(&self) -> &SimpleStrictIdentifierContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<SimpleStrictIdentifierContextExt<'input>> for SimpleQuotedIdentifierAlternativeContext<'input>{
	fn borrow_mut(&mut self) -> &mut SimpleStrictIdentifierContextExt<'input> { &mut self.base }
}

impl<'input> SimpleStrictIdentifierContextAttrs<'input> for SimpleQuotedIdentifierAlternativeContext<'input> {}

impl<'input> SimpleQuotedIdentifierAlternativeContextExt<'input>{
	fn new(ctx: &dyn SimpleStrictIdentifierContextAttrs<'input>) -> Rc<SimpleStrictIdentifierContextAll<'input>>  {
		Rc::new(
			SimpleStrictIdentifierContextAll::SimpleQuotedIdentifierAlternativeContext(
				BaseParserRuleContext::copy_from(ctx,SimpleQuotedIdentifierAlternativeContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn simpleStrictIdentifier(&mut self,)
	-> Result<Rc<SimpleStrictIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SimpleStrictIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 488, RULE_simpleStrictIdentifier);
        let mut _localctx: Rc<SimpleStrictIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4750);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(598,&mut recog.base)? {
				1 =>{
					let tmp = SimpleUnquotedIdentifierContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(4744);
					recog.base.match_token(IDENTIFIER,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = SimpleQuotedIdentifierAlternativeContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule quotedIdentifier*/
					recog.base.set_state(4745);
					recog.quotedIdentifier()?;

					}
				}
			,
				3 =>{
					let tmp = SimpleUnquotedIdentifierContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(4746);
					if !({SQL_standard_keyword_behavior}) {
						Err(FailedPredicateError::new(&mut recog.base, Some("SQL_standard_keyword_behavior".to_owned()), None))?;
					}
					/*InvokeRule ansiNonReserved*/
					recog.base.set_state(4747);
					recog.ansiNonReserved()?;

					}
				}
			,
				4 =>{
					let tmp = SimpleUnquotedIdentifierContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(4748);
					if !({!SQL_standard_keyword_behavior}) {
						Err(FailedPredicateError::new(&mut recog.base, Some("!SQL_standard_keyword_behavior".to_owned()), None))?;
					}
					/*InvokeRule nonReserved*/
					recog.base.set_state(4749);
					recog.nonReserved()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- quotedIdentifier ----------------
pub type QuotedIdentifierContextAll<'input> = QuotedIdentifierContext<'input>;


pub type QuotedIdentifierContext<'input> = BaseParserRuleContext<'input,QuotedIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct QuotedIdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for QuotedIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for QuotedIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_quotedIdentifier(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_quotedIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for QuotedIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_quotedIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for QuotedIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_quotedIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_quotedIdentifier }
}
antlr_rust::tid!{QuotedIdentifierContextExt<'a>}

impl<'input> QuotedIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QuotedIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QuotedIdentifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait QuotedIdentifierContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<QuotedIdentifierContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token BACKQUOTED_IDENTIFIER
/// Returns `None` if there is no child corresponding to token BACKQUOTED_IDENTIFIER
fn BACKQUOTED_IDENTIFIER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BACKQUOTED_IDENTIFIER, 0)
}
/// Retrieves first TerminalNode corresponding to token DOUBLEQUOTED_STRING
/// Returns `None` if there is no child corresponding to token DOUBLEQUOTED_STRING
fn DOUBLEQUOTED_STRING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DOUBLEQUOTED_STRING, 0)
}

}

impl<'input> QuotedIdentifierContextAttrs<'input> for QuotedIdentifierContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn quotedIdentifier(&mut self,)
	-> Result<Rc<QuotedIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QuotedIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 490, RULE_quotedIdentifier);
        let mut _localctx: Rc<QuotedIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4755);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(599,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4752);
					recog.base.match_token(BACKQUOTED_IDENTIFIER,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4753);
					if !({double_quoted_identifiers}) {
						Err(FailedPredicateError::new(&mut recog.base, Some("double_quoted_identifiers".to_owned()), None))?;
					}
					recog.base.set_state(4754);
					recog.base.match_token(DOUBLEQUOTED_STRING,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- backQuotedIdentifier ----------------
pub type BackQuotedIdentifierContextAll<'input> = BackQuotedIdentifierContext<'input>;


pub type BackQuotedIdentifierContext<'input> = BaseParserRuleContext<'input,BackQuotedIdentifierContextExt<'input>>;

#[derive(Clone)]
pub struct BackQuotedIdentifierContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for BackQuotedIdentifierContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for BackQuotedIdentifierContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_backQuotedIdentifier(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_backQuotedIdentifier(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for BackQuotedIdentifierContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_backQuotedIdentifier(self);
	}
}

impl<'input> CustomRuleContext<'input> for BackQuotedIdentifierContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_backQuotedIdentifier }
	//fn type_rule_index() -> usize where Self: Sized { RULE_backQuotedIdentifier }
}
antlr_rust::tid!{BackQuotedIdentifierContextExt<'a>}

impl<'input> BackQuotedIdentifierContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<BackQuotedIdentifierContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,BackQuotedIdentifierContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait BackQuotedIdentifierContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<BackQuotedIdentifierContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token BACKQUOTED_IDENTIFIER
/// Returns `None` if there is no child corresponding to token BACKQUOTED_IDENTIFIER
fn BACKQUOTED_IDENTIFIER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BACKQUOTED_IDENTIFIER, 0)
}

}

impl<'input> BackQuotedIdentifierContextAttrs<'input> for BackQuotedIdentifierContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn backQuotedIdentifier(&mut self,)
	-> Result<Rc<BackQuotedIdentifierContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = BackQuotedIdentifierContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 492, RULE_backQuotedIdentifier);
        let mut _localctx: Rc<BackQuotedIdentifierContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4757);
			recog.base.match_token(BACKQUOTED_IDENTIFIER,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- number ----------------
#[derive(Debug)]
pub enum NumberContextAll<'input>{
	DecimalLiteralContext(DecimalLiteralContext<'input>),
	BigIntLiteralContext(BigIntLiteralContext<'input>),
	TinyIntLiteralContext(TinyIntLiteralContext<'input>),
	LegacyDecimalLiteralContext(LegacyDecimalLiteralContext<'input>),
	BigDecimalLiteralContext(BigDecimalLiteralContext<'input>),
	ExponentLiteralContext(ExponentLiteralContext<'input>),
	DoubleLiteralContext(DoubleLiteralContext<'input>),
	IntegerLiteralContext(IntegerLiteralContext<'input>),
	FloatLiteralContext(FloatLiteralContext<'input>),
	SmallIntLiteralContext(SmallIntLiteralContext<'input>),
Error(NumberContext<'input>)
}
antlr_rust::tid!{NumberContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for NumberContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for NumberContextAll<'input>{}

impl<'input> Deref for NumberContextAll<'input>{
	type Target = dyn NumberContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use NumberContextAll::*;
		match self{
			DecimalLiteralContext(inner) => inner,
			BigIntLiteralContext(inner) => inner,
			TinyIntLiteralContext(inner) => inner,
			LegacyDecimalLiteralContext(inner) => inner,
			BigDecimalLiteralContext(inner) => inner,
			ExponentLiteralContext(inner) => inner,
			DoubleLiteralContext(inner) => inner,
			IntegerLiteralContext(inner) => inner,
			FloatLiteralContext(inner) => inner,
			SmallIntLiteralContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for NumberContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for NumberContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type NumberContext<'input> = BaseParserRuleContext<'input,NumberContextExt<'input>>;

#[derive(Clone)]
pub struct NumberContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for NumberContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for NumberContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for NumberContext<'input>{
}

impl<'input> CustomRuleContext<'input> for NumberContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}
antlr_rust::tid!{NumberContextExt<'a>}

impl<'input> NumberContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NumberContextAll<'input>> {
		Rc::new(
		NumberContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NumberContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait NumberContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<NumberContextExt<'input>>{


}

impl<'input> NumberContextAttrs<'input> for NumberContext<'input>{}

pub type DecimalLiteralContext<'input> = BaseParserRuleContext<'input,DecimalLiteralContextExt<'input>>;

pub trait DecimalLiteralContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DECIMAL_VALUE
	/// Returns `None` if there is no child corresponding to token DECIMAL_VALUE
	fn DECIMAL_VALUE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DECIMAL_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
}

impl<'input> DecimalLiteralContextAttrs<'input> for DecimalLiteralContext<'input>{}

pub struct DecimalLiteralContextExt<'input>{
	base:NumberContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DecimalLiteralContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for DecimalLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DecimalLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_decimalLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_decimalLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DecimalLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_decimalLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for DecimalLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}

impl<'input> Borrow<NumberContextExt<'input>> for DecimalLiteralContext<'input>{
	fn borrow(&self) -> &NumberContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NumberContextExt<'input>> for DecimalLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut NumberContextExt<'input> { &mut self.base }
}

impl<'input> NumberContextAttrs<'input> for DecimalLiteralContext<'input> {}

impl<'input> DecimalLiteralContextExt<'input>{
	fn new(ctx: &dyn NumberContextAttrs<'input>) -> Rc<NumberContextAll<'input>>  {
		Rc::new(
			NumberContextAll::DecimalLiteralContext(
				BaseParserRuleContext::copy_from(ctx,DecimalLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BigIntLiteralContext<'input> = BaseParserRuleContext<'input,BigIntLiteralContextExt<'input>>;

pub trait BigIntLiteralContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token BIGINT_LITERAL
	/// Returns `None` if there is no child corresponding to token BIGINT_LITERAL
	fn BIGINT_LITERAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(BIGINT_LITERAL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
}

impl<'input> BigIntLiteralContextAttrs<'input> for BigIntLiteralContext<'input>{}

pub struct BigIntLiteralContextExt<'input>{
	base:NumberContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BigIntLiteralContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for BigIntLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for BigIntLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_bigIntLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_bigIntLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for BigIntLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_bigIntLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for BigIntLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}

impl<'input> Borrow<NumberContextExt<'input>> for BigIntLiteralContext<'input>{
	fn borrow(&self) -> &NumberContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NumberContextExt<'input>> for BigIntLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut NumberContextExt<'input> { &mut self.base }
}

impl<'input> NumberContextAttrs<'input> for BigIntLiteralContext<'input> {}

impl<'input> BigIntLiteralContextExt<'input>{
	fn new(ctx: &dyn NumberContextAttrs<'input>) -> Rc<NumberContextAll<'input>>  {
		Rc::new(
			NumberContextAll::BigIntLiteralContext(
				BaseParserRuleContext::copy_from(ctx,BigIntLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type TinyIntLiteralContext<'input> = BaseParserRuleContext<'input,TinyIntLiteralContextExt<'input>>;

pub trait TinyIntLiteralContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token TINYINT_LITERAL
	/// Returns `None` if there is no child corresponding to token TINYINT_LITERAL
	fn TINYINT_LITERAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(TINYINT_LITERAL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
}

impl<'input> TinyIntLiteralContextAttrs<'input> for TinyIntLiteralContext<'input>{}

pub struct TinyIntLiteralContextExt<'input>{
	base:NumberContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{TinyIntLiteralContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for TinyIntLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for TinyIntLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_tinyIntLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_tinyIntLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for TinyIntLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_tinyIntLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for TinyIntLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}

impl<'input> Borrow<NumberContextExt<'input>> for TinyIntLiteralContext<'input>{
	fn borrow(&self) -> &NumberContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NumberContextExt<'input>> for TinyIntLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut NumberContextExt<'input> { &mut self.base }
}

impl<'input> NumberContextAttrs<'input> for TinyIntLiteralContext<'input> {}

impl<'input> TinyIntLiteralContextExt<'input>{
	fn new(ctx: &dyn NumberContextAttrs<'input>) -> Rc<NumberContextAll<'input>>  {
		Rc::new(
			NumberContextAll::TinyIntLiteralContext(
				BaseParserRuleContext::copy_from(ctx,TinyIntLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type LegacyDecimalLiteralContext<'input> = BaseParserRuleContext<'input,LegacyDecimalLiteralContextExt<'input>>;

pub trait LegacyDecimalLiteralContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token EXPONENT_VALUE
	/// Returns `None` if there is no child corresponding to token EXPONENT_VALUE
	fn EXPONENT_VALUE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXPONENT_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token DECIMAL_VALUE
	/// Returns `None` if there is no child corresponding to token DECIMAL_VALUE
	fn DECIMAL_VALUE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DECIMAL_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
}

impl<'input> LegacyDecimalLiteralContextAttrs<'input> for LegacyDecimalLiteralContext<'input>{}

pub struct LegacyDecimalLiteralContextExt<'input>{
	base:NumberContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{LegacyDecimalLiteralContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for LegacyDecimalLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for LegacyDecimalLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_legacyDecimalLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_legacyDecimalLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for LegacyDecimalLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_legacyDecimalLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for LegacyDecimalLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}

impl<'input> Borrow<NumberContextExt<'input>> for LegacyDecimalLiteralContext<'input>{
	fn borrow(&self) -> &NumberContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NumberContextExt<'input>> for LegacyDecimalLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut NumberContextExt<'input> { &mut self.base }
}

impl<'input> NumberContextAttrs<'input> for LegacyDecimalLiteralContext<'input> {}

impl<'input> LegacyDecimalLiteralContextExt<'input>{
	fn new(ctx: &dyn NumberContextAttrs<'input>) -> Rc<NumberContextAll<'input>>  {
		Rc::new(
			NumberContextAll::LegacyDecimalLiteralContext(
				BaseParserRuleContext::copy_from(ctx,LegacyDecimalLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type BigDecimalLiteralContext<'input> = BaseParserRuleContext<'input,BigDecimalLiteralContextExt<'input>>;

pub trait BigDecimalLiteralContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token BIGDECIMAL_LITERAL
	/// Returns `None` if there is no child corresponding to token BIGDECIMAL_LITERAL
	fn BIGDECIMAL_LITERAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(BIGDECIMAL_LITERAL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
}

impl<'input> BigDecimalLiteralContextAttrs<'input> for BigDecimalLiteralContext<'input>{}

pub struct BigDecimalLiteralContextExt<'input>{
	base:NumberContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{BigDecimalLiteralContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for BigDecimalLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for BigDecimalLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_bigDecimalLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_bigDecimalLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for BigDecimalLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_bigDecimalLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for BigDecimalLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}

impl<'input> Borrow<NumberContextExt<'input>> for BigDecimalLiteralContext<'input>{
	fn borrow(&self) -> &NumberContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NumberContextExt<'input>> for BigDecimalLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut NumberContextExt<'input> { &mut self.base }
}

impl<'input> NumberContextAttrs<'input> for BigDecimalLiteralContext<'input> {}

impl<'input> BigDecimalLiteralContextExt<'input>{
	fn new(ctx: &dyn NumberContextAttrs<'input>) -> Rc<NumberContextAll<'input>>  {
		Rc::new(
			NumberContextAll::BigDecimalLiteralContext(
				BaseParserRuleContext::copy_from(ctx,BigDecimalLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type ExponentLiteralContext<'input> = BaseParserRuleContext<'input,ExponentLiteralContextExt<'input>>;

pub trait ExponentLiteralContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token EXPONENT_VALUE
	/// Returns `None` if there is no child corresponding to token EXPONENT_VALUE
	fn EXPONENT_VALUE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(EXPONENT_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
}

impl<'input> ExponentLiteralContextAttrs<'input> for ExponentLiteralContext<'input>{}

pub struct ExponentLiteralContextExt<'input>{
	base:NumberContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ExponentLiteralContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ExponentLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ExponentLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_exponentLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_exponentLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ExponentLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_exponentLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExponentLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}

impl<'input> Borrow<NumberContextExt<'input>> for ExponentLiteralContext<'input>{
	fn borrow(&self) -> &NumberContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NumberContextExt<'input>> for ExponentLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut NumberContextExt<'input> { &mut self.base }
}

impl<'input> NumberContextAttrs<'input> for ExponentLiteralContext<'input> {}

impl<'input> ExponentLiteralContextExt<'input>{
	fn new(ctx: &dyn NumberContextAttrs<'input>) -> Rc<NumberContextAll<'input>>  {
		Rc::new(
			NumberContextAll::ExponentLiteralContext(
				BaseParserRuleContext::copy_from(ctx,ExponentLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type DoubleLiteralContext<'input> = BaseParserRuleContext<'input,DoubleLiteralContextExt<'input>>;

pub trait DoubleLiteralContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DOUBLE_LITERAL
	/// Returns `None` if there is no child corresponding to token DOUBLE_LITERAL
	fn DOUBLE_LITERAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DOUBLE_LITERAL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
}

impl<'input> DoubleLiteralContextAttrs<'input> for DoubleLiteralContext<'input>{}

pub struct DoubleLiteralContextExt<'input>{
	base:NumberContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{DoubleLiteralContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for DoubleLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for DoubleLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_doubleLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_doubleLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for DoubleLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_doubleLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for DoubleLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}

impl<'input> Borrow<NumberContextExt<'input>> for DoubleLiteralContext<'input>{
	fn borrow(&self) -> &NumberContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NumberContextExt<'input>> for DoubleLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut NumberContextExt<'input> { &mut self.base }
}

impl<'input> NumberContextAttrs<'input> for DoubleLiteralContext<'input> {}

impl<'input> DoubleLiteralContextExt<'input>{
	fn new(ctx: &dyn NumberContextAttrs<'input>) -> Rc<NumberContextAll<'input>>  {
		Rc::new(
			NumberContextAll::DoubleLiteralContext(
				BaseParserRuleContext::copy_from(ctx,DoubleLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type IntegerLiteralContext<'input> = BaseParserRuleContext<'input,IntegerLiteralContextExt<'input>>;

pub trait IntegerLiteralContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
	/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
	fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(INTEGER_VALUE, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
}

impl<'input> IntegerLiteralContextAttrs<'input> for IntegerLiteralContext<'input>{}

pub struct IntegerLiteralContextExt<'input>{
	base:NumberContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{IntegerLiteralContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for IntegerLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for IntegerLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_integerLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_integerLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for IntegerLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_integerLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for IntegerLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}

impl<'input> Borrow<NumberContextExt<'input>> for IntegerLiteralContext<'input>{
	fn borrow(&self) -> &NumberContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NumberContextExt<'input>> for IntegerLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut NumberContextExt<'input> { &mut self.base }
}

impl<'input> NumberContextAttrs<'input> for IntegerLiteralContext<'input> {}

impl<'input> IntegerLiteralContextExt<'input>{
	fn new(ctx: &dyn NumberContextAttrs<'input>) -> Rc<NumberContextAll<'input>>  {
		Rc::new(
			NumberContextAll::IntegerLiteralContext(
				BaseParserRuleContext::copy_from(ctx,IntegerLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type FloatLiteralContext<'input> = BaseParserRuleContext<'input,FloatLiteralContextExt<'input>>;

pub trait FloatLiteralContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token FLOAT_LITERAL
	/// Returns `None` if there is no child corresponding to token FLOAT_LITERAL
	fn FLOAT_LITERAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(FLOAT_LITERAL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
}

impl<'input> FloatLiteralContextAttrs<'input> for FloatLiteralContext<'input>{}

pub struct FloatLiteralContextExt<'input>{
	base:NumberContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{FloatLiteralContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for FloatLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for FloatLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_floatLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_floatLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for FloatLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_floatLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for FloatLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}

impl<'input> Borrow<NumberContextExt<'input>> for FloatLiteralContext<'input>{
	fn borrow(&self) -> &NumberContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NumberContextExt<'input>> for FloatLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut NumberContextExt<'input> { &mut self.base }
}

impl<'input> NumberContextAttrs<'input> for FloatLiteralContext<'input> {}

impl<'input> FloatLiteralContextExt<'input>{
	fn new(ctx: &dyn NumberContextAttrs<'input>) -> Rc<NumberContextAll<'input>>  {
		Rc::new(
			NumberContextAll::FloatLiteralContext(
				BaseParserRuleContext::copy_from(ctx,FloatLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SmallIntLiteralContext<'input> = BaseParserRuleContext<'input,SmallIntLiteralContextExt<'input>>;

pub trait SmallIntLiteralContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token SMALLINT_LITERAL
	/// Returns `None` if there is no child corresponding to token SMALLINT_LITERAL
	fn SMALLINT_LITERAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(SMALLINT_LITERAL, 0)
	}
	/// Retrieves first TerminalNode corresponding to token MINUS
	/// Returns `None` if there is no child corresponding to token MINUS
	fn MINUS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(MINUS, 0)
	}
}

impl<'input> SmallIntLiteralContextAttrs<'input> for SmallIntLiteralContext<'input>{}

pub struct SmallIntLiteralContextExt<'input>{
	base:NumberContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SmallIntLiteralContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SmallIntLiteralContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SmallIntLiteralContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_smallIntLiteral(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_smallIntLiteral(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SmallIntLiteralContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_smallIntLiteral(self);
	}
}

impl<'input> CustomRuleContext<'input> for SmallIntLiteralContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_number }
	//fn type_rule_index() -> usize where Self: Sized { RULE_number }
}

impl<'input> Borrow<NumberContextExt<'input>> for SmallIntLiteralContext<'input>{
	fn borrow(&self) -> &NumberContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<NumberContextExt<'input>> for SmallIntLiteralContext<'input>{
	fn borrow_mut(&mut self) -> &mut NumberContextExt<'input> { &mut self.base }
}

impl<'input> NumberContextAttrs<'input> for SmallIntLiteralContext<'input> {}

impl<'input> SmallIntLiteralContextExt<'input>{
	fn new(ctx: &dyn NumberContextAttrs<'input>) -> Rc<NumberContextAll<'input>>  {
		Rc::new(
			NumberContextAll::SmallIntLiteralContext(
				BaseParserRuleContext::copy_from(ctx,SmallIntLiteralContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn number(&mut self,)
	-> Result<Rc<NumberContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NumberContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 494, RULE_number);
        let mut _localctx: Rc<NumberContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4802);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(610,&mut recog.base)? {
				1 =>{
					let tmp = ExponentLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(4759);
					if !({!legacy_exponent_literal_as_decimal_enabled}) {
						Err(FailedPredicateError::new(&mut recog.base, Some("!legacy_exponent_literal_as_decimal_enabled".to_owned()), None))?;
					}
					recog.base.set_state(4761);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MINUS {
						{
						recog.base.set_state(4760);
						recog.base.match_token(MINUS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(4763);
					recog.base.match_token(EXPONENT_VALUE,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = DecimalLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(4764);
					if !({!legacy_exponent_literal_as_decimal_enabled}) {
						Err(FailedPredicateError::new(&mut recog.base, Some("!legacy_exponent_literal_as_decimal_enabled".to_owned()), None))?;
					}
					recog.base.set_state(4766);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MINUS {
						{
						recog.base.set_state(4765);
						recog.base.match_token(MINUS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(4768);
					recog.base.match_token(DECIMAL_VALUE,&mut recog.err_handler)?;

					}
				}
			,
				3 =>{
					let tmp = LegacyDecimalLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 3);
					_localctx = tmp;
					{
					recog.base.set_state(4769);
					if !({legacy_exponent_literal_as_decimal_enabled}) {
						Err(FailedPredicateError::new(&mut recog.base, Some("legacy_exponent_literal_as_decimal_enabled".to_owned()), None))?;
					}
					recog.base.set_state(4771);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MINUS {
						{
						recog.base.set_state(4770);
						recog.base.match_token(MINUS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(4773);
					_la = recog.base.input.la(1);
					if { !(_la==EXPONENT_VALUE || _la==DECIMAL_VALUE) } {
						recog.err_handler.recover_inline(&mut recog.base)?;

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					}
				}
			,
				4 =>{
					let tmp = IntegerLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 4);
					_localctx = tmp;
					{
					recog.base.set_state(4775);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MINUS {
						{
						recog.base.set_state(4774);
						recog.base.match_token(MINUS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(4777);
					recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;

					}
				}
			,
				5 =>{
					let tmp = BigIntLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 5);
					_localctx = tmp;
					{
					recog.base.set_state(4779);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MINUS {
						{
						recog.base.set_state(4778);
						recog.base.match_token(MINUS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(4781);
					recog.base.match_token(BIGINT_LITERAL,&mut recog.err_handler)?;

					}
				}
			,
				6 =>{
					let tmp = SmallIntLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 6);
					_localctx = tmp;
					{
					recog.base.set_state(4783);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MINUS {
						{
						recog.base.set_state(4782);
						recog.base.match_token(MINUS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(4785);
					recog.base.match_token(SMALLINT_LITERAL,&mut recog.err_handler)?;

					}
				}
			,
				7 =>{
					let tmp = TinyIntLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 7);
					_localctx = tmp;
					{
					recog.base.set_state(4787);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MINUS {
						{
						recog.base.set_state(4786);
						recog.base.match_token(MINUS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(4789);
					recog.base.match_token(TINYINT_LITERAL,&mut recog.err_handler)?;

					}
				}
			,
				8 =>{
					let tmp = DoubleLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 8);
					_localctx = tmp;
					{
					recog.base.set_state(4791);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MINUS {
						{
						recog.base.set_state(4790);
						recog.base.match_token(MINUS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(4793);
					recog.base.match_token(DOUBLE_LITERAL,&mut recog.err_handler)?;

					}
				}
			,
				9 =>{
					let tmp = FloatLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 9);
					_localctx = tmp;
					{
					recog.base.set_state(4795);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MINUS {
						{
						recog.base.set_state(4794);
						recog.base.match_token(MINUS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(4797);
					recog.base.match_token(FLOAT_LITERAL,&mut recog.err_handler)?;

					}
				}
			,
				10 =>{
					let tmp = BigDecimalLiteralContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 10);
					_localctx = tmp;
					{
					recog.base.set_state(4799);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==MINUS {
						{
						recog.base.set_state(4798);
						recog.base.match_token(MINUS,&mut recog.err_handler)?;

						}
					}

					recog.base.set_state(4801);
					recog.base.match_token(BIGDECIMAL_LITERAL,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- integerValue ----------------
#[derive(Debug)]
pub enum IntegerValueContextAll<'input>{
	ParameterIntegerValueContext(ParameterIntegerValueContext<'input>),
	IntegerValContext(IntegerValContext<'input>),
Error(IntegerValueContext<'input>)
}
antlr_rust::tid!{IntegerValueContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for IntegerValueContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for IntegerValueContextAll<'input>{}

impl<'input> Deref for IntegerValueContextAll<'input>{
	type Target = dyn IntegerValueContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use IntegerValueContextAll::*;
		match self{
			ParameterIntegerValueContext(inner) => inner,
			IntegerValContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for IntegerValueContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for IntegerValueContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type IntegerValueContext<'input> = BaseParserRuleContext<'input,IntegerValueContextExt<'input>>;

#[derive(Clone)]
pub struct IntegerValueContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for IntegerValueContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for IntegerValueContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for IntegerValueContext<'input>{
}

impl<'input> CustomRuleContext<'input> for IntegerValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_integerValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_integerValue }
}
antlr_rust::tid!{IntegerValueContextExt<'a>}

impl<'input> IntegerValueContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IntegerValueContextAll<'input>> {
		Rc::new(
		IntegerValueContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IntegerValueContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait IntegerValueContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<IntegerValueContextExt<'input>>{


}

impl<'input> IntegerValueContextAttrs<'input> for IntegerValueContext<'input>{}

pub type ParameterIntegerValueContext<'input> = BaseParserRuleContext<'input,ParameterIntegerValueContextExt<'input>>;

pub trait ParameterIntegerValueContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn parameterMarker(&self) -> Option<Rc<ParameterMarkerContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> ParameterIntegerValueContextAttrs<'input> for ParameterIntegerValueContext<'input>{}

pub struct ParameterIntegerValueContextExt<'input>{
	base:IntegerValueContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{ParameterIntegerValueContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for ParameterIntegerValueContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ParameterIntegerValueContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_parameterIntegerValue(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_parameterIntegerValue(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ParameterIntegerValueContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_parameterIntegerValue(self);
	}
}

impl<'input> CustomRuleContext<'input> for ParameterIntegerValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_integerValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_integerValue }
}

impl<'input> Borrow<IntegerValueContextExt<'input>> for ParameterIntegerValueContext<'input>{
	fn borrow(&self) -> &IntegerValueContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<IntegerValueContextExt<'input>> for ParameterIntegerValueContext<'input>{
	fn borrow_mut(&mut self) -> &mut IntegerValueContextExt<'input> { &mut self.base }
}

impl<'input> IntegerValueContextAttrs<'input> for ParameterIntegerValueContext<'input> {}

impl<'input> ParameterIntegerValueContextExt<'input>{
	fn new(ctx: &dyn IntegerValueContextAttrs<'input>) -> Rc<IntegerValueContextAll<'input>>  {
		Rc::new(
			IntegerValueContextAll::ParameterIntegerValueContext(
				BaseParserRuleContext::copy_from(ctx,ParameterIntegerValueContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type IntegerValContext<'input> = BaseParserRuleContext<'input,IntegerValContextExt<'input>>;

pub trait IntegerValContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
	/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
	fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(INTEGER_VALUE, 0)
	}
}

impl<'input> IntegerValContextAttrs<'input> for IntegerValContext<'input>{}

pub struct IntegerValContextExt<'input>{
	base:IntegerValueContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{IntegerValContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for IntegerValContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for IntegerValContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_integerVal(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_integerVal(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for IntegerValContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_integerVal(self);
	}
}

impl<'input> CustomRuleContext<'input> for IntegerValContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_integerValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_integerValue }
}

impl<'input> Borrow<IntegerValueContextExt<'input>> for IntegerValContext<'input>{
	fn borrow(&self) -> &IntegerValueContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<IntegerValueContextExt<'input>> for IntegerValContext<'input>{
	fn borrow_mut(&mut self) -> &mut IntegerValueContextExt<'input> { &mut self.base }
}

impl<'input> IntegerValueContextAttrs<'input> for IntegerValContext<'input> {}

impl<'input> IntegerValContextExt<'input>{
	fn new(ctx: &dyn IntegerValueContextAttrs<'input>) -> Rc<IntegerValueContextAll<'input>>  {
		Rc::new(
			IntegerValueContextAll::IntegerValContext(
				BaseParserRuleContext::copy_from(ctx,IntegerValContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn integerValue(&mut self,)
	-> Result<Rc<IntegerValueContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IntegerValueContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 496, RULE_integerValue);
        let mut _localctx: Rc<IntegerValueContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4806);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(611,&mut recog.base)? {
				1 =>{
					let tmp = IntegerValContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(4804);
					recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = ParameterIntegerValueContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					/*InvokeRule parameterMarker*/
					recog.base.set_state(4805);
					recog.parameterMarker()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnConstraintDefinition ----------------
pub type ColumnConstraintDefinitionContextAll<'input> = ColumnConstraintDefinitionContext<'input>;


pub type ColumnConstraintDefinitionContext<'input> = BaseParserRuleContext<'input,ColumnConstraintDefinitionContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnConstraintDefinitionContextExt<'input>{
	pub name: Option<Rc<ErrorCapturingIdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ColumnConstraintDefinitionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ColumnConstraintDefinitionContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnConstraintDefinition(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_columnConstraintDefinition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ColumnConstraintDefinitionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_columnConstraintDefinition(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnConstraintDefinitionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnConstraintDefinition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnConstraintDefinition }
}
antlr_rust::tid!{ColumnConstraintDefinitionContextExt<'a>}

impl<'input> ColumnConstraintDefinitionContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnConstraintDefinitionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnConstraintDefinitionContextExt{
				name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnConstraintDefinitionContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ColumnConstraintDefinitionContextExt<'input>>{

fn columnConstraint(&self) -> Option<Rc<ColumnConstraintContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token CONSTRAINT
/// Returns `None` if there is no child corresponding to token CONSTRAINT
fn CONSTRAINT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CONSTRAINT, 0)
}
fn constraintCharacteristic_all(&self) ->  Vec<Rc<ConstraintCharacteristicContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn constraintCharacteristic(&self, i: usize) -> Option<Rc<ConstraintCharacteristicContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn errorCapturingIdentifier(&self) -> Option<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColumnConstraintDefinitionContextAttrs<'input> for ColumnConstraintDefinitionContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnConstraintDefinition(&mut self,)
	-> Result<Rc<ColumnConstraintDefinitionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnConstraintDefinitionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 498, RULE_columnConstraintDefinition);
        let mut _localctx: Rc<ColumnConstraintDefinitionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4810);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==CONSTRAINT {
				{
				recog.base.set_state(4808);
				recog.base.match_token(CONSTRAINT,&mut recog.err_handler)?;

				/*InvokeRule errorCapturingIdentifier*/
				recog.base.set_state(4809);
				let tmp = recog.errorCapturingIdentifier()?;
				 cast_mut::<_,ColumnConstraintDefinitionContext >(&mut _localctx).name = Some(tmp.clone());
				  

				}
			}

			/*InvokeRule columnConstraint*/
			recog.base.set_state(4812);
			recog.columnConstraint()?;

			recog.base.set_state(4816);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(613,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					/*InvokeRule constraintCharacteristic*/
					recog.base.set_state(4813);
					recog.constraintCharacteristic()?;

					}
					} 
				}
				recog.base.set_state(4818);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(613,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- columnConstraint ----------------
pub type ColumnConstraintContextAll<'input> = ColumnConstraintContext<'input>;


pub type ColumnConstraintContext<'input> = BaseParserRuleContext<'input,ColumnConstraintContextExt<'input>>;

#[derive(Clone)]
pub struct ColumnConstraintContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ColumnConstraintContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ColumnConstraintContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_columnConstraint(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_columnConstraint(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ColumnConstraintContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_columnConstraint(self);
	}
}

impl<'input> CustomRuleContext<'input> for ColumnConstraintContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_columnConstraint }
	//fn type_rule_index() -> usize where Self: Sized { RULE_columnConstraint }
}
antlr_rust::tid!{ColumnConstraintContextExt<'a>}

impl<'input> ColumnConstraintContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ColumnConstraintContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ColumnConstraintContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ColumnConstraintContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ColumnConstraintContextExt<'input>>{

fn checkConstraint(&self) -> Option<Rc<CheckConstraintContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn uniqueSpec(&self) -> Option<Rc<UniqueSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn referenceSpec(&self) -> Option<Rc<ReferenceSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ColumnConstraintContextAttrs<'input> for ColumnConstraintContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn columnConstraint(&mut self,)
	-> Result<Rc<ColumnConstraintContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ColumnConstraintContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 500, RULE_columnConstraint);
        let mut _localctx: Rc<ColumnConstraintContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4822);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 CHECK 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule checkConstraint*/
					recog.base.set_state(4819);
					recog.checkConstraint()?;

					}
				}

			 PRIMARY | UNIQUE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule uniqueSpec*/
					recog.base.set_state(4820);
					recog.uniqueSpec()?;

					}
				}

			 REFERENCES 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule referenceSpec*/
					recog.base.set_state(4821);
					recog.referenceSpec()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableConstraintDefinition ----------------
pub type TableConstraintDefinitionContextAll<'input> = TableConstraintDefinitionContext<'input>;


pub type TableConstraintDefinitionContext<'input> = BaseParserRuleContext<'input,TableConstraintDefinitionContextExt<'input>>;

#[derive(Clone)]
pub struct TableConstraintDefinitionContextExt<'input>{
	pub name: Option<Rc<ErrorCapturingIdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for TableConstraintDefinitionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for TableConstraintDefinitionContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableConstraintDefinition(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_tableConstraintDefinition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for TableConstraintDefinitionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_tableConstraintDefinition(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableConstraintDefinitionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableConstraintDefinition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableConstraintDefinition }
}
antlr_rust::tid!{TableConstraintDefinitionContextExt<'a>}

impl<'input> TableConstraintDefinitionContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableConstraintDefinitionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableConstraintDefinitionContextExt{
				name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TableConstraintDefinitionContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<TableConstraintDefinitionContextExt<'input>>{

fn tableConstraint(&self) -> Option<Rc<TableConstraintContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token CONSTRAINT
/// Returns `None` if there is no child corresponding to token CONSTRAINT
fn CONSTRAINT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CONSTRAINT, 0)
}
fn constraintCharacteristic_all(&self) ->  Vec<Rc<ConstraintCharacteristicContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn constraintCharacteristic(&self, i: usize) -> Option<Rc<ConstraintCharacteristicContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn errorCapturingIdentifier(&self) -> Option<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TableConstraintDefinitionContextAttrs<'input> for TableConstraintDefinitionContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableConstraintDefinition(&mut self,)
	-> Result<Rc<TableConstraintDefinitionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableConstraintDefinitionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 502, RULE_tableConstraintDefinition);
        let mut _localctx: Rc<TableConstraintDefinitionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4826);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==CONSTRAINT {
				{
				recog.base.set_state(4824);
				recog.base.match_token(CONSTRAINT,&mut recog.err_handler)?;

				/*InvokeRule errorCapturingIdentifier*/
				recog.base.set_state(4825);
				let tmp = recog.errorCapturingIdentifier()?;
				 cast_mut::<_,TableConstraintDefinitionContext >(&mut _localctx).name = Some(tmp.clone());
				  

				}
			}

			/*InvokeRule tableConstraint*/
			recog.base.set_state(4828);
			recog.tableConstraint()?;

			recog.base.set_state(4832);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==ENFORCED || _la==NOT || _la==NORELY || _la==RELY {
				{
				{
				/*InvokeRule constraintCharacteristic*/
				recog.base.set_state(4829);
				recog.constraintCharacteristic()?;

				}
				}
				recog.base.set_state(4834);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tableConstraint ----------------
pub type TableConstraintContextAll<'input> = TableConstraintContext<'input>;


pub type TableConstraintContext<'input> = BaseParserRuleContext<'input,TableConstraintContextExt<'input>>;

#[derive(Clone)]
pub struct TableConstraintContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for TableConstraintContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for TableConstraintContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tableConstraint(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_tableConstraint(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for TableConstraintContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_tableConstraint(self);
	}
}

impl<'input> CustomRuleContext<'input> for TableConstraintContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tableConstraint }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tableConstraint }
}
antlr_rust::tid!{TableConstraintContextExt<'a>}

impl<'input> TableConstraintContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TableConstraintContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TableConstraintContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TableConstraintContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<TableConstraintContextExt<'input>>{

fn checkConstraint(&self) -> Option<Rc<CheckConstraintContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn uniqueConstraint(&self) -> Option<Rc<UniqueConstraintContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn foreignKeyConstraint(&self) -> Option<Rc<ForeignKeyConstraintContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TableConstraintContextAttrs<'input> for TableConstraintContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tableConstraint(&mut self,)
	-> Result<Rc<TableConstraintContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TableConstraintContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 504, RULE_tableConstraint);
        let mut _localctx: Rc<TableConstraintContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4838);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 CHECK 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule checkConstraint*/
					recog.base.set_state(4835);
					recog.checkConstraint()?;

					}
				}

			 PRIMARY | UNIQUE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule uniqueConstraint*/
					recog.base.set_state(4836);
					recog.uniqueConstraint()?;

					}
				}

			 FOREIGN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule foreignKeyConstraint*/
					recog.base.set_state(4837);
					recog.foreignKeyConstraint()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- checkConstraint ----------------
pub type CheckConstraintContextAll<'input> = CheckConstraintContext<'input>;


pub type CheckConstraintContext<'input> = BaseParserRuleContext<'input,CheckConstraintContextExt<'input>>;

#[derive(Clone)]
pub struct CheckConstraintContextExt<'input>{
	pub expr: Option<Rc<BooleanExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for CheckConstraintContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CheckConstraintContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_checkConstraint(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_checkConstraint(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CheckConstraintContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_checkConstraint(self);
	}
}

impl<'input> CustomRuleContext<'input> for CheckConstraintContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_checkConstraint }
	//fn type_rule_index() -> usize where Self: Sized { RULE_checkConstraint }
}
antlr_rust::tid!{CheckConstraintContextExt<'a>}

impl<'input> CheckConstraintContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CheckConstraintContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CheckConstraintContextExt{
				expr: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CheckConstraintContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<CheckConstraintContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token CHECK
/// Returns `None` if there is no child corresponding to token CHECK
fn CHECK(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CHECK, 0)
}
/// Retrieves first TerminalNode corresponding to token LEFT_PAREN
/// Returns `None` if there is no child corresponding to token LEFT_PAREN
fn LEFT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT_PAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT_PAREN
/// Returns `None` if there is no child corresponding to token RIGHT_PAREN
fn RIGHT_PAREN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT_PAREN, 0)
}
fn booleanExpression(&self) -> Option<Rc<BooleanExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CheckConstraintContextAttrs<'input> for CheckConstraintContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn checkConstraint(&mut self,)
	-> Result<Rc<CheckConstraintContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CheckConstraintContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 506, RULE_checkConstraint);
        let mut _localctx: Rc<CheckConstraintContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4840);
			recog.base.match_token(CHECK,&mut recog.err_handler)?;

			recog.base.set_state(4841);
			recog.base.match_token(LEFT_PAREN,&mut recog.err_handler)?;

			{
			/*InvokeRule booleanExpression*/
			recog.base.set_state(4842);
			let tmp = recog.booleanExpression_rec(0)?;
			 cast_mut::<_,CheckConstraintContext >(&mut _localctx).expr = Some(tmp.clone());
			  

			}
			recog.base.set_state(4843);
			recog.base.match_token(RIGHT_PAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- uniqueSpec ----------------
pub type UniqueSpecContextAll<'input> = UniqueSpecContext<'input>;


pub type UniqueSpecContext<'input> = BaseParserRuleContext<'input,UniqueSpecContextExt<'input>>;

#[derive(Clone)]
pub struct UniqueSpecContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for UniqueSpecContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for UniqueSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_uniqueSpec(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_uniqueSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for UniqueSpecContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_uniqueSpec(self);
	}
}

impl<'input> CustomRuleContext<'input> for UniqueSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_uniqueSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_uniqueSpec }
}
antlr_rust::tid!{UniqueSpecContextExt<'a>}

impl<'input> UniqueSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UniqueSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UniqueSpecContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait UniqueSpecContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<UniqueSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token UNIQUE
/// Returns `None` if there is no child corresponding to token UNIQUE
fn UNIQUE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UNIQUE, 0)
}
/// Retrieves first TerminalNode corresponding to token PRIMARY
/// Returns `None` if there is no child corresponding to token PRIMARY
fn PRIMARY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PRIMARY, 0)
}
/// Retrieves first TerminalNode corresponding to token KEY
/// Returns `None` if there is no child corresponding to token KEY
fn KEY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(KEY, 0)
}

}

impl<'input> UniqueSpecContextAttrs<'input> for UniqueSpecContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn uniqueSpec(&mut self,)
	-> Result<Rc<UniqueSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UniqueSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 508, RULE_uniqueSpec);
        let mut _localctx: Rc<UniqueSpecContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4848);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 UNIQUE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4845);
					recog.base.match_token(UNIQUE,&mut recog.err_handler)?;

					}
				}

			 PRIMARY 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4846);
					recog.base.match_token(PRIMARY,&mut recog.err_handler)?;

					recog.base.set_state(4847);
					recog.base.match_token(KEY,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- uniqueConstraint ----------------
pub type UniqueConstraintContextAll<'input> = UniqueConstraintContext<'input>;


pub type UniqueConstraintContext<'input> = BaseParserRuleContext<'input,UniqueConstraintContextExt<'input>>;

#[derive(Clone)]
pub struct UniqueConstraintContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for UniqueConstraintContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for UniqueConstraintContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_uniqueConstraint(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_uniqueConstraint(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for UniqueConstraintContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_uniqueConstraint(self);
	}
}

impl<'input> CustomRuleContext<'input> for UniqueConstraintContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_uniqueConstraint }
	//fn type_rule_index() -> usize where Self: Sized { RULE_uniqueConstraint }
}
antlr_rust::tid!{UniqueConstraintContextExt<'a>}

impl<'input> UniqueConstraintContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UniqueConstraintContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UniqueConstraintContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait UniqueConstraintContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<UniqueConstraintContextExt<'input>>{

fn uniqueSpec(&self) -> Option<Rc<UniqueSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn identifierList(&self) -> Option<Rc<IdentifierListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> UniqueConstraintContextAttrs<'input> for UniqueConstraintContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn uniqueConstraint(&mut self,)
	-> Result<Rc<UniqueConstraintContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UniqueConstraintContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 510, RULE_uniqueConstraint);
        let mut _localctx: Rc<UniqueConstraintContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule uniqueSpec*/
			recog.base.set_state(4850);
			recog.uniqueSpec()?;

			/*InvokeRule identifierList*/
			recog.base.set_state(4851);
			recog.identifierList()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- referenceSpec ----------------
pub type ReferenceSpecContextAll<'input> = ReferenceSpecContext<'input>;


pub type ReferenceSpecContext<'input> = BaseParserRuleContext<'input,ReferenceSpecContextExt<'input>>;

#[derive(Clone)]
pub struct ReferenceSpecContextExt<'input>{
	pub parentColumns: Option<Rc<IdentifierListContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ReferenceSpecContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ReferenceSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_referenceSpec(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_referenceSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ReferenceSpecContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_referenceSpec(self);
	}
}

impl<'input> CustomRuleContext<'input> for ReferenceSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_referenceSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_referenceSpec }
}
antlr_rust::tid!{ReferenceSpecContextExt<'a>}

impl<'input> ReferenceSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ReferenceSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ReferenceSpecContextExt{
				parentColumns: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ReferenceSpecContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ReferenceSpecContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token REFERENCES
/// Returns `None` if there is no child corresponding to token REFERENCES
fn REFERENCES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(REFERENCES, 0)
}
fn multipartIdentifier(&self) -> Option<Rc<MultipartIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn identifierList(&self) -> Option<Rc<IdentifierListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ReferenceSpecContextAttrs<'input> for ReferenceSpecContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn referenceSpec(&mut self,)
	-> Result<Rc<ReferenceSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ReferenceSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 512, RULE_referenceSpec);
        let mut _localctx: Rc<ReferenceSpecContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4853);
			recog.base.match_token(REFERENCES,&mut recog.err_handler)?;

			/*InvokeRule multipartIdentifier*/
			recog.base.set_state(4854);
			recog.multipartIdentifier()?;

			recog.base.set_state(4856);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==LEFT_PAREN {
				{
				/*InvokeRule identifierList*/
				recog.base.set_state(4855);
				let tmp = recog.identifierList()?;
				 cast_mut::<_,ReferenceSpecContext >(&mut _localctx).parentColumns = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- foreignKeyConstraint ----------------
pub type ForeignKeyConstraintContextAll<'input> = ForeignKeyConstraintContext<'input>;


pub type ForeignKeyConstraintContext<'input> = BaseParserRuleContext<'input,ForeignKeyConstraintContextExt<'input>>;

#[derive(Clone)]
pub struct ForeignKeyConstraintContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ForeignKeyConstraintContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ForeignKeyConstraintContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_foreignKeyConstraint(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_foreignKeyConstraint(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ForeignKeyConstraintContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_foreignKeyConstraint(self);
	}
}

impl<'input> CustomRuleContext<'input> for ForeignKeyConstraintContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_foreignKeyConstraint }
	//fn type_rule_index() -> usize where Self: Sized { RULE_foreignKeyConstraint }
}
antlr_rust::tid!{ForeignKeyConstraintContextExt<'a>}

impl<'input> ForeignKeyConstraintContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ForeignKeyConstraintContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ForeignKeyConstraintContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ForeignKeyConstraintContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ForeignKeyConstraintContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token FOREIGN
/// Returns `None` if there is no child corresponding to token FOREIGN
fn FOREIGN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FOREIGN, 0)
}
/// Retrieves first TerminalNode corresponding to token KEY
/// Returns `None` if there is no child corresponding to token KEY
fn KEY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(KEY, 0)
}
fn identifierList(&self) -> Option<Rc<IdentifierListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn referenceSpec(&self) -> Option<Rc<ReferenceSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ForeignKeyConstraintContextAttrs<'input> for ForeignKeyConstraintContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn foreignKeyConstraint(&mut self,)
	-> Result<Rc<ForeignKeyConstraintContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ForeignKeyConstraintContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 514, RULE_foreignKeyConstraint);
        let mut _localctx: Rc<ForeignKeyConstraintContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4858);
			recog.base.match_token(FOREIGN,&mut recog.err_handler)?;

			recog.base.set_state(4859);
			recog.base.match_token(KEY,&mut recog.err_handler)?;

			/*InvokeRule identifierList*/
			recog.base.set_state(4860);
			recog.identifierList()?;

			/*InvokeRule referenceSpec*/
			recog.base.set_state(4861);
			recog.referenceSpec()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- constraintCharacteristic ----------------
pub type ConstraintCharacteristicContextAll<'input> = ConstraintCharacteristicContext<'input>;


pub type ConstraintCharacteristicContext<'input> = BaseParserRuleContext<'input,ConstraintCharacteristicContextExt<'input>>;

#[derive(Clone)]
pub struct ConstraintCharacteristicContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ConstraintCharacteristicContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ConstraintCharacteristicContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_constraintCharacteristic(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_constraintCharacteristic(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ConstraintCharacteristicContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_constraintCharacteristic(self);
	}
}

impl<'input> CustomRuleContext<'input> for ConstraintCharacteristicContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_constraintCharacteristic }
	//fn type_rule_index() -> usize where Self: Sized { RULE_constraintCharacteristic }
}
antlr_rust::tid!{ConstraintCharacteristicContextExt<'a>}

impl<'input> ConstraintCharacteristicContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ConstraintCharacteristicContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ConstraintCharacteristicContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ConstraintCharacteristicContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ConstraintCharacteristicContextExt<'input>>{

fn enforcedCharacteristic(&self) -> Option<Rc<EnforcedCharacteristicContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn relyCharacteristic(&self) -> Option<Rc<RelyCharacteristicContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ConstraintCharacteristicContextAttrs<'input> for ConstraintCharacteristicContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn constraintCharacteristic(&mut self,)
	-> Result<Rc<ConstraintCharacteristicContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ConstraintCharacteristicContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 516, RULE_constraintCharacteristic);
        let mut _localctx: Rc<ConstraintCharacteristicContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4865);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ENFORCED | NOT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule enforcedCharacteristic*/
					recog.base.set_state(4863);
					recog.enforcedCharacteristic()?;

					}
				}

			 NORELY | RELY 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule relyCharacteristic*/
					recog.base.set_state(4864);
					recog.relyCharacteristic()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- enforcedCharacteristic ----------------
pub type EnforcedCharacteristicContextAll<'input> = EnforcedCharacteristicContext<'input>;


pub type EnforcedCharacteristicContext<'input> = BaseParserRuleContext<'input,EnforcedCharacteristicContextExt<'input>>;

#[derive(Clone)]
pub struct EnforcedCharacteristicContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for EnforcedCharacteristicContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for EnforcedCharacteristicContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_enforcedCharacteristic(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_enforcedCharacteristic(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for EnforcedCharacteristicContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_enforcedCharacteristic(self);
	}
}

impl<'input> CustomRuleContext<'input> for EnforcedCharacteristicContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_enforcedCharacteristic }
	//fn type_rule_index() -> usize where Self: Sized { RULE_enforcedCharacteristic }
}
antlr_rust::tid!{EnforcedCharacteristicContextExt<'a>}

impl<'input> EnforcedCharacteristicContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<EnforcedCharacteristicContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,EnforcedCharacteristicContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait EnforcedCharacteristicContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<EnforcedCharacteristicContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ENFORCED
/// Returns `None` if there is no child corresponding to token ENFORCED
fn ENFORCED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ENFORCED, 0)
}
/// Retrieves first TerminalNode corresponding to token NOT
/// Returns `None` if there is no child corresponding to token NOT
fn NOT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NOT, 0)
}

}

impl<'input> EnforcedCharacteristicContextAttrs<'input> for EnforcedCharacteristicContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn enforcedCharacteristic(&mut self,)
	-> Result<Rc<EnforcedCharacteristicContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = EnforcedCharacteristicContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 518, RULE_enforcedCharacteristic);
        let mut _localctx: Rc<EnforcedCharacteristicContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4870);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ENFORCED 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4867);
					recog.base.match_token(ENFORCED,&mut recog.err_handler)?;

					}
				}

			 NOT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4868);
					recog.base.match_token(NOT,&mut recog.err_handler)?;

					recog.base.set_state(4869);
					recog.base.match_token(ENFORCED,&mut recog.err_handler)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- relyCharacteristic ----------------
pub type RelyCharacteristicContextAll<'input> = RelyCharacteristicContext<'input>;


pub type RelyCharacteristicContext<'input> = BaseParserRuleContext<'input,RelyCharacteristicContextExt<'input>>;

#[derive(Clone)]
pub struct RelyCharacteristicContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for RelyCharacteristicContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for RelyCharacteristicContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_relyCharacteristic(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_relyCharacteristic(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for RelyCharacteristicContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_relyCharacteristic(self);
	}
}

impl<'input> CustomRuleContext<'input> for RelyCharacteristicContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relyCharacteristic }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relyCharacteristic }
}
antlr_rust::tid!{RelyCharacteristicContextExt<'a>}

impl<'input> RelyCharacteristicContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RelyCharacteristicContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RelyCharacteristicContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait RelyCharacteristicContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<RelyCharacteristicContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token RELY
/// Returns `None` if there is no child corresponding to token RELY
fn RELY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RELY, 0)
}
/// Retrieves first TerminalNode corresponding to token NORELY
/// Returns `None` if there is no child corresponding to token NORELY
fn NORELY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NORELY, 0)
}

}

impl<'input> RelyCharacteristicContextAttrs<'input> for RelyCharacteristicContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn relyCharacteristic(&mut self,)
	-> Result<Rc<RelyCharacteristicContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RelyCharacteristicContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 520, RULE_relyCharacteristic);
        let mut _localctx: Rc<RelyCharacteristicContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4872);
			_la = recog.base.input.la(1);
			if { !(_la==NORELY || _la==RELY) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterColumnSpecList ----------------
pub type AlterColumnSpecListContextAll<'input> = AlterColumnSpecListContext<'input>;


pub type AlterColumnSpecListContext<'input> = BaseParserRuleContext<'input,AlterColumnSpecListContextExt<'input>>;

#[derive(Clone)]
pub struct AlterColumnSpecListContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for AlterColumnSpecListContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for AlterColumnSpecListContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterColumnSpecList(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_alterColumnSpecList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for AlterColumnSpecListContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_alterColumnSpecList(self);
	}
}

impl<'input> CustomRuleContext<'input> for AlterColumnSpecListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterColumnSpecList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterColumnSpecList }
}
antlr_rust::tid!{AlterColumnSpecListContextExt<'a>}

impl<'input> AlterColumnSpecListContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterColumnSpecListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterColumnSpecListContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterColumnSpecListContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<AlterColumnSpecListContextExt<'input>>{

fn alterColumnSpec_all(&self) ->  Vec<Rc<AlterColumnSpecContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn alterColumnSpec(&self, i: usize) -> Option<Rc<AlterColumnSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> AlterColumnSpecListContextAttrs<'input> for AlterColumnSpecListContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterColumnSpecList(&mut self,)
	-> Result<Rc<AlterColumnSpecListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterColumnSpecListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 522, RULE_alterColumnSpecList);
        let mut _localctx: Rc<AlterColumnSpecListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule alterColumnSpec*/
			recog.base.set_state(4874);
			recog.alterColumnSpec()?;

			recog.base.set_state(4879);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(4875);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule alterColumnSpec*/
				recog.base.set_state(4876);
				recog.alterColumnSpec()?;

				}
				}
				recog.base.set_state(4881);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterColumnSpec ----------------
pub type AlterColumnSpecContextAll<'input> = AlterColumnSpecContext<'input>;


pub type AlterColumnSpecContext<'input> = BaseParserRuleContext<'input,AlterColumnSpecContextExt<'input>>;

#[derive(Clone)]
pub struct AlterColumnSpecContextExt<'input>{
	pub column: Option<Rc<MultipartIdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for AlterColumnSpecContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for AlterColumnSpecContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterColumnSpec(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_alterColumnSpec(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for AlterColumnSpecContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_alterColumnSpec(self);
	}
}

impl<'input> CustomRuleContext<'input> for AlterColumnSpecContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterColumnSpec }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterColumnSpec }
}
antlr_rust::tid!{AlterColumnSpecContextExt<'a>}

impl<'input> AlterColumnSpecContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterColumnSpecContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterColumnSpecContextExt{
				column: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterColumnSpecContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<AlterColumnSpecContextExt<'input>>{

fn multipartIdentifier(&self) -> Option<Rc<MultipartIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn alterColumnAction(&self) -> Option<Rc<AlterColumnActionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AlterColumnSpecContextAttrs<'input> for AlterColumnSpecContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterColumnSpec(&mut self,)
	-> Result<Rc<AlterColumnSpecContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterColumnSpecContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 524, RULE_alterColumnSpec);
        let mut _localctx: Rc<AlterColumnSpecContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule multipartIdentifier*/
			recog.base.set_state(4882);
			let tmp = recog.multipartIdentifier()?;
			 cast_mut::<_,AlterColumnSpecContext >(&mut _localctx).column = Some(tmp.clone());
			  

			recog.base.set_state(4884);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==AFTER || _la==COMMENT || _la==DROP || _la==FIRST || _la==SET || _la==TYPE {
				{
				/*InvokeRule alterColumnAction*/
				recog.base.set_state(4883);
				recog.alterColumnAction()?;

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- alterColumnAction ----------------
pub type AlterColumnActionContextAll<'input> = AlterColumnActionContext<'input>;


pub type AlterColumnActionContext<'input> = BaseParserRuleContext<'input,AlterColumnActionContextExt<'input>>;

#[derive(Clone)]
pub struct AlterColumnActionContextExt<'input>{
	pub setOrDrop: Option<TokenType<'input>>,
	pub dropDefault: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for AlterColumnActionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for AlterColumnActionContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_alterColumnAction(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_alterColumnAction(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for AlterColumnActionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_alterColumnAction(self);
	}
}

impl<'input> CustomRuleContext<'input> for AlterColumnActionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_alterColumnAction }
	//fn type_rule_index() -> usize where Self: Sized { RULE_alterColumnAction }
}
antlr_rust::tid!{AlterColumnActionContextExt<'a>}

impl<'input> AlterColumnActionContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AlterColumnActionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AlterColumnActionContextExt{
				setOrDrop: None, dropDefault: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AlterColumnActionContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<AlterColumnActionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token TYPE
/// Returns `None` if there is no child corresponding to token TYPE
fn TYPE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TYPE, 0)
}
fn dataType(&self) -> Option<Rc<DataTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn commentSpec(&self) -> Option<Rc<CommentSpecContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn colPosition(&self) -> Option<Rc<ColPositionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn errorCapturingNot(&self) -> Option<Rc<ErrorCapturingNotContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token NULL
/// Returns `None` if there is no child corresponding to token NULL
fn NULL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NULL, 0)
}
/// Retrieves first TerminalNode corresponding to token SET
/// Returns `None` if there is no child corresponding to token SET
fn SET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SET, 0)
}
/// Retrieves first TerminalNode corresponding to token DROP
/// Returns `None` if there is no child corresponding to token DROP
fn DROP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DROP, 0)
}
fn defaultExpression(&self) -> Option<Rc<DefaultExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token DEFAULT
/// Returns `None` if there is no child corresponding to token DEFAULT
fn DEFAULT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DEFAULT, 0)
}

}

impl<'input> AlterColumnActionContextAttrs<'input> for AlterColumnActionContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn alterColumnAction(&mut self,)
	-> Result<Rc<AlterColumnActionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AlterColumnActionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 526, RULE_alterColumnAction);
        let mut _localctx: Rc<AlterColumnActionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4898);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(624,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4886);
					recog.base.match_token(TYPE,&mut recog.err_handler)?;

					/*InvokeRule dataType*/
					recog.base.set_state(4887);
					recog.dataType()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule commentSpec*/
					recog.base.set_state(4888);
					recog.commentSpec()?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule colPosition*/
					recog.base.set_state(4889);
					recog.colPosition()?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(4890);
					 cast_mut::<_,AlterColumnActionContext >(&mut _localctx).setOrDrop = recog.base.input.lt(1).cloned();
					 
					_la = recog.base.input.la(1);
					if { !(_la==DROP || _la==SET) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						 cast_mut::<_,AlterColumnActionContext >(&mut _localctx).setOrDrop = Some(tmp.clone());
						  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					/*InvokeRule errorCapturingNot*/
					recog.base.set_state(4891);
					recog.errorCapturingNot()?;

					recog.base.set_state(4892);
					recog.base.match_token(NULL,&mut recog.err_handler)?;

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					recog.base.set_state(4894);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					/*InvokeRule defaultExpression*/
					recog.base.set_state(4895);
					recog.defaultExpression()?;

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					recog.base.set_state(4896);
					let tmp = recog.base.match_token(DROP,&mut recog.err_handler)?;
					 cast_mut::<_,AlterColumnActionContext >(&mut _localctx).dropDefault = Some(tmp.clone());
					  

					recog.base.set_state(4897);
					recog.base.match_token(DEFAULT,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- singleStringLitWithoutMarker ----------------
#[derive(Debug)]
pub enum SingleStringLitWithoutMarkerContextAll<'input>{
	SingleDoubleQuotedStringLiteralValueContext(SingleDoubleQuotedStringLiteralValueContext<'input>),
	SingleStringLiteralValueContext(SingleStringLiteralValueContext<'input>),
Error(SingleStringLitWithoutMarkerContext<'input>)
}
antlr_rust::tid!{SingleStringLitWithoutMarkerContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for SingleStringLitWithoutMarkerContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for SingleStringLitWithoutMarkerContextAll<'input>{}

impl<'input> Deref for SingleStringLitWithoutMarkerContextAll<'input>{
	type Target = dyn SingleStringLitWithoutMarkerContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use SingleStringLitWithoutMarkerContextAll::*;
		match self{
			SingleDoubleQuotedStringLiteralValueContext(inner) => inner,
			SingleStringLiteralValueContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SingleStringLitWithoutMarkerContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SingleStringLitWithoutMarkerContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type SingleStringLitWithoutMarkerContext<'input> = BaseParserRuleContext<'input,SingleStringLitWithoutMarkerContextExt<'input>>;

#[derive(Clone)]
pub struct SingleStringLitWithoutMarkerContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SingleStringLitWithoutMarkerContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SingleStringLitWithoutMarkerContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SingleStringLitWithoutMarkerContext<'input>{
}

impl<'input> CustomRuleContext<'input> for SingleStringLitWithoutMarkerContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_singleStringLitWithoutMarker }
	//fn type_rule_index() -> usize where Self: Sized { RULE_singleStringLitWithoutMarker }
}
antlr_rust::tid!{SingleStringLitWithoutMarkerContextExt<'a>}

impl<'input> SingleStringLitWithoutMarkerContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SingleStringLitWithoutMarkerContextAll<'input>> {
		Rc::new(
		SingleStringLitWithoutMarkerContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SingleStringLitWithoutMarkerContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait SingleStringLitWithoutMarkerContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SingleStringLitWithoutMarkerContextExt<'input>>{


}

impl<'input> SingleStringLitWithoutMarkerContextAttrs<'input> for SingleStringLitWithoutMarkerContext<'input>{}

pub type SingleDoubleQuotedStringLiteralValueContext<'input> = BaseParserRuleContext<'input,SingleDoubleQuotedStringLiteralValueContextExt<'input>>;

pub trait SingleDoubleQuotedStringLiteralValueContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token DOUBLEQUOTED_STRING
	/// Returns `None` if there is no child corresponding to token DOUBLEQUOTED_STRING
	fn DOUBLEQUOTED_STRING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(DOUBLEQUOTED_STRING, 0)
	}
}

impl<'input> SingleDoubleQuotedStringLiteralValueContextAttrs<'input> for SingleDoubleQuotedStringLiteralValueContext<'input>{}

pub struct SingleDoubleQuotedStringLiteralValueContextExt<'input>{
	base:SingleStringLitWithoutMarkerContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SingleDoubleQuotedStringLiteralValueContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SingleDoubleQuotedStringLiteralValueContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SingleDoubleQuotedStringLiteralValueContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_singleDoubleQuotedStringLiteralValue(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_singleDoubleQuotedStringLiteralValue(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SingleDoubleQuotedStringLiteralValueContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_singleDoubleQuotedStringLiteralValue(self);
	}
}

impl<'input> CustomRuleContext<'input> for SingleDoubleQuotedStringLiteralValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_singleStringLitWithoutMarker }
	//fn type_rule_index() -> usize where Self: Sized { RULE_singleStringLitWithoutMarker }
}

impl<'input> Borrow<SingleStringLitWithoutMarkerContextExt<'input>> for SingleDoubleQuotedStringLiteralValueContext<'input>{
	fn borrow(&self) -> &SingleStringLitWithoutMarkerContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<SingleStringLitWithoutMarkerContextExt<'input>> for SingleDoubleQuotedStringLiteralValueContext<'input>{
	fn borrow_mut(&mut self) -> &mut SingleStringLitWithoutMarkerContextExt<'input> { &mut self.base }
}

impl<'input> SingleStringLitWithoutMarkerContextAttrs<'input> for SingleDoubleQuotedStringLiteralValueContext<'input> {}

impl<'input> SingleDoubleQuotedStringLiteralValueContextExt<'input>{
	fn new(ctx: &dyn SingleStringLitWithoutMarkerContextAttrs<'input>) -> Rc<SingleStringLitWithoutMarkerContextAll<'input>>  {
		Rc::new(
			SingleStringLitWithoutMarkerContextAll::SingleDoubleQuotedStringLiteralValueContext(
				BaseParserRuleContext::copy_from(ctx,SingleDoubleQuotedStringLiteralValueContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type SingleStringLiteralValueContext<'input> = BaseParserRuleContext<'input,SingleStringLiteralValueContextExt<'input>>;

pub trait SingleStringLiteralValueContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token STRING_LITERAL
	/// Returns `None` if there is no child corresponding to token STRING_LITERAL
	fn STRING_LITERAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(STRING_LITERAL, 0)
	}
}

impl<'input> SingleStringLiteralValueContextAttrs<'input> for SingleStringLiteralValueContext<'input>{}

pub struct SingleStringLiteralValueContextExt<'input>{
	base:SingleStringLitWithoutMarkerContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{SingleStringLiteralValueContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for SingleStringLiteralValueContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SingleStringLiteralValueContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_singleStringLiteralValue(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_singleStringLiteralValue(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SingleStringLiteralValueContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_singleStringLiteralValue(self);
	}
}

impl<'input> CustomRuleContext<'input> for SingleStringLiteralValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_singleStringLitWithoutMarker }
	//fn type_rule_index() -> usize where Self: Sized { RULE_singleStringLitWithoutMarker }
}

impl<'input> Borrow<SingleStringLitWithoutMarkerContextExt<'input>> for SingleStringLiteralValueContext<'input>{
	fn borrow(&self) -> &SingleStringLitWithoutMarkerContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<SingleStringLitWithoutMarkerContextExt<'input>> for SingleStringLiteralValueContext<'input>{
	fn borrow_mut(&mut self) -> &mut SingleStringLitWithoutMarkerContextExt<'input> { &mut self.base }
}

impl<'input> SingleStringLitWithoutMarkerContextAttrs<'input> for SingleStringLiteralValueContext<'input> {}

impl<'input> SingleStringLiteralValueContextExt<'input>{
	fn new(ctx: &dyn SingleStringLitWithoutMarkerContextAttrs<'input>) -> Rc<SingleStringLitWithoutMarkerContextAll<'input>>  {
		Rc::new(
			SingleStringLitWithoutMarkerContextAll::SingleStringLiteralValueContext(
				BaseParserRuleContext::copy_from(ctx,SingleStringLiteralValueContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn singleStringLitWithoutMarker(&mut self,)
	-> Result<Rc<SingleStringLitWithoutMarkerContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SingleStringLitWithoutMarkerContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 528, RULE_singleStringLitWithoutMarker);
        let mut _localctx: Rc<SingleStringLitWithoutMarkerContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4903);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(625,&mut recog.base)? {
				1 =>{
					let tmp = SingleStringLiteralValueContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(4900);
					recog.base.match_token(STRING_LITERAL,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					let tmp = SingleDoubleQuotedStringLiteralValueContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(4901);
					if !({!double_quoted_identifiers}) {
						Err(FailedPredicateError::new(&mut recog.base, Some("!double_quoted_identifiers".to_owned()), None))?;
					}
					recog.base.set_state(4902);
					recog.base.match_token(DOUBLEQUOTED_STRING,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- singleStringLit ----------------
pub type SingleStringLitContextAll<'input> = SingleStringLitContext<'input>;


pub type SingleStringLitContext<'input> = BaseParserRuleContext<'input,SingleStringLitContextExt<'input>>;

#[derive(Clone)]
pub struct SingleStringLitContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for SingleStringLitContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for SingleStringLitContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_singleStringLit(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_singleStringLit(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for SingleStringLitContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_singleStringLit(self);
	}
}

impl<'input> CustomRuleContext<'input> for SingleStringLitContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_singleStringLit }
	//fn type_rule_index() -> usize where Self: Sized { RULE_singleStringLit }
}
antlr_rust::tid!{SingleStringLitContextExt<'a>}

impl<'input> SingleStringLitContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SingleStringLitContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SingleStringLitContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait SingleStringLitContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<SingleStringLitContextExt<'input>>{

fn singleStringLitWithoutMarker(&self) -> Option<Rc<SingleStringLitWithoutMarkerContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn parameterMarker(&self) -> Option<Rc<ParameterMarkerContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SingleStringLitContextAttrs<'input> for SingleStringLitContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn singleStringLit(&mut self,)
	-> Result<Rc<SingleStringLitContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SingleStringLitContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 530, RULE_singleStringLit);
        let mut _localctx: Rc<SingleStringLitContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4907);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(626,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule singleStringLitWithoutMarker*/
					recog.base.set_state(4905);
					recog.singleStringLitWithoutMarker()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule parameterMarker*/
					recog.base.set_state(4906);
					recog.parameterMarker()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- parameterMarker ----------------
#[derive(Debug)]
pub enum ParameterMarkerContextAll<'input>{
	PositionalParameterMarkerRuleContext(PositionalParameterMarkerRuleContext<'input>),
	NamedParameterMarkerRuleContext(NamedParameterMarkerRuleContext<'input>),
Error(ParameterMarkerContext<'input>)
}
antlr_rust::tid!{ParameterMarkerContextAll<'a>}

impl<'input> antlr_rust::parser_rule_context::DerefSeal for ParameterMarkerContextAll<'input>{}

impl<'input> SqlBaseParserParserContext<'input> for ParameterMarkerContextAll<'input>{}

impl<'input> Deref for ParameterMarkerContextAll<'input>{
	type Target = dyn ParameterMarkerContextAttrs<'input> + 'input;
	fn deref(&self) -> &Self::Target{
		use ParameterMarkerContextAll::*;
		match self{
			PositionalParameterMarkerRuleContext(inner) => inner,
			NamedParameterMarkerRuleContext(inner) => inner,
Error(inner) => inner
		}
	}
}
impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ParameterMarkerContextAll<'input>{
	fn accept(&self, visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) { self.deref().accept(visitor) }
}
impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ParameterMarkerContextAll<'input>{
    fn enter(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().enter(listener) }
    fn exit(&self, listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) { self.deref().exit(listener) }
}



pub type ParameterMarkerContext<'input> = BaseParserRuleContext<'input,ParameterMarkerContextExt<'input>>;

#[derive(Clone)]
pub struct ParameterMarkerContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for ParameterMarkerContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for ParameterMarkerContext<'input>{
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for ParameterMarkerContext<'input>{
}

impl<'input> CustomRuleContext<'input> for ParameterMarkerContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_parameterMarker }
	//fn type_rule_index() -> usize where Self: Sized { RULE_parameterMarker }
}
antlr_rust::tid!{ParameterMarkerContextExt<'a>}

impl<'input> ParameterMarkerContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ParameterMarkerContextAll<'input>> {
		Rc::new(
		ParameterMarkerContextAll::Error(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ParameterMarkerContextExt{
				ph:PhantomData
			}),
		)
		)
	}
}

pub trait ParameterMarkerContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<ParameterMarkerContextExt<'input>>{


}

impl<'input> ParameterMarkerContextAttrs<'input> for ParameterMarkerContext<'input>{}

pub type PositionalParameterMarkerRuleContext<'input> = BaseParserRuleContext<'input,PositionalParameterMarkerRuleContextExt<'input>>;

pub trait PositionalParameterMarkerRuleContextAttrs<'input>: SqlBaseParserContext<'input>{
	/// Retrieves first TerminalNode corresponding to token QUESTION
	/// Returns `None` if there is no child corresponding to token QUESTION
	fn QUESTION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
		self.get_token(QUESTION, 0)
	}
}

impl<'input> PositionalParameterMarkerRuleContextAttrs<'input> for PositionalParameterMarkerRuleContext<'input>{}

pub struct PositionalParameterMarkerRuleContextExt<'input>{
	base:ParameterMarkerContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{PositionalParameterMarkerRuleContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for PositionalParameterMarkerRuleContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for PositionalParameterMarkerRuleContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_positionalParameterMarkerRule(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_positionalParameterMarkerRule(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for PositionalParameterMarkerRuleContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_positionalParameterMarkerRule(self);
	}
}

impl<'input> CustomRuleContext<'input> for PositionalParameterMarkerRuleContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_parameterMarker }
	//fn type_rule_index() -> usize where Self: Sized { RULE_parameterMarker }
}

impl<'input> Borrow<ParameterMarkerContextExt<'input>> for PositionalParameterMarkerRuleContext<'input>{
	fn borrow(&self) -> &ParameterMarkerContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ParameterMarkerContextExt<'input>> for PositionalParameterMarkerRuleContext<'input>{
	fn borrow_mut(&mut self) -> &mut ParameterMarkerContextExt<'input> { &mut self.base }
}

impl<'input> ParameterMarkerContextAttrs<'input> for PositionalParameterMarkerRuleContext<'input> {}

impl<'input> PositionalParameterMarkerRuleContextExt<'input>{
	fn new(ctx: &dyn ParameterMarkerContextAttrs<'input>) -> Rc<ParameterMarkerContextAll<'input>>  {
		Rc::new(
			ParameterMarkerContextAll::PositionalParameterMarkerRuleContext(
				BaseParserRuleContext::copy_from(ctx,PositionalParameterMarkerRuleContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

pub type NamedParameterMarkerRuleContext<'input> = BaseParserRuleContext<'input,NamedParameterMarkerRuleContextExt<'input>>;

pub trait NamedParameterMarkerRuleContextAttrs<'input>: SqlBaseParserContext<'input>{
	fn namedParameterMarker(&self) -> Option<Rc<NamedParameterMarkerContextAll<'input>>> where Self:Sized{
		self.child_of_type(0)
	}
}

impl<'input> NamedParameterMarkerRuleContextAttrs<'input> for NamedParameterMarkerRuleContext<'input>{}

pub struct NamedParameterMarkerRuleContextExt<'input>{
	base:ParameterMarkerContextExt<'input>,
	ph:PhantomData<&'input str>
}

antlr_rust::tid!{NamedParameterMarkerRuleContextExt<'a>}

impl<'input> SqlBaseParserContext<'input> for NamedParameterMarkerRuleContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for NamedParameterMarkerRuleContext<'input>{
	fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_namedParameterMarkerRule(self);
	}
	fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
		listener.exit_namedParameterMarkerRule(self);
		listener.exit_every_rule(self);
	}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for NamedParameterMarkerRuleContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_namedParameterMarkerRule(self);
	}
}

impl<'input> CustomRuleContext<'input> for NamedParameterMarkerRuleContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_parameterMarker }
	//fn type_rule_index() -> usize where Self: Sized { RULE_parameterMarker }
}

impl<'input> Borrow<ParameterMarkerContextExt<'input>> for NamedParameterMarkerRuleContext<'input>{
	fn borrow(&self) -> &ParameterMarkerContextExt<'input> { &self.base }
}
impl<'input> BorrowMut<ParameterMarkerContextExt<'input>> for NamedParameterMarkerRuleContext<'input>{
	fn borrow_mut(&mut self) -> &mut ParameterMarkerContextExt<'input> { &mut self.base }
}

impl<'input> ParameterMarkerContextAttrs<'input> for NamedParameterMarkerRuleContext<'input> {}

impl<'input> NamedParameterMarkerRuleContextExt<'input>{
	fn new(ctx: &dyn ParameterMarkerContextAttrs<'input>) -> Rc<ParameterMarkerContextAll<'input>>  {
		Rc::new(
			ParameterMarkerContextAll::NamedParameterMarkerRuleContext(
				BaseParserRuleContext::copy_from(ctx,NamedParameterMarkerRuleContextExt{
        			base: ctx.borrow().clone(),
        			ph:PhantomData
				})
			)
		)
	}
}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn parameterMarker(&mut self,)
	-> Result<Rc<ParameterMarkerContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ParameterMarkerContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 532, RULE_parameterMarker);
        let mut _localctx: Rc<ParameterMarkerContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4913);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(627,&mut recog.base)? {
				1 =>{
					let tmp = NamedParameterMarkerRuleContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 1);
					_localctx = tmp;
					{
					recog.base.set_state(4909);
					if !({parameter_substitution_enabled}) {
						Err(FailedPredicateError::new(&mut recog.base, Some("parameter_substitution_enabled".to_owned()), None))?;
					}
					/*InvokeRule namedParameterMarker*/
					recog.base.set_state(4910);
					recog.namedParameterMarker()?;

					}
				}
			,
				2 =>{
					let tmp = PositionalParameterMarkerRuleContextExt::new(&**_localctx);
					recog.base.enter_outer_alt(Some(tmp.clone()), 2);
					_localctx = tmp;
					{
					recog.base.set_state(4911);
					if !({parameter_substitution_enabled}) {
						Err(FailedPredicateError::new(&mut recog.base, Some("parameter_substitution_enabled".to_owned()), None))?;
					}
					recog.base.set_state(4912);
					recog.base.match_token(QUESTION,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- stringLit ----------------
pub type StringLitContextAll<'input> = StringLitContext<'input>;


pub type StringLitContext<'input> = BaseParserRuleContext<'input,StringLitContextExt<'input>>;

#[derive(Clone)]
pub struct StringLitContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for StringLitContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for StringLitContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_stringLit(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_stringLit(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for StringLitContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_stringLit(self);
	}
}

impl<'input> CustomRuleContext<'input> for StringLitContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_stringLit }
	//fn type_rule_index() -> usize where Self: Sized { RULE_stringLit }
}
antlr_rust::tid!{StringLitContextExt<'a>}

impl<'input> StringLitContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StringLitContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StringLitContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StringLitContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<StringLitContextExt<'input>>{

fn singleStringLit_all(&self) ->  Vec<Rc<SingleStringLitContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn singleStringLit(&self, i: usize) -> Option<Rc<SingleStringLitContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> StringLitContextAttrs<'input> for StringLitContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn stringLit(&mut self,)
	-> Result<Rc<StringLitContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StringLitContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 534, RULE_stringLit);
        let mut _localctx: Rc<StringLitContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4916); 
			recog.err_handler.sync(&mut recog.base)?;
			_alt = 1;
			loop {
				match _alt {
				    x if x == 1=>
					{
					{
					/*InvokeRule singleStringLit*/
					recog.base.set_state(4915);
					recog.singleStringLit()?;

					}
					}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
				}
				recog.base.set_state(4918); 
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(628,&mut recog.base)?;
				if _alt==2 || _alt==INVALID_ALT { break }
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- comment ----------------
pub type CommentContextAll<'input> = CommentContext<'input>;


pub type CommentContext<'input> = BaseParserRuleContext<'input,CommentContextExt<'input>>;

#[derive(Clone)]
pub struct CommentContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for CommentContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for CommentContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_comment(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_comment(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for CommentContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_comment(self);
	}
}

impl<'input> CustomRuleContext<'input> for CommentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_comment }
	//fn type_rule_index() -> usize where Self: Sized { RULE_comment }
}
antlr_rust::tid!{CommentContextExt<'a>}

impl<'input> CommentContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CommentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CommentContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait CommentContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<CommentContextExt<'input>>{

fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token NULL
/// Returns `None` if there is no child corresponding to token NULL
fn NULL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NULL, 0)
}

}

impl<'input> CommentContextAttrs<'input> for CommentContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn comment(&mut self,)
	-> Result<Rc<CommentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CommentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 536, RULE_comment);
        let mut _localctx: Rc<CommentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4922);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(629,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule stringLit*/
					recog.base.set_state(4920);
					recog.stringLit()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4921);
					recog.base.match_token(NULL,&mut recog.err_handler)?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- version ----------------
pub type VersionContextAll<'input> = VersionContext<'input>;


pub type VersionContext<'input> = BaseParserRuleContext<'input,VersionContextExt<'input>>;

#[derive(Clone)]
pub struct VersionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for VersionContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for VersionContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_version(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_version(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for VersionContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_version(self);
	}
}

impl<'input> CustomRuleContext<'input> for VersionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_version }
	//fn type_rule_index() -> usize where Self: Sized { RULE_version }
}
antlr_rust::tid!{VersionContextExt<'a>}

impl<'input> VersionContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<VersionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,VersionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait VersionContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<VersionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token INTEGER_VALUE
/// Returns `None` if there is no child corresponding to token INTEGER_VALUE
fn INTEGER_VALUE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INTEGER_VALUE, 0)
}
fn stringLit(&self) -> Option<Rc<StringLitContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> VersionContextAttrs<'input> for VersionContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn version(&mut self,)
	-> Result<Rc<VersionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = VersionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 538, RULE_version);
        let mut _localctx: Rc<VersionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4926);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(630,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(4924);
					recog.base.match_token(INTEGER_VALUE,&mut recog.err_handler)?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule stringLit*/
					recog.base.set_state(4925);
					recog.stringLit()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- operatorPipeRightSide ----------------
pub type OperatorPipeRightSideContextAll<'input> = OperatorPipeRightSideContext<'input>;


pub type OperatorPipeRightSideContext<'input> = BaseParserRuleContext<'input,OperatorPipeRightSideContextExt<'input>>;

#[derive(Clone)]
pub struct OperatorPipeRightSideContextExt<'input>{
	pub extendList: Option<Rc<NamedExpressionSeqContextAll<'input>>>,
	pub operator: Option<TokenType<'input>>,
	pub right: Option<Rc<QueryPrimaryContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for OperatorPipeRightSideContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for OperatorPipeRightSideContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_operatorPipeRightSide(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_operatorPipeRightSide(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for OperatorPipeRightSideContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_operatorPipeRightSide(self);
	}
}

impl<'input> CustomRuleContext<'input> for OperatorPipeRightSideContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_operatorPipeRightSide }
	//fn type_rule_index() -> usize where Self: Sized { RULE_operatorPipeRightSide }
}
antlr_rust::tid!{OperatorPipeRightSideContextExt<'a>}

impl<'input> OperatorPipeRightSideContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<OperatorPipeRightSideContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,OperatorPipeRightSideContextExt{
				operator: None, 
				extendList: None, right: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait OperatorPipeRightSideContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<OperatorPipeRightSideContextExt<'input>>{

fn selectClause(&self) -> Option<Rc<SelectClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn aggregationClause(&self) -> Option<Rc<AggregationClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn windowClause(&self) -> Option<Rc<WindowClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EXTEND
/// Returns `None` if there is no child corresponding to token EXTEND
fn EXTEND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXTEND, 0)
}
fn namedExpressionSeq(&self) -> Option<Rc<NamedExpressionSeqContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token SET
/// Returns `None` if there is no child corresponding to token SET
fn SET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SET, 0)
}
fn operatorPipeSetAssignmentSeq(&self) -> Option<Rc<OperatorPipeSetAssignmentSeqContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token DROP
/// Returns `None` if there is no child corresponding to token DROP
fn DROP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DROP, 0)
}
fn identifierSeq(&self) -> Option<Rc<IdentifierSeqContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
fn errorCapturingIdentifier(&self) -> Option<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn whereClause(&self) -> Option<Rc<WhereClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn pivotClause(&self) -> Option<Rc<PivotClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn unpivotClause(&self) -> Option<Rc<UnpivotClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn sample(&self) -> Option<Rc<SampleContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn joinRelation(&self) -> Option<Rc<JoinRelationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn queryPrimary(&self) -> Option<Rc<QueryPrimaryContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token UNION
/// Returns `None` if there is no child corresponding to token UNION
fn UNION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UNION, 0)
}
/// Retrieves first TerminalNode corresponding to token EXCEPT
/// Returns `None` if there is no child corresponding to token EXCEPT
fn EXCEPT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXCEPT, 0)
}
/// Retrieves first TerminalNode corresponding to token SETMINUS
/// Returns `None` if there is no child corresponding to token SETMINUS
fn SETMINUS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SETMINUS, 0)
}
/// Retrieves first TerminalNode corresponding to token INTERSECT
/// Returns `None` if there is no child corresponding to token INTERSECT
fn INTERSECT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INTERSECT, 0)
}
fn setQuantifier(&self) -> Option<Rc<SetQuantifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn queryOrganization(&self) -> Option<Rc<QueryOrganizationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token AGGREGATE
/// Returns `None` if there is no child corresponding to token AGGREGATE
fn AGGREGATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AGGREGATE, 0)
}

}

impl<'input> OperatorPipeRightSideContextAttrs<'input> for OperatorPipeRightSideContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn operatorPipeRightSide(&mut self,)
	-> Result<Rc<OperatorPipeRightSideContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = OperatorPipeRightSideContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 540, RULE_operatorPipeRightSide);
        let mut _localctx: Rc<OperatorPipeRightSideContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(4970);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(639,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule selectClause*/
					recog.base.set_state(4928);
					recog.selectClause()?;

					recog.base.set_state(4930);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(631,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule aggregationClause*/
							recog.base.set_state(4929);
							recog.aggregationClause()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(4933);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(632,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule windowClause*/
							recog.base.set_state(4932);
							recog.windowClause()?;

							}
						}

						_ => {}
					}
					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					recog.base.set_state(4935);
					recog.base.match_token(EXTEND,&mut recog.err_handler)?;

					/*InvokeRule namedExpressionSeq*/
					recog.base.set_state(4936);
					let tmp = recog.namedExpressionSeq()?;
					 cast_mut::<_,OperatorPipeRightSideContext >(&mut _localctx).extendList = Some(tmp.clone());
					  

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					recog.base.set_state(4937);
					recog.base.match_token(SET,&mut recog.err_handler)?;

					/*InvokeRule operatorPipeSetAssignmentSeq*/
					recog.base.set_state(4938);
					recog.operatorPipeSetAssignmentSeq()?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(4939);
					recog.base.match_token(DROP,&mut recog.err_handler)?;

					/*InvokeRule identifierSeq*/
					recog.base.set_state(4940);
					recog.identifierSeq()?;

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					recog.base.set_state(4941);
					recog.base.match_token(AS,&mut recog.err_handler)?;

					/*InvokeRule errorCapturingIdentifier*/
					recog.base.set_state(4942);
					recog.errorCapturingIdentifier()?;

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					/*InvokeRule whereClause*/
					recog.base.set_state(4943);
					recog.whereClause()?;

					recog.base.set_state(4945);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(633,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule windowClause*/
							recog.base.set_state(4944);
							recog.windowClause()?;

							}
						}

						_ => {}
					}
					}
				}
			,
				7 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					/*InvokeRule pivotClause*/
					recog.base.set_state(4947);
					recog.pivotClause()?;

					recog.base.set_state(4949);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(634,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule unpivotClause*/
							recog.base.set_state(4948);
							recog.unpivotClause()?;

							}
						}

						_ => {}
					}
					}
				}
			,
				8 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 8);
					recog.base.enter_outer_alt(None, 8);
					{
					/*InvokeRule unpivotClause*/
					recog.base.set_state(4951);
					recog.unpivotClause()?;

					recog.base.set_state(4953);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(635,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule pivotClause*/
							recog.base.set_state(4952);
							recog.pivotClause()?;

							}
						}

						_ => {}
					}
					}
				}
			,
				9 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 9);
					recog.base.enter_outer_alt(None, 9);
					{
					/*InvokeRule sample*/
					recog.base.set_state(4955);
					recog.sample()?;

					}
				}
			,
				10 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 10);
					recog.base.enter_outer_alt(None, 10);
					{
					/*InvokeRule joinRelation*/
					recog.base.set_state(4956);
					recog.joinRelation()?;

					}
				}
			,
				11 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 11);
					recog.base.enter_outer_alt(None, 11);
					{
					recog.base.set_state(4957);
					 cast_mut::<_,OperatorPipeRightSideContext >(&mut _localctx).operator = recog.base.input.lt(1).cloned();
					 
					_la = recog.base.input.la(1);
					if { !(_la==EXCEPT || _la==INTERSECT || _la==SETMINUS || _la==UNION) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						 cast_mut::<_,OperatorPipeRightSideContext >(&mut _localctx).operator = Some(tmp.clone());
						  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					recog.base.set_state(4959);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					if _la==ALL || _la==DISTINCT {
						{
						/*InvokeRule setQuantifier*/
						recog.base.set_state(4958);
						recog.setQuantifier()?;

						}
					}

					/*InvokeRule queryPrimary*/
					recog.base.set_state(4961);
					let tmp = recog.queryPrimary()?;
					 cast_mut::<_,OperatorPipeRightSideContext >(&mut _localctx).right = Some(tmp.clone());
					  

					}
				}
			,
				12 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 12);
					recog.base.enter_outer_alt(None, 12);
					{
					/*InvokeRule queryOrganization*/
					recog.base.set_state(4962);
					recog.queryOrganization()?;

					}
				}
			,
				13 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 13);
					recog.base.enter_outer_alt(None, 13);
					{
					recog.base.set_state(4963);
					recog.base.match_token(AGGREGATE,&mut recog.err_handler)?;

					recog.base.set_state(4965);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(637,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule namedExpressionSeq*/
							recog.base.set_state(4964);
							recog.namedExpressionSeq()?;

							}
						}

						_ => {}
					}
					recog.base.set_state(4968);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(638,&mut recog.base)? {
						x if x == 1=>{
							{
							/*InvokeRule aggregationClause*/
							recog.base.set_state(4967);
							recog.aggregationClause()?;

							}
						}

						_ => {}
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- operatorPipeSetAssignmentSeq ----------------
pub type OperatorPipeSetAssignmentSeqContextAll<'input> = OperatorPipeSetAssignmentSeqContext<'input>;


pub type OperatorPipeSetAssignmentSeqContext<'input> = BaseParserRuleContext<'input,OperatorPipeSetAssignmentSeqContextExt<'input>>;

#[derive(Clone)]
pub struct OperatorPipeSetAssignmentSeqContextExt<'input>{
	pub errorCapturingIdentifier: Option<Rc<ErrorCapturingIdentifierContextAll<'input>>>,
	pub ident:Vec<Rc<ErrorCapturingIdentifierContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for OperatorPipeSetAssignmentSeqContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for OperatorPipeSetAssignmentSeqContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_operatorPipeSetAssignmentSeq(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_operatorPipeSetAssignmentSeq(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for OperatorPipeSetAssignmentSeqContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_operatorPipeSetAssignmentSeq(self);
	}
}

impl<'input> CustomRuleContext<'input> for OperatorPipeSetAssignmentSeqContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_operatorPipeSetAssignmentSeq }
	//fn type_rule_index() -> usize where Self: Sized { RULE_operatorPipeSetAssignmentSeq }
}
antlr_rust::tid!{OperatorPipeSetAssignmentSeqContextExt<'a>}

impl<'input> OperatorPipeSetAssignmentSeqContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<OperatorPipeSetAssignmentSeqContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,OperatorPipeSetAssignmentSeqContextExt{
				errorCapturingIdentifier: None, 
				ident: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait OperatorPipeSetAssignmentSeqContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<OperatorPipeSetAssignmentSeqContextExt<'input>>{

/// Retrieves all `TerminalNode`s corresponding to token EQ in current rule
fn EQ_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token EQ, starting from 0.
/// Returns `None` if number of children corresponding to token EQ is less or equal than `i`.
fn EQ(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EQ, i)
}
fn expression_all(&self) ->  Vec<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expression(&self, i: usize) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn errorCapturingIdentifier_all(&self) ->  Vec<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn errorCapturingIdentifier(&self, i: usize) -> Option<Rc<ErrorCapturingIdentifierContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token DOT in current rule
fn DOT_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token DOT, starting from 0.
/// Returns `None` if number of children corresponding to token DOT is less or equal than `i`.
fn DOT(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DOT, i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,SqlBaseParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> OperatorPipeSetAssignmentSeqContextAttrs<'input> for OperatorPipeSetAssignmentSeqContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn operatorPipeSetAssignmentSeq(&mut self,)
	-> Result<Rc<OperatorPipeSetAssignmentSeqContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = OperatorPipeSetAssignmentSeqContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 542, RULE_operatorPipeSetAssignmentSeq);
        let mut _localctx: Rc<OperatorPipeSetAssignmentSeqContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule errorCapturingIdentifier*/
			recog.base.set_state(4972);
			let tmp = recog.errorCapturingIdentifier()?;
			 cast_mut::<_,OperatorPipeSetAssignmentSeqContext >(&mut _localctx).errorCapturingIdentifier = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,OperatorPipeSetAssignmentSeqContext >(&mut _localctx).errorCapturingIdentifier.clone().unwrap()
			 ;
			 cast_mut::<_,OperatorPipeSetAssignmentSeqContext >(&mut _localctx).ident.push(temp);
			  
			recog.base.set_state(4977);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==DOT {
				{
				{
				recog.base.set_state(4973);
				recog.base.match_token(DOT,&mut recog.err_handler)?;

				/*InvokeRule errorCapturingIdentifier*/
				recog.base.set_state(4974);
				recog.errorCapturingIdentifier()?;

				}
				}
				recog.base.set_state(4979);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(4980);
			recog.base.match_token(EQ,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(4981);
			recog.expression()?;

			recog.base.set_state(4996);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(642,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(4982);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule errorCapturingIdentifier*/
					recog.base.set_state(4983);
					let tmp = recog.errorCapturingIdentifier()?;
					 cast_mut::<_,OperatorPipeSetAssignmentSeqContext >(&mut _localctx).errorCapturingIdentifier = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,OperatorPipeSetAssignmentSeqContext >(&mut _localctx).errorCapturingIdentifier.clone().unwrap()
					 ;
					 cast_mut::<_,OperatorPipeSetAssignmentSeqContext >(&mut _localctx).ident.push(temp);
					  
					recog.base.set_state(4988);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==DOT {
						{
						{
						recog.base.set_state(4984);
						recog.base.match_token(DOT,&mut recog.err_handler)?;

						/*InvokeRule errorCapturingIdentifier*/
						recog.base.set_state(4985);
						recog.errorCapturingIdentifier()?;

						}
						}
						recog.base.set_state(4990);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					recog.base.set_state(4991);
					recog.base.match_token(EQ,&mut recog.err_handler)?;

					/*InvokeRule expression*/
					recog.base.set_state(4992);
					recog.expression()?;

					}
					} 
				}
				recog.base.set_state(4998);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(642,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- ansiNonReserved ----------------
pub type AnsiNonReservedContextAll<'input> = AnsiNonReservedContext<'input>;


pub type AnsiNonReservedContext<'input> = BaseParserRuleContext<'input,AnsiNonReservedContextExt<'input>>;

#[derive(Clone)]
pub struct AnsiNonReservedContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for AnsiNonReservedContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for AnsiNonReservedContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_ansiNonReserved(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_ansiNonReserved(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for AnsiNonReservedContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_ansiNonReserved(self);
	}
}

impl<'input> CustomRuleContext<'input> for AnsiNonReservedContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_ansiNonReserved }
	//fn type_rule_index() -> usize where Self: Sized { RULE_ansiNonReserved }
}
antlr_rust::tid!{AnsiNonReservedContextExt<'a>}

impl<'input> AnsiNonReservedContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AnsiNonReservedContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AnsiNonReservedContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AnsiNonReservedContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<AnsiNonReservedContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ADD
/// Returns `None` if there is no child corresponding to token ADD
fn ADD(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ADD, 0)
}
/// Retrieves first TerminalNode corresponding to token AFTER
/// Returns `None` if there is no child corresponding to token AFTER
fn AFTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AFTER, 0)
}
/// Retrieves first TerminalNode corresponding to token AGGREGATE
/// Returns `None` if there is no child corresponding to token AGGREGATE
fn AGGREGATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AGGREGATE, 0)
}
/// Retrieves first TerminalNode corresponding to token ALTER
/// Returns `None` if there is no child corresponding to token ALTER
fn ALTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ALTER, 0)
}
/// Retrieves first TerminalNode corresponding to token ALWAYS
/// Returns `None` if there is no child corresponding to token ALWAYS
fn ALWAYS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ALWAYS, 0)
}
/// Retrieves first TerminalNode corresponding to token ANALYZE
/// Returns `None` if there is no child corresponding to token ANALYZE
fn ANALYZE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ANALYZE, 0)
}
/// Retrieves first TerminalNode corresponding to token ANTI
/// Returns `None` if there is no child corresponding to token ANTI
fn ANTI(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ANTI, 0)
}
/// Retrieves first TerminalNode corresponding to token ANY_VALUE
/// Returns `None` if there is no child corresponding to token ANY_VALUE
fn ANY_VALUE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ANY_VALUE, 0)
}
/// Retrieves first TerminalNode corresponding to token ARCHIVE
/// Returns `None` if there is no child corresponding to token ARCHIVE
fn ARCHIVE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ARCHIVE, 0)
}
/// Retrieves first TerminalNode corresponding to token ARRAY
/// Returns `None` if there is no child corresponding to token ARRAY
fn ARRAY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ARRAY, 0)
}
/// Retrieves first TerminalNode corresponding to token ASC
/// Returns `None` if there is no child corresponding to token ASC
fn ASC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ASC, 0)
}
/// Retrieves first TerminalNode corresponding to token AT
/// Returns `None` if there is no child corresponding to token AT
fn AT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AT, 0)
}
/// Retrieves first TerminalNode corresponding to token ATOMIC
/// Returns `None` if there is no child corresponding to token ATOMIC
fn ATOMIC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ATOMIC, 0)
}
/// Retrieves first TerminalNode corresponding to token BEGIN
/// Returns `None` if there is no child corresponding to token BEGIN
fn BEGIN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BEGIN, 0)
}
/// Retrieves first TerminalNode corresponding to token BETWEEN
/// Returns `None` if there is no child corresponding to token BETWEEN
fn BETWEEN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BETWEEN, 0)
}
/// Retrieves first TerminalNode corresponding to token BIGINT
/// Returns `None` if there is no child corresponding to token BIGINT
fn BIGINT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BIGINT, 0)
}
/// Retrieves first TerminalNode corresponding to token BINARY
/// Returns `None` if there is no child corresponding to token BINARY
fn BINARY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BINARY, 0)
}
/// Retrieves first TerminalNode corresponding to token BINARY_HEX
/// Returns `None` if there is no child corresponding to token BINARY_HEX
fn BINARY_HEX(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BINARY_HEX, 0)
}
/// Retrieves first TerminalNode corresponding to token BINDING
/// Returns `None` if there is no child corresponding to token BINDING
fn BINDING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BINDING, 0)
}
/// Retrieves first TerminalNode corresponding to token BOOLEAN
/// Returns `None` if there is no child corresponding to token BOOLEAN
fn BOOLEAN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BOOLEAN, 0)
}
/// Retrieves first TerminalNode corresponding to token BUCKET
/// Returns `None` if there is no child corresponding to token BUCKET
fn BUCKET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BUCKET, 0)
}
/// Retrieves first TerminalNode corresponding to token BUCKETS
/// Returns `None` if there is no child corresponding to token BUCKETS
fn BUCKETS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BUCKETS, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
/// Retrieves first TerminalNode corresponding to token BYTE
/// Returns `None` if there is no child corresponding to token BYTE
fn BYTE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BYTE, 0)
}
/// Retrieves first TerminalNode corresponding to token CACHE
/// Returns `None` if there is no child corresponding to token CACHE
fn CACHE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CACHE, 0)
}
/// Retrieves first TerminalNode corresponding to token CALLED
/// Returns `None` if there is no child corresponding to token CALLED
fn CALLED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CALLED, 0)
}
/// Retrieves first TerminalNode corresponding to token CASCADE
/// Returns `None` if there is no child corresponding to token CASCADE
fn CASCADE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CASCADE, 0)
}
/// Retrieves first TerminalNode corresponding to token CATALOG
/// Returns `None` if there is no child corresponding to token CATALOG
fn CATALOG(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CATALOG, 0)
}
/// Retrieves first TerminalNode corresponding to token CATALOGS
/// Returns `None` if there is no child corresponding to token CATALOGS
fn CATALOGS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CATALOGS, 0)
}
/// Retrieves first TerminalNode corresponding to token CHANGE
/// Returns `None` if there is no child corresponding to token CHANGE
fn CHANGE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CHANGE, 0)
}
/// Retrieves first TerminalNode corresponding to token CHAR
/// Returns `None` if there is no child corresponding to token CHAR
fn CHAR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CHAR, 0)
}
/// Retrieves first TerminalNode corresponding to token CHARACTER
/// Returns `None` if there is no child corresponding to token CHARACTER
fn CHARACTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CHARACTER, 0)
}
/// Retrieves first TerminalNode corresponding to token CLEAR
/// Returns `None` if there is no child corresponding to token CLEAR
fn CLEAR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CLEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token CLUSTER
/// Returns `None` if there is no child corresponding to token CLUSTER
fn CLUSTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CLUSTER, 0)
}
/// Retrieves first TerminalNode corresponding to token CLUSTERED
/// Returns `None` if there is no child corresponding to token CLUSTERED
fn CLUSTERED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CLUSTERED, 0)
}
/// Retrieves first TerminalNode corresponding to token CODEGEN
/// Returns `None` if there is no child corresponding to token CODEGEN
fn CODEGEN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CODEGEN, 0)
}
/// Retrieves first TerminalNode corresponding to token COLLECTION
/// Returns `None` if there is no child corresponding to token COLLECTION
fn COLLECTION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COLLECTION, 0)
}
/// Retrieves first TerminalNode corresponding to token COLUMNS
/// Returns `None` if there is no child corresponding to token COLUMNS
fn COLUMNS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COLUMNS, 0)
}
/// Retrieves first TerminalNode corresponding to token COMMENT
/// Returns `None` if there is no child corresponding to token COMMENT
fn COMMENT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMENT, 0)
}
/// Retrieves first TerminalNode corresponding to token COMMIT
/// Returns `None` if there is no child corresponding to token COMMIT
fn COMMIT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMIT, 0)
}
/// Retrieves first TerminalNode corresponding to token COMPACT
/// Returns `None` if there is no child corresponding to token COMPACT
fn COMPACT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMPACT, 0)
}
/// Retrieves first TerminalNode corresponding to token COMPACTIONS
/// Returns `None` if there is no child corresponding to token COMPACTIONS
fn COMPACTIONS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMPACTIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token COMPENSATION
/// Returns `None` if there is no child corresponding to token COMPENSATION
fn COMPENSATION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMPENSATION, 0)
}
/// Retrieves first TerminalNode corresponding to token COMPUTE
/// Returns `None` if there is no child corresponding to token COMPUTE
fn COMPUTE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMPUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token CONCATENATE
/// Returns `None` if there is no child corresponding to token CONCATENATE
fn CONCATENATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CONCATENATE, 0)
}
/// Retrieves first TerminalNode corresponding to token CONDITION
/// Returns `None` if there is no child corresponding to token CONDITION
fn CONDITION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CONDITION, 0)
}
/// Retrieves first TerminalNode corresponding to token CONTAINS
/// Returns `None` if there is no child corresponding to token CONTAINS
fn CONTAINS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CONTAINS, 0)
}
/// Retrieves first TerminalNode corresponding to token CONTINUE
/// Returns `None` if there is no child corresponding to token CONTINUE
fn CONTINUE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CONTINUE, 0)
}
/// Retrieves first TerminalNode corresponding to token COST
/// Returns `None` if there is no child corresponding to token COST
fn COST(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COST, 0)
}
/// Retrieves first TerminalNode corresponding to token CUBE
/// Returns `None` if there is no child corresponding to token CUBE
fn CUBE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CUBE, 0)
}
/// Retrieves first TerminalNode corresponding to token CURRENT
/// Returns `None` if there is no child corresponding to token CURRENT
fn CURRENT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CURRENT, 0)
}
/// Retrieves first TerminalNode corresponding to token DATA
/// Returns `None` if there is no child corresponding to token DATA
fn DATA(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DATA, 0)
}
/// Retrieves first TerminalNode corresponding to token DATABASE
/// Returns `None` if there is no child corresponding to token DATABASE
fn DATABASE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DATABASE, 0)
}
/// Retrieves first TerminalNode corresponding to token DATABASES
/// Returns `None` if there is no child corresponding to token DATABASES
fn DATABASES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DATABASES, 0)
}
/// Retrieves first TerminalNode corresponding to token DATE
/// Returns `None` if there is no child corresponding to token DATE
fn DATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DATE, 0)
}
/// Retrieves first TerminalNode corresponding to token DATEADD
/// Returns `None` if there is no child corresponding to token DATEADD
fn DATEADD(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DATEADD, 0)
}
/// Retrieves first TerminalNode corresponding to token DATE_ADD
/// Returns `None` if there is no child corresponding to token DATE_ADD
fn DATE_ADD(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DATE_ADD, 0)
}
/// Retrieves first TerminalNode corresponding to token DATEDIFF
/// Returns `None` if there is no child corresponding to token DATEDIFF
fn DATEDIFF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DATEDIFF, 0)
}
/// Retrieves first TerminalNode corresponding to token DATE_DIFF
/// Returns `None` if there is no child corresponding to token DATE_DIFF
fn DATE_DIFF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DATE_DIFF, 0)
}
/// Retrieves first TerminalNode corresponding to token DAY
/// Returns `None` if there is no child corresponding to token DAY
fn DAY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DAY, 0)
}
/// Retrieves first TerminalNode corresponding to token DAYS
/// Returns `None` if there is no child corresponding to token DAYS
fn DAYS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DAYS, 0)
}
/// Retrieves first TerminalNode corresponding to token DAYOFYEAR
/// Returns `None` if there is no child corresponding to token DAYOFYEAR
fn DAYOFYEAR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DAYOFYEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token DBPROPERTIES
/// Returns `None` if there is no child corresponding to token DBPROPERTIES
fn DBPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DBPROPERTIES, 0)
}
/// Retrieves first TerminalNode corresponding to token DEC
/// Returns `None` if there is no child corresponding to token DEC
fn DEC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DEC, 0)
}
/// Retrieves first TerminalNode corresponding to token DECIMAL
/// Returns `None` if there is no child corresponding to token DECIMAL
fn DECIMAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DECIMAL, 0)
}
/// Retrieves first TerminalNode corresponding to token DECLARE
/// Returns `None` if there is no child corresponding to token DECLARE
fn DECLARE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DECLARE, 0)
}
/// Retrieves first TerminalNode corresponding to token DEFAULT
/// Returns `None` if there is no child corresponding to token DEFAULT
fn DEFAULT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DEFAULT, 0)
}
/// Retrieves first TerminalNode corresponding to token DEFINED
/// Returns `None` if there is no child corresponding to token DEFINED
fn DEFINED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DEFINED, 0)
}
/// Retrieves first TerminalNode corresponding to token DEFINER
/// Returns `None` if there is no child corresponding to token DEFINER
fn DEFINER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DEFINER, 0)
}
/// Retrieves first TerminalNode corresponding to token DELAY
/// Returns `None` if there is no child corresponding to token DELAY
fn DELAY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DELAY, 0)
}
/// Retrieves first TerminalNode corresponding to token DELETE
/// Returns `None` if there is no child corresponding to token DELETE
fn DELETE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DELETE, 0)
}
/// Retrieves first TerminalNode corresponding to token DELIMITED
/// Returns `None` if there is no child corresponding to token DELIMITED
fn DELIMITED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DELIMITED, 0)
}
/// Retrieves first TerminalNode corresponding to token DESC
/// Returns `None` if there is no child corresponding to token DESC
fn DESC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DESC, 0)
}
/// Retrieves first TerminalNode corresponding to token DESCRIBE
/// Returns `None` if there is no child corresponding to token DESCRIBE
fn DESCRIBE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DESCRIBE, 0)
}
/// Retrieves first TerminalNode corresponding to token DETERMINISTIC
/// Returns `None` if there is no child corresponding to token DETERMINISTIC
fn DETERMINISTIC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DETERMINISTIC, 0)
}
/// Retrieves first TerminalNode corresponding to token DFS
/// Returns `None` if there is no child corresponding to token DFS
fn DFS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DFS, 0)
}
/// Retrieves first TerminalNode corresponding to token DIRECTORIES
/// Returns `None` if there is no child corresponding to token DIRECTORIES
fn DIRECTORIES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DIRECTORIES, 0)
}
/// Retrieves first TerminalNode corresponding to token DIRECTORY
/// Returns `None` if there is no child corresponding to token DIRECTORY
fn DIRECTORY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DIRECTORY, 0)
}
/// Retrieves first TerminalNode corresponding to token DISTRIBUTE
/// Returns `None` if there is no child corresponding to token DISTRIBUTE
fn DISTRIBUTE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DISTRIBUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token DIV
/// Returns `None` if there is no child corresponding to token DIV
fn DIV(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DIV, 0)
}
/// Retrieves first TerminalNode corresponding to token DO
/// Returns `None` if there is no child corresponding to token DO
fn DO(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DO, 0)
}
/// Retrieves first TerminalNode corresponding to token DOUBLE
/// Returns `None` if there is no child corresponding to token DOUBLE
fn DOUBLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DOUBLE, 0)
}
/// Retrieves first TerminalNode corresponding to token DROP
/// Returns `None` if there is no child corresponding to token DROP
fn DROP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DROP, 0)
}
/// Retrieves first TerminalNode corresponding to token ELSEIF
/// Returns `None` if there is no child corresponding to token ELSEIF
fn ELSEIF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ELSEIF, 0)
}
/// Retrieves first TerminalNode corresponding to token ENFORCED
/// Returns `None` if there is no child corresponding to token ENFORCED
fn ENFORCED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ENFORCED, 0)
}
/// Retrieves first TerminalNode corresponding to token ESCAPED
/// Returns `None` if there is no child corresponding to token ESCAPED
fn ESCAPED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ESCAPED, 0)
}
/// Retrieves first TerminalNode corresponding to token EVOLUTION
/// Returns `None` if there is no child corresponding to token EVOLUTION
fn EVOLUTION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EVOLUTION, 0)
}
/// Retrieves first TerminalNode corresponding to token EXCHANGE
/// Returns `None` if there is no child corresponding to token EXCHANGE
fn EXCHANGE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXCHANGE, 0)
}
/// Retrieves first TerminalNode corresponding to token EXCLUDE
/// Returns `None` if there is no child corresponding to token EXCLUDE
fn EXCLUDE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXCLUDE, 0)
}
/// Retrieves first TerminalNode corresponding to token EXISTS
/// Returns `None` if there is no child corresponding to token EXISTS
fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXISTS, 0)
}
/// Retrieves first TerminalNode corresponding to token EXIT
/// Returns `None` if there is no child corresponding to token EXIT
fn EXIT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXIT, 0)
}
/// Retrieves first TerminalNode corresponding to token EXPLAIN
/// Returns `None` if there is no child corresponding to token EXPLAIN
fn EXPLAIN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXPLAIN, 0)
}
/// Retrieves first TerminalNode corresponding to token EXPORT
/// Returns `None` if there is no child corresponding to token EXPORT
fn EXPORT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXPORT, 0)
}
/// Retrieves first TerminalNode corresponding to token EXTEND
/// Returns `None` if there is no child corresponding to token EXTEND
fn EXTEND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXTEND, 0)
}
/// Retrieves first TerminalNode corresponding to token EXTENDED
/// Returns `None` if there is no child corresponding to token EXTENDED
fn EXTENDED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXTENDED, 0)
}
/// Retrieves first TerminalNode corresponding to token EXTERNAL
/// Returns `None` if there is no child corresponding to token EXTERNAL
fn EXTERNAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXTERNAL, 0)
}
/// Retrieves first TerminalNode corresponding to token EXTRACT
/// Returns `None` if there is no child corresponding to token EXTRACT
fn EXTRACT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXTRACT, 0)
}
/// Retrieves first TerminalNode corresponding to token FIELDS
/// Returns `None` if there is no child corresponding to token FIELDS
fn FIELDS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FIELDS, 0)
}
/// Retrieves first TerminalNode corresponding to token FILEFORMAT
/// Returns `None` if there is no child corresponding to token FILEFORMAT
fn FILEFORMAT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FILEFORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token FIRST
/// Returns `None` if there is no child corresponding to token FIRST
fn FIRST(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FIRST, 0)
}
/// Retrieves first TerminalNode corresponding to token FLOAT
/// Returns `None` if there is no child corresponding to token FLOAT
fn FLOAT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FLOAT, 0)
}
/// Retrieves first TerminalNode corresponding to token FLOW
/// Returns `None` if there is no child corresponding to token FLOW
fn FLOW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FLOW, 0)
}
/// Retrieves first TerminalNode corresponding to token FOLLOWING
/// Returns `None` if there is no child corresponding to token FOLLOWING
fn FOLLOWING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FOLLOWING, 0)
}
/// Retrieves first TerminalNode corresponding to token FORMAT
/// Returns `None` if there is no child corresponding to token FORMAT
fn FORMAT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token FORMATTED
/// Returns `None` if there is no child corresponding to token FORMATTED
fn FORMATTED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FORMATTED, 0)
}
/// Retrieves first TerminalNode corresponding to token FOUND
/// Returns `None` if there is no child corresponding to token FOUND
fn FOUND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FOUND, 0)
}
/// Retrieves first TerminalNode corresponding to token FUNCTION
/// Returns `None` if there is no child corresponding to token FUNCTION
fn FUNCTION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FUNCTION, 0)
}
/// Retrieves first TerminalNode corresponding to token FUNCTIONS
/// Returns `None` if there is no child corresponding to token FUNCTIONS
fn FUNCTIONS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FUNCTIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token GENERATED
/// Returns `None` if there is no child corresponding to token GENERATED
fn GENERATED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(GENERATED, 0)
}
/// Retrieves first TerminalNode corresponding to token GEOGRAPHY
/// Returns `None` if there is no child corresponding to token GEOGRAPHY
fn GEOGRAPHY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(GEOGRAPHY, 0)
}
/// Retrieves first TerminalNode corresponding to token GEOMETRY
/// Returns `None` if there is no child corresponding to token GEOMETRY
fn GEOMETRY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(GEOMETRY, 0)
}
/// Retrieves first TerminalNode corresponding to token GLOBAL
/// Returns `None` if there is no child corresponding to token GLOBAL
fn GLOBAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(GLOBAL, 0)
}
/// Retrieves first TerminalNode corresponding to token GROUPING
/// Returns `None` if there is no child corresponding to token GROUPING
fn GROUPING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(GROUPING, 0)
}
/// Retrieves first TerminalNode corresponding to token HANDLER
/// Returns `None` if there is no child corresponding to token HANDLER
fn HANDLER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(HANDLER, 0)
}
/// Retrieves first TerminalNode corresponding to token HOUR
/// Returns `None` if there is no child corresponding to token HOUR
fn HOUR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(HOUR, 0)
}
/// Retrieves first TerminalNode corresponding to token HOURS
/// Returns `None` if there is no child corresponding to token HOURS
fn HOURS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(HOURS, 0)
}
/// Retrieves first TerminalNode corresponding to token IDENTIFIER_KW
/// Returns `None` if there is no child corresponding to token IDENTIFIER_KW
fn IDENTIFIER_KW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IDENTIFIER_KW, 0)
}
/// Retrieves first TerminalNode corresponding to token IDENTITY
/// Returns `None` if there is no child corresponding to token IDENTITY
fn IDENTITY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IDENTITY, 0)
}
/// Retrieves first TerminalNode corresponding to token IF
/// Returns `None` if there is no child corresponding to token IF
fn IF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IF, 0)
}
/// Retrieves first TerminalNode corresponding to token IGNORE
/// Returns `None` if there is no child corresponding to token IGNORE
fn IGNORE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IGNORE, 0)
}
/// Retrieves first TerminalNode corresponding to token IMMEDIATE
/// Returns `None` if there is no child corresponding to token IMMEDIATE
fn IMMEDIATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IMMEDIATE, 0)
}
/// Retrieves first TerminalNode corresponding to token IMPORT
/// Returns `None` if there is no child corresponding to token IMPORT
fn IMPORT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IMPORT, 0)
}
/// Retrieves first TerminalNode corresponding to token INCLUDE
/// Returns `None` if there is no child corresponding to token INCLUDE
fn INCLUDE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INCLUDE, 0)
}
/// Retrieves first TerminalNode corresponding to token INCREMENT
/// Returns `None` if there is no child corresponding to token INCREMENT
fn INCREMENT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INCREMENT, 0)
}
/// Retrieves first TerminalNode corresponding to token INDEX
/// Returns `None` if there is no child corresponding to token INDEX
fn INDEX(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INDEX, 0)
}
/// Retrieves first TerminalNode corresponding to token INDEXES
/// Returns `None` if there is no child corresponding to token INDEXES
fn INDEXES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INDEXES, 0)
}
/// Retrieves first TerminalNode corresponding to token INPATH
/// Returns `None` if there is no child corresponding to token INPATH
fn INPATH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INPATH, 0)
}
/// Retrieves first TerminalNode corresponding to token INPUT
/// Returns `None` if there is no child corresponding to token INPUT
fn INPUT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INPUT, 0)
}
/// Retrieves first TerminalNode corresponding to token INPUTFORMAT
/// Returns `None` if there is no child corresponding to token INPUTFORMAT
fn INPUTFORMAT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INPUTFORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token INSERT
/// Returns `None` if there is no child corresponding to token INSERT
fn INSERT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INSERT, 0)
}
/// Retrieves first TerminalNode corresponding to token INT
/// Returns `None` if there is no child corresponding to token INT
fn INT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INT, 0)
}
/// Retrieves first TerminalNode corresponding to token INTEGER
/// Returns `None` if there is no child corresponding to token INTEGER
fn INTEGER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INTEGER, 0)
}
/// Retrieves first TerminalNode corresponding to token INTERVAL
/// Returns `None` if there is no child corresponding to token INTERVAL
fn INTERVAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INTERVAL, 0)
}
/// Retrieves first TerminalNode corresponding to token INVOKER
/// Returns `None` if there is no child corresponding to token INVOKER
fn INVOKER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INVOKER, 0)
}
/// Retrieves first TerminalNode corresponding to token ITEMS
/// Returns `None` if there is no child corresponding to token ITEMS
fn ITEMS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ITEMS, 0)
}
/// Retrieves first TerminalNode corresponding to token ITERATE
/// Returns `None` if there is no child corresponding to token ITERATE
fn ITERATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ITERATE, 0)
}
/// Retrieves first TerminalNode corresponding to token JSON
/// Returns `None` if there is no child corresponding to token JSON
fn JSON(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(JSON, 0)
}
/// Retrieves first TerminalNode corresponding to token KEY
/// Returns `None` if there is no child corresponding to token KEY
fn KEY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(KEY, 0)
}
/// Retrieves first TerminalNode corresponding to token KEYS
/// Returns `None` if there is no child corresponding to token KEYS
fn KEYS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(KEYS, 0)
}
/// Retrieves first TerminalNode corresponding to token LANGUAGE
/// Returns `None` if there is no child corresponding to token LANGUAGE
fn LANGUAGE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LANGUAGE, 0)
}
/// Retrieves first TerminalNode corresponding to token LAST
/// Returns `None` if there is no child corresponding to token LAST
fn LAST(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LAST, 0)
}
/// Retrieves first TerminalNode corresponding to token LAZY
/// Returns `None` if there is no child corresponding to token LAZY
fn LAZY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LAZY, 0)
}
/// Retrieves first TerminalNode corresponding to token LEAVE
/// Returns `None` if there is no child corresponding to token LEAVE
fn LEAVE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEAVE, 0)
}
/// Retrieves first TerminalNode corresponding to token LEVEL
/// Returns `None` if there is no child corresponding to token LEVEL
fn LEVEL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEVEL, 0)
}
/// Retrieves first TerminalNode corresponding to token LIKE
/// Returns `None` if there is no child corresponding to token LIKE
fn LIKE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LIKE, 0)
}
/// Retrieves first TerminalNode corresponding to token ILIKE
/// Returns `None` if there is no child corresponding to token ILIKE
fn ILIKE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ILIKE, 0)
}
/// Retrieves first TerminalNode corresponding to token LIMIT
/// Returns `None` if there is no child corresponding to token LIMIT
fn LIMIT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LIMIT, 0)
}
/// Retrieves first TerminalNode corresponding to token LINES
/// Returns `None` if there is no child corresponding to token LINES
fn LINES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LINES, 0)
}
/// Retrieves first TerminalNode corresponding to token LIST
/// Returns `None` if there is no child corresponding to token LIST
fn LIST(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LIST, 0)
}
/// Retrieves first TerminalNode corresponding to token LOAD
/// Returns `None` if there is no child corresponding to token LOAD
fn LOAD(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LOAD, 0)
}
/// Retrieves first TerminalNode corresponding to token LOCAL
/// Returns `None` if there is no child corresponding to token LOCAL
fn LOCAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LOCAL, 0)
}
/// Retrieves first TerminalNode corresponding to token LOCATION
/// Returns `None` if there is no child corresponding to token LOCATION
fn LOCATION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LOCATION, 0)
}
/// Retrieves first TerminalNode corresponding to token LOCK
/// Returns `None` if there is no child corresponding to token LOCK
fn LOCK(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LOCK, 0)
}
/// Retrieves first TerminalNode corresponding to token LOCKS
/// Returns `None` if there is no child corresponding to token LOCKS
fn LOCKS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LOCKS, 0)
}
/// Retrieves first TerminalNode corresponding to token LOGICAL
/// Returns `None` if there is no child corresponding to token LOGICAL
fn LOGICAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LOGICAL, 0)
}
/// Retrieves first TerminalNode corresponding to token LONG
/// Returns `None` if there is no child corresponding to token LONG
fn LONG(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LONG, 0)
}
/// Retrieves first TerminalNode corresponding to token LOOP
/// Returns `None` if there is no child corresponding to token LOOP
fn LOOP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LOOP, 0)
}
/// Retrieves first TerminalNode corresponding to token MACRO
/// Returns `None` if there is no child corresponding to token MACRO
fn MACRO(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MACRO, 0)
}
/// Retrieves first TerminalNode corresponding to token MAP
/// Returns `None` if there is no child corresponding to token MAP
fn MAP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MAP, 0)
}
/// Retrieves first TerminalNode corresponding to token MATCHED
/// Returns `None` if there is no child corresponding to token MATCHED
fn MATCHED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MATCHED, 0)
}
/// Retrieves first TerminalNode corresponding to token MATERIALIZED
/// Returns `None` if there is no child corresponding to token MATERIALIZED
fn MATERIALIZED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MATERIALIZED, 0)
}
/// Retrieves first TerminalNode corresponding to token MAX
/// Returns `None` if there is no child corresponding to token MAX
fn MAX(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MAX, 0)
}
/// Retrieves first TerminalNode corresponding to token MEASURE
/// Returns `None` if there is no child corresponding to token MEASURE
fn MEASURE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MEASURE, 0)
}
/// Retrieves first TerminalNode corresponding to token MERGE
/// Returns `None` if there is no child corresponding to token MERGE
fn MERGE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MERGE, 0)
}
/// Retrieves first TerminalNode corresponding to token METRICS
/// Returns `None` if there is no child corresponding to token METRICS
fn METRICS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(METRICS, 0)
}
/// Retrieves first TerminalNode corresponding to token MICROSECOND
/// Returns `None` if there is no child corresponding to token MICROSECOND
fn MICROSECOND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MICROSECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token MICROSECONDS
/// Returns `None` if there is no child corresponding to token MICROSECONDS
fn MICROSECONDS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MICROSECONDS, 0)
}
/// Retrieves first TerminalNode corresponding to token MILLISECOND
/// Returns `None` if there is no child corresponding to token MILLISECOND
fn MILLISECOND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MILLISECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token MILLISECONDS
/// Returns `None` if there is no child corresponding to token MILLISECONDS
fn MILLISECONDS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MILLISECONDS, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUTE
/// Returns `None` if there is no child corresponding to token MINUTE
fn MINUTE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MINUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUTES
/// Returns `None` if there is no child corresponding to token MINUTES
fn MINUTES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MINUTES, 0)
}
/// Retrieves first TerminalNode corresponding to token MODIFIES
/// Returns `None` if there is no child corresponding to token MODIFIES
fn MODIFIES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MODIFIES, 0)
}
/// Retrieves first TerminalNode corresponding to token MONTH
/// Returns `None` if there is no child corresponding to token MONTH
fn MONTH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MONTH, 0)
}
/// Retrieves first TerminalNode corresponding to token MONTHS
/// Returns `None` if there is no child corresponding to token MONTHS
fn MONTHS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MONTHS, 0)
}
/// Retrieves first TerminalNode corresponding to token MSCK
/// Returns `None` if there is no child corresponding to token MSCK
fn MSCK(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MSCK, 0)
}
/// Retrieves first TerminalNode corresponding to token NAME
/// Returns `None` if there is no child corresponding to token NAME
fn NAME(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NAME, 0)
}
/// Retrieves first TerminalNode corresponding to token NAMESPACE
/// Returns `None` if there is no child corresponding to token NAMESPACE
fn NAMESPACE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NAMESPACE, 0)
}
/// Retrieves first TerminalNode corresponding to token NAMESPACES
/// Returns `None` if there is no child corresponding to token NAMESPACES
fn NAMESPACES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NAMESPACES, 0)
}
/// Retrieves first TerminalNode corresponding to token NANOSECOND
/// Returns `None` if there is no child corresponding to token NANOSECOND
fn NANOSECOND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NANOSECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token NANOSECONDS
/// Returns `None` if there is no child corresponding to token NANOSECONDS
fn NANOSECONDS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NANOSECONDS, 0)
}
/// Retrieves first TerminalNode corresponding to token NO
/// Returns `None` if there is no child corresponding to token NO
fn NO(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NO, 0)
}
/// Retrieves first TerminalNode corresponding to token NONE
/// Returns `None` if there is no child corresponding to token NONE
fn NONE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NONE, 0)
}
/// Retrieves first TerminalNode corresponding to token NORELY
/// Returns `None` if there is no child corresponding to token NORELY
fn NORELY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NORELY, 0)
}
/// Retrieves first TerminalNode corresponding to token NULLS
/// Returns `None` if there is no child corresponding to token NULLS
fn NULLS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NULLS, 0)
}
/// Retrieves first TerminalNode corresponding to token NUMERIC
/// Returns `None` if there is no child corresponding to token NUMERIC
fn NUMERIC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NUMERIC, 0)
}
/// Retrieves first TerminalNode corresponding to token OF
/// Returns `None` if there is no child corresponding to token OF
fn OF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OF, 0)
}
/// Retrieves first TerminalNode corresponding to token OPTION
/// Returns `None` if there is no child corresponding to token OPTION
fn OPTION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OPTION, 0)
}
/// Retrieves first TerminalNode corresponding to token OPTIONS
/// Returns `None` if there is no child corresponding to token OPTIONS
fn OPTIONS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OPTIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token OUT
/// Returns `None` if there is no child corresponding to token OUT
fn OUT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OUT, 0)
}
/// Retrieves first TerminalNode corresponding to token OUTPUTFORMAT
/// Returns `None` if there is no child corresponding to token OUTPUTFORMAT
fn OUTPUTFORMAT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OUTPUTFORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token OVER
/// Returns `None` if there is no child corresponding to token OVER
fn OVER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OVER, 0)
}
/// Retrieves first TerminalNode corresponding to token OVERLAY
/// Returns `None` if there is no child corresponding to token OVERLAY
fn OVERLAY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OVERLAY, 0)
}
/// Retrieves first TerminalNode corresponding to token OVERWRITE
/// Returns `None` if there is no child corresponding to token OVERWRITE
fn OVERWRITE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OVERWRITE, 0)
}
/// Retrieves first TerminalNode corresponding to token PARTITION
/// Returns `None` if there is no child corresponding to token PARTITION
fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PARTITION, 0)
}
/// Retrieves first TerminalNode corresponding to token PARTITIONED
/// Returns `None` if there is no child corresponding to token PARTITIONED
fn PARTITIONED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PARTITIONED, 0)
}
/// Retrieves first TerminalNode corresponding to token PARTITIONS
/// Returns `None` if there is no child corresponding to token PARTITIONS
fn PARTITIONS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PARTITIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token PERCENTLIT
/// Returns `None` if there is no child corresponding to token PERCENTLIT
fn PERCENTLIT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PERCENTLIT, 0)
}
/// Retrieves first TerminalNode corresponding to token PIVOT
/// Returns `None` if there is no child corresponding to token PIVOT
fn PIVOT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PIVOT, 0)
}
/// Retrieves first TerminalNode corresponding to token PLACING
/// Returns `None` if there is no child corresponding to token PLACING
fn PLACING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PLACING, 0)
}
/// Retrieves first TerminalNode corresponding to token POSITION
/// Returns `None` if there is no child corresponding to token POSITION
fn POSITION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(POSITION, 0)
}
/// Retrieves first TerminalNode corresponding to token PRECEDING
/// Returns `None` if there is no child corresponding to token PRECEDING
fn PRECEDING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PRECEDING, 0)
}
/// Retrieves first TerminalNode corresponding to token PRINCIPALS
/// Returns `None` if there is no child corresponding to token PRINCIPALS
fn PRINCIPALS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PRINCIPALS, 0)
}
/// Retrieves first TerminalNode corresponding to token PROCEDURE
/// Returns `None` if there is no child corresponding to token PROCEDURE
fn PROCEDURE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PROCEDURE, 0)
}
/// Retrieves first TerminalNode corresponding to token PROCEDURES
/// Returns `None` if there is no child corresponding to token PROCEDURES
fn PROCEDURES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PROCEDURES, 0)
}
/// Retrieves first TerminalNode corresponding to token PROPERTIES
/// Returns `None` if there is no child corresponding to token PROPERTIES
fn PROPERTIES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PROPERTIES, 0)
}
/// Retrieves first TerminalNode corresponding to token PURGE
/// Returns `None` if there is no child corresponding to token PURGE
fn PURGE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PURGE, 0)
}
/// Retrieves first TerminalNode corresponding to token QUARTER
/// Returns `None` if there is no child corresponding to token QUARTER
fn QUARTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(QUARTER, 0)
}
/// Retrieves first TerminalNode corresponding to token QUERY
/// Returns `None` if there is no child corresponding to token QUERY
fn QUERY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(QUERY, 0)
}
/// Retrieves first TerminalNode corresponding to token RANGE
/// Returns `None` if there is no child corresponding to token RANGE
fn RANGE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RANGE, 0)
}
/// Retrieves first TerminalNode corresponding to token READS
/// Returns `None` if there is no child corresponding to token READS
fn READS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(READS, 0)
}
/// Retrieves first TerminalNode corresponding to token REAL
/// Returns `None` if there is no child corresponding to token REAL
fn REAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(REAL, 0)
}
/// Retrieves first TerminalNode corresponding to token RECORDREADER
/// Returns `None` if there is no child corresponding to token RECORDREADER
fn RECORDREADER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RECORDREADER, 0)
}
/// Retrieves first TerminalNode corresponding to token RECORDWRITER
/// Returns `None` if there is no child corresponding to token RECORDWRITER
fn RECORDWRITER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RECORDWRITER, 0)
}
/// Retrieves first TerminalNode corresponding to token RECOVER
/// Returns `None` if there is no child corresponding to token RECOVER
fn RECOVER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RECOVER, 0)
}
/// Retrieves first TerminalNode corresponding to token RECURSION
/// Returns `None` if there is no child corresponding to token RECURSION
fn RECURSION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RECURSION, 0)
}
/// Retrieves first TerminalNode corresponding to token REDUCE
/// Returns `None` if there is no child corresponding to token REDUCE
fn REDUCE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(REDUCE, 0)
}
/// Retrieves first TerminalNode corresponding to token REFRESH
/// Returns `None` if there is no child corresponding to token REFRESH
fn REFRESH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(REFRESH, 0)
}
/// Retrieves first TerminalNode corresponding to token RELY
/// Returns `None` if there is no child corresponding to token RELY
fn RELY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RELY, 0)
}
/// Retrieves first TerminalNode corresponding to token RENAME
/// Returns `None` if there is no child corresponding to token RENAME
fn RENAME(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RENAME, 0)
}
/// Retrieves first TerminalNode corresponding to token REPAIR
/// Returns `None` if there is no child corresponding to token REPAIR
fn REPAIR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(REPAIR, 0)
}
/// Retrieves first TerminalNode corresponding to token REPEAT
/// Returns `None` if there is no child corresponding to token REPEAT
fn REPEAT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(REPEAT, 0)
}
/// Retrieves first TerminalNode corresponding to token REPEATABLE
/// Returns `None` if there is no child corresponding to token REPEATABLE
fn REPEATABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(REPEATABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token REPLACE
/// Returns `None` if there is no child corresponding to token REPLACE
fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(REPLACE, 0)
}
/// Retrieves first TerminalNode corresponding to token RESET
/// Returns `None` if there is no child corresponding to token RESET
fn RESET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RESET, 0)
}
/// Retrieves first TerminalNode corresponding to token RESPECT
/// Returns `None` if there is no child corresponding to token RESPECT
fn RESPECT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RESPECT, 0)
}
/// Retrieves first TerminalNode corresponding to token RESTRICT
/// Returns `None` if there is no child corresponding to token RESTRICT
fn RESTRICT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RESTRICT, 0)
}
/// Retrieves first TerminalNode corresponding to token RETURN
/// Returns `None` if there is no child corresponding to token RETURN
fn RETURN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RETURN, 0)
}
/// Retrieves first TerminalNode corresponding to token RETURNS
/// Returns `None` if there is no child corresponding to token RETURNS
fn RETURNS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RETURNS, 0)
}
/// Retrieves first TerminalNode corresponding to token REVOKE
/// Returns `None` if there is no child corresponding to token REVOKE
fn REVOKE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(REVOKE, 0)
}
/// Retrieves first TerminalNode corresponding to token RLIKE
/// Returns `None` if there is no child corresponding to token RLIKE
fn RLIKE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RLIKE, 0)
}
/// Retrieves first TerminalNode corresponding to token ROLE
/// Returns `None` if there is no child corresponding to token ROLE
fn ROLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ROLE, 0)
}
/// Retrieves first TerminalNode corresponding to token ROLES
/// Returns `None` if there is no child corresponding to token ROLES
fn ROLES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ROLES, 0)
}
/// Retrieves first TerminalNode corresponding to token ROLLBACK
/// Returns `None` if there is no child corresponding to token ROLLBACK
fn ROLLBACK(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ROLLBACK, 0)
}
/// Retrieves first TerminalNode corresponding to token ROLLUP
/// Returns `None` if there is no child corresponding to token ROLLUP
fn ROLLUP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ROLLUP, 0)
}
/// Retrieves first TerminalNode corresponding to token ROW
/// Returns `None` if there is no child corresponding to token ROW
fn ROW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ROW, 0)
}
/// Retrieves first TerminalNode corresponding to token ROWS
/// Returns `None` if there is no child corresponding to token ROWS
fn ROWS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ROWS, 0)
}
/// Retrieves first TerminalNode corresponding to token SCHEMA
/// Returns `None` if there is no child corresponding to token SCHEMA
fn SCHEMA(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SCHEMA, 0)
}
/// Retrieves first TerminalNode corresponding to token SCHEMAS
/// Returns `None` if there is no child corresponding to token SCHEMAS
fn SCHEMAS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SCHEMAS, 0)
}
/// Retrieves first TerminalNode corresponding to token SECOND
/// Returns `None` if there is no child corresponding to token SECOND
fn SECOND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token SECONDS
/// Returns `None` if there is no child corresponding to token SECONDS
fn SECONDS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SECONDS, 0)
}
/// Retrieves first TerminalNode corresponding to token SECURITY
/// Returns `None` if there is no child corresponding to token SECURITY
fn SECURITY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SECURITY, 0)
}
/// Retrieves first TerminalNode corresponding to token SEMI
/// Returns `None` if there is no child corresponding to token SEMI
fn SEMI(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SEMI, 0)
}
/// Retrieves first TerminalNode corresponding to token SEPARATED
/// Returns `None` if there is no child corresponding to token SEPARATED
fn SEPARATED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SEPARATED, 0)
}
/// Retrieves first TerminalNode corresponding to token SERDE
/// Returns `None` if there is no child corresponding to token SERDE
fn SERDE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SERDE, 0)
}
/// Retrieves first TerminalNode corresponding to token SERDEPROPERTIES
/// Returns `None` if there is no child corresponding to token SERDEPROPERTIES
fn SERDEPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SERDEPROPERTIES, 0)
}
/// Retrieves first TerminalNode corresponding to token SET
/// Returns `None` if there is no child corresponding to token SET
fn SET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SET, 0)
}
/// Retrieves first TerminalNode corresponding to token SETMINUS
/// Returns `None` if there is no child corresponding to token SETMINUS
fn SETMINUS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SETMINUS, 0)
}
/// Retrieves first TerminalNode corresponding to token SETS
/// Returns `None` if there is no child corresponding to token SETS
fn SETS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SETS, 0)
}
/// Retrieves first TerminalNode corresponding to token SHORT
/// Returns `None` if there is no child corresponding to token SHORT
fn SHORT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SHORT, 0)
}
/// Retrieves first TerminalNode corresponding to token SHOW
/// Returns `None` if there is no child corresponding to token SHOW
fn SHOW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SHOW, 0)
}
/// Retrieves first TerminalNode corresponding to token SINGLE
/// Returns `None` if there is no child corresponding to token SINGLE
fn SINGLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SINGLE, 0)
}
/// Retrieves first TerminalNode corresponding to token SKEWED
/// Returns `None` if there is no child corresponding to token SKEWED
fn SKEWED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SKEWED, 0)
}
/// Retrieves first TerminalNode corresponding to token SMALLINT
/// Returns `None` if there is no child corresponding to token SMALLINT
fn SMALLINT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SMALLINT, 0)
}
/// Retrieves first TerminalNode corresponding to token SORT
/// Returns `None` if there is no child corresponding to token SORT
fn SORT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SORT, 0)
}
/// Retrieves first TerminalNode corresponding to token SORTED
/// Returns `None` if there is no child corresponding to token SORTED
fn SORTED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SORTED, 0)
}
/// Retrieves first TerminalNode corresponding to token SOURCE
/// Returns `None` if there is no child corresponding to token SOURCE
fn SOURCE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SOURCE, 0)
}
/// Retrieves first TerminalNode corresponding to token SPECIFIC
/// Returns `None` if there is no child corresponding to token SPECIFIC
fn SPECIFIC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SPECIFIC, 0)
}
/// Retrieves first TerminalNode corresponding to token SQLEXCEPTION
/// Returns `None` if there is no child corresponding to token SQLEXCEPTION
fn SQLEXCEPTION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SQLEXCEPTION, 0)
}
/// Retrieves first TerminalNode corresponding to token SQLSTATE
/// Returns `None` if there is no child corresponding to token SQLSTATE
fn SQLSTATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SQLSTATE, 0)
}
/// Retrieves first TerminalNode corresponding to token START
/// Returns `None` if there is no child corresponding to token START
fn START(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(START, 0)
}
/// Retrieves first TerminalNode corresponding to token STATISTICS
/// Returns `None` if there is no child corresponding to token STATISTICS
fn STATISTICS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(STATISTICS, 0)
}
/// Retrieves first TerminalNode corresponding to token STORED
/// Returns `None` if there is no child corresponding to token STORED
fn STORED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(STORED, 0)
}
/// Retrieves first TerminalNode corresponding to token STRATIFY
/// Returns `None` if there is no child corresponding to token STRATIFY
fn STRATIFY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(STRATIFY, 0)
}
/// Retrieves first TerminalNode corresponding to token STRING
/// Returns `None` if there is no child corresponding to token STRING
fn STRING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(STRING, 0)
}
/// Retrieves first TerminalNode corresponding to token STRUCT
/// Returns `None` if there is no child corresponding to token STRUCT
fn STRUCT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(STRUCT, 0)
}
/// Retrieves first TerminalNode corresponding to token STREAM
/// Returns `None` if there is no child corresponding to token STREAM
fn STREAM(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(STREAM, 0)
}
/// Retrieves first TerminalNode corresponding to token STREAMING
/// Returns `None` if there is no child corresponding to token STREAMING
fn STREAMING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(STREAMING, 0)
}
/// Retrieves first TerminalNode corresponding to token SUBSTR
/// Returns `None` if there is no child corresponding to token SUBSTR
fn SUBSTR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SUBSTR, 0)
}
/// Retrieves first TerminalNode corresponding to token SUBSTRING
/// Returns `None` if there is no child corresponding to token SUBSTRING
fn SUBSTRING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SUBSTRING, 0)
}
/// Retrieves first TerminalNode corresponding to token SYNC
/// Returns `None` if there is no child corresponding to token SYNC
fn SYNC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SYNC, 0)
}
/// Retrieves first TerminalNode corresponding to token SYSTEM_TIME
/// Returns `None` if there is no child corresponding to token SYSTEM_TIME
fn SYSTEM_TIME(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SYSTEM_TIME, 0)
}
/// Retrieves first TerminalNode corresponding to token SYSTEM_VERSION
/// Returns `None` if there is no child corresponding to token SYSTEM_VERSION
fn SYSTEM_VERSION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SYSTEM_VERSION, 0)
}
/// Retrieves first TerminalNode corresponding to token TABLES
/// Returns `None` if there is no child corresponding to token TABLES
fn TABLES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TABLES, 0)
}
/// Retrieves first TerminalNode corresponding to token TABLESAMPLE
/// Returns `None` if there is no child corresponding to token TABLESAMPLE
fn TABLESAMPLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TABLESAMPLE, 0)
}
/// Retrieves first TerminalNode corresponding to token TARGET
/// Returns `None` if there is no child corresponding to token TARGET
fn TARGET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TARGET, 0)
}
/// Retrieves first TerminalNode corresponding to token TBLPROPERTIES
/// Returns `None` if there is no child corresponding to token TBLPROPERTIES
fn TBLPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TBLPROPERTIES, 0)
}
/// Retrieves first TerminalNode corresponding to token TEMPORARY
/// Returns `None` if there is no child corresponding to token TEMPORARY
fn TEMPORARY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TEMPORARY, 0)
}
/// Retrieves first TerminalNode corresponding to token TERMINATED
/// Returns `None` if there is no child corresponding to token TERMINATED
fn TERMINATED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TERMINATED, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMEDIFF
/// Returns `None` if there is no child corresponding to token TIMEDIFF
fn TIMEDIFF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TIMEDIFF, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMP
/// Returns `None` if there is no child corresponding to token TIMESTAMP
fn TIMESTAMP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMP_LTZ
/// Returns `None` if there is no child corresponding to token TIMESTAMP_LTZ
fn TIMESTAMP_LTZ(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP_LTZ, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMP_NTZ
/// Returns `None` if there is no child corresponding to token TIMESTAMP_NTZ
fn TIMESTAMP_NTZ(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP_NTZ, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMPADD
/// Returns `None` if there is no child corresponding to token TIMESTAMPADD
fn TIMESTAMPADD(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMPADD, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMPDIFF
/// Returns `None` if there is no child corresponding to token TIMESTAMPDIFF
fn TIMESTAMPDIFF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMPDIFF, 0)
}
/// Retrieves first TerminalNode corresponding to token TINYINT
/// Returns `None` if there is no child corresponding to token TINYINT
fn TINYINT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TINYINT, 0)
}
/// Retrieves first TerminalNode corresponding to token TOUCH
/// Returns `None` if there is no child corresponding to token TOUCH
fn TOUCH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TOUCH, 0)
}
/// Retrieves first TerminalNode corresponding to token TRANSACTION
/// Returns `None` if there is no child corresponding to token TRANSACTION
fn TRANSACTION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TRANSACTION, 0)
}
/// Retrieves first TerminalNode corresponding to token TRANSACTIONS
/// Returns `None` if there is no child corresponding to token TRANSACTIONS
fn TRANSACTIONS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TRANSACTIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token TRANSFORM
/// Returns `None` if there is no child corresponding to token TRANSFORM
fn TRANSFORM(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TRANSFORM, 0)
}
/// Retrieves first TerminalNode corresponding to token TRIM
/// Returns `None` if there is no child corresponding to token TRIM
fn TRIM(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TRIM, 0)
}
/// Retrieves first TerminalNode corresponding to token TRUE
/// Returns `None` if there is no child corresponding to token TRUE
fn TRUE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TRUE, 0)
}
/// Retrieves first TerminalNode corresponding to token TRUNCATE
/// Returns `None` if there is no child corresponding to token TRUNCATE
fn TRUNCATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TRUNCATE, 0)
}
/// Retrieves first TerminalNode corresponding to token TRY_CAST
/// Returns `None` if there is no child corresponding to token TRY_CAST
fn TRY_CAST(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TRY_CAST, 0)
}
/// Retrieves first TerminalNode corresponding to token TYPE
/// Returns `None` if there is no child corresponding to token TYPE
fn TYPE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TYPE, 0)
}
/// Retrieves first TerminalNode corresponding to token UNARCHIVE
/// Returns `None` if there is no child corresponding to token UNARCHIVE
fn UNARCHIVE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UNARCHIVE, 0)
}
/// Retrieves first TerminalNode corresponding to token UNBOUNDED
/// Returns `None` if there is no child corresponding to token UNBOUNDED
fn UNBOUNDED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UNBOUNDED, 0)
}
/// Retrieves first TerminalNode corresponding to token UNCACHE
/// Returns `None` if there is no child corresponding to token UNCACHE
fn UNCACHE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UNCACHE, 0)
}
/// Retrieves first TerminalNode corresponding to token UNLOCK
/// Returns `None` if there is no child corresponding to token UNLOCK
fn UNLOCK(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UNLOCK, 0)
}
/// Retrieves first TerminalNode corresponding to token UNPIVOT
/// Returns `None` if there is no child corresponding to token UNPIVOT
fn UNPIVOT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UNPIVOT, 0)
}
/// Retrieves first TerminalNode corresponding to token UNSET
/// Returns `None` if there is no child corresponding to token UNSET
fn UNSET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UNSET, 0)
}
/// Retrieves first TerminalNode corresponding to token UNTIL
/// Returns `None` if there is no child corresponding to token UNTIL
fn UNTIL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UNTIL, 0)
}
/// Retrieves first TerminalNode corresponding to token UPDATE
/// Returns `None` if there is no child corresponding to token UPDATE
fn UPDATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UPDATE, 0)
}
/// Retrieves first TerminalNode corresponding to token USE
/// Returns `None` if there is no child corresponding to token USE
fn USE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(USE, 0)
}
/// Retrieves first TerminalNode corresponding to token VALUE
/// Returns `None` if there is no child corresponding to token VALUE
fn VALUE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VALUE, 0)
}
/// Retrieves first TerminalNode corresponding to token VALUES
/// Returns `None` if there is no child corresponding to token VALUES
fn VALUES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VALUES, 0)
}
/// Retrieves first TerminalNode corresponding to token VARCHAR
/// Returns `None` if there is no child corresponding to token VARCHAR
fn VARCHAR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VARCHAR, 0)
}
/// Retrieves first TerminalNode corresponding to token VAR
/// Returns `None` if there is no child corresponding to token VAR
fn VAR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VAR, 0)
}
/// Retrieves first TerminalNode corresponding to token VARIABLE
/// Returns `None` if there is no child corresponding to token VARIABLE
fn VARIABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VARIABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token VARIANT
/// Returns `None` if there is no child corresponding to token VARIANT
fn VARIANT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VARIANT, 0)
}
/// Retrieves first TerminalNode corresponding to token VERSION
/// Returns `None` if there is no child corresponding to token VERSION
fn VERSION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VERSION, 0)
}
/// Retrieves first TerminalNode corresponding to token VIEW
/// Returns `None` if there is no child corresponding to token VIEW
fn VIEW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VIEW, 0)
}
/// Retrieves first TerminalNode corresponding to token VIEWS
/// Returns `None` if there is no child corresponding to token VIEWS
fn VIEWS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VIEWS, 0)
}
/// Retrieves first TerminalNode corresponding to token VOID
/// Returns `None` if there is no child corresponding to token VOID
fn VOID(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VOID, 0)
}
/// Retrieves first TerminalNode corresponding to token WEEK
/// Returns `None` if there is no child corresponding to token WEEK
fn WEEK(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WEEK, 0)
}
/// Retrieves first TerminalNode corresponding to token WEEKS
/// Returns `None` if there is no child corresponding to token WEEKS
fn WEEKS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WEEKS, 0)
}
/// Retrieves first TerminalNode corresponding to token WHILE
/// Returns `None` if there is no child corresponding to token WHILE
fn WHILE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WHILE, 0)
}
/// Retrieves first TerminalNode corresponding to token WATERMARK
/// Returns `None` if there is no child corresponding to token WATERMARK
fn WATERMARK(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WATERMARK, 0)
}
/// Retrieves first TerminalNode corresponding to token WINDOW
/// Returns `None` if there is no child corresponding to token WINDOW
fn WINDOW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WINDOW, 0)
}
/// Retrieves first TerminalNode corresponding to token WITHOUT
/// Returns `None` if there is no child corresponding to token WITHOUT
fn WITHOUT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WITHOUT, 0)
}
/// Retrieves first TerminalNode corresponding to token YEAR
/// Returns `None` if there is no child corresponding to token YEAR
fn YEAR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(YEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token YEARS
/// Returns `None` if there is no child corresponding to token YEARS
fn YEARS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(YEARS, 0)
}
/// Retrieves first TerminalNode corresponding to token ZONE
/// Returns `None` if there is no child corresponding to token ZONE
fn ZONE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ZONE, 0)
}

}

impl<'input> AnsiNonReservedContextAttrs<'input> for AnsiNonReservedContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn ansiNonReserved(&mut self,)
	-> Result<Rc<AnsiNonReservedContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AnsiNonReservedContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 544, RULE_ansiNonReserved);
        let mut _localctx: Rc<AnsiNonReservedContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(4999);
			_la = recog.base.input.la(1);
			if { !((((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ADD) | (1usize << AFTER) | (1usize << AGGREGATE) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << ANTI) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << ASC) | (1usize << AT) | (1usize << ATOMIC) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << BINDING))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BOOLEAN - 32)) | (1usize << (BUCKET - 32)) | (1usize << (BUCKETS - 32)) | (1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COMPUTE - 64)) | (1usize << (CONCATENATE - 64)) | (1usize << (CONDITION - 64)) | (1usize << (CONTAINS - 64)) | (1usize << (CONTINUE - 64)) | (1usize << (COST - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DEFINER - 96)) | (1usize << (DELAY - 96)) | (1usize << (DELETE - 96)) | (1usize << (DELIMITED - 96)) | (1usize << (DESC - 96)) | (1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSEIF - 96)) | (1usize << (ENFORCED - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXIT - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTEND - 96)) | (1usize << (EXTENDED - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (EXTERNAL - 128)) | (1usize << (EXTRACT - 128)) | (1usize << (FIELDS - 128)) | (1usize << (FILEFORMAT - 128)) | (1usize << (FIRST - 128)) | (1usize << (FLOAT - 128)) | (1usize << (FLOW - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FOUND - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GEOGRAPHY - 128)) | (1usize << (GEOMETRY - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HANDLER - 128)) | (1usize << (BINARY_HEX - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (IDENTIFIER_KW - 160)) | (1usize << (IDENTITY - 160)) | (1usize << (IF - 160)) | (1usize << (IGNORE - 160)) | (1usize << (IMMEDIATE - 160)) | (1usize << (IMPORT - 160)) | (1usize << (INCLUDE - 160)) | (1usize << (INCREMENT - 160)) | (1usize << (INDEX - 160)) | (1usize << (INDEXES - 160)) | (1usize << (INPATH - 160)) | (1usize << (INPUT - 160)) | (1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INVOKER - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ITERATE - 160)) | (1usize << (JSON - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LAZY - 192)) | (1usize << (LEAVE - 192)) | (1usize << (LEVEL - 192)) | (1usize << (LIKE - 192)) | (1usize << (ILIKE - 192)) | (1usize << (LIMIT - 192)) | (1usize << (LINES - 192)) | (1usize << (LIST - 192)) | (1usize << (LOAD - 192)) | (1usize << (LOCAL - 192)) | (1usize << (LOCATION - 192)) | (1usize << (LOCK - 192)) | (1usize << (LOCKS - 192)) | (1usize << (LOGICAL - 192)) | (1usize << (LONG - 192)) | (1usize << (LOOP - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MEASURE - 192)) | (1usize << (MERGE - 192)) | (1usize << (METRICS - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (MODIFIES - 224)) | (1usize << (MONTH - 224)) | (1usize << (MONTHS - 224)) | (1usize << (MSCK - 224)) | (1usize << (NAME - 224)) | (1usize << (NAMESPACE - 224)) | (1usize << (NAMESPACES - 224)) | (1usize << (NANOSECOND - 224)) | (1usize << (NANOSECONDS - 224)) | (1usize << (NO - 224)) | (1usize << (NONE - 224)) | (1usize << (NULLS - 224)) | (1usize << (NUMERIC - 224)) | (1usize << (NORELY - 224)) | (1usize << (OF - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PARTITION - 256)) | (1usize << (PARTITIONED - 256)) | (1usize << (PARTITIONS - 256)) | (1usize << (PERCENTLIT - 256)) | (1usize << (PIVOT - 256)) | (1usize << (PLACING - 256)) | (1usize << (POSITION - 256)) | (1usize << (PRECEDING - 256)) | (1usize << (PRINCIPALS - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PROCEDURES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PURGE - 256)) | (1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSION - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RELY - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEAT - 256)) | (1usize << (REPEATABLE - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (REPLACE - 288)) | (1usize << (RESET - 288)) | (1usize << (RESPECT - 288)) | (1usize << (RESTRICT - 288)) | (1usize << (RETURN - 288)) | (1usize << (RETURNS - 288)) | (1usize << (REVOKE - 288)) | (1usize << (RLIKE - 288)) | (1usize << (ROLE - 288)) | (1usize << (ROLES - 288)) | (1usize << (ROLLBACK - 288)) | (1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SEMI - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SET - 288)) | (1usize << (SETMINUS - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SKEWED - 320)) | (1usize << (SMALLINT - 320)) | (1usize << (SORT - 320)) | (1usize << (SORTED - 320)) | (1usize << (SOURCE - 320)) | (1usize << (SPECIFIC - 320)) | (1usize << (SQLEXCEPTION - 320)) | (1usize << (SQLSTATE - 320)) | (1usize << (START - 320)) | (1usize << (STATISTICS - 320)) | (1usize << (STORED - 320)) | (1usize << (STRATIFY - 320)) | (1usize << (STREAM - 320)) | (1usize << (STREAMING - 320)) | (1usize << (STRING - 320)) | (1usize << (STRUCT - 320)) | (1usize << (SUBSTR - 320)) | (1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TIMEDIFF - 352)) | (1usize << (TIMESTAMP - 352)) | (1usize << (TIMESTAMP_LTZ - 352)) | (1usize << (TIMESTAMP_NTZ - 352)) | (1usize << (TIMESTAMPADD - 352)) | (1usize << (TIMESTAMPDIFF - 352)) | (1usize << (TINYINT - 352)) | (1usize << (TOUCH - 352)) | (1usize << (TRANSACTION - 352)) | (1usize << (TRANSACTIONS - 352)) | (1usize << (TRANSFORM - 352)) | (1usize << (TRIM - 352)) | (1usize << (TRUE - 352)) | (1usize << (TRUNCATE - 352)) | (1usize << (TRY_CAST - 352)) | (1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UNTIL - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (VALUE - 385)) | (1usize << (VALUES - 385)) | (1usize << (VARCHAR - 385)) | (1usize << (VAR - 385)) | (1usize << (VARIABLE - 385)) | (1usize << (VARIANT - 385)) | (1usize << (VERSION - 385)) | (1usize << (VIEW - 385)) | (1usize << (VIEWS - 385)) | (1usize << (VOID - 385)) | (1usize << (WATERMARK - 385)) | (1usize << (WEEK - 385)) | (1usize << (WEEKS - 385)) | (1usize << (WHILE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (ZONE - 385)))) != 0)) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- strictNonReserved ----------------
pub type StrictNonReservedContextAll<'input> = StrictNonReservedContext<'input>;


pub type StrictNonReservedContext<'input> = BaseParserRuleContext<'input,StrictNonReservedContextExt<'input>>;

#[derive(Clone)]
pub struct StrictNonReservedContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for StrictNonReservedContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for StrictNonReservedContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_strictNonReserved(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_strictNonReserved(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for StrictNonReservedContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_strictNonReserved(self);
	}
}

impl<'input> CustomRuleContext<'input> for StrictNonReservedContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_strictNonReserved }
	//fn type_rule_index() -> usize where Self: Sized { RULE_strictNonReserved }
}
antlr_rust::tid!{StrictNonReservedContextExt<'a>}

impl<'input> StrictNonReservedContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StrictNonReservedContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StrictNonReservedContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StrictNonReservedContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<StrictNonReservedContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ANTI
/// Returns `None` if there is no child corresponding to token ANTI
fn ANTI(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ANTI, 0)
}
/// Retrieves first TerminalNode corresponding to token CROSS
/// Returns `None` if there is no child corresponding to token CROSS
fn CROSS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CROSS, 0)
}
/// Retrieves first TerminalNode corresponding to token EXCEPT
/// Returns `None` if there is no child corresponding to token EXCEPT
fn EXCEPT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXCEPT, 0)
}
/// Retrieves first TerminalNode corresponding to token FULL
/// Returns `None` if there is no child corresponding to token FULL
fn FULL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FULL, 0)
}
/// Retrieves first TerminalNode corresponding to token INNER
/// Returns `None` if there is no child corresponding to token INNER
fn INNER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INNER, 0)
}
/// Retrieves first TerminalNode corresponding to token INTERSECT
/// Returns `None` if there is no child corresponding to token INTERSECT
fn INTERSECT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INTERSECT, 0)
}
/// Retrieves first TerminalNode corresponding to token JOIN
/// Returns `None` if there is no child corresponding to token JOIN
fn JOIN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(JOIN, 0)
}
/// Retrieves first TerminalNode corresponding to token LATERAL
/// Returns `None` if there is no child corresponding to token LATERAL
fn LATERAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LATERAL, 0)
}
/// Retrieves first TerminalNode corresponding to token LEFT
/// Returns `None` if there is no child corresponding to token LEFT
fn LEFT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEFT, 0)
}
/// Retrieves first TerminalNode corresponding to token NATURAL
/// Returns `None` if there is no child corresponding to token NATURAL
fn NATURAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NATURAL, 0)
}
/// Retrieves first TerminalNode corresponding to token ON
/// Returns `None` if there is no child corresponding to token ON
fn ON(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ON, 0)
}
/// Retrieves first TerminalNode corresponding to token RIGHT
/// Returns `None` if there is no child corresponding to token RIGHT
fn RIGHT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RIGHT, 0)
}
/// Retrieves first TerminalNode corresponding to token SEMI
/// Returns `None` if there is no child corresponding to token SEMI
fn SEMI(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SEMI, 0)
}
/// Retrieves first TerminalNode corresponding to token SETMINUS
/// Returns `None` if there is no child corresponding to token SETMINUS
fn SETMINUS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SETMINUS, 0)
}
/// Retrieves first TerminalNode corresponding to token UNION
/// Returns `None` if there is no child corresponding to token UNION
fn UNION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UNION, 0)
}
/// Retrieves first TerminalNode corresponding to token USING
/// Returns `None` if there is no child corresponding to token USING
fn USING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(USING, 0)
}

}

impl<'input> StrictNonReservedContextAttrs<'input> for StrictNonReservedContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn strictNonReserved(&mut self,)
	-> Result<Rc<StrictNonReservedContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StrictNonReservedContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 546, RULE_strictNonReserved);
        let mut _localctx: Rc<StrictNonReservedContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5001);
			_la = recog.base.input.la(1);
			if { !(_la==ANTI || _la==CROSS || _la==EXCEPT || _la==FULL || ((((_la - 171)) & !0x3f) == 0 && ((1usize << (_la - 171)) & ((1usize << (INNER - 171)) | (1usize << (INTERSECT - 171)) | (1usize << (JOIN - 171)) | (1usize << (LATERAL - 171)) | (1usize << (LEFT - 171)))) != 0) || _la==NATURAL || _la==ON || ((((_la - 295)) & !0x3f) == 0 && ((1usize << (_la - 295)) & ((1usize << (RIGHT - 295)) | (1usize << (SEMI - 295)) | (1usize << (SETMINUS - 295)))) != 0) || _la==UNION || _la==USING) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- nonReserved ----------------
pub type NonReservedContextAll<'input> = NonReservedContext<'input>;


pub type NonReservedContext<'input> = BaseParserRuleContext<'input,NonReservedContextExt<'input>>;

#[derive(Clone)]
pub struct NonReservedContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> SqlBaseParserContext<'input> for NonReservedContext<'input>{}

impl<'input,'a> Listenable<dyn SqlBaseParserListener<'input> + 'a> for NonReservedContext<'input>{
		fn enter(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_nonReserved(self);
		}
		fn exit(&self,listener: &mut (dyn SqlBaseParserListener<'input> + 'a)) {
			listener.exit_nonReserved(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn SqlBaseParserVisitor<'input> + 'a> for NonReservedContext<'input>{
	fn accept(&self,visitor: &mut (dyn SqlBaseParserVisitor<'input> + 'a)) {
		visitor.visit_nonReserved(self);
	}
}

impl<'input> CustomRuleContext<'input> for NonReservedContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = SqlBaseParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nonReserved }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nonReserved }
}
antlr_rust::tid!{NonReservedContextExt<'a>}

impl<'input> NonReservedContextExt<'input>{
	fn new(parent: Option<Rc<dyn SqlBaseParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NonReservedContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NonReservedContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait NonReservedContextAttrs<'input>: SqlBaseParserContext<'input> + BorrowMut<NonReservedContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ADD
/// Returns `None` if there is no child corresponding to token ADD
fn ADD(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ADD, 0)
}
/// Retrieves first TerminalNode corresponding to token AFTER
/// Returns `None` if there is no child corresponding to token AFTER
fn AFTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AFTER, 0)
}
/// Retrieves first TerminalNode corresponding to token AGGREGATE
/// Returns `None` if there is no child corresponding to token AGGREGATE
fn AGGREGATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AGGREGATE, 0)
}
/// Retrieves first TerminalNode corresponding to token ALL
/// Returns `None` if there is no child corresponding to token ALL
fn ALL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ALL, 0)
}
/// Retrieves first TerminalNode corresponding to token ALTER
/// Returns `None` if there is no child corresponding to token ALTER
fn ALTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ALTER, 0)
}
/// Retrieves first TerminalNode corresponding to token ALWAYS
/// Returns `None` if there is no child corresponding to token ALWAYS
fn ALWAYS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ALWAYS, 0)
}
/// Retrieves first TerminalNode corresponding to token ANALYZE
/// Returns `None` if there is no child corresponding to token ANALYZE
fn ANALYZE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ANALYZE, 0)
}
/// Retrieves first TerminalNode corresponding to token AND
/// Returns `None` if there is no child corresponding to token AND
fn AND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AND, 0)
}
/// Retrieves first TerminalNode corresponding to token ANY
/// Returns `None` if there is no child corresponding to token ANY
fn ANY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ANY, 0)
}
/// Retrieves first TerminalNode corresponding to token ANY_VALUE
/// Returns `None` if there is no child corresponding to token ANY_VALUE
fn ANY_VALUE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ANY_VALUE, 0)
}
/// Retrieves first TerminalNode corresponding to token ARCHIVE
/// Returns `None` if there is no child corresponding to token ARCHIVE
fn ARCHIVE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ARCHIVE, 0)
}
/// Retrieves first TerminalNode corresponding to token ARRAY
/// Returns `None` if there is no child corresponding to token ARRAY
fn ARRAY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ARRAY, 0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
/// Retrieves first TerminalNode corresponding to token ASC
/// Returns `None` if there is no child corresponding to token ASC
fn ASC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ASC, 0)
}
/// Retrieves first TerminalNode corresponding to token AT
/// Returns `None` if there is no child corresponding to token AT
fn AT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AT, 0)
}
/// Retrieves first TerminalNode corresponding to token ATOMIC
/// Returns `None` if there is no child corresponding to token ATOMIC
fn ATOMIC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ATOMIC, 0)
}
/// Retrieves first TerminalNode corresponding to token AUTHORIZATION
/// Returns `None` if there is no child corresponding to token AUTHORIZATION
fn AUTHORIZATION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(AUTHORIZATION, 0)
}
/// Retrieves first TerminalNode corresponding to token BEGIN
/// Returns `None` if there is no child corresponding to token BEGIN
fn BEGIN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BEGIN, 0)
}
/// Retrieves first TerminalNode corresponding to token BETWEEN
/// Returns `None` if there is no child corresponding to token BETWEEN
fn BETWEEN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BETWEEN, 0)
}
/// Retrieves first TerminalNode corresponding to token BIGINT
/// Returns `None` if there is no child corresponding to token BIGINT
fn BIGINT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BIGINT, 0)
}
/// Retrieves first TerminalNode corresponding to token BINARY
/// Returns `None` if there is no child corresponding to token BINARY
fn BINARY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BINARY, 0)
}
/// Retrieves first TerminalNode corresponding to token BINARY_HEX
/// Returns `None` if there is no child corresponding to token BINARY_HEX
fn BINARY_HEX(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BINARY_HEX, 0)
}
/// Retrieves first TerminalNode corresponding to token BINDING
/// Returns `None` if there is no child corresponding to token BINDING
fn BINDING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BINDING, 0)
}
/// Retrieves first TerminalNode corresponding to token BOOLEAN
/// Returns `None` if there is no child corresponding to token BOOLEAN
fn BOOLEAN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BOOLEAN, 0)
}
/// Retrieves first TerminalNode corresponding to token BOTH
/// Returns `None` if there is no child corresponding to token BOTH
fn BOTH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BOTH, 0)
}
/// Retrieves first TerminalNode corresponding to token BUCKET
/// Returns `None` if there is no child corresponding to token BUCKET
fn BUCKET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BUCKET, 0)
}
/// Retrieves first TerminalNode corresponding to token BUCKETS
/// Returns `None` if there is no child corresponding to token BUCKETS
fn BUCKETS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BUCKETS, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
/// Retrieves first TerminalNode corresponding to token BYTE
/// Returns `None` if there is no child corresponding to token BYTE
fn BYTE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(BYTE, 0)
}
/// Retrieves first TerminalNode corresponding to token CACHE
/// Returns `None` if there is no child corresponding to token CACHE
fn CACHE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CACHE, 0)
}
/// Retrieves first TerminalNode corresponding to token CALL
/// Returns `None` if there is no child corresponding to token CALL
fn CALL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CALL, 0)
}
/// Retrieves first TerminalNode corresponding to token CALLED
/// Returns `None` if there is no child corresponding to token CALLED
fn CALLED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CALLED, 0)
}
/// Retrieves first TerminalNode corresponding to token CASCADE
/// Returns `None` if there is no child corresponding to token CASCADE
fn CASCADE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CASCADE, 0)
}
/// Retrieves first TerminalNode corresponding to token CASE
/// Returns `None` if there is no child corresponding to token CASE
fn CASE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CASE, 0)
}
/// Retrieves first TerminalNode corresponding to token CAST
/// Returns `None` if there is no child corresponding to token CAST
fn CAST(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CAST, 0)
}
/// Retrieves first TerminalNode corresponding to token CATALOG
/// Returns `None` if there is no child corresponding to token CATALOG
fn CATALOG(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CATALOG, 0)
}
/// Retrieves first TerminalNode corresponding to token CATALOGS
/// Returns `None` if there is no child corresponding to token CATALOGS
fn CATALOGS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CATALOGS, 0)
}
/// Retrieves first TerminalNode corresponding to token CHANGE
/// Returns `None` if there is no child corresponding to token CHANGE
fn CHANGE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CHANGE, 0)
}
/// Retrieves first TerminalNode corresponding to token CHAR
/// Returns `None` if there is no child corresponding to token CHAR
fn CHAR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CHAR, 0)
}
/// Retrieves first TerminalNode corresponding to token CHARACTER
/// Returns `None` if there is no child corresponding to token CHARACTER
fn CHARACTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CHARACTER, 0)
}
/// Retrieves first TerminalNode corresponding to token CHECK
/// Returns `None` if there is no child corresponding to token CHECK
fn CHECK(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CHECK, 0)
}
/// Retrieves first TerminalNode corresponding to token CLEAR
/// Returns `None` if there is no child corresponding to token CLEAR
fn CLEAR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CLEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token CLUSTER
/// Returns `None` if there is no child corresponding to token CLUSTER
fn CLUSTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CLUSTER, 0)
}
/// Retrieves first TerminalNode corresponding to token CLUSTERED
/// Returns `None` if there is no child corresponding to token CLUSTERED
fn CLUSTERED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CLUSTERED, 0)
}
/// Retrieves first TerminalNode corresponding to token CODEGEN
/// Returns `None` if there is no child corresponding to token CODEGEN
fn CODEGEN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CODEGEN, 0)
}
/// Retrieves first TerminalNode corresponding to token COLLATE
/// Returns `None` if there is no child corresponding to token COLLATE
fn COLLATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COLLATE, 0)
}
/// Retrieves first TerminalNode corresponding to token COLLATION
/// Returns `None` if there is no child corresponding to token COLLATION
fn COLLATION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COLLATION, 0)
}
/// Retrieves first TerminalNode corresponding to token COLLECTION
/// Returns `None` if there is no child corresponding to token COLLECTION
fn COLLECTION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COLLECTION, 0)
}
/// Retrieves first TerminalNode corresponding to token COLUMN
/// Returns `None` if there is no child corresponding to token COLUMN
fn COLUMN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COLUMN, 0)
}
/// Retrieves first TerminalNode corresponding to token COLUMNS
/// Returns `None` if there is no child corresponding to token COLUMNS
fn COLUMNS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COLUMNS, 0)
}
/// Retrieves first TerminalNode corresponding to token COMMENT
/// Returns `None` if there is no child corresponding to token COMMENT
fn COMMENT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMENT, 0)
}
/// Retrieves first TerminalNode corresponding to token COMMIT
/// Returns `None` if there is no child corresponding to token COMMIT
fn COMMIT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMMIT, 0)
}
/// Retrieves first TerminalNode corresponding to token COMPACT
/// Returns `None` if there is no child corresponding to token COMPACT
fn COMPACT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMPACT, 0)
}
/// Retrieves first TerminalNode corresponding to token COMPACTIONS
/// Returns `None` if there is no child corresponding to token COMPACTIONS
fn COMPACTIONS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMPACTIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token COMPENSATION
/// Returns `None` if there is no child corresponding to token COMPENSATION
fn COMPENSATION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMPENSATION, 0)
}
/// Retrieves first TerminalNode corresponding to token COMPUTE
/// Returns `None` if there is no child corresponding to token COMPUTE
fn COMPUTE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COMPUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token CONCATENATE
/// Returns `None` if there is no child corresponding to token CONCATENATE
fn CONCATENATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CONCATENATE, 0)
}
/// Retrieves first TerminalNode corresponding to token CONDITION
/// Returns `None` if there is no child corresponding to token CONDITION
fn CONDITION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CONDITION, 0)
}
/// Retrieves first TerminalNode corresponding to token CONSTRAINT
/// Returns `None` if there is no child corresponding to token CONSTRAINT
fn CONSTRAINT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CONSTRAINT, 0)
}
/// Retrieves first TerminalNode corresponding to token CONTAINS
/// Returns `None` if there is no child corresponding to token CONTAINS
fn CONTAINS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CONTAINS, 0)
}
/// Retrieves first TerminalNode corresponding to token CONTINUE
/// Returns `None` if there is no child corresponding to token CONTINUE
fn CONTINUE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CONTINUE, 0)
}
/// Retrieves first TerminalNode corresponding to token COST
/// Returns `None` if there is no child corresponding to token COST
fn COST(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(COST, 0)
}
/// Retrieves first TerminalNode corresponding to token CREATE
/// Returns `None` if there is no child corresponding to token CREATE
fn CREATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CREATE, 0)
}
/// Retrieves first TerminalNode corresponding to token CUBE
/// Returns `None` if there is no child corresponding to token CUBE
fn CUBE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CUBE, 0)
}
/// Retrieves first TerminalNode corresponding to token CURRENT
/// Returns `None` if there is no child corresponding to token CURRENT
fn CURRENT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CURRENT, 0)
}
/// Retrieves first TerminalNode corresponding to token CURRENT_DATE
/// Returns `None` if there is no child corresponding to token CURRENT_DATE
fn CURRENT_DATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CURRENT_DATE, 0)
}
/// Retrieves first TerminalNode corresponding to token CURRENT_TIME
/// Returns `None` if there is no child corresponding to token CURRENT_TIME
fn CURRENT_TIME(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CURRENT_TIME, 0)
}
/// Retrieves first TerminalNode corresponding to token CURRENT_TIMESTAMP
/// Returns `None` if there is no child corresponding to token CURRENT_TIMESTAMP
fn CURRENT_TIMESTAMP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CURRENT_TIMESTAMP, 0)
}
/// Retrieves first TerminalNode corresponding to token CURRENT_USER
/// Returns `None` if there is no child corresponding to token CURRENT_USER
fn CURRENT_USER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(CURRENT_USER, 0)
}
/// Retrieves first TerminalNode corresponding to token DATA
/// Returns `None` if there is no child corresponding to token DATA
fn DATA(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DATA, 0)
}
/// Retrieves first TerminalNode corresponding to token DATABASE
/// Returns `None` if there is no child corresponding to token DATABASE
fn DATABASE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DATABASE, 0)
}
/// Retrieves first TerminalNode corresponding to token DATABASES
/// Returns `None` if there is no child corresponding to token DATABASES
fn DATABASES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DATABASES, 0)
}
/// Retrieves first TerminalNode corresponding to token DATE
/// Returns `None` if there is no child corresponding to token DATE
fn DATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DATE, 0)
}
/// Retrieves first TerminalNode corresponding to token DATEADD
/// Returns `None` if there is no child corresponding to token DATEADD
fn DATEADD(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DATEADD, 0)
}
/// Retrieves first TerminalNode corresponding to token DATE_ADD
/// Returns `None` if there is no child corresponding to token DATE_ADD
fn DATE_ADD(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DATE_ADD, 0)
}
/// Retrieves first TerminalNode corresponding to token DATEDIFF
/// Returns `None` if there is no child corresponding to token DATEDIFF
fn DATEDIFF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DATEDIFF, 0)
}
/// Retrieves first TerminalNode corresponding to token DATE_DIFF
/// Returns `None` if there is no child corresponding to token DATE_DIFF
fn DATE_DIFF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DATE_DIFF, 0)
}
/// Retrieves first TerminalNode corresponding to token DAY
/// Returns `None` if there is no child corresponding to token DAY
fn DAY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DAY, 0)
}
/// Retrieves first TerminalNode corresponding to token DAYS
/// Returns `None` if there is no child corresponding to token DAYS
fn DAYS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DAYS, 0)
}
/// Retrieves first TerminalNode corresponding to token DAYOFYEAR
/// Returns `None` if there is no child corresponding to token DAYOFYEAR
fn DAYOFYEAR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DAYOFYEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token DBPROPERTIES
/// Returns `None` if there is no child corresponding to token DBPROPERTIES
fn DBPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DBPROPERTIES, 0)
}
/// Retrieves first TerminalNode corresponding to token DEC
/// Returns `None` if there is no child corresponding to token DEC
fn DEC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DEC, 0)
}
/// Retrieves first TerminalNode corresponding to token DECIMAL
/// Returns `None` if there is no child corresponding to token DECIMAL
fn DECIMAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DECIMAL, 0)
}
/// Retrieves first TerminalNode corresponding to token DECLARE
/// Returns `None` if there is no child corresponding to token DECLARE
fn DECLARE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DECLARE, 0)
}
/// Retrieves first TerminalNode corresponding to token DEFAULT
/// Returns `None` if there is no child corresponding to token DEFAULT
fn DEFAULT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DEFAULT, 0)
}
/// Retrieves first TerminalNode corresponding to token DEFINED
/// Returns `None` if there is no child corresponding to token DEFINED
fn DEFINED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DEFINED, 0)
}
/// Retrieves first TerminalNode corresponding to token DEFINER
/// Returns `None` if there is no child corresponding to token DEFINER
fn DEFINER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DEFINER, 0)
}
/// Retrieves first TerminalNode corresponding to token DELAY
/// Returns `None` if there is no child corresponding to token DELAY
fn DELAY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DELAY, 0)
}
/// Retrieves first TerminalNode corresponding to token DELETE
/// Returns `None` if there is no child corresponding to token DELETE
fn DELETE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DELETE, 0)
}
/// Retrieves first TerminalNode corresponding to token DELIMITED
/// Returns `None` if there is no child corresponding to token DELIMITED
fn DELIMITED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DELIMITED, 0)
}
/// Retrieves first TerminalNode corresponding to token DESC
/// Returns `None` if there is no child corresponding to token DESC
fn DESC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DESC, 0)
}
/// Retrieves first TerminalNode corresponding to token DESCRIBE
/// Returns `None` if there is no child corresponding to token DESCRIBE
fn DESCRIBE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DESCRIBE, 0)
}
/// Retrieves first TerminalNode corresponding to token DETERMINISTIC
/// Returns `None` if there is no child corresponding to token DETERMINISTIC
fn DETERMINISTIC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DETERMINISTIC, 0)
}
/// Retrieves first TerminalNode corresponding to token DFS
/// Returns `None` if there is no child corresponding to token DFS
fn DFS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DFS, 0)
}
/// Retrieves first TerminalNode corresponding to token DIRECTORIES
/// Returns `None` if there is no child corresponding to token DIRECTORIES
fn DIRECTORIES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DIRECTORIES, 0)
}
/// Retrieves first TerminalNode corresponding to token DIRECTORY
/// Returns `None` if there is no child corresponding to token DIRECTORY
fn DIRECTORY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DIRECTORY, 0)
}
/// Retrieves first TerminalNode corresponding to token DISTINCT
/// Returns `None` if there is no child corresponding to token DISTINCT
fn DISTINCT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DISTINCT, 0)
}
/// Retrieves first TerminalNode corresponding to token DISTRIBUTE
/// Returns `None` if there is no child corresponding to token DISTRIBUTE
fn DISTRIBUTE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DISTRIBUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token DIV
/// Returns `None` if there is no child corresponding to token DIV
fn DIV(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DIV, 0)
}
/// Retrieves first TerminalNode corresponding to token DO
/// Returns `None` if there is no child corresponding to token DO
fn DO(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DO, 0)
}
/// Retrieves first TerminalNode corresponding to token DOUBLE
/// Returns `None` if there is no child corresponding to token DOUBLE
fn DOUBLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DOUBLE, 0)
}
/// Retrieves first TerminalNode corresponding to token DROP
/// Returns `None` if there is no child corresponding to token DROP
fn DROP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(DROP, 0)
}
/// Retrieves first TerminalNode corresponding to token ELSE
/// Returns `None` if there is no child corresponding to token ELSE
fn ELSE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ELSE, 0)
}
/// Retrieves first TerminalNode corresponding to token ELSEIF
/// Returns `None` if there is no child corresponding to token ELSEIF
fn ELSEIF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ELSEIF, 0)
}
/// Retrieves first TerminalNode corresponding to token END
/// Returns `None` if there is no child corresponding to token END
fn END(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(END, 0)
}
/// Retrieves first TerminalNode corresponding to token ENFORCED
/// Returns `None` if there is no child corresponding to token ENFORCED
fn ENFORCED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ENFORCED, 0)
}
/// Retrieves first TerminalNode corresponding to token ESCAPE
/// Returns `None` if there is no child corresponding to token ESCAPE
fn ESCAPE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ESCAPE, 0)
}
/// Retrieves first TerminalNode corresponding to token ESCAPED
/// Returns `None` if there is no child corresponding to token ESCAPED
fn ESCAPED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ESCAPED, 0)
}
/// Retrieves first TerminalNode corresponding to token EVOLUTION
/// Returns `None` if there is no child corresponding to token EVOLUTION
fn EVOLUTION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EVOLUTION, 0)
}
/// Retrieves first TerminalNode corresponding to token EXCHANGE
/// Returns `None` if there is no child corresponding to token EXCHANGE
fn EXCHANGE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXCHANGE, 0)
}
/// Retrieves first TerminalNode corresponding to token EXCLUDE
/// Returns `None` if there is no child corresponding to token EXCLUDE
fn EXCLUDE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXCLUDE, 0)
}
/// Retrieves first TerminalNode corresponding to token EXECUTE
/// Returns `None` if there is no child corresponding to token EXECUTE
fn EXECUTE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXECUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token EXISTS
/// Returns `None` if there is no child corresponding to token EXISTS
fn EXISTS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXISTS, 0)
}
/// Retrieves first TerminalNode corresponding to token EXIT
/// Returns `None` if there is no child corresponding to token EXIT
fn EXIT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXIT, 0)
}
/// Retrieves first TerminalNode corresponding to token EXPLAIN
/// Returns `None` if there is no child corresponding to token EXPLAIN
fn EXPLAIN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXPLAIN, 0)
}
/// Retrieves first TerminalNode corresponding to token EXPORT
/// Returns `None` if there is no child corresponding to token EXPORT
fn EXPORT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXPORT, 0)
}
/// Retrieves first TerminalNode corresponding to token EXTEND
/// Returns `None` if there is no child corresponding to token EXTEND
fn EXTEND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXTEND, 0)
}
/// Retrieves first TerminalNode corresponding to token EXTENDED
/// Returns `None` if there is no child corresponding to token EXTENDED
fn EXTENDED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXTENDED, 0)
}
/// Retrieves first TerminalNode corresponding to token EXTERNAL
/// Returns `None` if there is no child corresponding to token EXTERNAL
fn EXTERNAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXTERNAL, 0)
}
/// Retrieves first TerminalNode corresponding to token EXTRACT
/// Returns `None` if there is no child corresponding to token EXTRACT
fn EXTRACT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(EXTRACT, 0)
}
/// Retrieves first TerminalNode corresponding to token FALSE
/// Returns `None` if there is no child corresponding to token FALSE
fn FALSE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FALSE, 0)
}
/// Retrieves first TerminalNode corresponding to token FETCH
/// Returns `None` if there is no child corresponding to token FETCH
fn FETCH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FETCH, 0)
}
/// Retrieves first TerminalNode corresponding to token FILTER
/// Returns `None` if there is no child corresponding to token FILTER
fn FILTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FILTER, 0)
}
/// Retrieves first TerminalNode corresponding to token FIELDS
/// Returns `None` if there is no child corresponding to token FIELDS
fn FIELDS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FIELDS, 0)
}
/// Retrieves first TerminalNode corresponding to token FILEFORMAT
/// Returns `None` if there is no child corresponding to token FILEFORMAT
fn FILEFORMAT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FILEFORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token FIRST
/// Returns `None` if there is no child corresponding to token FIRST
fn FIRST(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FIRST, 0)
}
/// Retrieves first TerminalNode corresponding to token FLOAT
/// Returns `None` if there is no child corresponding to token FLOAT
fn FLOAT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FLOAT, 0)
}
/// Retrieves first TerminalNode corresponding to token FLOW
/// Returns `None` if there is no child corresponding to token FLOW
fn FLOW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FLOW, 0)
}
/// Retrieves first TerminalNode corresponding to token FOLLOWING
/// Returns `None` if there is no child corresponding to token FOLLOWING
fn FOLLOWING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FOLLOWING, 0)
}
/// Retrieves first TerminalNode corresponding to token FOR
/// Returns `None` if there is no child corresponding to token FOR
fn FOR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FOR, 0)
}
/// Retrieves first TerminalNode corresponding to token FOREIGN
/// Returns `None` if there is no child corresponding to token FOREIGN
fn FOREIGN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FOREIGN, 0)
}
/// Retrieves first TerminalNode corresponding to token FORMAT
/// Returns `None` if there is no child corresponding to token FORMAT
fn FORMAT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token FORMATTED
/// Returns `None` if there is no child corresponding to token FORMATTED
fn FORMATTED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FORMATTED, 0)
}
/// Retrieves first TerminalNode corresponding to token FROM
/// Returns `None` if there is no child corresponding to token FROM
fn FROM(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FROM, 0)
}
/// Retrieves first TerminalNode corresponding to token FOUND
/// Returns `None` if there is no child corresponding to token FOUND
fn FOUND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FOUND, 0)
}
/// Retrieves first TerminalNode corresponding to token FUNCTION
/// Returns `None` if there is no child corresponding to token FUNCTION
fn FUNCTION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FUNCTION, 0)
}
/// Retrieves first TerminalNode corresponding to token FUNCTIONS
/// Returns `None` if there is no child corresponding to token FUNCTIONS
fn FUNCTIONS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(FUNCTIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token GENERATED
/// Returns `None` if there is no child corresponding to token GENERATED
fn GENERATED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(GENERATED, 0)
}
/// Retrieves first TerminalNode corresponding to token GEOGRAPHY
/// Returns `None` if there is no child corresponding to token GEOGRAPHY
fn GEOGRAPHY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(GEOGRAPHY, 0)
}
/// Retrieves first TerminalNode corresponding to token GEOMETRY
/// Returns `None` if there is no child corresponding to token GEOMETRY
fn GEOMETRY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(GEOMETRY, 0)
}
/// Retrieves first TerminalNode corresponding to token GLOBAL
/// Returns `None` if there is no child corresponding to token GLOBAL
fn GLOBAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(GLOBAL, 0)
}
/// Retrieves first TerminalNode corresponding to token GRANT
/// Returns `None` if there is no child corresponding to token GRANT
fn GRANT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(GRANT, 0)
}
/// Retrieves first TerminalNode corresponding to token GROUP
/// Returns `None` if there is no child corresponding to token GROUP
fn GROUP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(GROUP, 0)
}
/// Retrieves first TerminalNode corresponding to token GROUPING
/// Returns `None` if there is no child corresponding to token GROUPING
fn GROUPING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(GROUPING, 0)
}
/// Retrieves first TerminalNode corresponding to token HANDLER
/// Returns `None` if there is no child corresponding to token HANDLER
fn HANDLER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(HANDLER, 0)
}
/// Retrieves first TerminalNode corresponding to token HAVING
/// Returns `None` if there is no child corresponding to token HAVING
fn HAVING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(HAVING, 0)
}
/// Retrieves first TerminalNode corresponding to token HOUR
/// Returns `None` if there is no child corresponding to token HOUR
fn HOUR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(HOUR, 0)
}
/// Retrieves first TerminalNode corresponding to token HOURS
/// Returns `None` if there is no child corresponding to token HOURS
fn HOURS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(HOURS, 0)
}
/// Retrieves first TerminalNode corresponding to token IDENTIFIER_KW
/// Returns `None` if there is no child corresponding to token IDENTIFIER_KW
fn IDENTIFIER_KW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IDENTIFIER_KW, 0)
}
/// Retrieves first TerminalNode corresponding to token IDENTITY
/// Returns `None` if there is no child corresponding to token IDENTITY
fn IDENTITY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IDENTITY, 0)
}
/// Retrieves first TerminalNode corresponding to token IF
/// Returns `None` if there is no child corresponding to token IF
fn IF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IF, 0)
}
/// Retrieves first TerminalNode corresponding to token IGNORE
/// Returns `None` if there is no child corresponding to token IGNORE
fn IGNORE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IGNORE, 0)
}
/// Retrieves first TerminalNode corresponding to token IMMEDIATE
/// Returns `None` if there is no child corresponding to token IMMEDIATE
fn IMMEDIATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IMMEDIATE, 0)
}
/// Retrieves first TerminalNode corresponding to token IMPORT
/// Returns `None` if there is no child corresponding to token IMPORT
fn IMPORT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IMPORT, 0)
}
/// Retrieves first TerminalNode corresponding to token IN
/// Returns `None` if there is no child corresponding to token IN
fn IN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IN, 0)
}
/// Retrieves first TerminalNode corresponding to token INCLUDE
/// Returns `None` if there is no child corresponding to token INCLUDE
fn INCLUDE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INCLUDE, 0)
}
/// Retrieves first TerminalNode corresponding to token INCREMENT
/// Returns `None` if there is no child corresponding to token INCREMENT
fn INCREMENT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INCREMENT, 0)
}
/// Retrieves first TerminalNode corresponding to token INDEX
/// Returns `None` if there is no child corresponding to token INDEX
fn INDEX(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INDEX, 0)
}
/// Retrieves first TerminalNode corresponding to token INDEXES
/// Returns `None` if there is no child corresponding to token INDEXES
fn INDEXES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INDEXES, 0)
}
/// Retrieves first TerminalNode corresponding to token INPATH
/// Returns `None` if there is no child corresponding to token INPATH
fn INPATH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INPATH, 0)
}
/// Retrieves first TerminalNode corresponding to token INPUT
/// Returns `None` if there is no child corresponding to token INPUT
fn INPUT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INPUT, 0)
}
/// Retrieves first TerminalNode corresponding to token INPUTFORMAT
/// Returns `None` if there is no child corresponding to token INPUTFORMAT
fn INPUTFORMAT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INPUTFORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token INSERT
/// Returns `None` if there is no child corresponding to token INSERT
fn INSERT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INSERT, 0)
}
/// Retrieves first TerminalNode corresponding to token INT
/// Returns `None` if there is no child corresponding to token INT
fn INT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INT, 0)
}
/// Retrieves first TerminalNode corresponding to token INTEGER
/// Returns `None` if there is no child corresponding to token INTEGER
fn INTEGER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INTEGER, 0)
}
/// Retrieves first TerminalNode corresponding to token INTERVAL
/// Returns `None` if there is no child corresponding to token INTERVAL
fn INTERVAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INTERVAL, 0)
}
/// Retrieves first TerminalNode corresponding to token INTO
/// Returns `None` if there is no child corresponding to token INTO
fn INTO(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INTO, 0)
}
/// Retrieves first TerminalNode corresponding to token INVOKER
/// Returns `None` if there is no child corresponding to token INVOKER
fn INVOKER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(INVOKER, 0)
}
/// Retrieves first TerminalNode corresponding to token IS
/// Returns `None` if there is no child corresponding to token IS
fn IS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(IS, 0)
}
/// Retrieves first TerminalNode corresponding to token ITEMS
/// Returns `None` if there is no child corresponding to token ITEMS
fn ITEMS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ITEMS, 0)
}
/// Retrieves first TerminalNode corresponding to token ITERATE
/// Returns `None` if there is no child corresponding to token ITERATE
fn ITERATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ITERATE, 0)
}
/// Retrieves first TerminalNode corresponding to token JSON
/// Returns `None` if there is no child corresponding to token JSON
fn JSON(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(JSON, 0)
}
/// Retrieves first TerminalNode corresponding to token KEY
/// Returns `None` if there is no child corresponding to token KEY
fn KEY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(KEY, 0)
}
/// Retrieves first TerminalNode corresponding to token KEYS
/// Returns `None` if there is no child corresponding to token KEYS
fn KEYS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(KEYS, 0)
}
/// Retrieves first TerminalNode corresponding to token LANGUAGE
/// Returns `None` if there is no child corresponding to token LANGUAGE
fn LANGUAGE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LANGUAGE, 0)
}
/// Retrieves first TerminalNode corresponding to token LAST
/// Returns `None` if there is no child corresponding to token LAST
fn LAST(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LAST, 0)
}
/// Retrieves first TerminalNode corresponding to token LAZY
/// Returns `None` if there is no child corresponding to token LAZY
fn LAZY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LAZY, 0)
}
/// Retrieves first TerminalNode corresponding to token LEADING
/// Returns `None` if there is no child corresponding to token LEADING
fn LEADING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEADING, 0)
}
/// Retrieves first TerminalNode corresponding to token LEAVE
/// Returns `None` if there is no child corresponding to token LEAVE
fn LEAVE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEAVE, 0)
}
/// Retrieves first TerminalNode corresponding to token LEVEL
/// Returns `None` if there is no child corresponding to token LEVEL
fn LEVEL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LEVEL, 0)
}
/// Retrieves first TerminalNode corresponding to token LIKE
/// Returns `None` if there is no child corresponding to token LIKE
fn LIKE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LIKE, 0)
}
/// Retrieves first TerminalNode corresponding to token LONG
/// Returns `None` if there is no child corresponding to token LONG
fn LONG(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LONG, 0)
}
/// Retrieves first TerminalNode corresponding to token ILIKE
/// Returns `None` if there is no child corresponding to token ILIKE
fn ILIKE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ILIKE, 0)
}
/// Retrieves first TerminalNode corresponding to token LIMIT
/// Returns `None` if there is no child corresponding to token LIMIT
fn LIMIT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LIMIT, 0)
}
/// Retrieves first TerminalNode corresponding to token LINES
/// Returns `None` if there is no child corresponding to token LINES
fn LINES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LINES, 0)
}
/// Retrieves first TerminalNode corresponding to token LIST
/// Returns `None` if there is no child corresponding to token LIST
fn LIST(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LIST, 0)
}
/// Retrieves first TerminalNode corresponding to token LOAD
/// Returns `None` if there is no child corresponding to token LOAD
fn LOAD(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LOAD, 0)
}
/// Retrieves first TerminalNode corresponding to token LOCAL
/// Returns `None` if there is no child corresponding to token LOCAL
fn LOCAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LOCAL, 0)
}
/// Retrieves first TerminalNode corresponding to token LOCATION
/// Returns `None` if there is no child corresponding to token LOCATION
fn LOCATION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LOCATION, 0)
}
/// Retrieves first TerminalNode corresponding to token LOCK
/// Returns `None` if there is no child corresponding to token LOCK
fn LOCK(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LOCK, 0)
}
/// Retrieves first TerminalNode corresponding to token LOCKS
/// Returns `None` if there is no child corresponding to token LOCKS
fn LOCKS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LOCKS, 0)
}
/// Retrieves first TerminalNode corresponding to token LOGICAL
/// Returns `None` if there is no child corresponding to token LOGICAL
fn LOGICAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LOGICAL, 0)
}
/// Retrieves first TerminalNode corresponding to token LOOP
/// Returns `None` if there is no child corresponding to token LOOP
fn LOOP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(LOOP, 0)
}
/// Retrieves first TerminalNode corresponding to token MACRO
/// Returns `None` if there is no child corresponding to token MACRO
fn MACRO(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MACRO, 0)
}
/// Retrieves first TerminalNode corresponding to token MAP
/// Returns `None` if there is no child corresponding to token MAP
fn MAP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MAP, 0)
}
/// Retrieves first TerminalNode corresponding to token MATCHED
/// Returns `None` if there is no child corresponding to token MATCHED
fn MATCHED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MATCHED, 0)
}
/// Retrieves first TerminalNode corresponding to token MATERIALIZED
/// Returns `None` if there is no child corresponding to token MATERIALIZED
fn MATERIALIZED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MATERIALIZED, 0)
}
/// Retrieves first TerminalNode corresponding to token MAX
/// Returns `None` if there is no child corresponding to token MAX
fn MAX(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MAX, 0)
}
/// Retrieves first TerminalNode corresponding to token MEASURE
/// Returns `None` if there is no child corresponding to token MEASURE
fn MEASURE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MEASURE, 0)
}
/// Retrieves first TerminalNode corresponding to token MERGE
/// Returns `None` if there is no child corresponding to token MERGE
fn MERGE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MERGE, 0)
}
/// Retrieves first TerminalNode corresponding to token METRICS
/// Returns `None` if there is no child corresponding to token METRICS
fn METRICS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(METRICS, 0)
}
/// Retrieves first TerminalNode corresponding to token MICROSECOND
/// Returns `None` if there is no child corresponding to token MICROSECOND
fn MICROSECOND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MICROSECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token MICROSECONDS
/// Returns `None` if there is no child corresponding to token MICROSECONDS
fn MICROSECONDS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MICROSECONDS, 0)
}
/// Retrieves first TerminalNode corresponding to token MILLISECOND
/// Returns `None` if there is no child corresponding to token MILLISECOND
fn MILLISECOND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MILLISECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token MILLISECONDS
/// Returns `None` if there is no child corresponding to token MILLISECONDS
fn MILLISECONDS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MILLISECONDS, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUTE
/// Returns `None` if there is no child corresponding to token MINUTE
fn MINUTE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MINUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token MINUTES
/// Returns `None` if there is no child corresponding to token MINUTES
fn MINUTES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MINUTES, 0)
}
/// Retrieves first TerminalNode corresponding to token MODIFIES
/// Returns `None` if there is no child corresponding to token MODIFIES
fn MODIFIES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MODIFIES, 0)
}
/// Retrieves first TerminalNode corresponding to token MONTH
/// Returns `None` if there is no child corresponding to token MONTH
fn MONTH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MONTH, 0)
}
/// Retrieves first TerminalNode corresponding to token MONTHS
/// Returns `None` if there is no child corresponding to token MONTHS
fn MONTHS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MONTHS, 0)
}
/// Retrieves first TerminalNode corresponding to token MSCK
/// Returns `None` if there is no child corresponding to token MSCK
fn MSCK(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(MSCK, 0)
}
/// Retrieves first TerminalNode corresponding to token NAME
/// Returns `None` if there is no child corresponding to token NAME
fn NAME(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NAME, 0)
}
/// Retrieves first TerminalNode corresponding to token NAMESPACE
/// Returns `None` if there is no child corresponding to token NAMESPACE
fn NAMESPACE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NAMESPACE, 0)
}
/// Retrieves first TerminalNode corresponding to token NAMESPACES
/// Returns `None` if there is no child corresponding to token NAMESPACES
fn NAMESPACES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NAMESPACES, 0)
}
/// Retrieves first TerminalNode corresponding to token NANOSECOND
/// Returns `None` if there is no child corresponding to token NANOSECOND
fn NANOSECOND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NANOSECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token NANOSECONDS
/// Returns `None` if there is no child corresponding to token NANOSECONDS
fn NANOSECONDS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NANOSECONDS, 0)
}
/// Retrieves first TerminalNode corresponding to token NO
/// Returns `None` if there is no child corresponding to token NO
fn NO(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NO, 0)
}
/// Retrieves first TerminalNode corresponding to token NONE
/// Returns `None` if there is no child corresponding to token NONE
fn NONE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NONE, 0)
}
/// Retrieves first TerminalNode corresponding to token NORELY
/// Returns `None` if there is no child corresponding to token NORELY
fn NORELY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NORELY, 0)
}
/// Retrieves first TerminalNode corresponding to token NOT
/// Returns `None` if there is no child corresponding to token NOT
fn NOT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NOT, 0)
}
/// Retrieves first TerminalNode corresponding to token NULL
/// Returns `None` if there is no child corresponding to token NULL
fn NULL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NULL, 0)
}
/// Retrieves first TerminalNode corresponding to token NULLS
/// Returns `None` if there is no child corresponding to token NULLS
fn NULLS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NULLS, 0)
}
/// Retrieves first TerminalNode corresponding to token NUMERIC
/// Returns `None` if there is no child corresponding to token NUMERIC
fn NUMERIC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(NUMERIC, 0)
}
/// Retrieves first TerminalNode corresponding to token OF
/// Returns `None` if there is no child corresponding to token OF
fn OF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OF, 0)
}
/// Retrieves first TerminalNode corresponding to token OFFSET
/// Returns `None` if there is no child corresponding to token OFFSET
fn OFFSET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OFFSET, 0)
}
/// Retrieves first TerminalNode corresponding to token ONLY
/// Returns `None` if there is no child corresponding to token ONLY
fn ONLY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ONLY, 0)
}
/// Retrieves first TerminalNode corresponding to token OPTION
/// Returns `None` if there is no child corresponding to token OPTION
fn OPTION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OPTION, 0)
}
/// Retrieves first TerminalNode corresponding to token OPTIONS
/// Returns `None` if there is no child corresponding to token OPTIONS
fn OPTIONS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OPTIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token OR
/// Returns `None` if there is no child corresponding to token OR
fn OR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OR, 0)
}
/// Retrieves first TerminalNode corresponding to token ORDER
/// Returns `None` if there is no child corresponding to token ORDER
fn ORDER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ORDER, 0)
}
/// Retrieves first TerminalNode corresponding to token OUT
/// Returns `None` if there is no child corresponding to token OUT
fn OUT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OUT, 0)
}
/// Retrieves first TerminalNode corresponding to token OUTER
/// Returns `None` if there is no child corresponding to token OUTER
fn OUTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OUTER, 0)
}
/// Retrieves first TerminalNode corresponding to token OUTPUTFORMAT
/// Returns `None` if there is no child corresponding to token OUTPUTFORMAT
fn OUTPUTFORMAT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OUTPUTFORMAT, 0)
}
/// Retrieves first TerminalNode corresponding to token OVER
/// Returns `None` if there is no child corresponding to token OVER
fn OVER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OVER, 0)
}
/// Retrieves first TerminalNode corresponding to token OVERLAPS
/// Returns `None` if there is no child corresponding to token OVERLAPS
fn OVERLAPS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OVERLAPS, 0)
}
/// Retrieves first TerminalNode corresponding to token OVERLAY
/// Returns `None` if there is no child corresponding to token OVERLAY
fn OVERLAY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OVERLAY, 0)
}
/// Retrieves first TerminalNode corresponding to token OVERWRITE
/// Returns `None` if there is no child corresponding to token OVERWRITE
fn OVERWRITE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(OVERWRITE, 0)
}
/// Retrieves first TerminalNode corresponding to token PARTITION
/// Returns `None` if there is no child corresponding to token PARTITION
fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PARTITION, 0)
}
/// Retrieves first TerminalNode corresponding to token PARTITIONED
/// Returns `None` if there is no child corresponding to token PARTITIONED
fn PARTITIONED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PARTITIONED, 0)
}
/// Retrieves first TerminalNode corresponding to token PARTITIONS
/// Returns `None` if there is no child corresponding to token PARTITIONS
fn PARTITIONS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PARTITIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token PERCENTLIT
/// Returns `None` if there is no child corresponding to token PERCENTLIT
fn PERCENTLIT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PERCENTLIT, 0)
}
/// Retrieves first TerminalNode corresponding to token PIVOT
/// Returns `None` if there is no child corresponding to token PIVOT
fn PIVOT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PIVOT, 0)
}
/// Retrieves first TerminalNode corresponding to token PLACING
/// Returns `None` if there is no child corresponding to token PLACING
fn PLACING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PLACING, 0)
}
/// Retrieves first TerminalNode corresponding to token POSITION
/// Returns `None` if there is no child corresponding to token POSITION
fn POSITION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(POSITION, 0)
}
/// Retrieves first TerminalNode corresponding to token PRECEDING
/// Returns `None` if there is no child corresponding to token PRECEDING
fn PRECEDING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PRECEDING, 0)
}
/// Retrieves first TerminalNode corresponding to token PRIMARY
/// Returns `None` if there is no child corresponding to token PRIMARY
fn PRIMARY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PRIMARY, 0)
}
/// Retrieves first TerminalNode corresponding to token PRINCIPALS
/// Returns `None` if there is no child corresponding to token PRINCIPALS
fn PRINCIPALS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PRINCIPALS, 0)
}
/// Retrieves first TerminalNode corresponding to token PROCEDURE
/// Returns `None` if there is no child corresponding to token PROCEDURE
fn PROCEDURE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PROCEDURE, 0)
}
/// Retrieves first TerminalNode corresponding to token PROCEDURES
/// Returns `None` if there is no child corresponding to token PROCEDURES
fn PROCEDURES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PROCEDURES, 0)
}
/// Retrieves first TerminalNode corresponding to token PROPERTIES
/// Returns `None` if there is no child corresponding to token PROPERTIES
fn PROPERTIES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PROPERTIES, 0)
}
/// Retrieves first TerminalNode corresponding to token PURGE
/// Returns `None` if there is no child corresponding to token PURGE
fn PURGE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(PURGE, 0)
}
/// Retrieves first TerminalNode corresponding to token QUARTER
/// Returns `None` if there is no child corresponding to token QUARTER
fn QUARTER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(QUARTER, 0)
}
/// Retrieves first TerminalNode corresponding to token QUERY
/// Returns `None` if there is no child corresponding to token QUERY
fn QUERY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(QUERY, 0)
}
/// Retrieves first TerminalNode corresponding to token RANGE
/// Returns `None` if there is no child corresponding to token RANGE
fn RANGE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RANGE, 0)
}
/// Retrieves first TerminalNode corresponding to token READS
/// Returns `None` if there is no child corresponding to token READS
fn READS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(READS, 0)
}
/// Retrieves first TerminalNode corresponding to token REAL
/// Returns `None` if there is no child corresponding to token REAL
fn REAL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(REAL, 0)
}
/// Retrieves first TerminalNode corresponding to token RECORDREADER
/// Returns `None` if there is no child corresponding to token RECORDREADER
fn RECORDREADER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RECORDREADER, 0)
}
/// Retrieves first TerminalNode corresponding to token RECORDWRITER
/// Returns `None` if there is no child corresponding to token RECORDWRITER
fn RECORDWRITER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RECORDWRITER, 0)
}
/// Retrieves first TerminalNode corresponding to token RECOVER
/// Returns `None` if there is no child corresponding to token RECOVER
fn RECOVER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RECOVER, 0)
}
/// Retrieves first TerminalNode corresponding to token RECURSION
/// Returns `None` if there is no child corresponding to token RECURSION
fn RECURSION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RECURSION, 0)
}
/// Retrieves first TerminalNode corresponding to token RECURSIVE
/// Returns `None` if there is no child corresponding to token RECURSIVE
fn RECURSIVE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RECURSIVE, 0)
}
/// Retrieves first TerminalNode corresponding to token REDUCE
/// Returns `None` if there is no child corresponding to token REDUCE
fn REDUCE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(REDUCE, 0)
}
/// Retrieves first TerminalNode corresponding to token REFERENCES
/// Returns `None` if there is no child corresponding to token REFERENCES
fn REFERENCES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(REFERENCES, 0)
}
/// Retrieves first TerminalNode corresponding to token REFRESH
/// Returns `None` if there is no child corresponding to token REFRESH
fn REFRESH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(REFRESH, 0)
}
/// Retrieves first TerminalNode corresponding to token RELY
/// Returns `None` if there is no child corresponding to token RELY
fn RELY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RELY, 0)
}
/// Retrieves first TerminalNode corresponding to token RENAME
/// Returns `None` if there is no child corresponding to token RENAME
fn RENAME(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RENAME, 0)
}
/// Retrieves first TerminalNode corresponding to token REPAIR
/// Returns `None` if there is no child corresponding to token REPAIR
fn REPAIR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(REPAIR, 0)
}
/// Retrieves first TerminalNode corresponding to token REPEAT
/// Returns `None` if there is no child corresponding to token REPEAT
fn REPEAT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(REPEAT, 0)
}
/// Retrieves first TerminalNode corresponding to token REPEATABLE
/// Returns `None` if there is no child corresponding to token REPEATABLE
fn REPEATABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(REPEATABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token REPLACE
/// Returns `None` if there is no child corresponding to token REPLACE
fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(REPLACE, 0)
}
/// Retrieves first TerminalNode corresponding to token RESET
/// Returns `None` if there is no child corresponding to token RESET
fn RESET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RESET, 0)
}
/// Retrieves first TerminalNode corresponding to token RESPECT
/// Returns `None` if there is no child corresponding to token RESPECT
fn RESPECT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RESPECT, 0)
}
/// Retrieves first TerminalNode corresponding to token RESTRICT
/// Returns `None` if there is no child corresponding to token RESTRICT
fn RESTRICT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RESTRICT, 0)
}
/// Retrieves first TerminalNode corresponding to token RETURN
/// Returns `None` if there is no child corresponding to token RETURN
fn RETURN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RETURN, 0)
}
/// Retrieves first TerminalNode corresponding to token RETURNS
/// Returns `None` if there is no child corresponding to token RETURNS
fn RETURNS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RETURNS, 0)
}
/// Retrieves first TerminalNode corresponding to token REVOKE
/// Returns `None` if there is no child corresponding to token REVOKE
fn REVOKE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(REVOKE, 0)
}
/// Retrieves first TerminalNode corresponding to token RLIKE
/// Returns `None` if there is no child corresponding to token RLIKE
fn RLIKE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(RLIKE, 0)
}
/// Retrieves first TerminalNode corresponding to token ROLE
/// Returns `None` if there is no child corresponding to token ROLE
fn ROLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ROLE, 0)
}
/// Retrieves first TerminalNode corresponding to token ROLES
/// Returns `None` if there is no child corresponding to token ROLES
fn ROLES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ROLES, 0)
}
/// Retrieves first TerminalNode corresponding to token ROLLBACK
/// Returns `None` if there is no child corresponding to token ROLLBACK
fn ROLLBACK(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ROLLBACK, 0)
}
/// Retrieves first TerminalNode corresponding to token ROLLUP
/// Returns `None` if there is no child corresponding to token ROLLUP
fn ROLLUP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ROLLUP, 0)
}
/// Retrieves first TerminalNode corresponding to token ROW
/// Returns `None` if there is no child corresponding to token ROW
fn ROW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ROW, 0)
}
/// Retrieves first TerminalNode corresponding to token ROWS
/// Returns `None` if there is no child corresponding to token ROWS
fn ROWS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ROWS, 0)
}
/// Retrieves first TerminalNode corresponding to token SCHEMA
/// Returns `None` if there is no child corresponding to token SCHEMA
fn SCHEMA(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SCHEMA, 0)
}
/// Retrieves first TerminalNode corresponding to token SCHEMAS
/// Returns `None` if there is no child corresponding to token SCHEMAS
fn SCHEMAS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SCHEMAS, 0)
}
/// Retrieves first TerminalNode corresponding to token SECOND
/// Returns `None` if there is no child corresponding to token SECOND
fn SECOND(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SECOND, 0)
}
/// Retrieves first TerminalNode corresponding to token SECONDS
/// Returns `None` if there is no child corresponding to token SECONDS
fn SECONDS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SECONDS, 0)
}
/// Retrieves first TerminalNode corresponding to token SECURITY
/// Returns `None` if there is no child corresponding to token SECURITY
fn SECURITY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SECURITY, 0)
}
/// Retrieves first TerminalNode corresponding to token SELECT
/// Returns `None` if there is no child corresponding to token SELECT
fn SELECT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SELECT, 0)
}
/// Retrieves first TerminalNode corresponding to token SEPARATED
/// Returns `None` if there is no child corresponding to token SEPARATED
fn SEPARATED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SEPARATED, 0)
}
/// Retrieves first TerminalNode corresponding to token SERDE
/// Returns `None` if there is no child corresponding to token SERDE
fn SERDE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SERDE, 0)
}
/// Retrieves first TerminalNode corresponding to token SERDEPROPERTIES
/// Returns `None` if there is no child corresponding to token SERDEPROPERTIES
fn SERDEPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SERDEPROPERTIES, 0)
}
/// Retrieves first TerminalNode corresponding to token SESSION_USER
/// Returns `None` if there is no child corresponding to token SESSION_USER
fn SESSION_USER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SESSION_USER, 0)
}
/// Retrieves first TerminalNode corresponding to token SET
/// Returns `None` if there is no child corresponding to token SET
fn SET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SET, 0)
}
/// Retrieves first TerminalNode corresponding to token SETS
/// Returns `None` if there is no child corresponding to token SETS
fn SETS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SETS, 0)
}
/// Retrieves first TerminalNode corresponding to token SHORT
/// Returns `None` if there is no child corresponding to token SHORT
fn SHORT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SHORT, 0)
}
/// Retrieves first TerminalNode corresponding to token SHOW
/// Returns `None` if there is no child corresponding to token SHOW
fn SHOW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SHOW, 0)
}
/// Retrieves first TerminalNode corresponding to token SINGLE
/// Returns `None` if there is no child corresponding to token SINGLE
fn SINGLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SINGLE, 0)
}
/// Retrieves first TerminalNode corresponding to token SKEWED
/// Returns `None` if there is no child corresponding to token SKEWED
fn SKEWED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SKEWED, 0)
}
/// Retrieves first TerminalNode corresponding to token SMALLINT
/// Returns `None` if there is no child corresponding to token SMALLINT
fn SMALLINT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SMALLINT, 0)
}
/// Retrieves first TerminalNode corresponding to token SOME
/// Returns `None` if there is no child corresponding to token SOME
fn SOME(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SOME, 0)
}
/// Retrieves first TerminalNode corresponding to token SORT
/// Returns `None` if there is no child corresponding to token SORT
fn SORT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SORT, 0)
}
/// Retrieves first TerminalNode corresponding to token SORTED
/// Returns `None` if there is no child corresponding to token SORTED
fn SORTED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SORTED, 0)
}
/// Retrieves first TerminalNode corresponding to token SOURCE
/// Returns `None` if there is no child corresponding to token SOURCE
fn SOURCE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SOURCE, 0)
}
/// Retrieves first TerminalNode corresponding to token SPECIFIC
/// Returns `None` if there is no child corresponding to token SPECIFIC
fn SPECIFIC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SPECIFIC, 0)
}
/// Retrieves first TerminalNode corresponding to token SQL
/// Returns `None` if there is no child corresponding to token SQL
fn SQL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SQL, 0)
}
/// Retrieves first TerminalNode corresponding to token SQLEXCEPTION
/// Returns `None` if there is no child corresponding to token SQLEXCEPTION
fn SQLEXCEPTION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SQLEXCEPTION, 0)
}
/// Retrieves first TerminalNode corresponding to token SQLSTATE
/// Returns `None` if there is no child corresponding to token SQLSTATE
fn SQLSTATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SQLSTATE, 0)
}
/// Retrieves first TerminalNode corresponding to token START
/// Returns `None` if there is no child corresponding to token START
fn START(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(START, 0)
}
/// Retrieves first TerminalNode corresponding to token STATISTICS
/// Returns `None` if there is no child corresponding to token STATISTICS
fn STATISTICS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(STATISTICS, 0)
}
/// Retrieves first TerminalNode corresponding to token STORED
/// Returns `None` if there is no child corresponding to token STORED
fn STORED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(STORED, 0)
}
/// Retrieves first TerminalNode corresponding to token STRATIFY
/// Returns `None` if there is no child corresponding to token STRATIFY
fn STRATIFY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(STRATIFY, 0)
}
/// Retrieves first TerminalNode corresponding to token STREAM
/// Returns `None` if there is no child corresponding to token STREAM
fn STREAM(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(STREAM, 0)
}
/// Retrieves first TerminalNode corresponding to token STREAMING
/// Returns `None` if there is no child corresponding to token STREAMING
fn STREAMING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(STREAMING, 0)
}
/// Retrieves first TerminalNode corresponding to token STRING
/// Returns `None` if there is no child corresponding to token STRING
fn STRING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(STRING, 0)
}
/// Retrieves first TerminalNode corresponding to token STRUCT
/// Returns `None` if there is no child corresponding to token STRUCT
fn STRUCT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(STRUCT, 0)
}
/// Retrieves first TerminalNode corresponding to token SUBSTR
/// Returns `None` if there is no child corresponding to token SUBSTR
fn SUBSTR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SUBSTR, 0)
}
/// Retrieves first TerminalNode corresponding to token SUBSTRING
/// Returns `None` if there is no child corresponding to token SUBSTRING
fn SUBSTRING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SUBSTRING, 0)
}
/// Retrieves first TerminalNode corresponding to token SYNC
/// Returns `None` if there is no child corresponding to token SYNC
fn SYNC(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SYNC, 0)
}
/// Retrieves first TerminalNode corresponding to token SYSTEM_TIME
/// Returns `None` if there is no child corresponding to token SYSTEM_TIME
fn SYSTEM_TIME(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SYSTEM_TIME, 0)
}
/// Retrieves first TerminalNode corresponding to token SYSTEM_VERSION
/// Returns `None` if there is no child corresponding to token SYSTEM_VERSION
fn SYSTEM_VERSION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(SYSTEM_VERSION, 0)
}
/// Retrieves first TerminalNode corresponding to token TABLE
/// Returns `None` if there is no child corresponding to token TABLE
fn TABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token TABLES
/// Returns `None` if there is no child corresponding to token TABLES
fn TABLES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TABLES, 0)
}
/// Retrieves first TerminalNode corresponding to token TABLESAMPLE
/// Returns `None` if there is no child corresponding to token TABLESAMPLE
fn TABLESAMPLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TABLESAMPLE, 0)
}
/// Retrieves first TerminalNode corresponding to token TARGET
/// Returns `None` if there is no child corresponding to token TARGET
fn TARGET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TARGET, 0)
}
/// Retrieves first TerminalNode corresponding to token TBLPROPERTIES
/// Returns `None` if there is no child corresponding to token TBLPROPERTIES
fn TBLPROPERTIES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TBLPROPERTIES, 0)
}
/// Retrieves first TerminalNode corresponding to token TEMPORARY
/// Returns `None` if there is no child corresponding to token TEMPORARY
fn TEMPORARY(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TEMPORARY, 0)
}
/// Retrieves first TerminalNode corresponding to token TERMINATED
/// Returns `None` if there is no child corresponding to token TERMINATED
fn TERMINATED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TERMINATED, 0)
}
/// Retrieves first TerminalNode corresponding to token THEN
/// Returns `None` if there is no child corresponding to token THEN
fn THEN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(THEN, 0)
}
/// Retrieves first TerminalNode corresponding to token TIME
/// Returns `None` if there is no child corresponding to token TIME
fn TIME(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TIME, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMEDIFF
/// Returns `None` if there is no child corresponding to token TIMEDIFF
fn TIMEDIFF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TIMEDIFF, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMP
/// Returns `None` if there is no child corresponding to token TIMESTAMP
fn TIMESTAMP(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMP_LTZ
/// Returns `None` if there is no child corresponding to token TIMESTAMP_LTZ
fn TIMESTAMP_LTZ(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP_LTZ, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMP_NTZ
/// Returns `None` if there is no child corresponding to token TIMESTAMP_NTZ
fn TIMESTAMP_NTZ(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMP_NTZ, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMPADD
/// Returns `None` if there is no child corresponding to token TIMESTAMPADD
fn TIMESTAMPADD(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMPADD, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESTAMPDIFF
/// Returns `None` if there is no child corresponding to token TIMESTAMPDIFF
fn TIMESTAMPDIFF(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TIMESTAMPDIFF, 0)
}
/// Retrieves first TerminalNode corresponding to token TINYINT
/// Returns `None` if there is no child corresponding to token TINYINT
fn TINYINT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TINYINT, 0)
}
/// Retrieves first TerminalNode corresponding to token TO
/// Returns `None` if there is no child corresponding to token TO
fn TO(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TO, 0)
}
/// Retrieves first TerminalNode corresponding to token TOUCH
/// Returns `None` if there is no child corresponding to token TOUCH
fn TOUCH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TOUCH, 0)
}
/// Retrieves first TerminalNode corresponding to token TRAILING
/// Returns `None` if there is no child corresponding to token TRAILING
fn TRAILING(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TRAILING, 0)
}
/// Retrieves first TerminalNode corresponding to token TRANSACTION
/// Returns `None` if there is no child corresponding to token TRANSACTION
fn TRANSACTION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TRANSACTION, 0)
}
/// Retrieves first TerminalNode corresponding to token TRANSACTIONS
/// Returns `None` if there is no child corresponding to token TRANSACTIONS
fn TRANSACTIONS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TRANSACTIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token TRANSFORM
/// Returns `None` if there is no child corresponding to token TRANSFORM
fn TRANSFORM(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TRANSFORM, 0)
}
/// Retrieves first TerminalNode corresponding to token TRIM
/// Returns `None` if there is no child corresponding to token TRIM
fn TRIM(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TRIM, 0)
}
/// Retrieves first TerminalNode corresponding to token TRUE
/// Returns `None` if there is no child corresponding to token TRUE
fn TRUE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TRUE, 0)
}
/// Retrieves first TerminalNode corresponding to token TRUNCATE
/// Returns `None` if there is no child corresponding to token TRUNCATE
fn TRUNCATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TRUNCATE, 0)
}
/// Retrieves first TerminalNode corresponding to token TRY_CAST
/// Returns `None` if there is no child corresponding to token TRY_CAST
fn TRY_CAST(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TRY_CAST, 0)
}
/// Retrieves first TerminalNode corresponding to token TYPE
/// Returns `None` if there is no child corresponding to token TYPE
fn TYPE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(TYPE, 0)
}
/// Retrieves first TerminalNode corresponding to token UNARCHIVE
/// Returns `None` if there is no child corresponding to token UNARCHIVE
fn UNARCHIVE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UNARCHIVE, 0)
}
/// Retrieves first TerminalNode corresponding to token UNBOUNDED
/// Returns `None` if there is no child corresponding to token UNBOUNDED
fn UNBOUNDED(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UNBOUNDED, 0)
}
/// Retrieves first TerminalNode corresponding to token UNCACHE
/// Returns `None` if there is no child corresponding to token UNCACHE
fn UNCACHE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UNCACHE, 0)
}
/// Retrieves first TerminalNode corresponding to token UNIQUE
/// Returns `None` if there is no child corresponding to token UNIQUE
fn UNIQUE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UNIQUE, 0)
}
/// Retrieves first TerminalNode corresponding to token UNKNOWN
/// Returns `None` if there is no child corresponding to token UNKNOWN
fn UNKNOWN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UNKNOWN, 0)
}
/// Retrieves first TerminalNode corresponding to token UNLOCK
/// Returns `None` if there is no child corresponding to token UNLOCK
fn UNLOCK(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UNLOCK, 0)
}
/// Retrieves first TerminalNode corresponding to token UNPIVOT
/// Returns `None` if there is no child corresponding to token UNPIVOT
fn UNPIVOT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UNPIVOT, 0)
}
/// Retrieves first TerminalNode corresponding to token UNSET
/// Returns `None` if there is no child corresponding to token UNSET
fn UNSET(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UNSET, 0)
}
/// Retrieves first TerminalNode corresponding to token UNTIL
/// Returns `None` if there is no child corresponding to token UNTIL
fn UNTIL(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UNTIL, 0)
}
/// Retrieves first TerminalNode corresponding to token UPDATE
/// Returns `None` if there is no child corresponding to token UPDATE
fn UPDATE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(UPDATE, 0)
}
/// Retrieves first TerminalNode corresponding to token USE
/// Returns `None` if there is no child corresponding to token USE
fn USE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(USE, 0)
}
/// Retrieves first TerminalNode corresponding to token USER
/// Returns `None` if there is no child corresponding to token USER
fn USER(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(USER, 0)
}
/// Retrieves first TerminalNode corresponding to token VALUE
/// Returns `None` if there is no child corresponding to token VALUE
fn VALUE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VALUE, 0)
}
/// Retrieves first TerminalNode corresponding to token VALUES
/// Returns `None` if there is no child corresponding to token VALUES
fn VALUES(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VALUES, 0)
}
/// Retrieves first TerminalNode corresponding to token VARCHAR
/// Returns `None` if there is no child corresponding to token VARCHAR
fn VARCHAR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VARCHAR, 0)
}
/// Retrieves first TerminalNode corresponding to token VAR
/// Returns `None` if there is no child corresponding to token VAR
fn VAR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VAR, 0)
}
/// Retrieves first TerminalNode corresponding to token VARIABLE
/// Returns `None` if there is no child corresponding to token VARIABLE
fn VARIABLE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VARIABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token VARIANT
/// Returns `None` if there is no child corresponding to token VARIANT
fn VARIANT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VARIANT, 0)
}
/// Retrieves first TerminalNode corresponding to token VERSION
/// Returns `None` if there is no child corresponding to token VERSION
fn VERSION(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VERSION, 0)
}
/// Retrieves first TerminalNode corresponding to token VIEW
/// Returns `None` if there is no child corresponding to token VIEW
fn VIEW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VIEW, 0)
}
/// Retrieves first TerminalNode corresponding to token VIEWS
/// Returns `None` if there is no child corresponding to token VIEWS
fn VIEWS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VIEWS, 0)
}
/// Retrieves first TerminalNode corresponding to token VOID
/// Returns `None` if there is no child corresponding to token VOID
fn VOID(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(VOID, 0)
}
/// Retrieves first TerminalNode corresponding to token WATERMARK
/// Returns `None` if there is no child corresponding to token WATERMARK
fn WATERMARK(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WATERMARK, 0)
}
/// Retrieves first TerminalNode corresponding to token WEEK
/// Returns `None` if there is no child corresponding to token WEEK
fn WEEK(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WEEK, 0)
}
/// Retrieves first TerminalNode corresponding to token WEEKS
/// Returns `None` if there is no child corresponding to token WEEKS
fn WEEKS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WEEKS, 0)
}
/// Retrieves first TerminalNode corresponding to token WHILE
/// Returns `None` if there is no child corresponding to token WHILE
fn WHILE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WHILE, 0)
}
/// Retrieves first TerminalNode corresponding to token WHEN
/// Returns `None` if there is no child corresponding to token WHEN
fn WHEN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WHEN, 0)
}
/// Retrieves first TerminalNode corresponding to token WHERE
/// Returns `None` if there is no child corresponding to token WHERE
fn WHERE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WHERE, 0)
}
/// Retrieves first TerminalNode corresponding to token WINDOW
/// Returns `None` if there is no child corresponding to token WINDOW
fn WINDOW(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WINDOW, 0)
}
/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token WITHIN
/// Returns `None` if there is no child corresponding to token WITHIN
fn WITHIN(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WITHIN, 0)
}
/// Retrieves first TerminalNode corresponding to token WITHOUT
/// Returns `None` if there is no child corresponding to token WITHOUT
fn WITHOUT(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(WITHOUT, 0)
}
/// Retrieves first TerminalNode corresponding to token YEAR
/// Returns `None` if there is no child corresponding to token YEAR
fn YEAR(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(YEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token YEARS
/// Returns `None` if there is no child corresponding to token YEARS
fn YEARS(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(YEARS, 0)
}
/// Retrieves first TerminalNode corresponding to token ZONE
/// Returns `None` if there is no child corresponding to token ZONE
fn ZONE(&self) -> Option<Rc<TerminalNode<'input,SqlBaseParserContextType>>> where Self:Sized{
	self.get_token(ZONE, 0)
}

}

impl<'input> NonReservedContextAttrs<'input> for NonReservedContext<'input>{}

impl<'input, I, H> SqlBaseParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn nonReserved(&mut self,)
	-> Result<Rc<NonReservedContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NonReservedContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 548, RULE_nonReserved);
        let mut _localctx: Rc<NonReservedContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(5003);
			_la = recog.base.input.la(1);
			if { !((((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ADD) | (1usize << AFTER) | (1usize << AGGREGATE) | (1usize << ALL) | (1usize << ALTER) | (1usize << ALWAYS) | (1usize << ANALYZE) | (1usize << AND) | (1usize << ANY) | (1usize << ANY_VALUE) | (1usize << ARCHIVE) | (1usize << ARRAY) | (1usize << AS) | (1usize << ASC) | (1usize << AT) | (1usize << ATOMIC) | (1usize << AUTHORIZATION) | (1usize << BEGIN) | (1usize << BETWEEN) | (1usize << BIGINT) | (1usize << BINARY) | (1usize << BINDING))) != 0) || ((((_la - 32)) & !0x3f) == 0 && ((1usize << (_la - 32)) & ((1usize << (BOOLEAN - 32)) | (1usize << (BOTH - 32)) | (1usize << (BUCKET - 32)) | (1usize << (BUCKETS - 32)) | (1usize << (BY - 32)) | (1usize << (BYTE - 32)) | (1usize << (CACHE - 32)) | (1usize << (CALL - 32)) | (1usize << (CALLED - 32)) | (1usize << (CASCADE - 32)) | (1usize << (CASE - 32)) | (1usize << (CAST - 32)) | (1usize << (CATALOG - 32)) | (1usize << (CATALOGS - 32)) | (1usize << (CHANGE - 32)) | (1usize << (CHAR - 32)) | (1usize << (CHARACTER - 32)) | (1usize << (CHECK - 32)) | (1usize << (CLEAR - 32)) | (1usize << (CLUSTER - 32)) | (1usize << (CLUSTERED - 32)) | (1usize << (CODEGEN - 32)) | (1usize << (COLLATE - 32)) | (1usize << (COLLATION - 32)) | (1usize << (COLLECTION - 32)) | (1usize << (COLUMN - 32)) | (1usize << (COLUMNS - 32)) | (1usize << (COMMENT - 32)) | (1usize << (COMMIT - 32)) | (1usize << (COMPACT - 32)) | (1usize << (COMPACTIONS - 32)) | (1usize << (COMPENSATION - 32)))) != 0) || ((((_la - 64)) & !0x3f) == 0 && ((1usize << (_la - 64)) & ((1usize << (COMPUTE - 64)) | (1usize << (CONCATENATE - 64)) | (1usize << (CONDITION - 64)) | (1usize << (CONSTRAINT - 64)) | (1usize << (CONTAINS - 64)) | (1usize << (CONTINUE - 64)) | (1usize << (COST - 64)) | (1usize << (CREATE - 64)) | (1usize << (CUBE - 64)) | (1usize << (CURRENT - 64)) | (1usize << (CURRENT_DATE - 64)) | (1usize << (CURRENT_TIME - 64)) | (1usize << (CURRENT_TIMESTAMP - 64)) | (1usize << (CURRENT_USER - 64)) | (1usize << (DAY - 64)) | (1usize << (DAYS - 64)) | (1usize << (DAYOFYEAR - 64)) | (1usize << (DATA - 64)) | (1usize << (DATE - 64)) | (1usize << (DATABASE - 64)) | (1usize << (DATABASES - 64)) | (1usize << (DATEADD - 64)) | (1usize << (DATE_ADD - 64)) | (1usize << (DATEDIFF - 64)) | (1usize << (DATE_DIFF - 64)) | (1usize << (DBPROPERTIES - 64)) | (1usize << (DEC - 64)) | (1usize << (DECIMAL - 64)) | (1usize << (DECLARE - 64)) | (1usize << (DEFAULT - 64)) | (1usize << (DEFINED - 64)))) != 0) || ((((_la - 96)) & !0x3f) == 0 && ((1usize << (_la - 96)) & ((1usize << (DEFINER - 96)) | (1usize << (DELAY - 96)) | (1usize << (DELETE - 96)) | (1usize << (DELIMITED - 96)) | (1usize << (DESC - 96)) | (1usize << (DESCRIBE - 96)) | (1usize << (DETERMINISTIC - 96)) | (1usize << (DFS - 96)) | (1usize << (DIRECTORIES - 96)) | (1usize << (DIRECTORY - 96)) | (1usize << (DISTINCT - 96)) | (1usize << (DISTRIBUTE - 96)) | (1usize << (DIV - 96)) | (1usize << (DO - 96)) | (1usize << (DOUBLE - 96)) | (1usize << (DROP - 96)) | (1usize << (ELSE - 96)) | (1usize << (ELSEIF - 96)) | (1usize << (END - 96)) | (1usize << (ENFORCED - 96)) | (1usize << (ESCAPE - 96)) | (1usize << (ESCAPED - 96)) | (1usize << (EVOLUTION - 96)) | (1usize << (EXCHANGE - 96)) | (1usize << (EXCLUDE - 96)) | (1usize << (EXISTS - 96)) | (1usize << (EXIT - 96)) | (1usize << (EXPLAIN - 96)) | (1usize << (EXPORT - 96)) | (1usize << (EXTEND - 96)) | (1usize << (EXTENDED - 96)))) != 0) || ((((_la - 128)) & !0x3f) == 0 && ((1usize << (_la - 128)) & ((1usize << (EXTERNAL - 128)) | (1usize << (EXTRACT - 128)) | (1usize << (FALSE - 128)) | (1usize << (FETCH - 128)) | (1usize << (FIELDS - 128)) | (1usize << (FILTER - 128)) | (1usize << (FILEFORMAT - 128)) | (1usize << (FIRST - 128)) | (1usize << (FLOAT - 128)) | (1usize << (FLOW - 128)) | (1usize << (FOLLOWING - 128)) | (1usize << (FOR - 128)) | (1usize << (FOREIGN - 128)) | (1usize << (FORMAT - 128)) | (1usize << (FORMATTED - 128)) | (1usize << (FOUND - 128)) | (1usize << (FROM - 128)) | (1usize << (FUNCTION - 128)) | (1usize << (FUNCTIONS - 128)) | (1usize << (GENERATED - 128)) | (1usize << (GEOGRAPHY - 128)) | (1usize << (GEOMETRY - 128)) | (1usize << (GLOBAL - 128)) | (1usize << (GRANT - 128)) | (1usize << (GROUP - 128)) | (1usize << (GROUPING - 128)) | (1usize << (HANDLER - 128)) | (1usize << (HAVING - 128)) | (1usize << (BINARY_HEX - 128)) | (1usize << (HOUR - 128)) | (1usize << (HOURS - 128)))) != 0) || ((((_la - 160)) & !0x3f) == 0 && ((1usize << (_la - 160)) & ((1usize << (IDENTIFIER_KW - 160)) | (1usize << (IDENTITY - 160)) | (1usize << (IF - 160)) | (1usize << (IGNORE - 160)) | (1usize << (IMMEDIATE - 160)) | (1usize << (IMPORT - 160)) | (1usize << (IN - 160)) | (1usize << (INCLUDE - 160)) | (1usize << (INCREMENT - 160)) | (1usize << (INDEX - 160)) | (1usize << (INDEXES - 160)) | (1usize << (INPATH - 160)) | (1usize << (INPUT - 160)) | (1usize << (INPUTFORMAT - 160)) | (1usize << (INSERT - 160)) | (1usize << (INTERVAL - 160)) | (1usize << (INT - 160)) | (1usize << (INTEGER - 160)) | (1usize << (INTO - 160)) | (1usize << (INVOKER - 160)) | (1usize << (IS - 160)) | (1usize << (ITEMS - 160)) | (1usize << (ITERATE - 160)) | (1usize << (JSON - 160)) | (1usize << (KEY - 160)) | (1usize << (KEYS - 160)) | (1usize << (LANGUAGE - 160)) | (1usize << (LAST - 160)))) != 0) || ((((_la - 192)) & !0x3f) == 0 && ((1usize << (_la - 192)) & ((1usize << (LAZY - 192)) | (1usize << (LEADING - 192)) | (1usize << (LEAVE - 192)) | (1usize << (LEVEL - 192)) | (1usize << (LIKE - 192)) | (1usize << (ILIKE - 192)) | (1usize << (LIMIT - 192)) | (1usize << (LINES - 192)) | (1usize << (LIST - 192)) | (1usize << (LOAD - 192)) | (1usize << (LOCAL - 192)) | (1usize << (LOCATION - 192)) | (1usize << (LOCK - 192)) | (1usize << (LOCKS - 192)) | (1usize << (LOGICAL - 192)) | (1usize << (LONG - 192)) | (1usize << (LOOP - 192)) | (1usize << (MACRO - 192)) | (1usize << (MAP - 192)) | (1usize << (MATCHED - 192)) | (1usize << (MATERIALIZED - 192)) | (1usize << (MAX - 192)) | (1usize << (MEASURE - 192)) | (1usize << (MERGE - 192)) | (1usize << (METRICS - 192)) | (1usize << (MICROSECOND - 192)) | (1usize << (MICROSECONDS - 192)) | (1usize << (MILLISECOND - 192)) | (1usize << (MILLISECONDS - 192)) | (1usize << (MINUTE - 192)) | (1usize << (MINUTES - 192)))) != 0) || ((((_la - 224)) & !0x3f) == 0 && ((1usize << (_la - 224)) & ((1usize << (MODIFIES - 224)) | (1usize << (MONTH - 224)) | (1usize << (MONTHS - 224)) | (1usize << (MSCK - 224)) | (1usize << (NAME - 224)) | (1usize << (NAMESPACE - 224)) | (1usize << (NAMESPACES - 224)) | (1usize << (NANOSECOND - 224)) | (1usize << (NANOSECONDS - 224)) | (1usize << (NO - 224)) | (1usize << (NONE - 224)) | (1usize << (NOT - 224)) | (1usize << (NULL - 224)) | (1usize << (NULLS - 224)) | (1usize << (NUMERIC - 224)) | (1usize << (NORELY - 224)) | (1usize << (OF - 224)) | (1usize << (OFFSET - 224)) | (1usize << (ONLY - 224)) | (1usize << (OPTION - 224)) | (1usize << (OPTIONS - 224)) | (1usize << (OR - 224)) | (1usize << (ORDER - 224)) | (1usize << (OUT - 224)) | (1usize << (OUTER - 224)) | (1usize << (OUTPUTFORMAT - 224)) | (1usize << (OVER - 224)) | (1usize << (OVERLAPS - 224)) | (1usize << (OVERLAY - 224)) | (1usize << (OVERWRITE - 224)))) != 0) || ((((_la - 256)) & !0x3f) == 0 && ((1usize << (_la - 256)) & ((1usize << (PARTITION - 256)) | (1usize << (PARTITIONED - 256)) | (1usize << (PARTITIONS - 256)) | (1usize << (PERCENTLIT - 256)) | (1usize << (PIVOT - 256)) | (1usize << (PLACING - 256)) | (1usize << (POSITION - 256)) | (1usize << (PRECEDING - 256)) | (1usize << (PRIMARY - 256)) | (1usize << (PRINCIPALS - 256)) | (1usize << (PROCEDURE - 256)) | (1usize << (PROCEDURES - 256)) | (1usize << (PROPERTIES - 256)) | (1usize << (PURGE - 256)) | (1usize << (QUARTER - 256)) | (1usize << (QUERY - 256)) | (1usize << (RANGE - 256)) | (1usize << (READS - 256)) | (1usize << (REAL - 256)) | (1usize << (RECORDREADER - 256)) | (1usize << (RECORDWRITER - 256)) | (1usize << (RECOVER - 256)) | (1usize << (RECURSION - 256)) | (1usize << (RECURSIVE - 256)) | (1usize << (REDUCE - 256)) | (1usize << (REFERENCES - 256)) | (1usize << (REFRESH - 256)) | (1usize << (RELY - 256)) | (1usize << (RENAME - 256)) | (1usize << (REPAIR - 256)) | (1usize << (REPEAT - 256)) | (1usize << (REPEATABLE - 256)))) != 0) || ((((_la - 288)) & !0x3f) == 0 && ((1usize << (_la - 288)) & ((1usize << (REPLACE - 288)) | (1usize << (RESET - 288)) | (1usize << (RESPECT - 288)) | (1usize << (RESTRICT - 288)) | (1usize << (RETURN - 288)) | (1usize << (RETURNS - 288)) | (1usize << (REVOKE - 288)) | (1usize << (RLIKE - 288)) | (1usize << (ROLE - 288)) | (1usize << (ROLES - 288)) | (1usize << (ROLLBACK - 288)) | (1usize << (ROLLUP - 288)) | (1usize << (ROW - 288)) | (1usize << (ROWS - 288)) | (1usize << (SECOND - 288)) | (1usize << (SECONDS - 288)) | (1usize << (SCHEMA - 288)) | (1usize << (SCHEMAS - 288)) | (1usize << (SECURITY - 288)) | (1usize << (SELECT - 288)) | (1usize << (SEPARATED - 288)) | (1usize << (SERDE - 288)) | (1usize << (SERDEPROPERTIES - 288)) | (1usize << (SESSION_USER - 288)) | (1usize << (SET - 288)) | (1usize << (SETS - 288)) | (1usize << (SHORT - 288)) | (1usize << (SHOW - 288)) | (1usize << (SINGLE - 288)))) != 0) || ((((_la - 320)) & !0x3f) == 0 && ((1usize << (_la - 320)) & ((1usize << (SKEWED - 320)) | (1usize << (SMALLINT - 320)) | (1usize << (SOME - 320)) | (1usize << (SORT - 320)) | (1usize << (SORTED - 320)) | (1usize << (SOURCE - 320)) | (1usize << (SPECIFIC - 320)) | (1usize << (SQL - 320)) | (1usize << (SQLEXCEPTION - 320)) | (1usize << (SQLSTATE - 320)) | (1usize << (START - 320)) | (1usize << (STATISTICS - 320)) | (1usize << (STORED - 320)) | (1usize << (STRATIFY - 320)) | (1usize << (STREAM - 320)) | (1usize << (STREAMING - 320)) | (1usize << (STRING - 320)) | (1usize << (STRUCT - 320)) | (1usize << (SUBSTR - 320)) | (1usize << (SUBSTRING - 320)) | (1usize << (SYNC - 320)) | (1usize << (SYSTEM_TIME - 320)) | (1usize << (SYSTEM_VERSION - 320)) | (1usize << (TABLE - 320)) | (1usize << (TABLES - 320)) | (1usize << (TABLESAMPLE - 320)) | (1usize << (TARGET - 320)) | (1usize << (TBLPROPERTIES - 320)) | (1usize << (TEMPORARY - 320)) | (1usize << (TERMINATED - 320)) | (1usize << (THEN - 320)) | (1usize << (TIME - 320)))) != 0) || ((((_la - 352)) & !0x3f) == 0 && ((1usize << (_la - 352)) & ((1usize << (TIMEDIFF - 352)) | (1usize << (TIMESTAMP - 352)) | (1usize << (TIMESTAMP_LTZ - 352)) | (1usize << (TIMESTAMP_NTZ - 352)) | (1usize << (TIMESTAMPADD - 352)) | (1usize << (TIMESTAMPDIFF - 352)) | (1usize << (TINYINT - 352)) | (1usize << (TO - 352)) | (1usize << (EXECUTE - 352)) | (1usize << (TOUCH - 352)) | (1usize << (TRAILING - 352)) | (1usize << (TRANSACTION - 352)) | (1usize << (TRANSACTIONS - 352)) | (1usize << (TRANSFORM - 352)) | (1usize << (TRIM - 352)) | (1usize << (TRUE - 352)) | (1usize << (TRUNCATE - 352)) | (1usize << (TRY_CAST - 352)) | (1usize << (TYPE - 352)) | (1usize << (UNARCHIVE - 352)) | (1usize << (UNBOUNDED - 352)) | (1usize << (UNCACHE - 352)) | (1usize << (UNIQUE - 352)) | (1usize << (UNKNOWN - 352)) | (1usize << (UNLOCK - 352)) | (1usize << (UNPIVOT - 352)) | (1usize << (UNSET - 352)) | (1usize << (UNTIL - 352)) | (1usize << (UPDATE - 352)) | (1usize << (USE - 352)) | (1usize << (USER - 352)))) != 0) || ((((_la - 385)) & !0x3f) == 0 && ((1usize << (_la - 385)) & ((1usize << (VALUE - 385)) | (1usize << (VALUES - 385)) | (1usize << (VARCHAR - 385)) | (1usize << (VAR - 385)) | (1usize << (VARIABLE - 385)) | (1usize << (VARIANT - 385)) | (1usize << (VERSION - 385)) | (1usize << (VIEW - 385)) | (1usize << (VIEWS - 385)) | (1usize << (VOID - 385)) | (1usize << (WATERMARK - 385)) | (1usize << (WEEK - 385)) | (1usize << (WEEKS - 385)) | (1usize << (WHEN - 385)) | (1usize << (WHERE - 385)) | (1usize << (WHILE - 385)) | (1usize << (WINDOW - 385)) | (1usize << (WITH - 385)) | (1usize << (WITHIN - 385)) | (1usize << (WITHOUT - 385)) | (1usize << (YEAR - 385)) | (1usize << (YEARS - 385)) | (1usize << (ZONE - 385)))) != 0)) } {
				recog.err_handler.recover_inline(&mut recog.base)?;

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}

lazy_static! {
    static ref _ATN: Arc<ATN> =
        Arc::new(ATNDeserializer::new(None).deserialize(_serializedATN.chars()));
    static ref _decision_to_DFA: Arc<Vec<antlr_rust::RwLock<DFA>>> = {
        let mut dfa = Vec::new();
        let size = _ATN.decision_to_state.len();
        for i in 0..size {
            dfa.push(DFA::new(
                _ATN.clone(),
                _ATN.get_decision_state(i),
                i as isize,
            ).into())
        }
        Arc::new(dfa)
    };
}



const _serializedATN:&'static str =
	"\x03\u{608b}\u{a72a}\u{8133}\u{b9ed}\u{417c}\u{3be7}\u{7786}\u{5964}\x03\
	\u{1ca}\u{1390}\x04\x02\x09\x02\x04\x03\x09\x03\x04\x04\x09\x04\x04\x05\
	\x09\x05\x04\x06\x09\x06\x04\x07\x09\x07\x04\x08\x09\x08\x04\x09\x09\x09\
	\x04\x0a\x09\x0a\x04\x0b\x09\x0b\x04\x0c\x09\x0c\x04\x0d\x09\x0d\x04\x0e\
	\x09\x0e\x04\x0f\x09\x0f\x04\x10\x09\x10\x04\x11\x09\x11\x04\x12\x09\x12\
	\x04\x13\x09\x13\x04\x14\x09\x14\x04\x15\x09\x15\x04\x16\x09\x16\x04\x17\
	\x09\x17\x04\x18\x09\x18\x04\x19\x09\x19\x04\x1a\x09\x1a\x04\x1b\x09\x1b\
	\x04\x1c\x09\x1c\x04\x1d\x09\x1d\x04\x1e\x09\x1e\x04\x1f\x09\x1f\x04\x20\
	\x09\x20\x04\x21\x09\x21\x04\x22\x09\x22\x04\x23\x09\x23\x04\x24\x09\x24\
	\x04\x25\x09\x25\x04\x26\x09\x26\x04\x27\x09\x27\x04\x28\x09\x28\x04\x29\
	\x09\x29\x04\x2a\x09\x2a\x04\x2b\x09\x2b\x04\x2c\x09\x2c\x04\x2d\x09\x2d\
	\x04\x2e\x09\x2e\x04\x2f\x09\x2f\x04\x30\x09\x30\x04\x31\x09\x31\x04\x32\
	\x09\x32\x04\x33\x09\x33\x04\x34\x09\x34\x04\x35\x09\x35\x04\x36\x09\x36\
	\x04\x37\x09\x37\x04\x38\x09\x38\x04\x39\x09\x39\x04\x3a\x09\x3a\x04\x3b\
	\x09\x3b\x04\x3c\x09\x3c\x04\x3d\x09\x3d\x04\x3e\x09\x3e\x04\x3f\x09\x3f\
	\x04\x40\x09\x40\x04\x41\x09\x41\x04\x42\x09\x42\x04\x43\x09\x43\x04\x44\
	\x09\x44\x04\x45\x09\x45\x04\x46\x09\x46\x04\x47\x09\x47\x04\x48\x09\x48\
	\x04\x49\x09\x49\x04\x4a\x09\x4a\x04\x4b\x09\x4b\x04\x4c\x09\x4c\x04\x4d\
	\x09\x4d\x04\x4e\x09\x4e\x04\x4f\x09\x4f\x04\x50\x09\x50\x04\x51\x09\x51\
	\x04\x52\x09\x52\x04\x53\x09\x53\x04\x54\x09\x54\x04\x55\x09\x55\x04\x56\
	\x09\x56\x04\x57\x09\x57\x04\x58\x09\x58\x04\x59\x09\x59\x04\x5a\x09\x5a\
	\x04\x5b\x09\x5b\x04\x5c\x09\x5c\x04\x5d\x09\x5d\x04\x5e\x09\x5e\x04\x5f\
	\x09\x5f\x04\x60\x09\x60\x04\x61\x09\x61\x04\x62\x09\x62\x04\x63\x09\x63\
	\x04\x64\x09\x64\x04\x65\x09\x65\x04\x66\x09\x66\x04\x67\x09\x67\x04\x68\
	\x09\x68\x04\x69\x09\x69\x04\x6a\x09\x6a\x04\x6b\x09\x6b\x04\x6c\x09\x6c\
	\x04\x6d\x09\x6d\x04\x6e\x09\x6e\x04\x6f\x09\x6f\x04\x70\x09\x70\x04\x71\
	\x09\x71\x04\x72\x09\x72\x04\x73\x09\x73\x04\x74\x09\x74\x04\x75\x09\x75\
	\x04\x76\x09\x76\x04\x77\x09\x77\x04\x78\x09\x78\x04\x79\x09\x79\x04\x7a\
	\x09\x7a\x04\x7b\x09\x7b\x04\x7c\x09\x7c\x04\x7d\x09\x7d\x04\x7e\x09\x7e\
	\x04\x7f\x09\x7f\x04\u{80}\x09\u{80}\x04\u{81}\x09\u{81}\x04\u{82}\x09\u{82}\
	\x04\u{83}\x09\u{83}\x04\u{84}\x09\u{84}\x04\u{85}\x09\u{85}\x04\u{86}\x09\
	\u{86}\x04\u{87}\x09\u{87}\x04\u{88}\x09\u{88}\x04\u{89}\x09\u{89}\x04\u{8a}\
	\x09\u{8a}\x04\u{8b}\x09\u{8b}\x04\u{8c}\x09\u{8c}\x04\u{8d}\x09\u{8d}\x04\
	\u{8e}\x09\u{8e}\x04\u{8f}\x09\u{8f}\x04\u{90}\x09\u{90}\x04\u{91}\x09\u{91}\
	\x04\u{92}\x09\u{92}\x04\u{93}\x09\u{93}\x04\u{94}\x09\u{94}\x04\u{95}\x09\
	\u{95}\x04\u{96}\x09\u{96}\x04\u{97}\x09\u{97}\x04\u{98}\x09\u{98}\x04\u{99}\
	\x09\u{99}\x04\u{9a}\x09\u{9a}\x04\u{9b}\x09\u{9b}\x04\u{9c}\x09\u{9c}\x04\
	\u{9d}\x09\u{9d}\x04\u{9e}\x09\u{9e}\x04\u{9f}\x09\u{9f}\x04\u{a0}\x09\u{a0}\
	\x04\u{a1}\x09\u{a1}\x04\u{a2}\x09\u{a2}\x04\u{a3}\x09\u{a3}\x04\u{a4}\x09\
	\u{a4}\x04\u{a5}\x09\u{a5}\x04\u{a6}\x09\u{a6}\x04\u{a7}\x09\u{a7}\x04\u{a8}\
	\x09\u{a8}\x04\u{a9}\x09\u{a9}\x04\u{aa}\x09\u{aa}\x04\u{ab}\x09\u{ab}\x04\
	\u{ac}\x09\u{ac}\x04\u{ad}\x09\u{ad}\x04\u{ae}\x09\u{ae}\x04\u{af}\x09\u{af}\
	\x04\u{b0}\x09\u{b0}\x04\u{b1}\x09\u{b1}\x04\u{b2}\x09\u{b2}\x04\u{b3}\x09\
	\u{b3}\x04\u{b4}\x09\u{b4}\x04\u{b5}\x09\u{b5}\x04\u{b6}\x09\u{b6}\x04\u{b7}\
	\x09\u{b7}\x04\u{b8}\x09\u{b8}\x04\u{b9}\x09\u{b9}\x04\u{ba}\x09\u{ba}\x04\
	\u{bb}\x09\u{bb}\x04\u{bc}\x09\u{bc}\x04\u{bd}\x09\u{bd}\x04\u{be}\x09\u{be}\
	\x04\u{bf}\x09\u{bf}\x04\u{c0}\x09\u{c0}\x04\u{c1}\x09\u{c1}\x04\u{c2}\x09\
	\u{c2}\x04\u{c3}\x09\u{c3}\x04\u{c4}\x09\u{c4}\x04\u{c5}\x09\u{c5}\x04\u{c6}\
	\x09\u{c6}\x04\u{c7}\x09\u{c7}\x04\u{c8}\x09\u{c8}\x04\u{c9}\x09\u{c9}\x04\
	\u{ca}\x09\u{ca}\x04\u{cb}\x09\u{cb}\x04\u{cc}\x09\u{cc}\x04\u{cd}\x09\u{cd}\
	\x04\u{ce}\x09\u{ce}\x04\u{cf}\x09\u{cf}\x04\u{d0}\x09\u{d0}\x04\u{d1}\x09\
	\u{d1}\x04\u{d2}\x09\u{d2}\x04\u{d3}\x09\u{d3}\x04\u{d4}\x09\u{d4}\x04\u{d5}\
	\x09\u{d5}\x04\u{d6}\x09\u{d6}\x04\u{d7}\x09\u{d7}\x04\u{d8}\x09\u{d8}\x04\
	\u{d9}\x09\u{d9}\x04\u{da}\x09\u{da}\x04\u{db}\x09\u{db}\x04\u{dc}\x09\u{dc}\
	\x04\u{dd}\x09\u{dd}\x04\u{de}\x09\u{de}\x04\u{df}\x09\u{df}\x04\u{e0}\x09\
	\u{e0}\x04\u{e1}\x09\u{e1}\x04\u{e2}\x09\u{e2}\x04\u{e3}\x09\u{e3}\x04\u{e4}\
	\x09\u{e4}\x04\u{e5}\x09\u{e5}\x04\u{e6}\x09\u{e6}\x04\u{e7}\x09\u{e7}\x04\
	\u{e8}\x09\u{e8}\x04\u{e9}\x09\u{e9}\x04\u{ea}\x09\u{ea}\x04\u{eb}\x09\u{eb}\
	\x04\u{ec}\x09\u{ec}\x04\u{ed}\x09\u{ed}\x04\u{ee}\x09\u{ee}\x04\u{ef}\x09\
	\u{ef}\x04\u{f0}\x09\u{f0}\x04\u{f1}\x09\u{f1}\x04\u{f2}\x09\u{f2}\x04\u{f3}\
	\x09\u{f3}\x04\u{f4}\x09\u{f4}\x04\u{f5}\x09\u{f5}\x04\u{f6}\x09\u{f6}\x04\
	\u{f7}\x09\u{f7}\x04\u{f8}\x09\u{f8}\x04\u{f9}\x09\u{f9}\x04\u{fa}\x09\u{fa}\
	\x04\u{fb}\x09\u{fb}\x04\u{fc}\x09\u{fc}\x04\u{fd}\x09\u{fd}\x04\u{fe}\x09\
	\u{fe}\x04\u{ff}\x09\u{ff}\x04\u{100}\x09\u{100}\x04\u{101}\x09\u{101}\x04\
	\u{102}\x09\u{102}\x04\u{103}\x09\u{103}\x04\u{104}\x09\u{104}\x04\u{105}\
	\x09\u{105}\x04\u{106}\x09\u{106}\x04\u{107}\x09\u{107}\x04\u{108}\x09\u{108}\
	\x04\u{109}\x09\u{109}\x04\u{10a}\x09\u{10a}\x04\u{10b}\x09\u{10b}\x04\u{10c}\
	\x09\u{10c}\x04\u{10d}\x09\u{10d}\x04\u{10e}\x09\u{10e}\x04\u{10f}\x09\u{10f}\
	\x04\u{110}\x09\u{110}\x04\u{111}\x09\u{111}\x04\u{112}\x09\u{112}\x04\u{113}\
	\x09\u{113}\x04\u{114}\x09\u{114}\x03\x02\x03\x02\x05\x02\u{22b}\x0a\x02\
	\x03\x03\x03\x03\x03\x03\x05\x03\u{230}\x0a\x03\x03\x03\x05\x03\u{233}\x0a\
	\x03\x03\x03\x03\x03\x05\x03\u{237}\x0a\x03\x03\x03\x03\x03\x03\x04\x05\
	\x04\u{23c}\x0a\x04\x03\x04\x03\x04\x03\x04\x05\x04\u{241}\x0a\x04\x03\x04\
	\x05\x04\u{244}\x0a\x04\x03\x04\x03\x04\x05\x04\u{248}\x0a\x04\x03\x05\x03\
	\x05\x03\x05\x06\x05\u{24d}\x0a\x05\x0d\x05\x0e\x05\u{24e}\x03\x06\x03\x06\
	\x03\x06\x03\x06\x03\x06\x03\x06\x03\x06\x03\x06\x03\x06\x03\x06\x03\x06\
	\x03\x06\x03\x06\x05\x06\u{25e}\x0a\x06\x03\x07\x03\x07\x03\x07\x03\x07\
	\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x03\x07\x05\x07\u{26b}\
	\x0a\x07\x03\x08\x03\x08\x03\x09\x03\x09\x03\x09\x03\x09\x03\x09\x03\x09\
	\x05\x09\u{275}\x0a\x09\x03\x09\x05\x09\u{278}\x0a\x09\x03\x0a\x03\x0a\x05\
	\x0a\u{27c}\x0a\x0a\x03\x0a\x03\x0a\x03\x0a\x03\x0a\x03\x0a\x05\x0a\u{283}\
	\x0a\x0a\x03\x0b\x03\x0b\x03\x0b\x07\x0b\u{288}\x0a\x0b\x0c\x0b\x0e\x0b\
	\u{28b}\x0b\x0b\x03\x0c\x03\x0c\x03\x0c\x03\x0c\x03\x0c\x03\x0c\x03\x0c\
	\x03\x0c\x05\x0c\u{295}\x0a\x0c\x03\x0d\x05\x0d\u{298}\x0a\x0d\x03\x0d\x03\
	\x0d\x03\x0d\x03\x0d\x03\x0d\x03\x0d\x03\x0d\x05\x0d\u{2a1}\x0a\x0d\x03\
	\x0e\x03\x0e\x03\x0e\x03\x0e\x03\x0e\x03\x0e\x03\x0e\x03\x0e\x03\x0e\x07\
	\x0e\u{2ac}\x0a\x0e\x0c\x0e\x0e\x0e\u{2af}\x0b\x0e\x03\x0e\x03\x0e\x05\x0e\
	\u{2b3}\x0a\x0e\x03\x0e\x03\x0e\x03\x0e\x03\x0f\x05\x0f\u{2b9}\x0a\x0f\x03\
	\x0f\x03\x0f\x03\x0f\x03\x0f\x03\x0f\x03\x0f\x03\x0f\x05\x0f\u{2c2}\x0a\
	\x0f\x03\x10\x03\x10\x03\x10\x03\x11\x03\x11\x03\x11\x03\x12\x03\x12\x03\
	\x12\x03\x12\x03\x12\x03\x12\x06\x12\u{2d0}\x0a\x12\x0d\x12\x0e\x12\u{2d1}\
	\x03\x12\x03\x12\x05\x12\u{2d6}\x0a\x12\x03\x12\x03\x12\x03\x12\x03\x12\
	\x03\x12\x03\x12\x03\x12\x03\x12\x03\x12\x03\x12\x06\x12\u{2e2}\x0a\x12\
	\x0d\x12\x0e\x12\u{2e3}\x03\x12\x03\x12\x05\x12\u{2e8}\x0a\x12\x03\x12\x03\
	\x12\x03\x12\x05\x12\u{2ed}\x0a\x12\x03\x13\x05\x13\u{2f0}\x0a\x13\x03\x13\
	\x03\x13\x03\x13\x03\x13\x03\x13\x05\x13\u{2f7}\x0a\x13\x03\x14\x05\x14\
	\u{2fa}\x0a\x14\x03\x14\x03\x14\x03\x14\x03\x14\x05\x14\u{300}\x0a\x14\x03\
	\x14\x03\x14\x03\x14\x03\x14\x03\x14\x03\x14\x05\x14\u{308}\x0a\x14\x03\
	\x15\x03\x15\x05\x15\u{30c}\x0a\x15\x03\x15\x07\x15\u{30f}\x0a\x15\x0c\x15\
	\x0e\x15\u{312}\x0b\x15\x03\x15\x03\x15\x03\x16\x03\x16\x03\x16\x03\x17\
	\x03\x17\x03\x18\x03\x18\x03\x18\x03\x19\x03\x19\x03\x19\x03\x1a\x03\x1a\
	\x03\x1a\x03\x1b\x03\x1b\x03\x1b\x03\x1c\x03\x1c\x03\x1c\x03\x1d\x03\x1d\
	\x03\x1d\x03\x1e\x03\x1e\x03\x1e\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{333}\
	\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\
	\u{345}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x07\x1f\u{34e}\x0a\x1f\x0c\x1f\x0e\x1f\u{351}\x0b\x1f\x03\x1f\x03\x1f\x03\
	\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\
	\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\
	\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\
	\x1f\u{370}\x0a\x1f\x03\x1f\x03\x1f\x05\x1f\u{374}\x0a\x1f\x03\x1f\x03\x1f\
	\x03\x1f\x03\x1f\x05\x1f\u{37a}\x0a\x1f\x03\x1f\x05\x1f\u{37d}\x0a\x1f\x03\
	\x1f\x05\x1f\u{380}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\
	\x1f\u{387}\x0a\x1f\x03\x1f\x05\x1f\u{38a}\x0a\x1f\x03\x1f\x03\x1f\x05\x1f\
	\u{38e}\x0a\x1f\x03\x1f\x05\x1f\u{391}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\
	\x1f\x03\x1f\x03\x1f\x05\x1f\u{399}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\
	\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x07\x1f\u{3a4}\x0a\x1f\x0c\
	\x1f\x0e\x1f\u{3a7}\x0b\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\
	\x1f\u{3ae}\x0a\x1f\x03\x1f\x05\x1f\u{3b1}\x0a\x1f\x03\x1f\x03\x1f\x05\x1f\
	\u{3b5}\x0a\x1f\x03\x1f\x05\x1f\u{3b8}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\
	\x1f\x05\x1f\u{3be}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\
	\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{3c9}\x0a\x1f\x03\x1f\x03\x1f\x03\
	\x1f\x03\x1f\x05\x1f\u{3cf}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{3d4}\
	\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{3f6}\x0a\x1f\
	\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x03\x1f\x03\x1f\x05\x1f\u{403}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x03\x1f\x05\x1f\u{41c}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x03\x1f\x03\x1f\x05\x1f\u{425}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x03\x1f\x03\x1f\x05\x1f\u{42d}\x0a\x1f\x03\x1f\x03\x1f\x05\x1f\u{431}\x0a\
	\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{436}\x0a\x1f\x03\x1f\x03\x1f\x03\
	\x1f\x03\x1f\x05\x1f\u{43c}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\
	\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{448}\x0a\x1f\x03\
	\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{450}\x0a\x1f\x03\
	\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{456}\x0a\x1f\x03\x1f\x03\x1f\x03\
	\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\
	\x1f\x05\x1f\u{464}\x0a\x1f\x03\x1f\x06\x1f\u{467}\x0a\x1f\x0d\x1f\x0e\x1f\
	\u{468}\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{479}\x0a\x1f\
	\x03\x1f\x03\x1f\x03\x1f\x07\x1f\u{47e}\x0a\x1f\x0c\x1f\x0e\x1f\u{481}\x0b\
	\x1f\x03\x1f\x05\x1f\u{484}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\
	\x1f\u{48a}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\
	\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\
	\x1f\x05\x1f\u{49c}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\
	\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\
	\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{4b0}\x0a\x1f\x03\x1f\x03\x1f\x05\
	\x1f\u{4b4}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{4ba}\x0a\x1f\
	\x03\x1f\x03\x1f\x05\x1f\u{4be}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x05\x1f\u{4c4}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{4ca}\x0a\
	\x1f\x03\x1f\x05\x1f\u{4cd}\x0a\x1f\x03\x1f\x05\x1f\u{4d0}\x0a\x1f\x03\x1f\
	\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{4d7}\x0a\x1f\x03\x1f\x03\x1f\
	\x05\x1f\u{4db}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x03\x1f\x03\x1f\x07\x1f\u{4e5}\x0a\x1f\x0c\x1f\x0e\x1f\u{4e8}\x0b\x1f\x03\
	\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{4f0}\x0a\x1f\x03\
	\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{4f7}\x0a\x1f\x03\x1f\x03\
	\x1f\x05\x1f\u{4fb}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\
	\x1f\x07\x1f\u{503}\x0a\x1f\x0c\x1f\x0e\x1f\u{506}\x0b\x1f\x03\x1f\x03\x1f\
	\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{50e}\x0a\x1f\x03\x1f\x05\x1f\
	\u{511}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x05\x1f\u{51a}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{51f}\x0a\x1f\x03\
	\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{525}\x0a\x1f\x03\x1f\x03\x1f\x03\
	\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{531}\
	\x0a\x1f\x03\x1f\x05\x1f\u{534}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x03\x1f\x05\x1f\u{53b}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x03\x1f\x03\x1f\x07\x1f\u{544}\x0a\x1f\x0c\x1f\x0e\x1f\u{547}\x0b\x1f\x05\
	\x1f\u{549}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{54e}\x0a\x1f\x03\x1f\
	\x05\x1f\u{551}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\
	\u{558}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{55d}\x0a\x1f\x03\x1f\x03\
	\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{567}\x0a\
	\x1f\x05\x1f\u{569}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{56f}\
	\x0a\x1f\x03\x1f\x03\x1f\x05\x1f\u{573}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x05\x1f\u{578}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{57e}\x0a\
	\x1f\x03\x1f\x05\x1f\u{581}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x07\x1f\u{586}\
	\x0a\x1f\x0c\x1f\x0e\x1f\u{589}\x0b\x1f\x03\x1f\x05\x1f\u{58c}\x0a\x1f\x03\
	\x1f\x05\x1f\u{58f}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\
	\x1f\u{596}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{59c}\x0a\x1f\
	\x03\x1f\x03\x1f\x05\x1f\u{5a0}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x05\x1f\u{5a6}\x0a\x1f\x03\x1f\x05\x1f\u{5a9}\x0a\x1f\x03\x1f\x05\x1f\u{5ac}\
	\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{5b3}\x0a\x1f\
	\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{5b8}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{5c1}\x0a\x1f\x03\x1f\x03\x1f\
	\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{5c9}\x0a\x1f\x03\x1f\x03\x1f\
	\x03\x1f\x03\x1f\x05\x1f\u{5cf}\x0a\x1f\x03\x1f\x05\x1f\u{5d2}\x0a\x1f\x03\
	\x1f\x05\x1f\u{5d5}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{5db}\
	\x0a\x1f\x03\x1f\x03\x1f\x05\x1f\u{5df}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x05\x1f\u{5e4}\x0a\x1f\x03\x1f\x05\x1f\u{5e7}\x0a\x1f\x03\x1f\x03\x1f\x05\
	\x1f\u{5eb}\x0a\x1f\x05\x1f\u{5ed}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x05\x1f\u{5f3}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x05\x1f\u{5fb}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x05\x1f\u{603}\x0a\x1f\x03\x1f\x05\x1f\u{606}\x0a\x1f\x03\x1f\x03\x1f\x03\
	\x1f\x05\x1f\u{60b}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\
	\x1f\x03\x1f\x05\x1f\u{614}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\
	\x1f\u{61a}\x0a\x1f\x03\x1f\x05\x1f\u{61d}\x0a\x1f\x03\x1f\x03\x1f\x05\x1f\
	\u{621}\x0a\x1f\x03\x1f\x05\x1f\u{624}\x0a\x1f\x03\x1f\x03\x1f\x05\x1f\u{628}\
	\x0a\x1f\x03\x1f\x03\x1f\x05\x1f\u{62c}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x03\x1f\x03\x1f\x03\x1f\x07\x1f\u{646}\x0a\x1f\x0c\x1f\x0e\x1f\u{649}\x0b\
	\x1f\x05\x1f\u{64b}\x0a\x1f\x03\x1f\x03\x1f\x05\x1f\u{64f}\x0a\x1f\x03\x1f\
	\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{655}\x0a\x1f\x03\x1f\x05\x1f\u{658}\x0a\
	\x1f\x03\x1f\x05\x1f\u{65b}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\
	\x1f\u{661}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\
	\x1f\u{669}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{66e}\x0a\x1f\x03\x1f\
	\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{674}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\
	\x03\x1f\x05\x1f\u{67a}\x0a\x1f\x03\x1f\x05\x1f\u{67d}\x0a\x1f\x03\x1f\x03\
	\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{684}\x0a\x1f\x03\x1f\x03\x1f\x03\
	\x1f\x07\x1f\u{689}\x0a\x1f\x0c\x1f\x0e\x1f\u{68c}\x0b\x1f\x03\x1f\x03\x1f\
	\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{694}\x0a\x1f\x03\x1f\x03\x1f\
	\x03\x1f\x05\x1f\u{699}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{69e}\x0a\
	\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{6a5}\x0a\x1f\x03\
	\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{6ab}\x0a\x1f\x03\x1f\x03\x1f\x03\
	\x1f\x05\x1f\u{6b0}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x03\
	\x1f\x03\x1f\x03\x1f\x07\x1f\u{6ba}\x0a\x1f\x0c\x1f\x0e\x1f\u{6bd}\x0b\x1f\
	\x05\x1f\u{6bf}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x1f\x07\x1f\u{6c5}\x0a\
	\x1f\x0c\x1f\x0e\x1f\u{6c8}\x0b\x1f\x03\x1f\x03\x1f\x03\x1f\x05\x1f\u{6cd}\
	\x0a\x1f\x03\x1f\x05\x1f\u{6d0}\x0a\x1f\x03\x1f\x05\x1f\u{6d3}\x0a\x1f\x03\
	\x1f\x03\x1f\x03\x1f\x05\x1f\u{6d8}\x0a\x1f\x03\x1f\x03\x1f\x03\x1f\x03\
	\x1f\x05\x1f\u{6de}\x0a\x1f\x03\x20\x03\x20\x03\x20\x03\x21\x03\x21\x03\
	\x21\x03\x22\x03\x22\x03\x22\x05\x22\u{6e9}\x0a\x22\x03\x22\x03\x22\x03\
	\x22\x03\x22\x05\x22\u{6ef}\x0a\x22\x03\x22\x03\x22\x03\x23\x03\x23\x03\
	\x23\x05\x23\u{6f6}\x0a\x23\x03\x23\x05\x23\u{6f9}\x0a\x23\x03\x23\x03\x23\
	\x03\x23\x03\x23\x03\x23\x03\x23\x03\x23\x05\x23\u{702}\x0a\x23\x03\x23\
	\x05\x23\u{705}\x0a\x23\x03\x23\x03\x23\x05\x23\u{709}\x0a\x23\x03\x24\x03\
	\x24\x03\x24\x07\x24\u{70e}\x0a\x24\x0c\x24\x0e\x24\u{711}\x0b\x24\x03\x24\
	\x03\x24\x03\x24\x03\x24\x03\x24\x03\x24\x03\x24\x03\x24\x03\x24\x03\x24\
	\x03\x24\x03\x24\x07\x24\u{71f}\x0a\x24\x0c\x24\x0e\x24\u{722}\x0b\x24\x03\
	\x24\x03\x24\x03\x24\x03\x24\x03\x24\x03\x24\x03\x24\x03\x24\x03\x24\x03\
	\x24\x03\x24\x03\x24\x03\x24\x03\x24\x03\x24\x03\x24\x03\x24\x03\x24\x03\
	\x24\x03\x24\x03\x24\x03\x24\x03\x24\x07\x24\u{73b}\x0a\x24\x0c\x24\x0e\
	\x24\u{73e}\x0b\x24\x05\x24\u{740}\x0a\x24\x03\x24\x03\x24\x07\x24\u{744}\
	\x0a\x24\x0c\x24\x0e\x24\u{747}\x0b\x24\x03\x24\x03\x24\x03\x24\x03\x24\
	\x07\x24\u{74d}\x0a\x24\x0c\x24\x0e\x24\u{750}\x0b\x24\x03\x24\x03\x24\x03\
	\x24\x03\x24\x07\x24\u{756}\x0a\x24\x0c\x24\x0e\x24\u{759}\x0b\x24\x05\x24\
	\u{75b}\x0a\x24\x03\x25\x03\x25\x03\x25\x03\x25\x03\x25\x05\x25\u{762}\x0a\
	\x25\x03\x25\x05\x25\u{765}\x0a\x25\x03\x26\x03\x26\x03\x26\x03\x26\x03\
	\x26\x03\x26\x03\x26\x05\x26\u{76e}\x0a\x26\x03\x27\x03\x27\x05\x27\u{772}\
	\x0a\x27\x03\x28\x03\x28\x03\x29\x03\x29\x03\x2a\x03\x2a\x03\x2a\x03\x2a\
	\x03\x2a\x03\x2a\x05\x2a\u{77e}\x0a\x2a\x03\x2a\x03\x2a\x05\x2a\u{782}\x0a\
	\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x05\x2a\u{789}\x0a\x2a\x03\
	\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\
	\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\
	\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\
	\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\
	\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\
	\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\
	\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\
	\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\
	\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\
	\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\
	\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\
	\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\
	\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x05\x2a\u{7fd}\x0a\x2a\x03\
	\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x05\x2a\u{805}\x0a\x2a\x03\
	\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x05\x2a\u{80d}\x0a\x2a\x03\
	\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x05\x2a\u{816}\x0a\
	\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x03\x2a\x05\
	\x2a\u{820}\x0a\x2a\x03\x2b\x03\x2b\x05\x2b\u{824}\x0a\x2b\x03\x2b\x05\x2b\
	\u{827}\x0a\x2b\x03\x2b\x03\x2b\x03\x2b\x03\x2b\x03\x2b\x05\x2b\u{82e}\x0a\
	\x2b\x03\x2b\x03\x2b\x03\x2c\x03\x2c\x05\x2c\u{834}\x0a\x2c\x03\x2c\x03\
	\x2c\x03\x2c\x03\x2c\x03\x2d\x03\x2d\x03\x2d\x03\x2d\x03\x2d\x03\x2d\x03\
	\x2e\x03\x2e\x03\x2e\x03\x2e\x03\x2e\x03\x2e\x05\x2e\u{846}\x0a\x2e\x03\
	\x2e\x03\x2e\x03\x2e\x03\x2e\x03\x2f\x03\x2f\x03\x2f\x03\x2f\x03\x2f\x03\
	\x2f\x05\x2f\u{852}\x0a\x2f\x03\x2f\x03\x2f\x03\x2f\x05\x2f\u{857}\x0a\x2f\
	\x03\x30\x03\x30\x03\x30\x03\x31\x03\x31\x03\x31\x03\x31\x03\x31\x03\x31\
	\x03\x31\x05\x31\u{863}\x0a\x31\x03\x32\x03\x32\x03\x32\x03\x33\x03\x33\
	\x03\x33\x03\x34\x05\x34\u{86c}\x0a\x34\x03\x34\x03\x34\x03\x34\x03\x35\
	\x03\x35\x03\x35\x05\x35\u{874}\x0a\x35\x03\x35\x03\x35\x05\x35\u{878}\x0a\
	\x35\x03\x35\x03\x35\x03\x35\x03\x35\x03\x35\x05\x35\u{87f}\x0a\x35\x05\
	\x35\u{881}\x0a\x35\x03\x35\x03\x35\x03\x35\x05\x35\u{886}\x0a\x35\x03\x35\
	\x03\x35\x03\x35\x05\x35\u{88b}\x0a\x35\x03\x35\x03\x35\x05\x35\u{88f}\x0a\
	\x35\x03\x35\x05\x35\u{892}\x0a\x35\x03\x35\x03\x35\x03\x35\x03\x35\x05\
	\x35\u{898}\x0a\x35\x03\x35\x03\x35\x03\x35\x05\x35\u{89d}\x0a\x35\x03\x35\
	\x03\x35\x03\x35\x05\x35\u{8a2}\x0a\x35\x03\x35\x03\x35\x05\x35\u{8a6}\x0a\
	\x35\x03\x35\x03\x35\x03\x35\x03\x35\x03\x35\x03\x35\x05\x35\u{8ae}\x0a\
	\x35\x03\x35\x03\x35\x03\x35\x05\x35\u{8b3}\x0a\x35\x03\x35\x05\x35\u{8b6}\
	\x0a\x35\x03\x35\x03\x35\x03\x35\x05\x35\u{8bb}\x0a\x35\x03\x35\x03\x35\
	\x05\x35\u{8bf}\x0a\x35\x03\x35\x03\x35\x03\x35\x05\x35\u{8c4}\x0a\x35\x05\
	\x35\u{8c6}\x0a\x35\x03\x36\x03\x36\x05\x36\u{8ca}\x0a\x36\x03\x37\x03\x37\
	\x03\x37\x03\x37\x03\x37\x07\x37\u{8d1}\x0a\x37\x0c\x37\x0e\x37\u{8d4}\x0b\
	\x37\x03\x37\x03\x37\x03\x38\x03\x38\x03\x38\x05\x38\u{8db}\x0a\x38\x03\
	\x38\x03\x38\x03\x38\x03\x38\x05\x38\u{8e1}\x0a\x38\x03\x39\x03\x39\x03\
	\x39\x03\x39\x05\x39\u{8e7}\x0a\x39\x03\x39\x03\x39\x03\x3a\x03\x3a\x03\
	\x3b\x03\x3b\x03\x3c\x03\x3c\x03\x3d\x03\x3d\x03\x3d\x03\x3d\x03\x3d\x03\
	\x3d\x03\x3d\x05\x3d\u{8f8}\x0a\x3d\x03\x3e\x03\x3e\x03\x3e\x07\x3e\u{8fd}\
	\x0a\x3e\x0c\x3e\x0e\x3e\u{900}\x0b\x3e\x03\x3f\x03\x3f\x05\x3f\u{904}\x0a\
	\x3f\x03\x3f\x03\x3f\x03\x3f\x07\x3f\u{909}\x0a\x3f\x0c\x3f\x0e\x3f\u{90c}\
	\x0b\x3f\x03\x40\x03\x40\x05\x40\u{910}\x0a\x40\x03\x40\x03\x40\x03\x40\
	\x03\x40\x05\x40\u{916}\x0a\x40\x03\x40\x05\x40\u{919}\x0a\x40\x03\x40\x03\
	\x40\x03\x40\x03\x40\x03\x41\x03\x41\x03\x41\x03\x42\x03\x42\x03\x42\x03\
	\x42\x03\x42\x03\x42\x03\x42\x03\x42\x03\x42\x03\x42\x03\x42\x03\x42\x03\
	\x42\x03\x42\x03\x42\x07\x42\u{931}\x0a\x42\x0c\x42\x0e\x42\u{934}\x0b\x42\
	\x03\x43\x03\x43\x03\x43\x03\x43\x07\x43\u{93a}\x0a\x43\x0c\x43\x0e\x43\
	\u{93d}\x0b\x43\x03\x43\x03\x43\x03\x44\x03\x44\x03\x44\x03\x44\x03\x44\
	\x03\x44\x05\x44\u{947}\x0a\x44\x05\x44\u{949}\x0a\x44\x03\x45\x03\x45\x03\
	\x45\x07\x45\u{94e}\x0a\x45\x0c\x45\x0e\x45\u{951}\x0b\x45\x03\x46\x03\x46\
	\x05\x46\u{955}\x0a\x46\x03\x47\x03\x47\x05\x47\u{959}\x0a\x47\x03\x48\x03\
	\x48\x03\x48\x03\x48\x05\x48\u{95f}\x0a\x48\x03\x49\x03\x49\x03\x49\x03\
	\x49\x07\x49\u{965}\x0a\x49\x0c\x49\x0e\x49\u{968}\x0b\x49\x03\x49\x03\x49\
	\x03\x4a\x03\x4a\x03\x4a\x03\x4a\x03\x4a\x03\x4a\x05\x4a\u{972}\x0a\x4a\
	\x05\x4a\u{974}\x0a\x4a\x03\x4b\x03\x4b\x03\x4b\x03\x4b\x07\x4b\u{97a}\x0a\
	\x4b\x0c\x4b\x0e\x4b\u{97d}\x0b\x4b\x03\x4b\x03\x4b\x03\x4c\x03\x4c\x03\
	\x4c\x03\x4c\x07\x4c\u{985}\x0a\x4c\x0c\x4c\x0e\x4c\u{988}\x0b\x4c\x03\x4c\
	\x03\x4c\x03\x4d\x03\x4d\x03\x4d\x03\x4d\x03\x4d\x03\x4d\x05\x4d\u{992}\
	\x0a\x4d\x03\x4e\x03\x4e\x03\x4e\x03\x4e\x03\x4e\x03\x4e\x05\x4e\u{99a}\
	\x0a\x4e\x03\x4f\x03\x4f\x03\x4f\x03\x4f\x05\x4f\u{9a0}\x0a\x4f\x03\x50\
	\x03\x50\x03\x50\x03\x51\x03\x51\x03\x51\x03\x51\x03\x51\x06\x51\u{9aa}\
	\x0a\x51\x0d\x51\x0e\x51\u{9ab}\x03\x51\x03\x51\x03\x51\x03\x51\x03\x51\
	\x05\x51\u{9b3}\x0a\x51\x03\x51\x03\x51\x03\x51\x03\x51\x03\x51\x05\x51\
	\u{9ba}\x0a\x51\x03\x51\x03\x51\x03\x51\x03\x51\x05\x51\u{9c0}\x0a\x51\x03\
	\x51\x03\x51\x03\x51\x03\x51\x03\x51\x03\x51\x03\x51\x03\x51\x03\x51\x05\
	\x51\u{9cb}\x0a\x51\x03\x51\x03\x51\x03\x51\x03\x51\x07\x51\u{9d1}\x0a\x51\
	\x0c\x51\x0e\x51\u{9d4}\x0b\x51\x03\x51\x07\x51\u{9d7}\x0a\x51\x0c\x51\x0e\
	\x51\u{9da}\x0b\x51\x03\x51\x07\x51\u{9dd}\x0a\x51\x0c\x51\x0e\x51\u{9e0}\
	\x0b\x51\x05\x51\u{9e2}\x0a\x51\x03\x52\x03\x52\x03\x52\x03\x52\x03\x52\
	\x03\x52\x05\x52\u{9ea}\x0a\x52\x03\x53\x03\x53\x03\x53\x03\x53\x03\x53\
	\x03\x53\x03\x53\x05\x53\u{9f3}\x0a\x53\x03\x54\x03\x54\x03\x54\x03\x54\
	\x03\x54\x07\x54\u{9fa}\x0a\x54\x0c\x54\x0e\x54\u{9fd}\x0b\x54\x05\x54\u{9ff}\
	\x0a\x54\x03\x54\x03\x54\x03\x54\x03\x54\x03\x54\x07\x54\u{a06}\x0a\x54\
	\x0c\x54\x0e\x54\u{a09}\x0b\x54\x05\x54\u{a0b}\x0a\x54\x03\x54\x03\x54\x03\
	\x54\x03\x54\x03\x54\x07\x54\u{a12}\x0a\x54\x0c\x54\x0e\x54\u{a15}\x0b\x54\
	\x05\x54\u{a17}\x0a\x54\x03\x54\x03\x54\x03\x54\x03\x54\x03\x54\x07\x54\
	\u{a1e}\x0a\x54\x0c\x54\x0e\x54\u{a21}\x0b\x54\x05\x54\u{a23}\x0a\x54\x03\
	\x54\x05\x54\u{a26}\x0a\x54\x03\x54\x03\x54\x03\x54\x05\x54\u{a2b}\x0a\x54\
	\x05\x54\u{a2d}\x0a\x54\x03\x54\x03\x54\x05\x54\u{a31}\x0a\x54\x03\x55\x03\
	\x55\x03\x55\x03\x56\x03\x56\x03\x56\x03\x56\x03\x56\x03\x56\x03\x56\x05\
	\x56\u{a3d}\x0a\x56\x03\x56\x03\x56\x03\x56\x03\x56\x03\x56\x05\x56\u{a44}\
	\x0a\x56\x03\x56\x03\x56\x03\x56\x03\x56\x03\x56\x05\x56\u{a4b}\x0a\x56\
	\x03\x56\x03\x56\x03\x56\x03\x56\x03\x56\x03\x56\x03\x56\x03\x56\x07\x56\
	\u{a55}\x0a\x56\x0c\x56\x0e\x56\u{a58}\x0b\x56\x03\x57\x03\x57\x03\x57\x03\
	\x57\x03\x57\x03\x57\x03\x57\x03\x57\x03\x57\x05\x57\u{a63}\x0a\x57\x03\
	\x58\x03\x58\x05\x58\u{a67}\x0a\x58\x03\x58\x03\x58\x05\x58\u{a6b}\x0a\x58\
	\x03\x59\x03\x59\x07\x59\u{a6f}\x0a\x59\x0c\x59\x0e\x59\u{a72}\x0b\x59\x03\
	\x5a\x03\x5a\x05\x5a\u{a76}\x0a\x5a\x03\x5a\x03\x5a\x03\x5a\x03\x5a\x07\
	\x5a\u{a7c}\x0a\x5a\x0c\x5a\x0e\x5a\u{a7f}\x0b\x5a\x03\x5a\x05\x5a\u{a82}\
	\x0a\x5a\x03\x5a\x05\x5a\u{a85}\x0a\x5a\x03\x5a\x05\x5a\u{a88}\x0a\x5a\x03\
	\x5a\x05\x5a\u{a8b}\x0a\x5a\x03\x5a\x03\x5a\x05\x5a\u{a8f}\x0a\x5a\x03\x5b\
	\x03\x5b\x05\x5b\u{a93}\x0a\x5b\x03\x5b\x07\x5b\u{a96}\x0a\x5b\x0c\x5b\x0e\
	\x5b\u{a99}\x0b\x5b\x03\x5b\x05\x5b\u{a9c}\x0a\x5b\x03\x5b\x05\x5b\u{a9f}\
	\x0a\x5b\x03\x5b\x05\x5b\u{aa2}\x0a\x5b\x03\x5b\x05\x5b\u{aa5}\x0a\x5b\x03\
	\x5b\x03\x5b\x05\x5b\u{aa9}\x0a\x5b\x03\x5b\x07\x5b\u{aac}\x0a\x5b\x0c\x5b\
	\x0e\x5b\u{aaf}\x0b\x5b\x03\x5b\x05\x5b\u{ab2}\x0a\x5b\x03\x5b\x05\x5b\u{ab5}\
	\x0a\x5b\x03\x5b\x05\x5b\u{ab8}\x0a\x5b\x03\x5b\x05\x5b\u{abb}\x0a\x5b\x05\
	\x5b\u{abd}\x0a\x5b\x03\x5c\x03\x5c\x03\x5c\x03\x5c\x05\x5c\u{ac3}\x0a\x5c\
	\x03\x5c\x03\x5c\x03\x5c\x03\x5c\x03\x5c\x05\x5c\u{aca}\x0a\x5c\x03\x5c\
	\x03\x5c\x03\x5c\x05\x5c\u{acf}\x0a\x5c\x03\x5c\x05\x5c\u{ad2}\x0a\x5c\x03\
	\x5c\x05\x5c\u{ad5}\x0a\x5c\x03\x5c\x03\x5c\x05\x5c\u{ad9}\x0a\x5c\x03\x5c\
	\x03\x5c\x03\x5c\x03\x5c\x03\x5c\x03\x5c\x03\x5c\x03\x5c\x05\x5c\u{ae3}\
	\x0a\x5c\x03\x5c\x03\x5c\x05\x5c\u{ae7}\x0a\x5c\x05\x5c\u{ae9}\x0a\x5c\x03\
	\x5c\x05\x5c\u{aec}\x0a\x5c\x03\x5c\x03\x5c\x05\x5c\u{af0}\x0a\x5c\x03\x5d\
	\x03\x5d\x07\x5d\u{af4}\x0a\x5d\x0c\x5d\x0e\x5d\u{af7}\x0b\x5d\x03\x5d\x05\
	\x5d\u{afa}\x0a\x5d\x03\x5d\x03\x5d\x03\x5e\x03\x5e\x03\x5e\x03\x5f\x03\
	\x5f\x03\x5f\x03\x5f\x05\x5f\u{b05}\x0a\x5f\x03\x5f\x03\x5f\x03\x5f\x03\
	\x60\x03\x60\x03\x60\x03\x60\x03\x60\x05\x60\u{b0f}\x0a\x60\x03\x60\x03\
	\x60\x05\x60\u{b13}\x0a\x60\x03\x60\x03\x60\x03\x60\x03\x61\x03\x61\x03\
	\x61\x03\x61\x03\x61\x03\x61\x03\x61\x05\x61\u{b1f}\x0a\x61\x03\x61\x03\
	\x61\x03\x61\x03\x62\x03\x62\x03\x62\x03\x62\x03\x62\x03\x62\x03\x62\x05\
	\x62\u{b2b}\x0a\x62\x03\x63\x03\x63\x03\x63\x03\x63\x03\x63\x03\x63\x03\
	\x63\x03\x63\x03\x63\x03\x63\x03\x63\x07\x63\u{b38}\x0a\x63\x0c\x63\x0e\
	\x63\u{b3b}\x0b\x63\x03\x63\x03\x63\x05\x63\u{b3f}\x0a\x63\x03\x64\x03\x64\
	\x03\x64\x03\x64\x05\x64\u{b45}\x0a\x64\x03\x65\x03\x65\x03\x65\x03\x65\
	\x03\x65\x03\x66\x03\x66\x03\x66\x07\x66\u{b4f}\x0a\x66\x0c\x66\x0e\x66\
	\u{b52}\x0b\x66\x03\x67\x03\x67\x03\x67\x03\x67\x03\x68\x03\x68\x03\x68\
	\x03\x69\x03\x69\x03\x69\x03\x6a\x03\x6a\x03\x6a\x05\x6a\u{b61}\x0a\x6a\
	\x03\x6a\x07\x6a\u{b64}\x0a\x6a\x0c\x6a\x0e\x6a\u{b67}\x0b\x6a\x03\x6a\x03\
	\x6a\x03\x6b\x03\x6b\x03\x6b\x03\x6b\x03\x6b\x03\x6b\x07\x6b\u{b71}\x0a\
	\x6b\x0c\x6b\x0e\x6b\u{b74}\x0b\x6b\x03\x6b\x03\x6b\x05\x6b\u{b78}\x0a\x6b\
	\x03\x6c\x03\x6c\x03\x6c\x03\x6c\x07\x6c\u{b7e}\x0a\x6c\x0c\x6c\x0e\x6c\
	\u{b81}\x0b\x6c\x03\x6c\x07\x6c\u{b84}\x0a\x6c\x0c\x6c\x0e\x6c\u{b87}\x0b\
	\x6c\x03\x6c\x05\x6c\u{b8a}\x0a\x6c\x03\x6c\x05\x6c\u{b8d}\x0a\x6c\x03\x6d\
	\x05\x6d\u{b90}\x0a\x6d\x03\x6d\x03\x6d\x03\x6d\x03\x6d\x03\x6d\x05\x6d\
	\u{b97}\x0a\x6d\x03\x6d\x03\x6d\x03\x6d\x03\x6d\x05\x6d\u{b9d}\x0a\x6d\x03\
	\x6e\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x07\x6e\u{ba4}\x0a\x6e\x0c\x6e\x0e\
	\x6e\u{ba7}\x0b\x6e\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x07\x6e\u{bae}\
	\x0a\x6e\x0c\x6e\x0e\x6e\u{bb1}\x0b\x6e\x03\x6e\x03\x6e\x03\x6e\x03\x6e\
	\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x03\x6e\x07\x6e\u{bbd}\x0a\x6e\
	\x0c\x6e\x0e\x6e\u{bc0}\x0b\x6e\x03\x6e\x03\x6e\x05\x6e\u{bc4}\x0a\x6e\x05\
	\x6e\u{bc6}\x0a\x6e\x03\x6f\x03\x6f\x05\x6f\u{bca}\x0a\x6f\x03\x70\x03\x70\
	\x03\x70\x03\x70\x03\x70\x07\x70\u{bd1}\x0a\x70\x0c\x70\x0e\x70\u{bd4}\x0b\
	\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x07\
	\x70\u{bde}\x0a\x70\x0c\x70\x0e\x70\u{be1}\x0b\x70\x03\x70\x03\x70\x05\x70\
	\u{be5}\x0a\x70\x03\x71\x03\x71\x05\x71\u{be9}\x0a\x71\x03\x72\x03\x72\x03\
	\x72\x03\x72\x07\x72\u{bef}\x0a\x72\x0c\x72\x0e\x72\u{bf2}\x0b\x72\x05\x72\
	\u{bf4}\x0a\x72\x03\x72\x03\x72\x05\x72\u{bf8}\x0a\x72\x03\x73\x03\x73\x03\
	\x73\x03\x73\x03\x73\x03\x73\x03\x73\x03\x73\x03\x73\x03\x73\x07\x73\u{c04}\
	\x0a\x73\x0c\x73\x0e\x73\u{c07}\x0b\x73\x03\x73\x03\x73\x03\x73\x03\x74\
	\x03\x74\x03\x74\x03\x74\x03\x74\x07\x74\u{c11}\x0a\x74\x0c\x74\x0e\x74\
	\u{c14}\x0b\x74\x03\x74\x03\x74\x05\x74\u{c18}\x0a\x74\x03\x75\x03\x75\x05\
	\x75\u{c1c}\x0a\x75\x03\x75\x05\x75\u{c1f}\x0a\x75\x03\x76\x03\x76\x05\x76\
	\u{c23}\x0a\x76\x03\x76\x03\x76\x03\x76\x03\x76\x05\x76\u{c29}\x0a\x76\x03\
	\x76\x05\x76\u{c2c}\x0a\x76\x03\x77\x03\x77\x03\x77\x03\x78\x03\x78\x05\
	\x78\u{c33}\x0a\x78\x03\x79\x03\x79\x03\x79\x03\x79\x03\x79\x03\x79\x03\
	\x79\x03\x79\x07\x79\u{c3d}\x0a\x79\x0c\x79\x0e\x79\u{c40}\x0b\x79\x03\x79\
	\x03\x79\x03\x7a\x03\x7a\x03\x7a\x03\x7a\x07\x7a\u{c48}\x0a\x7a\x0c\x7a\
	\x0e\x7a\u{c4b}\x0b\x7a\x03\x7a\x03\x7a\x03\x7a\x03\x7a\x03\x7a\x03\x7a\
	\x03\x7a\x03\x7a\x07\x7a\u{c55}\x0a\x7a\x0c\x7a\x0e\x7a\u{c58}\x0b\x7a\x03\
	\x7a\x03\x7a\x03\x7b\x03\x7b\x03\x7b\x03\x7b\x07\x7b\u{c60}\x0a\x7b\x0c\
	\x7b\x0e\x7b\u{c63}\x0b\x7b\x03\x7b\x03\x7b\x05\x7b\u{c67}\x0a\x7b\x03\x7c\
	\x03\x7c\x03\x7d\x03\x7d\x03\x7e\x03\x7e\x05\x7e\u{c6f}\x0a\x7e\x03\x7f\
	\x03\x7f\x03\u{80}\x05\u{80}\u{c74}\x0a\u{80}\x03\u{80}\x03\u{80}\x03\u{81}\
	\x03\u{81}\x03\u{81}\x05\u{81}\u{c7b}\x0a\u{81}\x03\u{81}\x03\u{81}\x03\
	\u{81}\x03\u{81}\x03\u{81}\x07\u{81}\u{c82}\x0a\u{81}\x0c\u{81}\x0e\u{81}\
	\u{c85}\x0b\u{81}\x05\u{81}\u{c87}\x0a\u{81}\x03\u{81}\x03\u{81}\x03\u{81}\
	\x05\u{81}\u{c8c}\x0a\u{81}\x03\u{81}\x03\u{81}\x03\u{81}\x07\u{81}\u{c91}\
	\x0a\u{81}\x0c\u{81}\x0e\u{81}\u{c94}\x0b\u{81}\x05\u{81}\u{c96}\x0a\u{81}\
	\x03\u{82}\x03\u{82}\x03\u{82}\x03\u{82}\x03\u{82}\x03\u{82}\x03\u{83}\x03\
	\u{83}\x03\u{84}\x05\u{84}\u{ca1}\x0a\u{84}\x03\u{84}\x03\u{84}\x07\u{84}\
	\u{ca5}\x0a\u{84}\x0c\u{84}\x0e\u{84}\u{ca8}\x0b\u{84}\x03\u{85}\x03\u{85}\
	\x03\u{85}\x05\u{85}\u{cad}\x0a\u{85}\x03\u{86}\x03\u{86}\x03\u{86}\x05\
	\u{86}\u{cb2}\x0a\u{86}\x03\u{86}\x03\u{86}\x05\u{86}\u{cb6}\x0a\u{86}\x03\
	\u{86}\x03\u{86}\x03\u{86}\x03\u{86}\x05\u{86}\u{cbc}\x0a\u{86}\x03\u{86}\
	\x03\u{86}\x05\u{86}\u{cc0}\x0a\u{86}\x03\u{87}\x05\u{87}\u{cc3}\x0a\u{87}\
	\x03\u{87}\x03\u{87}\x03\u{87}\x05\u{87}\u{cc8}\x0a\u{87}\x03\u{87}\x05\
	\u{87}\u{ccb}\x0a\u{87}\x03\u{87}\x03\u{87}\x03\u{87}\x05\u{87}\u{cd0}\x0a\
	\u{87}\x03\u{87}\x03\u{87}\x05\u{87}\u{cd4}\x0a\u{87}\x03\u{87}\x05\u{87}\
	\u{cd7}\x0a\u{87}\x03\u{87}\x05\u{87}\u{cda}\x0a\u{87}\x03\u{88}\x03\u{88}\
	\x03\u{88}\x03\u{88}\x05\u{88}\u{ce0}\x0a\u{88}\x03\u{89}\x03\u{89}\x03\
	\u{89}\x05\u{89}\u{ce5}\x0a\u{89}\x03\u{89}\x03\u{89}\x03\u{89}\x03\u{89}\
	\x03\u{89}\x03\u{89}\x05\u{89}\u{ced}\x0a\u{89}\x03\u{8a}\x05\u{8a}\u{cf0}\
	\x0a\u{8a}\x03\u{8a}\x03\u{8a}\x05\u{8a}\u{cf4}\x0a\u{8a}\x03\u{8a}\x03\
	\u{8a}\x03\u{8a}\x03\u{8a}\x03\u{8a}\x03\u{8a}\x03\u{8a}\x03\u{8a}\x03\u{8a}\
	\x03\u{8a}\x03\u{8a}\x03\u{8a}\x03\u{8a}\x03\u{8a}\x03\u{8a}\x05\u{8a}\u{d05}\
	\x0a\u{8a}\x05\u{8a}\u{d07}\x0a\u{8a}\x03\u{8a}\x05\u{8a}\u{d0a}\x0a\u{8a}\
	\x03\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8c}\x03\u{8c}\x03\u{8c}\x07\
	\u{8c}\u{d13}\x0a\u{8c}\x0c\u{8c}\x0e\u{8c}\u{d16}\x0b\u{8c}\x03\u{8d}\x03\
	\u{8d}\x03\u{8d}\x03\u{8d}\x07\u{8d}\u{d1c}\x0a\u{8d}\x0c\u{8d}\x0e\u{8d}\
	\u{d1f}\x0b\u{8d}\x03\u{8d}\x03\u{8d}\x03\u{8e}\x03\u{8e}\x05\u{8e}\u{d25}\
	\x0a\u{8e}\x03\u{8f}\x03\u{8f}\x03\u{8f}\x03\u{8f}\x07\u{8f}\u{d2b}\x0a\
	\u{8f}\x0c\u{8f}\x0e\u{8f}\u{d2e}\x0b\u{8f}\x03\u{8f}\x03\u{8f}\x03\u{90}\
	\x03\u{90}\x05\u{90}\u{d34}\x0a\u{90}\x03\u{91}\x03\u{91}\x03\u{91}\x05\
	\u{91}\u{d39}\x0a\u{91}\x03\u{91}\x05\u{91}\u{d3c}\x0a\u{91}\x03\u{91}\x05\
	\u{91}\u{d3f}\x0a\u{91}\x03\u{91}\x05\u{91}\u{d42}\x0a\u{91}\x03\u{91}\x03\
	\u{91}\x03\u{91}\x03\u{91}\x03\u{91}\x03\u{91}\x05\u{91}\u{d4a}\x0a\u{91}\
	\x03\u{91}\x05\u{91}\u{d4d}\x0a\u{91}\x03\u{91}\x03\u{91}\x03\u{91}\x03\
	\u{91}\x03\u{91}\x03\u{91}\x05\u{91}\u{d55}\x0a\u{91}\x03\u{91}\x05\u{91}\
	\u{d58}\x0a\u{91}\x03\u{91}\x03\u{91}\x03\u{91}\x03\u{91}\x05\u{91}\u{d5e}\
	\x0a\u{91}\x03\u{92}\x03\u{92}\x03\u{92}\x03\u{93}\x03\u{93}\x03\u{93}\x03\
	\u{93}\x07\u{93}\u{d67}\x0a\u{93}\x0c\u{93}\x0e\u{93}\u{d6a}\x0b\u{93}\x03\
	\u{93}\x03\u{93}\x03\u{94}\x03\u{94}\x03\u{94}\x05\u{94}\u{d71}\x0a\u{94}\
	\x03\u{94}\x03\u{94}\x03\u{94}\x03\u{94}\x03\u{94}\x05\u{94}\u{d78}\x0a\
	\u{94}\x03\u{94}\x03\u{94}\x03\u{94}\x03\u{94}\x03\u{94}\x05\u{94}\u{d7f}\
	\x0a\u{94}\x05\u{94}\u{d81}\x0a\u{94}\x03\u{95}\x03\u{95}\x03\u{95}\x03\
	\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x07\u{95}\u{d8c}\
	\x0a\u{95}\x0c\u{95}\x0e\u{95}\u{d8f}\x0b\u{95}\x03\u{95}\x03\u{95}\x03\
	\u{95}\x03\u{95}\x03\u{95}\x06\u{95}\u{d96}\x0a\u{95}\x0d\u{95}\x0e\u{95}\
	\u{d97}\x03\u{95}\x05\u{95}\u{d9b}\x0a\u{95}\x05\u{95}\u{d9d}\x0a\u{95}\
	\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x07\u{95}\u{da5}\
	\x0a\u{95}\x0c\u{95}\x0e\u{95}\u{da8}\x0b\u{95}\x03\u{95}\x03\u{95}\x03\
	\u{95}\x03\u{95}\x03\u{95}\x06\u{95}\u{daf}\x0a\u{95}\x0d\u{95}\x0e\u{95}\
	\u{db0}\x03\u{95}\x05\u{95}\u{db4}\x0a\u{95}\x05\u{95}\u{db6}\x0a\u{95}\
	\x03\u{96}\x03\u{96}\x03\u{96}\x03\u{96}\x03\u{97}\x03\u{97}\x05\u{97}\u{dbe}\
	\x0a\u{97}\x03\u{98}\x03\u{98}\x05\u{98}\u{dc2}\x0a\u{98}\x03\u{99}\x03\
	\u{99}\x03\u{99}\x03\u{99}\x03\u{99}\x07\u{99}\u{dc9}\x0a\u{99}\x0c\u{99}\
	\x0e\u{99}\u{dcc}\x0b\u{99}\x05\u{99}\u{dce}\x0a\u{99}\x03\u{99}\x03\u{99}\
	\x05\u{99}\u{dd2}\x0a\u{99}\x03\u{99}\x03\u{99}\x03\u{9a}\x05\u{9a}\u{dd7}\
	\x0a\u{9a}\x03\u{9a}\x03\u{9a}\x05\u{9a}\u{ddb}\x0a\u{9a}\x05\u{9a}\u{ddd}\
	\x0a\u{9a}\x03\u{9b}\x03\u{9b}\x03\u{9b}\x03\u{9b}\x03\u{9b}\x03\u{9b}\x03\
	\u{9b}\x05\u{9b}\u{de6}\x0a\u{9b}\x03\u{9b}\x03\u{9b}\x03\u{9b}\x03\u{9b}\
	\x03\u{9b}\x03\u{9b}\x03\u{9b}\x03\u{9b}\x03\u{9b}\x03\u{9b}\x05\u{9b}\u{df2}\
	\x0a\u{9b}\x05\u{9b}\u{df4}\x0a\u{9b}\x03\u{9b}\x03\u{9b}\x03\u{9b}\x03\
	\u{9b}\x03\u{9b}\x05\u{9b}\u{dfb}\x0a\u{9b}\x03\u{9b}\x03\u{9b}\x03\u{9b}\
	\x03\u{9b}\x03\u{9b}\x05\u{9b}\u{e02}\x0a\u{9b}\x03\u{9b}\x03\u{9b}\x03\
	\u{9b}\x03\u{9b}\x05\u{9b}\u{e08}\x0a\u{9b}\x03\u{9b}\x03\u{9b}\x03\u{9b}\
	\x03\u{9b}\x05\u{9b}\u{e0e}\x0a\u{9b}\x05\u{9b}\u{e10}\x0a\u{9b}\x03\u{9c}\
	\x03\u{9c}\x03\u{9c}\x07\u{9c}\u{e15}\x0a\u{9c}\x0c\u{9c}\x0e\u{9c}\u{e18}\
	\x0b\u{9c}\x03\u{9d}\x03\u{9d}\x03\u{9d}\x07\u{9d}\u{e1d}\x0a\u{9d}\x0c\
	\u{9d}\x0e\u{9d}\u{e20}\x0b\u{9d}\x03\u{9e}\x03\u{9e}\x03\u{9e}\x07\u{9e}\
	\u{e25}\x0a\u{9e}\x0c\u{9e}\x0e\u{9e}\u{e28}\x0b\u{9e}\x03\u{9f}\x03\u{9f}\
	\x03\u{9f}\x05\u{9f}\u{e2d}\x0a\u{9f}\x03\u{a0}\x03\u{a0}\x03\u{a0}\x05\
	\u{a0}\u{e32}\x0a\u{a0}\x03\u{a0}\x03\u{a0}\x03\u{a1}\x03\u{a1}\x03\u{a1}\
	\x05\u{a1}\u{e39}\x0a\u{a1}\x03\u{a1}\x03\u{a1}\x03\u{a2}\x03\u{a2}\x05\
	\u{a2}\u{e3f}\x0a\u{a2}\x03\u{a2}\x03\u{a2}\x05\u{a2}\u{e43}\x0a\u{a2}\x05\
	\u{a2}\u{e45}\x0a\u{a2}\x03\u{a3}\x03\u{a3}\x03\u{a3}\x07\u{a3}\u{e4a}\x0a\
	\u{a3}\x0c\u{a3}\x0e\u{a3}\u{e4d}\x0b\u{a3}\x03\u{a4}\x03\u{a4}\x03\u{a4}\
	\x03\u{a4}\x07\u{a4}\u{e53}\x0a\u{a4}\x0c\u{a4}\x0e\u{a4}\u{e56}\x0b\u{a4}\
	\x03\u{a4}\x03\u{a4}\x03\u{a5}\x03\u{a5}\x05\u{a5}\u{e5c}\x0a\u{a5}\x03\
	\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x07\u{a6}\u{e64}\
	\x0a\u{a6}\x0c\u{a6}\x0e\u{a6}\u{e67}\x0b\u{a6}\x03\u{a6}\x03\u{a6}\x05\
	\u{a6}\u{e6b}\x0a\u{a6}\x03\u{a7}\x03\u{a7}\x05\u{a7}\u{e6f}\x0a\u{a7}\x03\
	\u{a8}\x03\u{a8}\x03\u{a9}\x03\u{a9}\x03\u{a9}\x03\u{a9}\x03\u{aa}\x03\u{aa}\
	\x05\u{aa}\u{e79}\x0a\u{aa}\x03\u{ab}\x03\u{ab}\x03\u{ab}\x07\u{ab}\u{e7e}\
	\x0a\u{ab}\x0c\u{ab}\x0e\u{ab}\u{e81}\x0b\u{ab}\x03\u{ac}\x03\u{ac}\x03\
	\u{ac}\x03\u{ac}\x03\u{ac}\x03\u{ac}\x03\u{ac}\x03\u{ac}\x03\u{ac}\x03\u{ac}\
	\x05\u{ac}\u{e8d}\x0a\u{ac}\x05\u{ac}\u{e8f}\x0a\u{ac}\x03\u{ac}\x03\u{ac}\
	\x03\u{ac}\x03\u{ac}\x03\u{ac}\x03\u{ac}\x07\u{ac}\u{e97}\x0a\u{ac}\x0c\
	\u{ac}\x0e\u{ac}\u{e9a}\x0b\u{ac}\x03\u{ad}\x05\u{ad}\u{e9d}\x0a\u{ad}\x03\
	\u{ad}\x03\u{ad}\x03\u{ad}\x03\u{ad}\x03\u{ad}\x03\u{ad}\x05\u{ad}\u{ea5}\
	\x0a\u{ad}\x03\u{ad}\x03\u{ad}\x03\u{ad}\x03\u{ad}\x03\u{ad}\x07\u{ad}\u{eac}\
	\x0a\u{ad}\x0c\u{ad}\x0e\u{ad}\u{eaf}\x0b\u{ad}\x03\u{ad}\x03\u{ad}\x03\
	\u{ad}\x05\u{ad}\u{eb4}\x0a\u{ad}\x03\u{ad}\x03\u{ad}\x03\u{ad}\x03\u{ad}\
	\x03\u{ad}\x03\u{ad}\x05\u{ad}\u{ebc}\x0a\u{ad}\x03\u{ad}\x03\u{ad}\x03\
	\u{ad}\x05\u{ad}\u{ec1}\x0a\u{ad}\x03\u{ad}\x03\u{ad}\x03\u{ad}\x03\u{ad}\
	\x03\u{ad}\x03\u{ad}\x03\u{ad}\x03\u{ad}\x07\u{ad}\u{ecb}\x0a\u{ad}\x0c\
	\u{ad}\x0e\u{ad}\u{ece}\x0b\u{ad}\x03\u{ad}\x03\u{ad}\x05\u{ad}\u{ed2}\x0a\
	\u{ad}\x03\u{ad}\x05\u{ad}\u{ed5}\x0a\u{ad}\x03\u{ad}\x03\u{ad}\x03\u{ad}\
	\x03\u{ad}\x05\u{ad}\u{edb}\x0a\u{ad}\x03\u{ad}\x03\u{ad}\x05\u{ad}\u{edf}\
	\x0a\u{ad}\x03\u{ad}\x03\u{ad}\x03\u{ad}\x05\u{ad}\u{ee4}\x0a\u{ad}\x03\
	\u{ad}\x03\u{ad}\x03\u{ad}\x05\u{ad}\u{ee9}\x0a\u{ad}\x03\u{ad}\x03\u{ad}\
	\x03\u{ad}\x05\u{ad}\u{eee}\x0a\u{ad}\x03\u{ae}\x03\u{ae}\x03\u{af}\x03\
	\u{af}\x03\u{af}\x03\u{af}\x05\u{af}\u{ef6}\x0a\u{af}\x03\u{af}\x03\u{af}\
	\x03\u{af}\x03\u{af}\x03\u{af}\x03\u{af}\x03\u{af}\x03\u{af}\x03\u{af}\x03\
	\u{af}\x03\u{af}\x03\u{af}\x03\u{af}\x03\u{af}\x03\u{af}\x03\u{af}\x03\u{af}\
	\x03\u{af}\x03\u{af}\x03\u{af}\x03\u{af}\x03\u{af}\x03\u{af}\x03\u{af}\x07\
	\u{af}\u{f10}\x0a\u{af}\x0c\u{af}\x0e\u{af}\u{f13}\x0b\u{af}\x03\u{b0}\x03\
	\u{b0}\x03\u{b1}\x03\u{b1}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\
	\x03\u{b2}\x05\u{b2}\u{f1f}\x0a\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\
	\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x05\u{b2}\
	\u{f2b}\x0a\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\
	\u{b2}\x03\u{b2}\x03\u{b2}\x06\u{b2}\u{f35}\x0a\u{b2}\x0d\u{b2}\x0e\u{b2}\
	\u{f36}\x03\u{b2}\x03\u{b2}\x05\u{b2}\u{f3b}\x0a\u{b2}\x03\u{b2}\x03\u{b2}\
	\x03\u{b2}\x03\u{b2}\x03\u{b2}\x06\u{b2}\u{f42}\x0a\u{b2}\x0d\u{b2}\x0e\
	\u{b2}\u{f43}\x03\u{b2}\x03\u{b2}\x05\u{b2}\u{f48}\x0a\u{b2}\x03\u{b2}\x03\
	\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\
	\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x07\u{b2}\u{f58}\x0a\
	\u{b2}\x0c\u{b2}\x0e\u{b2}\u{f5b}\x0b\u{b2}\x05\u{b2}\u{f5d}\x0a\u{b2}\x03\
	\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x05\u{b2}\u{f65}\
	\x0a\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\
	\u{b2}\x05\u{b2}\u{f6e}\x0a\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\
	\x03\u{b2}\x03\u{b2}\x03\u{b2}\x05\u{b2}\u{f77}\x0a\u{b2}\x03\u{b2}\x03\
	\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\
	\x03\u{b2}\x03\u{b2}\x03\u{b2}\x05\u{b2}\u{f85}\x0a\u{b2}\x03\u{b2}\x03\
	\u{b2}\x03\u{b2}\x03\u{b2}\x05\u{b2}\u{f8b}\x0a\u{b2}\x03\u{b2}\x03\u{b2}\
	\x03\u{b2}\x03\u{b2}\x06\u{b2}\u{f91}\x0a\u{b2}\x0d\u{b2}\x0e\u{b2}\u{f92}\
	\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\
	\u{b2}\x03\u{b2}\x05\u{b2}\u{f9e}\x0a\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\
	\x07\u{b2}\u{fa3}\x0a\u{b2}\x0c\u{b2}\x0e\u{b2}\u{fa6}\x0b\u{b2}\x05\u{b2}\
	\u{fa8}\x0a\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\
	\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x07\u{b2}\u{fb3}\x0a\u{b2}\x0c\u{b2}\
	\x0e\u{b2}\u{fb6}\x0b\u{b2}\x03\u{b2}\x03\u{b2}\x05\u{b2}\u{fba}\x0a\u{b2}\
	\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x05\u{b2}\u{fc2}\
	\x0a\u{b2}\x03\u{b2}\x03\u{b2}\x05\u{b2}\u{fc6}\x0a\u{b2}\x03\u{b2}\x03\
	\u{b2}\x05\u{b2}\u{fca}\x0a\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\
	\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x06\u{b2}\u{fd4}\x0a\u{b2}\x0d\
	\u{b2}\x0e\u{b2}\u{fd5}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\
	\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\
	\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\
	\x03\u{b2}\x03\u{b2}\x03\u{b2}\x05\u{b2}\u{fef}\x0a\u{b2}\x03\u{b2}\x03\
	\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x05\u{b2}\u{ff6}\x0a\u{b2}\x03\u{b2}\
	\x05\u{b2}\u{ff9}\x0a\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\
	\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\
	\x03\u{b2}\x05\u{b2}\u{1008}\x0a\u{b2}\x03\u{b2}\x03\u{b2}\x05\u{b2}\u{100c}\
	\x0a\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\
	\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\
	\x03\u{b2}\x03\u{b2}\x07\u{b2}\u{101e}\x0a\u{b2}\x0c\u{b2}\x0e\u{b2}\u{1021}\
	\x0b\u{b2}\x03\u{b3}\x03\u{b3}\x07\u{b3}\u{1025}\x0a\u{b3}\x0c\u{b3}\x0e\
	\u{b3}\u{1028}\x0b\u{b3}\x03\u{b4}\x03\u{b4}\x05\u{b4}\u{102c}\x0a\u{b4}\
	\x03\u{b5}\x03\u{b5}\x03\u{b5}\x03\u{b5}\x03\u{b6}\x03\u{b6}\x03\u{b6}\x03\
	\u{b6}\x03\u{b6}\x03\u{b6}\x05\u{b6}\u{1038}\x0a\u{b6}\x03\u{b7}\x03\u{b7}\
	\x03\u{b7}\x03\u{b7}\x03\u{b7}\x03\u{b7}\x03\u{b7}\x03\u{b7}\x03\u{b7}\x03\
	\u{b7}\x03\u{b7}\x05\u{b7}\u{1045}\x0a\u{b7}\x03\u{b8}\x03\u{b8}\x03\u{b8}\
	\x03\u{b8}\x03\u{b8}\x03\u{b8}\x03\u{b8}\x03\u{b8}\x05\u{b8}\u{104f}\x0a\
	\u{b8}\x03\u{b9}\x03\u{b9}\x03\u{b9}\x03\u{b9}\x03\u{b9}\x03\u{b9}\x03\u{b9}\
	\x03\u{b9}\x03\u{b9}\x03\u{b9}\x05\u{b9}\u{105b}\x0a\u{b9}\x03\u{ba}\x03\
	\u{ba}\x03\u{ba}\x03\u{bb}\x03\u{bb}\x03\u{bc}\x03\u{bc}\x03\u{bd}\x03\u{bd}\
	\x03\u{be}\x03\u{be}\x03\u{bf}\x03\u{bf}\x03\u{bf}\x05\u{bf}\u{106b}\x0a\
	\u{bf}\x03\u{c0}\x03\u{c0}\x05\u{c0}\u{106f}\x0a\u{c0}\x03\u{c1}\x03\u{c1}\
	\x03\u{c1}\x06\u{c1}\u{1074}\x0a\u{c1}\x0d\u{c1}\x0e\u{c1}\u{1075}\x03\u{c2}\
	\x03\u{c2}\x03\u{c2}\x05\u{c2}\u{107b}\x0a\u{c2}\x03\u{c3}\x03\u{c3}\x03\
	\u{c3}\x03\u{c3}\x03\u{c3}\x03\u{c4}\x05\u{c4}\u{1083}\x0a\u{c4}\x03\u{c4}\
	\x03\u{c4}\x03\u{c4}\x05\u{c4}\u{1088}\x0a\u{c4}\x03\u{c5}\x03\u{c5}\x03\
	\u{c6}\x03\u{c6}\x03\u{c7}\x03\u{c7}\x03\u{c7}\x05\u{c7}\u{1091}\x0a\u{c7}\
	\x03\u{c8}\x03\u{c8}\x03\u{c8}\x03\u{c8}\x03\u{c9}\x03\u{c9}\x03\u{c9}\x03\
	\u{ca}\x03\u{ca}\x05\u{ca}\u{109c}\x0a\u{ca}\x03\u{ca}\x03\u{ca}\x03\u{ca}\
	\x03\u{ca}\x03\u{ca}\x05\u{ca}\u{10a3}\x0a\u{ca}\x03\u{ca}\x03\u{ca}\x03\
	\u{ca}\x03\u{ca}\x03\u{ca}\x05\u{ca}\u{10aa}\x0a\u{ca}\x03\u{ca}\x03\u{ca}\
	\x03\u{ca}\x03\u{ca}\x03\u{ca}\x05\u{ca}\u{10b1}\x0a\u{ca}\x03\u{ca}\x03\
	\u{ca}\x05\u{ca}\u{10b5}\x0a\u{ca}\x03\u{ca}\x03\u{ca}\x03\u{ca}\x03\u{ca}\
	\x05\u{ca}\u{10bb}\x0a\u{ca}\x03\u{ca}\x03\u{ca}\x03\u{ca}\x05\u{ca}\u{10c0}\
	\x0a\u{ca}\x05\u{ca}\u{10c2}\x0a\u{ca}\x03\u{ca}\x03\u{ca}\x03\u{ca}\x03\
	\u{ca}\x05\u{ca}\u{10c8}\x0a\u{ca}\x03\u{ca}\x03\u{ca}\x03\u{ca}\x03\u{ca}\
	\x03\u{ca}\x05\u{ca}\u{10cf}\x0a\u{ca}\x03\u{ca}\x03\u{ca}\x03\u{ca}\x05\
	\u{ca}\u{10d4}\x0a\u{ca}\x03\u{ca}\x03\u{ca}\x03\u{ca}\x03\u{ca}\x05\u{ca}\
	\u{10da}\x0a\u{ca}\x03\u{ca}\x03\u{ca}\x03\u{ca}\x03\u{ca}\x03\u{ca}\x05\
	\u{ca}\u{10e1}\x0a\u{ca}\x03\u{ca}\x05\u{ca}\u{10e4}\x0a\u{ca}\x03\u{cb}\
	\x03\u{cb}\x03\u{cc}\x03\u{cc}\x03\u{cc}\x03\u{cc}\x03\u{cc}\x03\u{cc}\x03\
	\u{cc}\x07\u{cc}\u{10ef}\x0a\u{cc}\x0c\u{cc}\x0e\u{cc}\u{10f2}\x0b\u{cc}\
	\x03\u{cc}\x03\u{cc}\x05\u{cc}\u{10f6}\x0a\u{cc}\x05\u{cc}\u{10f8}\x0a\u{cc}\
	\x03\u{cd}\x03\u{cd}\x03\u{cd}\x03\u{cd}\x03\u{cd}\x05\u{cd}\u{10ff}\x0a\
	\u{cd}\x03\u{cd}\x03\u{cd}\x03\u{cd}\x03\u{cd}\x03\u{cd}\x03\u{cd}\x03\u{cd}\
	\x05\u{cd}\u{1108}\x0a\u{cd}\x03\u{cd}\x03\u{cd}\x03\u{cd}\x05\u{cd}\u{110d}\
	\x0a\u{cd}\x03\u{cd}\x03\u{cd}\x05\u{cd}\u{1111}\x0a\u{cd}\x03\u{cd}\x05\
	\u{cd}\u{1114}\x0a\u{cd}\x03\u{ce}\x03\u{ce}\x03\u{ce}\x07\u{ce}\u{1119}\
	\x0a\u{ce}\x0c\u{ce}\x0e\u{ce}\u{111c}\x0b\u{ce}\x03\u{cf}\x03\u{cf}\x03\
	\u{cf}\x07\u{cf}\u{1121}\x0a\u{cf}\x0c\u{cf}\x0e\u{cf}\u{1124}\x0b\u{cf}\
	\x03\u{d0}\x03\u{d0}\x03\u{d0}\x03\u{d0}\x03\u{d0}\x03\u{d0}\x05\u{d0}\u{112c}\
	\x0a\u{d0}\x03\u{d1}\x03\u{d1}\x03\u{d1}\x03\u{d2}\x03\u{d2}\x03\u{d2}\x03\
	\u{d3}\x03\u{d3}\x03\u{d3}\x07\u{d3}\u{1137}\x0a\u{d3}\x0c\u{d3}\x0e\u{d3}\
	\u{113a}\x0b\u{d3}\x03\u{d4}\x03\u{d4}\x03\u{d4}\x03\u{d4}\x03\u{d4}\x05\
	\u{d4}\u{1141}\x0a\u{d4}\x03\u{d4}\x05\u{d4}\u{1144}\x0a\u{d4}\x03\u{d5}\
	\x03\u{d5}\x03\u{d5}\x07\u{d5}\u{1149}\x0a\u{d5}\x0c\u{d5}\x0e\u{d5}\u{114c}\
	\x0b\u{d5}\x03\u{d6}\x03\u{d6}\x05\u{d6}\u{1150}\x0a\u{d6}\x03\u{d7}\x03\
	\u{d7}\x03\u{d7}\x07\u{d7}\u{1155}\x0a\u{d7}\x0c\u{d7}\x0e\u{d7}\u{1158}\
	\x0b\u{d7}\x03\u{d8}\x03\u{d8}\x03\u{d8}\x07\u{d8}\u{115d}\x0a\u{d8}\x0c\
	\u{d8}\x0e\u{d8}\u{1160}\x0b\u{d8}\x03\u{d9}\x03\u{d9}\x03\u{d9}\x03\u{d9}\
	\x03\u{d9}\x03\u{d9}\x03\u{d9}\x05\u{d9}\u{1169}\x0a\u{d9}\x03\u{da}\x03\
	\u{da}\x03\u{da}\x03\u{da}\x03\u{da}\x03\u{da}\x03\u{da}\x03\u{da}\x03\u{da}\
	\x03\u{da}\x03\u{da}\x05\u{da}\u{1176}\x0a\u{da}\x03\u{da}\x03\u{da}\x03\
	\u{da}\x05\u{da}\u{117b}\x0a\u{da}\x05\u{da}\u{117d}\x0a\u{da}\x03\u{db}\
	\x03\u{db}\x07\u{db}\u{1181}\x0a\u{db}\x0c\u{db}\x0e\u{db}\u{1184}\x0b\u{db}\
	\x03\u{db}\x03\u{db}\x03\u{dc}\x03\u{dc}\x03\u{dc}\x03\u{dc}\x03\u{dc}\x03\
	\u{dc}\x05\u{dc}\u{118e}\x0a\u{dc}\x03\u{dd}\x05\u{dd}\u{1191}\x0a\u{dd}\
	\x03\u{dd}\x03\u{dd}\x05\u{dd}\u{1195}\x0a\u{dd}\x03\u{dd}\x05\u{dd}\u{1198}\
	\x0a\u{dd}\x03\u{de}\x03\u{de}\x03\u{de}\x07\u{de}\u{119d}\x0a\u{de}\x0c\
	\u{de}\x0e\u{de}\u{11a0}\x0b\u{de}\x03\u{df}\x03\u{df}\x05\u{df}\u{11a4}\
	\x0a\u{df}\x03\u{df}\x03\u{df}\x03\u{df}\x03\u{df}\x05\u{df}\u{11aa}\x0a\
	\u{df}\x03\u{df}\x05\u{df}\u{11ad}\x0a\u{df}\x03\u{e0}\x03\u{e0}\x06\u{e0}\
	\u{11b1}\x0a\u{e0}\x0d\u{e0}\x0e\u{e0}\u{11b2}\x03\u{e0}\x03\u{e0}\x03\u{e1}\
	\x03\u{e1}\x03\u{e1}\x03\u{e1}\x03\u{e1}\x03\u{e1}\x03\u{e1}\x07\u{e1}\u{11be}\
	\x0a\u{e1}\x0c\u{e1}\x0e\u{e1}\u{11c1}\x0b\u{e1}\x03\u{e2}\x03\u{e2}\x03\
	\u{e2}\x03\u{e3}\x03\u{e3}\x03\u{e3}\x03\u{e4}\x03\u{e4}\x03\u{e4}\x03\u{e4}\
	\x05\u{e4}\u{11cd}\x0a\u{e4}\x03\u{e5}\x03\u{e5}\x03\u{e5}\x03\u{e5}\x03\
	\u{e5}\x03\u{e5}\x03\u{e5}\x03\u{e5}\x03\u{e5}\x03\u{e5}\x05\u{e5}\u{11d9}\
	\x0a\u{e5}\x03\u{e6}\x03\u{e6}\x03\u{e6}\x03\u{e6}\x03\u{e6}\x03\u{e6}\x03\
	\u{e6}\x03\u{e6}\x03\u{e6}\x05\u{e6}\u{11e4}\x0a\u{e6}\x03\u{e7}\x03\u{e7}\
	\x03\u{e7}\x03\u{e7}\x03\u{e7}\x03\u{e7}\x05\u{e7}\u{11ec}\x0a\u{e7}\x03\
	\u{e8}\x03\u{e8}\x03\u{e8}\x03\u{e8}\x03\u{e8}\x03\u{e9}\x03\u{e9}\x03\u{e9}\
	\x03\u{e9}\x07\u{e9}\u{11f7}\x0a\u{e9}\x0c\u{e9}\x0e\u{e9}\u{11fa}\x0b\u{e9}\
	\x03\u{ea}\x03\u{ea}\x03\u{ea}\x03\u{ea}\x03\u{eb}\x03\u{eb}\x03\u{eb}\x03\
	\u{eb}\x03\u{eb}\x03\u{eb}\x03\u{eb}\x03\u{eb}\x03\u{eb}\x03\u{eb}\x03\u{eb}\
	\x07\u{eb}\u{120b}\x0a\u{eb}\x0c\u{eb}\x0e\u{eb}\u{120e}\x0b\u{eb}\x03\u{eb}\
	\x03\u{eb}\x03\u{eb}\x03\u{eb}\x03\u{eb}\x07\u{eb}\u{1215}\x0a\u{eb}\x0c\
	\u{eb}\x0e\u{eb}\u{1218}\x0b\u{eb}\x05\u{eb}\u{121a}\x0a\u{eb}\x03\u{eb}\
	\x03\u{eb}\x03\u{eb}\x03\u{eb}\x03\u{eb}\x07\u{eb}\u{1221}\x0a\u{eb}\x0c\
	\u{eb}\x0e\u{eb}\u{1224}\x0b\u{eb}\x05\u{eb}\u{1226}\x0a\u{eb}\x05\u{eb}\
	\u{1228}\x0a\u{eb}\x03\u{eb}\x05\u{eb}\u{122b}\x0a\u{eb}\x03\u{eb}\x05\u{eb}\
	\u{122e}\x0a\u{eb}\x03\u{ec}\x03\u{ec}\x03\u{ec}\x03\u{ec}\x03\u{ec}\x03\
	\u{ec}\x03\u{ec}\x03\u{ec}\x03\u{ec}\x03\u{ec}\x03\u{ec}\x03\u{ec}\x03\u{ec}\
	\x03\u{ec}\x03\u{ec}\x03\u{ec}\x05\u{ec}\u{1240}\x0a\u{ec}\x03\u{ed}\x03\
	\u{ed}\x03\u{ed}\x03\u{ed}\x03\u{ed}\x03\u{ed}\x03\u{ed}\x05\u{ed}\u{1249}\
	\x0a\u{ed}\x03\u{ee}\x03\u{ee}\x03\u{ee}\x07\u{ee}\u{124e}\x0a\u{ee}\x0c\
	\u{ee}\x0e\u{ee}\u{1251}\x0b\u{ee}\x03\u{ef}\x03\u{ef}\x03\u{ef}\x03\u{ef}\
	\x03\u{ef}\x03\u{ef}\x03\u{ef}\x03\u{ef}\x03\u{ef}\x03\u{ef}\x05\u{ef}\u{125d}\
	\x0a\u{ef}\x03\u{f0}\x03\u{f0}\x03\u{f0}\x07\u{f0}\u{1262}\x0a\u{f0}\x0c\
	\u{f0}\x0e\u{f0}\u{1265}\x0b\u{f0}\x03\u{f1}\x03\u{f1}\x03\u{f1}\x03\u{f2}\
	\x03\u{f2}\x06\u{f2}\u{126c}\x0a\u{f2}\x0d\u{f2}\x0e\u{f2}\u{126d}\x03\u{f2}\
	\x05\u{f2}\u{1271}\x0a\u{f2}\x03\u{f3}\x03\u{f3}\x03\u{f3}\x05\u{f3}\u{1276}\
	\x0a\u{f3}\x03\u{f4}\x03\u{f4}\x03\u{f4}\x05\u{f4}\u{127b}\x0a\u{f4}\x03\
	\u{f5}\x03\u{f5}\x03\u{f5}\x03\u{f5}\x03\u{f5}\x03\u{f5}\x03\u{f5}\x03\u{f5}\
	\x03\u{f5}\x03\u{f5}\x03\u{f5}\x03\u{f5}\x05\u{f5}\u{1289}\x0a\u{f5}\x03\
	\u{f6}\x03\u{f6}\x03\u{f6}\x03\u{f6}\x03\u{f6}\x03\u{f6}\x05\u{f6}\u{1291}\
	\x0a\u{f6}\x03\u{f7}\x03\u{f7}\x03\u{f7}\x05\u{f7}\u{1296}\x0a\u{f7}\x03\
	\u{f8}\x03\u{f8}\x03\u{f9}\x03\u{f9}\x05\u{f9}\u{129c}\x0a\u{f9}\x03\u{f9}\
	\x03\u{f9}\x03\u{f9}\x05\u{f9}\u{12a1}\x0a\u{f9}\x03\u{f9}\x03\u{f9}\x03\
	\u{f9}\x05\u{f9}\u{12a6}\x0a\u{f9}\x03\u{f9}\x03\u{f9}\x05\u{f9}\u{12aa}\
	\x0a\u{f9}\x03\u{f9}\x03\u{f9}\x05\u{f9}\u{12ae}\x0a\u{f9}\x03\u{f9}\x03\
	\u{f9}\x05\u{f9}\u{12b2}\x0a\u{f9}\x03\u{f9}\x03\u{f9}\x05\u{f9}\u{12b6}\
	\x0a\u{f9}\x03\u{f9}\x03\u{f9}\x05\u{f9}\u{12ba}\x0a\u{f9}\x03\u{f9}\x03\
	\u{f9}\x05\u{f9}\u{12be}\x0a\u{f9}\x03\u{f9}\x03\u{f9}\x05\u{f9}\u{12c2}\
	\x0a\u{f9}\x03\u{f9}\x05\u{f9}\u{12c5}\x0a\u{f9}\x03\u{fa}\x03\u{fa}\x05\
	\u{fa}\u{12c9}\x0a\u{fa}\x03\u{fb}\x03\u{fb}\x05\u{fb}\u{12cd}\x0a\u{fb}\
	\x03\u{fb}\x03\u{fb}\x07\u{fb}\u{12d1}\x0a\u{fb}\x0c\u{fb}\x0e\u{fb}\u{12d4}\
	\x0b\u{fb}\x03\u{fc}\x03\u{fc}\x03\u{fc}\x05\u{fc}\u{12d9}\x0a\u{fc}\x03\
	\u{fd}\x03\u{fd}\x05\u{fd}\u{12dd}\x0a\u{fd}\x03\u{fd}\x03\u{fd}\x07\u{fd}\
	\u{12e1}\x0a\u{fd}\x0c\u{fd}\x0e\u{fd}\u{12e4}\x0b\u{fd}\x03\u{fe}\x03\u{fe}\
	\x03\u{fe}\x05\u{fe}\u{12e9}\x0a\u{fe}\x03\u{ff}\x03\u{ff}\x03\u{ff}\x03\
	\u{ff}\x03\u{ff}\x03\u{100}\x03\u{100}\x03\u{100}\x05\u{100}\u{12f3}\x0a\
	\u{100}\x03\u{101}\x03\u{101}\x03\u{101}\x03\u{102}\x03\u{102}\x03\u{102}\
	\x05\u{102}\u{12fb}\x0a\u{102}\x03\u{103}\x03\u{103}\x03\u{103}\x03\u{103}\
	\x03\u{103}\x03\u{104}\x03\u{104}\x05\u{104}\u{1304}\x0a\u{104}\x03\u{105}\
	\x03\u{105}\x03\u{105}\x05\u{105}\u{1309}\x0a\u{105}\x03\u{106}\x03\u{106}\
	\x03\u{107}\x03\u{107}\x03\u{107}\x07\u{107}\u{1310}\x0a\u{107}\x0c\u{107}\
	\x0e\u{107}\u{1313}\x0b\u{107}\x03\u{108}\x03\u{108}\x05\u{108}\u{1317}\
	\x0a\u{108}\x03\u{109}\x03\u{109}\x03\u{109}\x03\u{109}\x03\u{109}\x03\u{109}\
	\x03\u{109}\x03\u{109}\x03\u{109}\x03\u{109}\x03\u{109}\x03\u{109}\x05\u{109}\
	\u{1325}\x0a\u{109}\x03\u{10a}\x03\u{10a}\x03\u{10a}\x05\u{10a}\u{132a}\
	\x0a\u{10a}\x03\u{10b}\x03\u{10b}\x05\u{10b}\u{132e}\x0a\u{10b}\x03\u{10c}\
	\x03\u{10c}\x03\u{10c}\x03\u{10c}\x05\u{10c}\u{1334}\x0a\u{10c}\x03\u{10d}\
	\x06\u{10d}\u{1337}\x0a\u{10d}\x0d\u{10d}\x0e\u{10d}\u{1338}\x03\u{10e}\
	\x03\u{10e}\x05\u{10e}\u{133d}\x0a\u{10e}\x03\u{10f}\x03\u{10f}\x05\u{10f}\
	\u{1341}\x0a\u{10f}\x03\u{110}\x03\u{110}\x05\u{110}\u{1345}\x0a\u{110}\
	\x03\u{110}\x05\u{110}\u{1348}\x0a\u{110}\x03\u{110}\x03\u{110}\x03\u{110}\
	\x03\u{110}\x03\u{110}\x03\u{110}\x03\u{110}\x03\u{110}\x03\u{110}\x03\u{110}\
	\x05\u{110}\u{1354}\x0a\u{110}\x03\u{110}\x03\u{110}\x05\u{110}\u{1358}\
	\x0a\u{110}\x03\u{110}\x03\u{110}\x05\u{110}\u{135c}\x0a\u{110}\x03\u{110}\
	\x03\u{110}\x03\u{110}\x03\u{110}\x05\u{110}\u{1362}\x0a\u{110}\x03\u{110}\
	\x03\u{110}\x03\u{110}\x03\u{110}\x05\u{110}\u{1368}\x0a\u{110}\x03\u{110}\
	\x05\u{110}\u{136b}\x0a\u{110}\x05\u{110}\u{136d}\x0a\u{110}\x03\u{111}\
	\x03\u{111}\x03\u{111}\x07\u{111}\u{1372}\x0a\u{111}\x0c\u{111}\x0e\u{111}\
	\u{1375}\x0b\u{111}\x03\u{111}\x03\u{111}\x03\u{111}\x03\u{111}\x03\u{111}\
	\x03\u{111}\x07\u{111}\u{137d}\x0a\u{111}\x0c\u{111}\x0e\u{111}\u{1380}\
	\x0b\u{111}\x03\u{111}\x03\u{111}\x03\u{111}\x07\u{111}\u{1385}\x0a\u{111}\
	\x0c\u{111}\x0e\u{111}\u{1388}\x0b\u{111}\x03\u{112}\x03\u{112}\x03\u{113}\
	\x03\u{113}\x03\u{114}\x03\u{114}\x03\u{114}\x0b\u{647}\u{68a}\u{6c6}\u{70f}\
	\u{720}\u{73c}\u{745}\u{74e}\u{757}\x06\u{aa}\u{156}\u{15c}\u{162}\u{115}\
	\x02\x04\x06\x08\x0a\x0c\x0e\x10\x12\x14\x16\x18\x1a\x1c\x1e\x20\x22\x24\
	\x26\x28\x2a\x2c\x2e\x30\x32\x34\x36\x38\x3a\x3c\x3e\x40\x42\x44\x46\x48\
	\x4a\x4c\x4e\x50\x52\x54\x56\x58\x5a\x5c\x5e\x60\x62\x64\x66\x68\x6a\x6c\
	\x6e\x70\x72\x74\x76\x78\x7a\x7c\x7e\u{80}\u{82}\u{84}\u{86}\u{88}\u{8a}\
	\u{8c}\u{8e}\u{90}\u{92}\u{94}\u{96}\u{98}\u{9a}\u{9c}\u{9e}\u{a0}\u{a2}\
	\u{a4}\u{a6}\u{a8}\u{aa}\u{ac}\u{ae}\u{b0}\u{b2}\u{b4}\u{b6}\u{b8}\u{ba}\
	\u{bc}\u{be}\u{c0}\u{c2}\u{c4}\u{c6}\u{c8}\u{ca}\u{cc}\u{ce}\u{d0}\u{d2}\
	\u{d4}\u{d6}\u{d8}\u{da}\u{dc}\u{de}\u{e0}\u{e2}\u{e4}\u{e6}\u{e8}\u{ea}\
	\u{ec}\u{ee}\u{f0}\u{f2}\u{f4}\u{f6}\u{f8}\u{fa}\u{fc}\u{fe}\u{100}\u{102}\
	\u{104}\u{106}\u{108}\u{10a}\u{10c}\u{10e}\u{110}\u{112}\u{114}\u{116}\u{118}\
	\u{11a}\u{11c}\u{11e}\u{120}\u{122}\u{124}\u{126}\u{128}\u{12a}\u{12c}\u{12e}\
	\u{130}\u{132}\u{134}\u{136}\u{138}\u{13a}\u{13c}\u{13e}\u{140}\u{142}\u{144}\
	\u{146}\u{148}\u{14a}\u{14c}\u{14e}\u{150}\u{152}\u{154}\u{156}\u{158}\u{15a}\
	\u{15c}\u{15e}\u{160}\u{162}\u{164}\u{166}\u{168}\u{16a}\u{16c}\u{16e}\u{170}\
	\u{172}\u{174}\u{176}\u{178}\u{17a}\u{17c}\u{17e}\u{180}\u{182}\u{184}\u{186}\
	\u{188}\u{18a}\u{18c}\u{18e}\u{190}\u{192}\u{194}\u{196}\u{198}\u{19a}\u{19c}\
	\u{19e}\u{1a0}\u{1a2}\u{1a4}\u{1a6}\u{1a8}\u{1aa}\u{1ac}\u{1ae}\u{1b0}\u{1b2}\
	\u{1b4}\u{1b6}\u{1b8}\u{1ba}\u{1bc}\u{1be}\u{1c0}\u{1c2}\u{1c4}\u{1c6}\u{1c8}\
	\u{1ca}\u{1cc}\u{1ce}\u{1d0}\u{1d2}\u{1d4}\u{1d6}\u{1d8}\u{1da}\u{1dc}\u{1de}\
	\u{1e0}\u{1e2}\u{1e4}\u{1e6}\u{1e8}\u{1ea}\u{1ec}\u{1ee}\u{1f0}\u{1f2}\u{1f4}\
	\u{1f6}\u{1f8}\u{1fa}\u{1fc}\u{1fe}\u{200}\u{202}\u{204}\u{206}\u{208}\u{20a}\
	\u{20c}\u{20e}\u{210}\u{212}\u{214}\u{216}\u{218}\u{21a}\u{21c}\u{21e}\u{220}\
	\u{222}\u{224}\u{226}\x02\x44\x04\x02\x47\x47\x7d\x7d\x04\x02\x5c\x5c\u{10e}\
	\u{10e}\x04\x02\x2b\x2b\u{125}\u{125}\x04\x02\u{92}\u{92}\u{a8}\u{a8}\x03\
	\x02\x3b\x3c\x04\x02\u{159}\u{159}\u{18a}\u{18a}\x04\x02\x0f\x0f\x30\x30\
	\x07\x02\x37\x37\x48\x48\u{81}\u{81}\u{90}\u{90}\u{d1}\u{d1}\x03\x02\x66\
	\x67\x04\x02\u{81}\u{81}\u{90}\u{90}\x05\x02\x0b\x0b\x71\x71\u{156}\u{156}\
	\x04\x02\x0b\x0b\u{cb}\u{cb}\x05\x02\x56\x56\u{e7}\u{e7}\u{133}\u{133}\x05\
	\x02\x57\x57\u{e8}\u{e8}\u{134}\u{134}\x03\x02\u{186}\u{187}\x06\x02\x79\
	\x79\u{b2}\u{b2}\u{13d}\u{13d}\u{178}\u{178}\x05\x02\x79\x79\u{13d}\u{13d}\
	\u{178}\u{178}\x04\x02\x19\x19\x66\x66\x04\x02\u{89}\u{89}\u{c0}\u{c0}\x04\
	\x02\u{158}\u{158}\u{189}\u{189}\x04\x02\u{157}\u{157}\u{163}\u{163}\x04\
	\x02\x4b\x4b\u{12e}\u{12e}\x04\x02\x7b\x7b\u{a9}\u{a9}\x04\x02\x0e\x0e\x6c\
	\x6c\x04\x02\x6d\x6d\u{102}\u{102}\x04\x02\u{fa}\u{fa}\u{145}\u{145}\x04\
	\x02\x0a\x0a\u{ee}\u{ee}\x03\x02\u{c7}\u{c8}\x05\x02\x0e\x0e\x14\x14\u{144}\
	\u{144}\x05\x02\u{84}\u{84}\u{171}\u{171}\u{17a}\u{17a}\x04\x02\u{1a5}\u{1a6}\
	\u{1aa}\u{1aa}\x04\x02\x6e\x6e\u{1a7}\u{1a9}\x04\x02\u{1a5}\u{1a6}\u{1ad}\
	\u{1ad}\x03\x02\u{1a2}\u{1a4}\x0d\x02\x51\x51\x53\x53\u{a0}\u{a0}\u{dc}\
	\u{dc}\u{de}\u{de}\u{e0}\u{e0}\u{e3}\u{e3}\u{110}\u{110}\u{131}\u{131}\u{18e}\
	\u{18e}\u{197}\u{197}\x05\x02\x4d\x50\u{13b}\u{13b}\u{181}\u{181}\x04\x02\
	\x58\x59\u{166}\u{166}\x05\x02\x5a\x5b\u{162}\u{162}\u{167}\u{167}\x04\x02\
	\x2d\x2d\u{173}\u{173}\x04\x02\u{a5}\u{a5}\u{124}\u{124}\x03\x02\u{154}\
	\u{155}\x04\x02\x06\x06\u{92}\u{92}\x04\x02\x06\x06\u{8d}\u{8d}\x05\x02\
	\x23\x23\u{c3}\u{c3}\u{16c}\u{16c}\x03\x02\u{19a}\u{1a1}\x05\x02\x6e\x6e\
	\u{1a5}\u{1ad}\u{1af}\u{1af}\x06\x02\x12\x12\u{a8}\u{a8}\u{ee}\u{ee}\u{f9}\
	\u{f9}\x04\x02\u{84}\u{84}\u{171}\u{171}\x03\x02\u{1a5}\u{1a6}\x0a\x02\x51\
	\x52\u{a0}\u{a1}\u{dc}\u{e1}\u{e3}\u{e4}\u{e9}\u{ea}\u{131}\u{132}\u{18e}\
	\u{18f}\u{197}\u{198}\x08\x02\x51\x51\u{a0}\u{a0}\u{e0}\u{e0}\u{e3}\u{e3}\
	\u{131}\u{131}\u{197}\u{197}\x03\x02\x31\x32\x04\x02\x5d\x5e\u{f1}\u{f1}\
	\x04\x02\u{e3}\u{e3}\u{197}\u{197}\x06\x02\x51\x51\u{a0}\u{a0}\u{e0}\u{e0}\
	\u{131}\u{131}\x05\x02\u{a0}\u{a0}\u{e0}\u{e0}\u{131}\u{131}\x11\x02\x1f\
	\x20\x22\x22\x27\x27\x55\x55\x70\x70\u{8a}\u{8a}\u{b4}\u{b5}\u{d2}\u{d2}\
	\u{114}\u{114}\u{13f}\u{13f}\u{143}\u{143}\u{164}\u{165}\u{168}\u{168}\u{188}\
	\u{188}\u{18c}\u{18c}\x04\x02\x60\x60\u{19a}\u{19a}\x04\x02\u{149}\u{149}\
	\u{1c3}\u{1c3}\x04\x02\u{8c}\u{8c}\u{109}\u{109}\x03\x02\u{1be}\u{1bf}\x04\
	\x02\u{f2}\u{f2}\u{11d}\u{11d}\x04\x02\x71\x71\u{13c}\u{13c}\x3b\x02\x0b\
	\x0d\x0f\x11\x13\x13\x15\x17\x19\x1b\x1d\x22\x24\x28\x2a\x2b\x2e\x32\x34\
	\x37\x3a\x3a\x3c\x44\x46\x48\x4b\x4c\x51\x6b\x6d\x71\x73\x73\x75\x75\x77\
	\x78\x7a\u{83}\u{86}\u{86}\u{88}\u{8c}\u{8f}\u{91}\u{94}\u{99}\u{9c}\u{9d}\
	\u{9f}\u{a7}\u{a9}\u{ac}\u{ae}\u{b1}\u{b3}\u{b5}\u{b7}\u{b7}\u{b9}\u{ba}\
	\u{bc}\u{c0}\u{c2}\u{c2}\u{c4}\u{c4}\u{c6}\u{ea}\u{ec}\u{ed}\u{f0}\u{f3}\
	\u{f7}\u{f8}\u{fb}\u{fb}\u{fd}\u{fe}\u{100}\u{109}\u{10b}\u{118}\u{11a}\
	\u{11a}\u{11c}\u{128}\u{12a}\u{135}\u{137}\u{13a}\u{13c}\u{143}\u{145}\u{148}\
	\u{14a}\u{158}\u{15a}\u{15f}\u{162}\u{168}\u{16b}\u{16b}\u{16d}\u{177}\u{17b}\
	\u{180}\u{183}\u{18f}\u{192}\u{193}\u{196}\u{199}\x12\x02\x13\x13\x4a\x4a\
	\x79\x79\u{93}\u{93}\u{ad}\u{ad}\u{b2}\u{b2}\u{bb}\u{bb}\u{c1}\u{c1}\u{c5}\
	\u{c5}\u{eb}\u{eb}\u{f5}\u{f5}\u{129}\u{129}\u{137}\u{137}\u{13d}\u{13d}\
	\u{178}\u{178}\u{182}\u{182}\x13\x02\x0b\x12\x14\x49\x4b\x78\x7a\u{92}\u{94}\
	\u{ac}\u{ae}\u{b1}\u{b3}\u{ba}\u{bc}\u{c0}\u{c2}\u{c4}\u{c6}\u{ea}\u{ec}\
	\u{f4}\u{f6}\u{128}\u{12a}\u{136}\u{138}\u{13c}\u{13e}\u{177}\u{179}\u{181}\
	\u{183}\u{199}\x02\u{164d}\x02\u{22a}\x03\x02\x02\x02\x04\u{22c}\x03\x02\
	\x02\x02\x06\u{23b}\x03\x02\x02\x02\x08\u{24c}\x03\x02\x02\x02\x0a\u{25d}\
	\x03\x02\x02\x02\x0c\u{26a}\x03\x02\x02\x02\x0e\u{26c}\x03\x02\x02\x02\x10\
	\u{26e}\x03\x02\x02\x02\x12\u{282}\x03\x02\x02\x02\x14\u{284}\x03\x02\x02\
	\x02\x16\u{28c}\x03\x02\x02\x02\x18\u{297}\x03\x02\x02\x02\x1a\u{2a2}\x03\
	\x02\x02\x02\x1c\u{2b8}\x03\x02\x02\x02\x1e\u{2c3}\x03\x02\x02\x02\x20\u{2c6}\
	\x03\x02\x02\x02\x22\u{2ec}\x03\x02\x02\x02\x24\u{2ef}\x03\x02\x02\x02\x26\
	\u{2f9}\x03\x02\x02\x02\x28\u{30b}\x03\x02\x02\x02\x2a\u{315}\x03\x02\x02\
	\x02\x2c\u{318}\x03\x02\x02\x02\x2e\u{31a}\x03\x02\x02\x02\x30\u{31d}\x03\
	\x02\x02\x02\x32\u{320}\x03\x02\x02\x02\x34\u{323}\x03\x02\x02\x02\x36\u{326}\
	\x03\x02\x02\x02\x38\u{329}\x03\x02\x02\x02\x3a\u{32c}\x03\x02\x02\x02\x3c\
	\u{6dd}\x03\x02\x02\x02\x3e\u{6df}\x03\x02\x02\x02\x40\u{6e2}\x03\x02\x02\
	\x02\x42\u{6e5}\x03\x02\x02\x02\x44\u{708}\x03\x02\x02\x02\x46\u{75a}\x03\
	\x02\x02\x02\x48\u{75c}\x03\x02\x02\x02\x4a\u{76d}\x03\x02\x02\x02\x4c\u{771}\
	\x03\x02\x02\x02\x4e\u{773}\x03\x02\x02\x02\x50\u{775}\x03\x02\x02\x02\x52\
	\u{81f}\x03\x02\x02\x02\x54\u{821}\x03\x02\x02\x02\x56\u{833}\x03\x02\x02\
	\x02\x58\u{839}\x03\x02\x02\x02\x5a\u{83f}\x03\x02\x02\x02\x5c\u{84b}\x03\
	\x02\x02\x02\x5e\u{858}\x03\x02\x02\x02\x60\u{85b}\x03\x02\x02\x02\x62\u{864}\
	\x03\x02\x02\x02\x64\u{867}\x03\x02\x02\x02\x66\u{86b}\x03\x02\x02\x02\x68\
	\u{8c5}\x03\x02\x02\x02\x6a\u{8c7}\x03\x02\x02\x02\x6c\u{8cb}\x03\x02\x02\
	\x02\x6e\u{8e0}\x03\x02\x02\x02\x70\u{8e2}\x03\x02\x02\x02\x72\u{8ea}\x03\
	\x02\x02\x02\x74\u{8ec}\x03\x02\x02\x02\x76\u{8ee}\x03\x02\x02\x02\x78\u{8f7}\
	\x03\x02\x02\x02\x7a\u{8f9}\x03\x02\x02\x02\x7c\u{901}\x03\x02\x02\x02\x7e\
	\u{90d}\x03\x02\x02\x02\u{80}\u{91e}\x03\x02\x02\x02\u{82}\u{932}\x03\x02\
	\x02\x02\u{84}\u{935}\x03\x02\x02\x02\u{86}\u{948}\x03\x02\x02\x02\u{88}\
	\u{94a}\x03\x02\x02\x02\u{8a}\u{954}\x03\x02\x02\x02\u{8c}\u{958}\x03\x02\
	\x02\x02\u{8e}\u{95e}\x03\x02\x02\x02\u{90}\u{960}\x03\x02\x02\x02\u{92}\
	\u{973}\x03\x02\x02\x02\u{94}\u{975}\x03\x02\x02\x02\u{96}\u{980}\x03\x02\
	\x02\x02\u{98}\u{991}\x03\x02\x02\x02\u{9a}\u{999}\x03\x02\x02\x02\u{9c}\
	\u{99b}\x03\x02\x02\x02\u{9e}\u{9a1}\x03\x02\x02\x02\u{a0}\u{9e1}\x03\x02\
	\x02\x02\u{a2}\u{9e9}\x03\x02\x02\x02\u{a4}\u{9f2}\x03\x02\x02\x02\u{a6}\
	\u{9fe}\x03\x02\x02\x02\u{a8}\u{a32}\x03\x02\x02\x02\u{aa}\u{a35}\x03\x02\
	\x02\x02\u{ac}\u{a62}\x03\x02\x02\x02\u{ae}\u{a64}\x03\x02\x02\x02\u{b0}\
	\u{a6c}\x03\x02\x02\x02\u{b2}\u{a8e}\x03\x02\x02\x02\u{b4}\u{abc}\x03\x02\
	\x02\x02\u{b6}\u{ad1}\x03\x02\x02\x02\u{b8}\u{af1}\x03\x02\x02\x02\u{ba}\
	\u{afd}\x03\x02\x02\x02\u{bc}\u{b00}\x03\x02\x02\x02\u{be}\u{b09}\x03\x02\
	\x02\x02\u{c0}\u{b17}\x03\x02\x02\x02\u{c2}\u{b2a}\x03\x02\x02\x02\u{c4}\
	\u{b3e}\x03\x02\x02\x02\u{c6}\u{b44}\x03\x02\x02\x02\u{c8}\u{b46}\x03\x02\
	\x02\x02\u{ca}\u{b4b}\x03\x02\x02\x02\u{cc}\u{b53}\x03\x02\x02\x02\u{ce}\
	\u{b57}\x03\x02\x02\x02\u{d0}\u{b5a}\x03\x02\x02\x02\u{d2}\u{b5d}\x03\x02\
	\x02\x02\u{d4}\u{b77}\x03\x02\x02\x02\u{d6}\u{b79}\x03\x02\x02\x02\u{d8}\
	\u{b9c}\x03\x02\x02\x02\u{da}\u{bc5}\x03\x02\x02\x02\u{dc}\u{bc9}\x03\x02\
	\x02\x02\u{de}\u{be4}\x03\x02\x02\x02\u{e0}\u{be8}\x03\x02\x02\x02\u{e2}\
	\u{bf7}\x03\x02\x02\x02\u{e4}\u{bf9}\x03\x02\x02\x02\u{e6}\u{c17}\x03\x02\
	\x02\x02\u{e8}\u{c19}\x03\x02\x02\x02\u{ea}\u{c20}\x03\x02\x02\x02\u{ec}\
	\u{c2d}\x03\x02\x02\x02\u{ee}\u{c32}\x03\x02\x02\x02\u{f0}\u{c34}\x03\x02\
	\x02\x02\u{f2}\u{c43}\x03\x02\x02\x02\u{f4}\u{c5b}\x03\x02\x02\x02\u{f6}\
	\u{c68}\x03\x02\x02\x02\u{f8}\u{c6a}\x03\x02\x02\x02\u{fa}\u{c6c}\x03\x02\
	\x02\x02\u{fc}\u{c70}\x03\x02\x02\x02\u{fe}\u{c73}\x03\x02\x02\x02\u{100}\
	\u{c77}\x03\x02\x02\x02\u{102}\u{c97}\x03\x02\x02\x02\u{104}\u{c9d}\x03\
	\x02\x02\x02\u{106}\u{ca0}\x03\x02\x02\x02\u{108}\u{cac}\x03\x02\x02\x02\
	\u{10a}\u{cbf}\x03\x02\x02\x02\u{10c}\u{cd9}\x03\x02\x02\x02\u{10e}\u{cdf}\
	\x03\x02\x02\x02\u{110}\u{ce1}\x03\x02\x02\x02\u{112}\u{d09}\x03\x02\x02\
	\x02\u{114}\u{d0b}\x03\x02\x02\x02\u{116}\u{d0f}\x03\x02\x02\x02\u{118}\
	\u{d17}\x03\x02\x02\x02\u{11a}\u{d22}\x03\x02\x02\x02\u{11c}\u{d26}\x03\
	\x02\x02\x02\u{11e}\u{d31}\x03\x02\x02\x02\u{120}\u{d5d}\x03\x02\x02\x02\
	\u{122}\u{d5f}\x03\x02\x02\x02\u{124}\u{d62}\x03\x02\x02\x02\u{126}\u{d80}\
	\x03\x02\x02\x02\u{128}\u{d9c}\x03\x02\x02\x02\u{12a}\u{db7}\x03\x02\x02\
	\x02\u{12c}\u{dbd}\x03\x02\x02\x02\u{12e}\u{dc1}\x03\x02\x02\x02\u{130}\
	\u{dc3}\x03\x02\x02\x02\u{132}\u{ddc}\x03\x02\x02\x02\u{134}\u{e0f}\x03\
	\x02\x02\x02\u{136}\u{e11}\x03\x02\x02\x02\u{138}\u{e19}\x03\x02\x02\x02\
	\u{13a}\u{e21}\x03\x02\x02\x02\u{13c}\u{e29}\x03\x02\x02\x02\u{13e}\u{e31}\
	\x03\x02\x02\x02\u{140}\u{e38}\x03\x02\x02\x02\u{142}\u{e3c}\x03\x02\x02\
	\x02\u{144}\u{e46}\x03\x02\x02\x02\u{146}\u{e4e}\x03\x02\x02\x02\u{148}\
	\u{e5b}\x03\x02\x02\x02\u{14a}\u{e6a}\x03\x02\x02\x02\u{14c}\u{e6e}\x03\
	\x02\x02\x02\u{14e}\u{e70}\x03\x02\x02\x02\u{150}\u{e72}\x03\x02\x02\x02\
	\u{152}\u{e78}\x03\x02\x02\x02\u{154}\u{e7a}\x03\x02\x02\x02\u{156}\u{e8e}\
	\x03\x02\x02\x02\u{158}\u{eed}\x03\x02\x02\x02\u{15a}\u{eef}\x03\x02\x02\
	\x02\u{15c}\u{ef5}\x03\x02\x02\x02\u{15e}\u{f14}\x03\x02\x02\x02\u{160}\
	\u{f16}\x03\x02\x02\x02\u{162}\u{100b}\x03\x02\x02\x02\u{164}\u{1022}\x03\
	\x02\x02\x02\u{166}\u{102b}\x03\x02\x02\x02\u{168}\u{102d}\x03\x02\x02\x02\
	\u{16a}\u{1037}\x03\x02\x02\x02\u{16c}\u{1044}\x03\x02\x02\x02\u{16e}\u{104e}\
	\x03\x02\x02\x02\u{170}\u{105a}\x03\x02\x02\x02\u{172}\u{105c}\x03\x02\x02\
	\x02\u{174}\u{105f}\x03\x02\x02\x02\u{176}\u{1061}\x03\x02\x02\x02\u{178}\
	\u{1063}\x03\x02\x02\x02\u{17a}\u{1065}\x03\x02\x02\x02\u{17c}\u{1067}\x03\
	\x02\x02\x02\u{17e}\u{106c}\x03\x02\x02\x02\u{180}\u{1073}\x03\x02\x02\x02\
	\u{182}\u{1077}\x03\x02\x02\x02\u{184}\u{107c}\x03\x02\x02\x02\u{186}\u{1082}\
	\x03\x02\x02\x02\u{188}\u{1089}\x03\x02\x02\x02\u{18a}\u{108b}\x03\x02\x02\
	\x02\u{18c}\u{1090}\x03\x02\x02\x02\u{18e}\u{1092}\x03\x02\x02\x02\u{190}\
	\u{1096}\x03\x02\x02\x02\u{192}\u{10e3}\x03\x02\x02\x02\u{194}\u{10e5}\x03\
	\x02\x02\x02\u{196}\u{10f7}\x03\x02\x02\x02\u{198}\u{1113}\x03\x02\x02\x02\
	\u{19a}\u{1115}\x03\x02\x02\x02\u{19c}\u{111d}\x03\x02\x02\x02\u{19e}\u{112b}\
	\x03\x02\x02\x02\u{1a0}\u{112d}\x03\x02\x02\x02\u{1a2}\u{1130}\x03\x02\x02\
	\x02\u{1a4}\u{1133}\x03\x02\x02\x02\u{1a6}\u{113b}\x03\x02\x02\x02\u{1a8}\
	\u{1145}\x03\x02\x02\x02\u{1aa}\u{114f}\x03\x02\x02\x02\u{1ac}\u{1151}\x03\
	\x02\x02\x02\u{1ae}\u{1159}\x03\x02\x02\x02\u{1b0}\u{1168}\x03\x02\x02\x02\
	\u{1b2}\u{117c}\x03\x02\x02\x02\u{1b4}\u{117e}\x03\x02\x02\x02\u{1b6}\u{118d}\
	\x03\x02\x02\x02\u{1b8}\u{1197}\x03\x02\x02\x02\u{1ba}\u{1199}\x03\x02\x02\
	\x02\u{1bc}\u{11a1}\x03\x02\x02\x02\u{1be}\u{11ae}\x03\x02\x02\x02\u{1c0}\
	\u{11bf}\x03\x02\x02\x02\u{1c2}\u{11c2}\x03\x02\x02\x02\u{1c4}\u{11c5}\x03\
	\x02\x02\x02\u{1c6}\u{11cc}\x03\x02\x02\x02\u{1c8}\u{11d8}\x03\x02\x02\x02\
	\u{1ca}\u{11e3}\x03\x02\x02\x02\u{1cc}\u{11eb}\x03\x02\x02\x02\u{1ce}\u{11ed}\
	\x03\x02\x02\x02\u{1d0}\u{11f2}\x03\x02\x02\x02\u{1d2}\u{11fb}\x03\x02\x02\
	\x02\u{1d4}\u{122d}\x03\x02\x02\x02\u{1d6}\u{123f}\x03\x02\x02\x02\u{1d8}\
	\u{1248}\x03\x02\x02\x02\u{1da}\u{124a}\x03\x02\x02\x02\u{1dc}\u{125c}\x03\
	\x02\x02\x02\u{1de}\u{125e}\x03\x02\x02\x02\u{1e0}\u{1266}\x03\x02\x02\x02\
	\u{1e2}\u{1270}\x03\x02\x02\x02\u{1e4}\u{1275}\x03\x02\x02\x02\u{1e6}\u{127a}\
	\x03\x02\x02\x02\u{1e8}\u{1288}\x03\x02\x02\x02\u{1ea}\u{1290}\x03\x02\x02\
	\x02\u{1ec}\u{1295}\x03\x02\x02\x02\u{1ee}\u{1297}\x03\x02\x02\x02\u{1f0}\
	\u{12c4}\x03\x02\x02\x02\u{1f2}\u{12c8}\x03\x02\x02\x02\u{1f4}\u{12cc}\x03\
	\x02\x02\x02\u{1f6}\u{12d8}\x03\x02\x02\x02\u{1f8}\u{12dc}\x03\x02\x02\x02\
	\u{1fa}\u{12e8}\x03\x02\x02\x02\u{1fc}\u{12ea}\x03\x02\x02\x02\u{1fe}\u{12f2}\
	\x03\x02\x02\x02\u{200}\u{12f4}\x03\x02\x02\x02\u{202}\u{12f7}\x03\x02\x02\
	\x02\u{204}\u{12fc}\x03\x02\x02\x02\u{206}\u{1303}\x03\x02\x02\x02\u{208}\
	\u{1308}\x03\x02\x02\x02\u{20a}\u{130a}\x03\x02\x02\x02\u{20c}\u{130c}\x03\
	\x02\x02\x02\u{20e}\u{1314}\x03\x02\x02\x02\u{210}\u{1324}\x03\x02\x02\x02\
	\u{212}\u{1329}\x03\x02\x02\x02\u{214}\u{132d}\x03\x02\x02\x02\u{216}\u{1333}\
	\x03\x02\x02\x02\u{218}\u{1336}\x03\x02\x02\x02\u{21a}\u{133c}\x03\x02\x02\
	\x02\u{21c}\u{1340}\x03\x02\x02\x02\u{21e}\u{136c}\x03\x02\x02\x02\u{220}\
	\u{136e}\x03\x02\x02\x02\u{222}\u{1389}\x03\x02\x02\x02\u{224}\u{138b}\x03\
	\x02\x02\x02\u{226}\u{138d}\x03\x02\x02\x02\u{228}\u{22b}\x05\x28\x15\x02\
	\u{229}\u{22b}\x05\x04\x03\x02\u{22a}\u{228}\x03\x02\x02\x02\u{22a}\u{229}\
	\x03\x02\x02\x02\u{22b}\x03\x03\x02\x02\x02\u{22c}\u{22f}\x07\x1d\x02\x02\
	\u{22d}\u{22e}\x07\u{ee}\x02\x02\u{22e}\u{230}\x07\x1b\x02\x02\u{22f}\u{22d}\
	\x03\x02\x02\x02\u{22f}\u{230}\x03\x02\x02\x02\u{230}\u{232}\x03\x02\x02\
	\x02\u{231}\u{233}\x05\x08\x05\x02\u{232}\u{231}\x03\x02\x02\x02\u{232}\
	\u{233}\x03\x02\x02\x02\u{233}\u{234}\x03\x02\x02\x02\u{234}\u{236}\x07\
	\x74\x02\x02\u{235}\u{237}\x07\x03\x02\x02\u{236}\u{235}\x03\x02\x02\x02\
	\u{236}\u{237}\x03\x02\x02\x02\u{237}\u{238}\x03\x02\x02\x02\u{238}\u{239}\
	\x07\x02\x02\x03\u{239}\x05\x03\x02\x02\x02\u{23a}\u{23c}\x05\x2a\x16\x02\
	\u{23b}\u{23a}\x03\x02\x02\x02\u{23b}\u{23c}\x03\x02\x02\x02\u{23c}\u{23d}\
	\x03\x02\x02\x02\u{23d}\u{240}\x07\x1d\x02\x02\u{23e}\u{23f}\x07\u{ee}\x02\
	\x02\u{23f}\u{241}\x07\x1b\x02\x02\u{240}\u{23e}\x03\x02\x02\x02\u{240}\
	\u{241}\x03\x02\x02\x02\u{241}\u{243}\x03\x02\x02\x02\u{242}\u{244}\x05\
	\x08\x05\x02\u{243}\u{242}\x03\x02\x02\x02\u{243}\u{244}\x03\x02\x02\x02\
	\u{244}\u{245}\x03\x02\x02\x02\u{245}\u{247}\x07\x74\x02\x02\u{246}\u{248}\
	\x05\x2c\x17\x02\u{247}\u{246}\x03\x02\x02\x02\u{247}\u{248}\x03\x02\x02\
	\x02\u{248}\x07\x03\x02\x02\x02\u{249}\u{24a}\x05\x0a\x06\x02\u{24a}\u{24b}\
	\x07\x03\x02\x02\u{24b}\u{24d}\x03\x02\x02\x02\u{24c}\u{249}\x03\x02\x02\
	\x02\u{24d}\u{24e}\x03\x02\x02\x02\u{24e}\u{24c}\x03\x02\x02\x02\u{24e}\
	\u{24f}\x03\x02\x02\x02\u{24f}\x09\x03\x02\x02\x02\u{250}\u{25e}\x05\x10\
	\x09\x02\u{251}\u{25e}\x05\x3c\x1f\x02\u{252}\u{25e}\x05\x0c\x07\x02\u{253}\
	\u{25e}\x05\x06\x04\x02\u{254}\u{25e}\x05\x16\x0c\x02\u{255}\u{25e}\x05\
	\x1a\x0e\x02\u{256}\u{25e}\x05\x22\x12\x02\u{257}\u{25e}\x05\x18\x0d\x02\
	\u{258}\u{25e}\x05\x1c\x0f\x02\u{259}\u{25e}\x05\x1e\x10\x02\u{25a}\u{25e}\
	\x05\x20\x11\x02\u{25b}\u{25e}\x05\x24\x13\x02\u{25c}\u{25e}\x05\x26\x14\
	\x02\u{25d}\u{250}\x03\x02\x02\x02\u{25d}\u{251}\x03\x02\x02\x02\u{25d}\
	\u{252}\x03\x02\x02\x02\u{25d}\u{253}\x03\x02\x02\x02\u{25d}\u{254}\x03\
	\x02\x02\x02\u{25d}\u{255}\x03\x02\x02\x02\u{25d}\u{256}\x03\x02\x02\x02\
	\u{25d}\u{257}\x03\x02\x02\x02\u{25d}\u{258}\x03\x02\x02\x02\u{25d}\u{259}\
	\x03\x02\x02\x02\u{25d}\u{25a}\x03\x02\x02\x02\u{25d}\u{25b}\x03\x02\x02\
	\x02\u{25d}\u{25c}\x03\x02\x02\x02\u{25e}\x0b\x03\x02\x02\x02\u{25f}\u{260}\
	\x07\u{13c}\x02\x02\u{260}\u{26b}\x05\u{ca}\x66\x02\u{261}\u{262}\x07\u{13c}\
	\x02\x02\u{262}\u{263}\x07\x04\x02\x02\u{263}\u{264}\x05\u{136}\u{9c}\x02\
	\u{264}\u{265}\x07\x05\x02\x02\u{265}\u{266}\x07\u{19a}\x02\x02\u{266}\u{267}\
	\x07\x04\x02\x02\u{267}\u{268}\x05\x66\x34\x02\u{268}\u{269}\x07\x05\x02\
	\x02\u{269}\u{26b}\x03\x02\x02\x02\u{26a}\u{25f}\x03\x02\x02\x02\u{26a}\
	\u{261}\x03\x02\x02\x02\u{26b}\x0d\x03\x02\x02\x02\u{26c}\u{26d}\x05\u{218}\
	\u{10d}\x02\u{26d}\x0f\x03\x02\x02\x02\u{26e}\u{26f}\x07\x5f\x02\x02\u{26f}\
	\u{270}\x05\u{1e8}\u{f5}\x02\u{270}\u{277}\x07\x44\x02\x02\u{271}\u{272}\
	\x07\u{8d}\x02\x02\u{272}\u{274}\x07\u{14b}\x02\x02\u{273}\u{275}\x07\u{183}\
	\x02\x02\u{274}\u{273}\x03\x02\x02\x02\u{274}\u{275}\x03\x02\x02\x02\u{275}\
	\u{276}\x03\x02\x02\x02\u{276}\u{278}\x05\x0e\x08\x02\u{277}\u{271}\x03\
	\x02\x02\x02\u{277}\u{278}\x03\x02\x02\x02\u{278}\x11\x03\x02\x02\x02\u{279}\
	\u{27b}\x07\u{14b}\x02\x02\u{27a}\u{27c}\x07\u{183}\x02\x02\u{27b}\u{27a}\
	\x03\x02\x02\x02\u{27b}\u{27c}\x03\x02\x02\x02\u{27c}\u{27d}\x03\x02\x02\
	\x02\u{27d}\u{283}\x05\x0e\x08\x02\u{27e}\u{283}\x07\u{14a}\x02\x02\u{27f}\
	\u{280}\x07\u{ee}\x02\x02\u{280}\u{283}\x07\u{91}\x02\x02\u{281}\u{283}\
	\x05\u{138}\u{9d}\x02\u{282}\u{279}\x03\x02\x02\x02\u{282}\u{27e}\x03\x02\
	\x02\x02\u{282}\u{27f}\x03\x02\x02\x02\u{282}\u{281}\x03\x02\x02\x02\u{283}\
	\x13\x03\x02\x02\x02\u{284}\u{289}\x05\x12\x0a\x02\u{285}\u{286}\x07\x06\
	\x02\x02\u{286}\u{288}\x05\x12\x0a\x02\u{287}\u{285}\x03\x02\x02\x02\u{288}\
	\u{28b}\x03\x02\x02\x02\u{289}\u{287}\x03\x02\x02\x02\u{289}\u{28a}\x03\
	\x02\x02\x02\u{28a}\x15\x03\x02\x02\x02\u{28b}\u{289}\x03\x02\x02\x02\u{28c}\
	\u{28d}\x07\x5f\x02\x02\u{28d}\u{28e}\x09\x02\x02\x02\u{28e}\u{28f}\x07\
	\u{9d}\x02\x02\u{28f}\u{290}\x07\u{8d}\x02\x02\u{290}\u{294}\x05\x14\x0b\
	\x02\u{291}\u{295}\x05\x06\x04\x02\u{292}\u{295}\x05\x3c\x1f\x02\u{293}\
	\u{295}\x05\x0c\x07\x02\u{294}\u{291}\x03\x02\x02\x02\u{294}\u{292}\x03\
	\x02\x02\x02\u{294}\u{293}\x03\x02\x02\x02\u{295}\x17\x03\x02\x02\x02\u{296}\
	\u{298}\x05\x2a\x16\x02\u{297}\u{296}\x03\x02\x02\x02\u{297}\u{298}\x03\
	\x02\x02\x02\u{298}\u{299}\x03\x02\x02\x02\u{299}\u{29a}\x07\u{192}\x02\
	\x02\u{29a}\u{29b}\x05\u{156}\u{ac}\x02\u{29b}\u{29c}\x07\x6f\x02\x02\u{29c}\
	\u{29d}\x05\x08\x05\x02\u{29d}\u{29e}\x07\x74\x02\x02\u{29e}\u{2a0}\x07\
	\u{192}\x02\x02\u{29f}\u{2a1}\x05\x2c\x17\x02\u{2a0}\u{29f}\x03\x02\x02\
	\x02\u{2a0}\u{2a1}\x03\x02\x02\x02\u{2a1}\x19\x03\x02\x02\x02\u{2a2}\u{2a3}\
	\x07\u{a4}\x02\x02\u{2a3}\u{2a4}\x05\u{156}\u{ac}\x02\u{2a4}\u{2a5}\x07\
	\u{160}\x02\x02\u{2a5}\u{2ad}\x05\x08\x05\x02\u{2a6}\u{2a7}\x07\x73\x02\
	\x02\u{2a7}\u{2a8}\x05\u{156}\u{ac}\x02\u{2a8}\u{2a9}\x07\u{160}\x02\x02\
	\u{2a9}\u{2aa}\x05\x08\x05\x02\u{2aa}\u{2ac}\x03\x02\x02\x02\u{2ab}\u{2a6}\
	\x03\x02\x02\x02\u{2ac}\u{2af}\x03\x02\x02\x02\u{2ad}\u{2ab}\x03\x02\x02\
	\x02\u{2ad}\u{2ae}\x03\x02\x02\x02\u{2ae}\u{2b2}\x03\x02\x02\x02\u{2af}\
	\u{2ad}\x03\x02\x02\x02\u{2b0}\u{2b1}\x07\x72\x02\x02\u{2b1}\u{2b3}\x05\
	\x08\x05\x02\u{2b2}\u{2b0}\x03\x02\x02\x02\u{2b2}\u{2b3}\x03\x02\x02\x02\
	\u{2b3}\u{2b4}\x03\x02\x02\x02\u{2b4}\u{2b5}\x07\x74\x02\x02\u{2b5}\u{2b6}\
	\x07\u{a4}\x02\x02\u{2b6}\x1b\x03\x02\x02\x02\u{2b7}\u{2b9}\x05\x2a\x16\
	\x02\u{2b8}\u{2b7}\x03\x02\x02\x02\u{2b8}\u{2b9}\x03\x02\x02\x02\u{2b9}\
	\u{2ba}\x03\x02\x02\x02\u{2ba}\u{2bb}\x07\u{120}\x02\x02\u{2bb}\u{2bc}\x05\
	\x08\x05\x02\u{2bc}\u{2bd}\x07\u{17e}\x02\x02\u{2bd}\u{2be}\x05\u{156}\u{ac}\
	\x02\u{2be}\u{2bf}\x07\x74\x02\x02\u{2bf}\u{2c1}\x07\u{120}\x02\x02\u{2c0}\
	\u{2c2}\x05\x2c\x17\x02\u{2c1}\u{2c0}\x03\x02\x02\x02\u{2c1}\u{2c2}\x03\
	\x02\x02\x02\u{2c2}\x1d\x03\x02\x02\x02\u{2c3}\u{2c4}\x07\u{c4}\x02\x02\
	\u{2c4}\u{2c5}\x05\u{1e8}\u{f5}\x02\u{2c5}\x1f\x03\x02\x02\x02\u{2c6}\u{2c7}\
	\x07\u{ba}\x02\x02\u{2c7}\u{2c8}\x05\u{1e8}\u{f5}\x02\u{2c8}\x21\x03\x02\
	\x02\x02\u{2c9}\u{2cf}\x07\x2c\x02\x02\u{2ca}\u{2cb}\x07\u{190}\x02\x02\
	\u{2cb}\u{2cc}\x05\u{156}\u{ac}\x02\u{2cc}\u{2cd}\x07\u{160}\x02\x02\u{2cd}\
	\u{2ce}\x05\x08\x05\x02\u{2ce}\u{2d0}\x03\x02\x02\x02\u{2cf}\u{2ca}\x03\
	\x02\x02\x02\u{2d0}\u{2d1}\x03\x02\x02\x02\u{2d1}\u{2cf}\x03\x02\x02\x02\
	\u{2d1}\u{2d2}\x03\x02\x02\x02\u{2d2}\u{2d5}\x03\x02\x02\x02\u{2d3}\u{2d4}\
	\x07\x72\x02\x02\u{2d4}\u{2d6}\x05\x08\x05\x02\u{2d5}\u{2d3}\x03\x02\x02\
	\x02\u{2d5}\u{2d6}\x03\x02\x02\x02\u{2d6}\u{2d7}\x03\x02\x02\x02\u{2d7}\
	\u{2d8}\x07\x74\x02\x02\u{2d8}\u{2d9}\x07\x2c\x02\x02\u{2d9}\u{2ed}\x03\
	\x02\x02\x02\u{2da}\u{2db}\x07\x2c\x02\x02\u{2db}\u{2e1}\x05\u{14e}\u{a8}\
	\x02\u{2dc}\u{2dd}\x07\u{190}\x02\x02\u{2dd}\u{2de}\x05\u{14e}\u{a8}\x02\
	\u{2de}\u{2df}\x07\u{160}\x02\x02\u{2df}\u{2e0}\x05\x08\x05\x02\u{2e0}\u{2e2}\
	\x03\x02\x02\x02\u{2e1}\u{2dc}\x03\x02\x02\x02\u{2e2}\u{2e3}\x03\x02\x02\
	\x02\u{2e3}\u{2e1}\x03\x02\x02\x02\u{2e3}\u{2e4}\x03\x02\x02\x02\u{2e4}\
	\u{2e7}\x03\x02\x02\x02\u{2e5}\u{2e6}\x07\x72\x02\x02\u{2e6}\u{2e8}\x05\
	\x08\x05\x02\u{2e7}\u{2e5}\x03\x02\x02\x02\u{2e7}\u{2e8}\x03\x02\x02\x02\
	\u{2e8}\u{2e9}\x03\x02\x02\x02\u{2e9}\u{2ea}\x07\x74\x02\x02\u{2ea}\u{2eb}\
	\x07\x2c\x02\x02\u{2eb}\u{2ed}\x03\x02\x02\x02\u{2ec}\u{2c9}\x03\x02\x02\
	\x02\u{2ec}\u{2da}\x03\x02\x02\x02\u{2ed}\x23\x03\x02\x02\x02\u{2ee}\u{2f0}\
	\x05\x2a\x16\x02\u{2ef}\u{2ee}\x03\x02\x02\x02\u{2ef}\u{2f0}\x03\x02\x02\
	\x02\u{2f0}\u{2f1}\x03\x02\x02\x02\u{2f1}\u{2f2}\x07\u{d3}\x02\x02\u{2f2}\
	\u{2f3}\x05\x08\x05\x02\u{2f3}\u{2f4}\x07\x74\x02\x02\u{2f4}\u{2f6}\x07\
	\u{d3}\x02\x02\u{2f5}\u{2f7}\x05\x2c\x17\x02\u{2f6}\u{2f5}\x03\x02\x02\x02\
	\u{2f6}\u{2f7}\x03\x02\x02\x02\u{2f7}\x25\x03\x02\x02\x02\u{2f8}\u{2fa}\
	\x05\x2a\x16\x02\u{2f9}\u{2f8}\x03\x02\x02\x02\u{2f9}\u{2fa}\x03\x02\x02\
	\x02\u{2fa}\u{2fb}\x03\x02\x02\x02\u{2fb}\u{2ff}\x07\u{8d}\x02\x02\u{2fc}\
	\u{2fd}\x05\u{1e8}\u{f5}\x02\u{2fd}\u{2fe}\x07\x18\x02\x02\u{2fe}\u{300}\
	\x03\x02\x02\x02\u{2ff}\u{2fc}\x03\x02\x02\x02\u{2ff}\u{300}\x03\x02\x02\
	\x02\u{300}\u{301}\x03\x02\x02\x02\u{301}\u{302}\x05\x66\x34\x02\u{302}\
	\u{303}\x07\x6f\x02\x02\u{303}\u{304}\x05\x08\x05\x02\u{304}\u{305}\x07\
	\x74\x02\x02\u{305}\u{307}\x07\u{8d}\x02\x02\u{306}\u{308}\x05\x2c\x17\x02\
	\u{307}\u{306}\x03\x02\x02\x02\u{307}\u{308}\x03\x02\x02\x02\u{308}\x27\
	\x03\x02\x02\x02\u{309}\u{30c}\x05\x3c\x1f\x02\u{30a}\u{30c}\x05\x46\x24\
	\x02\u{30b}\u{309}\x03\x02\x02\x02\u{30b}\u{30a}\x03\x02\x02\x02\u{30c}\
	\u{310}\x03\x02\x02\x02\u{30d}\u{30f}\x07\x03\x02\x02\u{30e}\u{30d}\x03\
	\x02\x02\x02\u{30f}\u{312}\x03\x02\x02\x02\u{310}\u{30e}\x03\x02\x02\x02\
	\u{310}\u{311}\x03\x02\x02\x02\u{311}\u{313}\x03\x02\x02\x02\u{312}\u{310}\
	\x03\x02\x02\x02\u{313}\u{314}\x07\x02\x02\x03\u{314}\x29\x03\x02\x02\x02\
	\u{315}\u{316}\x05\u{1e8}\u{f5}\x02\u{316}\u{317}\x07\u{1b0}\x02\x02\u{317}\
	\x2b\x03\x02\x02\x02\u{318}\u{319}\x05\u{1e8}\u{f5}\x02\u{319}\x2d\x03\x02\
	\x02\x02\u{31a}\u{31b}\x05\u{142}\u{a2}\x02\u{31b}\u{31c}\x07\x02\x02\x03\
	\u{31c}\x2f\x03\x02\x02\x02\u{31d}\u{31e}\x05\u{13e}\u{a0}\x02\u{31e}\u{31f}\
	\x07\x02\x02\x03\u{31f}\x31\x03\x02\x02\x02\u{320}\u{321}\x05\u{138}\u{9d}\
	\x02\u{321}\u{322}\x07\x02\x02\x03\u{322}\x33\x03\x02\x02\x02\u{323}\u{324}\
	\x05\u{140}\u{a1}\x02\u{324}\u{325}\x07\x02\x02\x03\u{325}\x35\x03\x02\x02\
	\x02\u{326}\u{327}\x05\u{198}\u{cd}\x02\u{327}\u{328}\x07\x02\x02\x03\u{328}\
	\x37\x03\x02\x02\x02\u{329}\u{32a}\x05\u{1a4}\u{d3}\x02\u{32a}\u{32b}\x07\
	\x02\x02\x03\u{32b}\x39\x03\x02\x02\x02\u{32c}\u{32d}\x05\u{1ac}\u{d7}\x02\
	\u{32d}\u{32e}\x07\x02\x02\x03\u{32e}\x3b\x03\x02\x02\x02\u{32f}\u{6de}\
	\x05\x66\x34\x02\u{330}\u{6de}\x05\x48\x25\x02\u{331}\u{333}\x05\x7c\x3f\
	\x02\u{332}\u{331}\x03\x02\x02\x02\u{332}\u{333}\x03\x02\x02\x02\u{333}\
	\u{334}\x03\x02\x02\x02\u{334}\u{6de}\x05\u{a0}\x51\x02\u{335}\u{336}\x07\
	\u{180}\x02\x02\u{336}\u{6de}\x05\u{a2}\x52\x02\u{337}\u{338}\x07\u{180}\
	\x02\x02\u{338}\u{339}\x05\x72\x3a\x02\u{339}\u{33a}\x05\u{a2}\x52\x02\u{33a}\
	\u{6de}\x03\x02\x02\x02\u{33b}\u{33c}\x07\u{13c}\x02\x02\u{33c}\u{33d}\x07\
	\x2e\x02\x02\u{33d}\u{6de}\x05\u{a4}\x53\x02\u{33e}\u{33f}\x07\x49\x02\x02\
	\u{33f}\u{344}\x05\x72\x3a\x02\u{340}\u{341}\x07\u{a4}\x02\x02\u{341}\u{342}\
	\x05\u{15a}\u{ae}\x02\u{342}\u{343}\x07\x7c\x02\x02\u{343}\u{345}\x03\x02\
	\x02\x02\u{344}\u{340}\x03\x02\x02\x02\u{344}\u{345}\x03\x02\x02\x02\u{345}\
	\u{346}\x03\x02\x02\x02\u{346}\u{34f}\x05\u{a2}\x52\x02\u{347}\u{34e}\x05\
	\x62\x32\x02\u{348}\u{34e}\x05\x5e\x30\x02\u{349}\u{34e}\x05\u{18e}\u{c8}\
	\x02\u{34a}\u{34b}\x07\u{194}\x02\x02\u{34b}\u{34c}\x09\x03\x02\x02\u{34c}\
	\u{34e}\x05\u{84}\x43\x02\u{34d}\u{347}\x03\x02\x02\x02\u{34d}\u{348}\x03\
	\x02\x02\x02\u{34d}\u{349}\x03\x02\x02\x02\u{34d}\u{34a}\x03\x02\x02\x02\
	\u{34e}\u{351}\x03\x02\x02\x02\u{34f}\u{34d}\x03\x02\x02\x02\u{34f}\u{350}\
	\x03\x02\x02\x02\u{350}\u{6de}\x03\x02\x02\x02\u{351}\u{34f}\x03\x02\x02\
	\x02\u{352}\u{353}\x07\x0f\x02\x02\u{353}\u{354}\x05\x72\x3a\x02\u{354}\
	\u{355}\x05\u{a2}\x52\x02\u{355}\u{356}\x07\u{13c}\x02\x02\u{356}\u{357}\
	\x09\x03\x02\x02\u{357}\u{358}\x05\u{84}\x43\x02\u{358}\u{6de}\x03\x02\x02\
	\x02\u{359}\u{35a}\x07\x0f\x02\x02\u{35a}\u{35b}\x05\x72\x3a\x02\u{35b}\
	\u{35c}\x05\u{a2}\x52\x02\u{35c}\u{35d}\x07\u{17d}\x02\x02\u{35d}\u{35e}\
	\x09\x03\x02\x02\u{35e}\u{35f}\x05\u{84}\x43\x02\u{35f}\u{6de}\x03\x02\x02\
	\x02\u{360}\u{361}\x07\x0f\x02\x02\u{361}\u{362}\x05\x72\x3a\x02\u{362}\
	\u{363}\x05\u{a2}\x52\x02\u{363}\u{364}\x05\u{18e}\u{c8}\x02\u{364}\u{6de}\
	\x03\x02\x02\x02\u{365}\u{366}\x07\x0f\x02\x02\u{366}\u{367}\x05\x72\x3a\
	\x02\u{367}\u{368}\x05\u{a2}\x52\x02\u{368}\u{369}\x07\u{13c}\x02\x02\u{369}\
	\u{36a}\x05\x5e\x30\x02\u{36a}\u{6de}\x03\x02\x02\x02\u{36b}\u{36c}\x07\
	\x71\x02\x02\u{36c}\u{36f}\x05\x72\x3a\x02\u{36d}\u{36e}\x07\u{a4}\x02\x02\
	\u{36e}\u{370}\x07\x7c\x02\x02\u{36f}\u{36d}\x03\x02\x02\x02\u{36f}\u{370}\
	\x03\x02\x02\x02\u{370}\u{371}\x03\x02\x02\x02\u{371}\u{373}\x05\u{a2}\x52\
	\x02\u{372}\u{374}\x09\x04\x02\x02\u{373}\u{372}\x03\x02\x02\x02\u{373}\
	\u{374}\x03\x02\x02\x02\u{374}\u{6de}\x03\x02\x02\x02\u{375}\u{376}\x07\
	\u{140}\x02\x02\u{376}\u{379}\x05\x74\x3b\x02\u{377}\u{378}\x09\x05\x02\
	\x02\u{378}\u{37a}\x05\u{138}\u{9d}\x02\u{379}\u{377}\x03\x02\x02\x02\u{379}\
	\u{37a}\x03\x02\x02\x02\u{37a}\u{37f}\x03\x02\x02\x02\u{37b}\u{37d}\x07\
	\u{c7}\x02\x02\u{37c}\u{37b}\x03\x02\x02\x02\u{37c}\u{37d}\x03\x02\x02\x02\
	\u{37d}\u{37e}\x03\x02\x02\x02\u{37e}\u{380}\x05\u{218}\u{10d}\x02\u{37f}\
	\u{37c}\x03\x02\x02\x02\u{37f}\u{380}\x03\x02\x02\x02\u{380}\u{6de}\x03\
	\x02\x02\x02\u{381}\u{386}\x05\x54\x2b\x02\u{382}\u{383}\x07\x04\x02\x02\
	\u{383}\u{384}\x05\u{1a8}\u{d5}\x02\u{384}\u{385}\x07\x05\x02\x02\u{385}\
	\u{387}\x03\x02\x02\x02\u{386}\u{382}\x03\x02\x02\x02\u{386}\u{387}\x03\
	\x02\x02\x02\u{387}\u{389}\x03\x02\x02\x02\u{388}\u{38a}\x05\u{80}\x41\x02\
	\u{389}\u{388}\x03\x02\x02\x02\u{389}\u{38a}\x03\x02\x02\x02\u{38a}\u{38b}\
	\x03\x02\x02\x02\u{38b}\u{390}\x05\u{82}\x42\x02\u{38c}\u{38e}\x07\x18\x02\
	\x02\u{38d}\u{38c}\x03\x02\x02\x02\u{38d}\u{38e}\x03\x02\x02\x02\u{38e}\
	\u{38f}\x03\x02\x02\x02\u{38f}\u{391}\x05\x66\x34\x02\u{390}\u{38d}\x03\
	\x02\x02\x02\u{390}\u{391}\x03\x02\x02\x02\u{391}\u{6de}\x03\x02\x02\x02\
	\u{392}\u{393}\x07\x49\x02\x02\u{393}\u{398}\x07\u{159}\x02\x02\u{394}\u{395}\
	\x07\u{a4}\x02\x02\u{395}\u{396}\x05\u{15a}\u{ae}\x02\u{396}\u{397}\x07\
	\x7c\x02\x02\u{397}\u{399}\x03\x02\x02\x02\u{398}\u{394}\x03\x02\x02\x02\
	\u{398}\u{399}\x03\x02\x02\x02\u{399}\u{39a}\x03\x02\x02\x02\u{39a}\u{39b}\
	\x05\u{13e}\u{a0}\x02\u{39b}\u{39c}\x07\u{c7}\x02\x02\u{39c}\u{3a5}\x05\
	\u{13e}\u{a0}\x02\u{39d}\u{3a4}\x05\u{80}\x41\x02\u{39e}\u{3a4}\x05\u{134}\
	\u{9b}\x02\u{39f}\u{3a4}\x05\u{98}\x4d\x02\u{3a0}\u{3a4}\x05\x5e\x30\x02\
	\u{3a1}\u{3a2}\x07\u{15d}\x02\x02\u{3a2}\u{3a4}\x05\u{84}\x43\x02\u{3a3}\
	\u{39d}\x03\x02\x02\x02\u{3a3}\u{39e}\x03\x02\x02\x02\u{3a3}\u{39f}\x03\
	\x02\x02\x02\u{3a3}\u{3a0}\x03\x02\x02\x02\u{3a3}\u{3a1}\x03\x02\x02\x02\
	\u{3a4}\u{3a7}\x03\x02\x02\x02\u{3a5}\u{3a3}\x03\x02\x02\x02\u{3a5}\u{3a6}\
	\x03\x02\x02\x02\u{3a6}\u{6de}\x03\x02\x02\x02\u{3a7}\u{3a5}\x03\x02\x02\
	\x02\u{3a8}\u{3ad}\x05\x56\x2c\x02\u{3a9}\u{3aa}\x07\x04\x02\x02\u{3aa}\
	\u{3ab}\x05\u{1a8}\u{d5}\x02\u{3ab}\u{3ac}\x07\x05\x02\x02\u{3ac}\u{3ae}\
	\x03\x02\x02\x02\u{3ad}\u{3a9}\x03\x02\x02\x02\u{3ad}\u{3ae}\x03\x02\x02\
	\x02\u{3ae}\u{3b0}\x03\x02\x02\x02\u{3af}\u{3b1}\x05\u{80}\x41\x02\u{3b0}\
	\u{3af}\x03\x02\x02\x02\u{3b0}\u{3b1}\x03\x02\x02\x02\u{3b1}\u{3b2}\x03\
	\x02\x02\x02\u{3b2}\u{3b7}\x05\u{82}\x42\x02\u{3b3}\u{3b5}\x07\x18\x02\x02\
	\u{3b4}\u{3b3}\x03\x02\x02\x02\u{3b4}\u{3b5}\x03\x02\x02\x02\u{3b5}\u{3b6}\
	\x03\x02\x02\x02\u{3b6}\u{3b8}\x05\x66\x34\x02\u{3b7}\u{3b4}\x03\x02\x02\
	\x02\u{3b7}\u{3b8}\x03\x02\x02\x02\u{3b8}\u{6de}\x03\x02\x02\x02\u{3b9}\
	\u{3ba}\x07\x11\x02\x02\u{3ba}\u{3bb}\x07\u{159}\x02\x02\u{3bb}\u{3bd}\x05\
	\u{a2}\x52\x02\u{3bc}\u{3be}\x05\x6c\x37\x02\u{3bd}\u{3bc}\x03\x02\x02\x02\
	\u{3bd}\u{3be}\x03\x02\x02\x02\u{3be}\u{3bf}\x03\x02\x02\x02\u{3bf}\u{3c0}\
	\x07\x42\x02\x02\u{3c0}\u{3c8}\x07\u{14d}\x02\x02\u{3c1}\u{3c9}\x05\u{1e6}\
	\u{f4}\x02\u{3c2}\u{3c3}\x07\u{8d}\x02\x02\u{3c3}\u{3c4}\x07\x3c\x02\x02\
	\u{3c4}\u{3c9}\x05\u{116}\u{8c}\x02\u{3c5}\u{3c6}\x07\u{8d}\x02\x02\u{3c6}\
	\u{3c7}\x07\x0e\x02\x02\u{3c7}\u{3c9}\x07\x3c\x02\x02\u{3c8}\u{3c1}\x03\
	\x02\x02\x02\u{3c8}\u{3c2}\x03\x02\x02\x02\u{3c8}\u{3c5}\x03\x02\x02\x02\
	\u{3c8}\u{3c9}\x03\x02\x02\x02\u{3c9}\u{6de}\x03\x02\x02\x02\u{3ca}\u{3cb}\
	\x07\x11\x02\x02\u{3cb}\u{3ce}\x07\u{15a}\x02\x02\u{3cc}\u{3cd}\x09\x05\
	\x02\x02\u{3cd}\u{3cf}\x05\u{a2}\x52\x02\u{3ce}\u{3cc}\x03\x02\x02\x02\u{3ce}\
	\u{3cf}\x03\x02\x02\x02\u{3cf}\u{3d0}\x03\x02\x02\x02\u{3d0}\u{3d1}\x07\
	\x42\x02\x02\u{3d1}\u{3d3}\x07\u{14d}\x02\x02\u{3d2}\u{3d4}\x05\u{1e6}\u{f4}\
	\x02\u{3d3}\u{3d2}\x03\x02\x02\x02\u{3d3}\u{3d4}\x03\x02\x02\x02\u{3d4}\
	\u{6de}\x03\x02\x02\x02\u{3d5}\u{3d6}\x07\x0f\x02\x02\u{3d6}\u{3d7}\x07\
	\u{159}\x02\x02\u{3d7}\u{3d8}\x05\u{a2}\x52\x02\u{3d8}\u{3d9}\x07\x0b\x02\
	\x02\u{3d9}\u{3da}\x09\x06\x02\x02\u{3da}\u{3db}\x05\u{19a}\u{ce}\x02\u{3db}\
	\u{6de}\x03\x02\x02\x02\u{3dc}\u{3dd}\x07\x0f\x02\x02\u{3dd}\u{3de}\x07\
	\u{159}\x02\x02\u{3de}\u{3df}\x05\u{a2}\x52\x02\u{3df}\u{3e0}\x07\x0b\x02\
	\x02\u{3e0}\u{3e1}\x09\x06\x02\x02\u{3e1}\u{3e2}\x07\x04\x02\x02\u{3e2}\
	\u{3e3}\x05\u{19a}\u{ce}\x02\u{3e3}\u{3e4}\x07\x05\x02\x02\u{3e4}\u{6de}\
	\x03\x02\x02\x02\u{3e5}\u{3e6}\x07\x0f\x02\x02\u{3e6}\u{3e7}\x07\u{159}\
	\x02\x02\u{3e7}\u{3e8}\x05\u{a2}\x52\x02\u{3e8}\u{3e9}\x07\u{11e}\x02\x02\
	\u{3e9}\u{3ea}\x07\x3b\x02\x02\u{3ea}\u{3eb}\x05\u{138}\u{9d}\x02\u{3eb}\
	\u{3ec}\x07\u{169}\x02\x02\u{3ec}\u{3ed}\x05\u{1e0}\u{f1}\x02\u{3ed}\u{6de}\
	\x03\x02\x02\x02\u{3ee}\u{3ef}\x07\x0f\x02\x02\u{3ef}\u{3f0}\x07\u{159}\
	\x02\x02\u{3f0}\u{3f1}\x05\u{a2}\x52\x02\u{3f1}\u{3f2}\x07\x71\x02\x02\u{3f2}\
	\u{3f5}\x09\x06\x02\x02\u{3f3}\u{3f4}\x07\u{a4}\x02\x02\u{3f4}\u{3f6}\x07\
	\x7c\x02\x02\u{3f5}\u{3f3}\x03\x02\x02\x02\u{3f5}\u{3f6}\x03\x02\x02\x02\
	\u{3f6}\u{3f7}\x03\x02\x02\x02\u{3f7}\u{3f8}\x07\x04\x02\x02\u{3f8}\u{3f9}\
	\x05\u{136}\u{9c}\x02\u{3f9}\u{3fa}\x07\x05\x02\x02\u{3fa}\u{6de}\x03\x02\
	\x02\x02\u{3fb}\u{3fc}\x07\x0f\x02\x02\u{3fc}\u{3fd}\x07\u{159}\x02\x02\
	\u{3fd}\u{3fe}\x05\u{a2}\x52\x02\u{3fe}\u{3ff}\x07\x71\x02\x02\u{3ff}\u{402}\
	\x09\x06\x02\x02\u{400}\u{401}\x07\u{a4}\x02\x02\u{401}\u{403}\x07\x7c\x02\
	\x02\u{402}\u{400}\x03\x02\x02\x02\u{402}\u{403}\x03\x02\x02\x02\u{403}\
	\u{404}\x03\x02\x02\x02\u{404}\u{405}\x05\u{136}\u{9c}\x02\u{405}\u{6de}\
	\x03\x02\x02\x02\u{406}\u{407}\x07\x0f\x02\x02\u{407}\u{408}\x09\x07\x02\
	\x02\u{408}\u{409}\x05\u{a2}\x52\x02\u{409}\u{40a}\x07\u{11e}\x02\x02\u{40a}\
	\u{40b}\x07\u{169}\x02\x02\u{40b}\u{40c}\x05\u{138}\u{9d}\x02\u{40c}\u{6de}\
	\x03\x02\x02\x02\u{40d}\u{40e}\x07\x0f\x02\x02\u{40e}\u{40f}\x09\x07\x02\
	\x02\u{40f}\u{410}\x05\u{a2}\x52\x02\u{410}\u{411}\x07\u{13c}\x02\x02\u{411}\
	\u{412}\x07\u{15d}\x02\x02\u{412}\u{413}\x05\u{84}\x43\x02\u{413}\u{6de}\
	\x03\x02\x02\x02\u{414}\u{415}\x07\x0f\x02\x02\u{415}\u{416}\x09\x07\x02\
	\x02\u{416}\u{417}\x05\u{a2}\x52\x02\u{417}\u{418}\x07\u{17d}\x02\x02\u{418}\
	\u{41b}\x07\u{15d}\x02\x02\u{419}\u{41a}\x07\u{a4}\x02\x02\u{41a}\u{41c}\
	\x07\x7c\x02\x02\u{41b}\u{419}\x03\x02\x02\x02\u{41b}\u{41c}\x03\x02\x02\
	\x02\u{41c}\u{41d}\x03\x02\x02\x02\u{41d}\u{41e}\x05\u{84}\x43\x02\u{41e}\
	\u{6de}\x03\x02\x02\x02\u{41f}\u{420}\x07\x0f\x02\x02\u{420}\u{421}\x07\
	\u{159}\x02\x02\u{421}\u{422}\x05\u{a2}\x52\x02\u{422}\u{424}\x09\x08\x02\
	\x02\u{423}\u{425}\x07\x3b\x02\x02\u{424}\u{423}\x03\x02\x02\x02\u{424}\
	\u{425}\x03\x02\x02\x02\u{425}\u{426}\x03\x02\x02\x02\u{426}\u{427}\x05\
	\u{20c}\u{107}\x02\u{427}\u{6de}\x03\x02\x02\x02\u{428}\u{429}\x07\x0f\x02\
	\x02\u{429}\u{42a}\x07\u{159}\x02\x02\u{42a}\u{42c}\x05\u{a2}\x52\x02\u{42b}\
	\u{42d}\x05\x6c\x37\x02\u{42c}\u{42b}\x03\x02\x02\x02\u{42c}\u{42d}\x03\
	\x02\x02\x02\u{42d}\u{42e}\x03\x02\x02\x02\u{42e}\u{430}\x07\x30\x02\x02\
	\u{42f}\u{431}\x07\x3b\x02\x02\u{430}\u{42f}\x03\x02\x02\x02\u{430}\u{431}\
	\x03\x02\x02\x02\u{431}\u{432}\x03\x02\x02\x02\u{432}\u{433}\x05\u{138}\
	\u{9d}\x02\u{433}\u{435}\x05\u{1a6}\u{d4}\x02\u{434}\u{436}\x05\u{18c}\u{c7}\
	\x02\u{435}\u{434}\x03\x02\x02\x02\u{435}\u{436}\x03\x02\x02\x02\u{436}\
	\u{6de}\x03\x02\x02\x02\u{437}\u{438}\x07\x0f\x02\x02\u{438}\u{439}\x07\
	\u{159}\x02\x02\u{439}\u{43b}\x05\u{a2}\x52\x02\u{43a}\u{43c}\x05\x6c\x37\
	\x02\u{43b}\u{43a}\x03\x02\x02\x02\u{43b}\u{43c}\x03\x02\x02\x02\u{43c}\
	\u{43d}\x03\x02\x02\x02\u{43d}\u{43e}\x07\u{122}\x02\x02\u{43e}\u{43f}\x07\
	\x3c\x02\x02\u{43f}\u{440}\x07\x04\x02\x02\u{440}\u{441}\x05\u{19a}\u{ce}\
	\x02\u{441}\u{442}\x07\x05\x02\x02\u{442}\u{6de}\x03\x02\x02\x02\u{443}\
	\u{444}\x07\x0f\x02\x02\u{444}\u{445}\x07\u{159}\x02\x02\u{445}\u{447}\x05\
	\u{a2}\x52\x02\u{446}\u{448}\x05\x6c\x37\x02\u{447}\u{446}\x03\x02\x02\x02\
	\u{447}\u{448}\x03\x02\x02\x02\u{448}\u{449}\x03\x02\x02\x02\u{449}\u{44a}\
	\x07\u{13c}\x02\x02\u{44a}\u{44b}\x07\u{139}\x02\x02\u{44b}\u{44f}\x05\u{218}\
	\u{10d}\x02\u{44c}\u{44d}\x07\u{194}\x02\x02\u{44d}\u{44e}\x07\u{13a}\x02\
	\x02\u{44e}\u{450}\x05\u{84}\x43\x02\u{44f}\u{44c}\x03\x02\x02\x02\u{44f}\
	\u{450}\x03\x02\x02\x02\u{450}\u{6de}\x03\x02\x02\x02\u{451}\u{452}\x07\
	\x0f\x02\x02\u{452}\u{453}\x07\u{159}\x02\x02\u{453}\u{455}\x05\u{a2}\x52\
	\x02\u{454}\u{456}\x05\x6c\x37\x02\u{455}\u{454}\x03\x02\x02\x02\u{455}\
	\u{456}\x03\x02\x02\x02\u{456}\u{457}\x03\x02\x02\x02\u{457}\u{458}\x07\
	\u{13c}\x02\x02\u{458}\u{459}\x07\u{13a}\x02\x02\u{459}\u{45a}\x05\u{84}\
	\x43\x02\u{45a}\u{6de}\x03\x02\x02\x02\u{45b}\u{45c}\x07\x0f\x02\x02\u{45c}\
	\u{45d}\x09\x07\x02\x02\u{45d}\u{45e}\x05\u{a2}\x52\x02\u{45e}\u{463}\x07\
	\x0b\x02\x02\u{45f}\u{460}\x07\u{a4}\x02\x02\u{460}\u{461}\x05\u{15a}\u{ae}\
	\x02\u{461}\u{462}\x07\x7c\x02\x02\u{462}\u{464}\x03\x02\x02\x02\u{463}\
	\u{45f}\x03\x02\x02\x02\u{463}\u{464}\x03\x02\x02\x02\u{464}\u{466}\x03\
	\x02\x02\x02\u{465}\u{467}\x05\x6a\x36\x02\u{466}\u{465}\x03\x02\x02\x02\
	\u{467}\u{468}\x03\x02\x02\x02\u{468}\u{466}\x03\x02\x02\x02\u{468}\u{469}\
	\x03\x02\x02\x02\u{469}\u{6de}\x03\x02\x02\x02\u{46a}\u{46b}\x07\x0f\x02\
	\x02\u{46b}\u{46c}\x07\u{159}\x02\x02\u{46c}\u{46d}\x05\u{a2}\x52\x02\u{46d}\
	\u{46e}\x05\x6c\x37\x02\u{46e}\u{46f}\x07\u{11e}\x02\x02\u{46f}\u{470}\x07\
	\u{169}\x02\x02\u{470}\u{471}\x05\x6c\x37\x02\u{471}\u{6de}\x03\x02\x02\
	\x02\u{472}\u{473}\x07\x0f\x02\x02\u{473}\u{474}\x09\x07\x02\x02\u{474}\
	\u{475}\x05\u{a2}\x52\x02\u{475}\u{478}\x07\x71\x02\x02\u{476}\u{477}\x07\
	\u{a4}\x02\x02\u{477}\u{479}\x07\x7c\x02\x02\u{478}\u{476}\x03\x02\x02\x02\
	\u{478}\u{479}\x03\x02\x02\x02\u{479}\u{47a}\x03\x02\x02\x02\u{47a}\u{47f}\
	\x05\x6c\x37\x02\u{47b}\u{47c}\x07\x06\x02\x02\u{47c}\u{47e}\x05\x6c\x37\
	\x02\u{47d}\u{47b}\x03\x02\x02\x02\u{47e}\u{481}\x03\x02\x02\x02\u{47f}\
	\u{47d}\x03\x02\x02\x02\u{47f}\u{480}\x03\x02\x02\x02\u{480}\u{483}\x03\
	\x02\x02\x02\u{481}\u{47f}\x03\x02\x02\x02\u{482}\u{484}\x07\u{10f}\x02\
	\x02\u{483}\u{482}\x03\x02\x02\x02\u{483}\u{484}\x03\x02\x02\x02\u{484}\
	\u{6de}\x03\x02\x02\x02\u{485}\u{486}\x07\x0f\x02\x02\u{486}\u{487}\x07\
	\u{159}\x02\x02\u{487}\u{489}\x05\u{a2}\x52\x02\u{488}\u{48a}\x05\x6c\x37\
	\x02\u{489}\u{488}\x03\x02\x02\x02\u{489}\u{48a}\x03\x02\x02\x02\u{48a}\
	\u{48b}\x03\x02\x02\x02\u{48b}\u{48c}\x07\u{13c}\x02\x02\u{48c}\u{48d}\x05\
	\x5e\x30\x02\u{48d}\u{6de}\x03\x02\x02\x02\u{48e}\u{48f}\x07\x0f\x02\x02\
	\u{48f}\u{490}\x07\u{159}\x02\x02\u{490}\u{491}\x05\u{a2}\x52\x02\u{491}\
	\u{492}\x07\u{117}\x02\x02\u{492}\u{493}\x07\u{104}\x02\x02\u{493}\u{6de}\
	\x03\x02\x02\x02\u{494}\u{495}\x07\x0f\x02\x02\u{495}\u{496}\x07\u{159}\
	\x02\x02\u{496}\u{49b}\x05\u{a2}\x52\x02\u{497}\u{49c}\x05\x58\x2d\x02\u{498}\
	\u{499}\x07\x35\x02\x02\u{499}\u{49a}\x07\x26\x02\x02\u{49a}\u{49c}\x07\
	\u{ed}\x02\x02\u{49b}\u{497}\x03\x02\x02\x02\u{49b}\u{498}\x03\x02\x02\x02\
	\u{49c}\u{6de}\x03\x02\x02\x02\u{49d}\u{49e}\x07\x0f\x02\x02\u{49e}\u{49f}\
	\x07\u{159}\x02\x02\u{49f}\u{4a0}\x05\u{a2}\x52\x02\u{4a0}\u{4a1}\x05\u{18e}\
	\u{c8}\x02\u{4a1}\u{6de}\x03\x02\x02\x02\u{4a2}\u{4a3}\x07\x0f\x02\x02\u{4a3}\
	\u{4a4}\x07\u{159}\x02\x02\u{4a4}\u{4a5}\x05\u{a2}\x52\x02\u{4a5}\u{4a6}\
	\x07\x0b\x02\x02\u{4a6}\u{4a7}\x05\u{1f8}\u{fd}\x02\u{4a7}\u{6de}\x03\x02\
	\x02\x02\u{4a8}\u{4a9}\x07\x0f\x02\x02\u{4a9}\u{4aa}\x07\u{159}\x02\x02\
	\u{4aa}\u{4ab}\x05\u{a2}\x52\x02\u{4ab}\u{4ac}\x07\x71\x02\x02\u{4ac}\u{4af}\
	\x07\x45\x02\x02\u{4ad}\u{4ae}\x07\u{a4}\x02\x02\u{4ae}\u{4b0}\x07\x7c\x02\
	\x02\u{4af}\u{4ad}\x03\x02\x02\x02\u{4af}\u{4b0}\x03\x02\x02\x02\u{4b0}\
	\u{4b1}\x03\x02\x02\x02\u{4b1}\u{4b3}\x05\u{1e4}\u{f3}\x02\u{4b2}\u{4b4}\
	\x09\x04\x02\x02\u{4b3}\u{4b2}\x03\x02\x02\x02\u{4b3}\u{4b4}\x03\x02\x02\
	\x02\u{4b4}\u{6de}\x03\x02\x02\x02\u{4b5}\u{4b6}\x07\x71\x02\x02\u{4b6}\
	\u{4b9}\x07\u{159}\x02\x02\u{4b7}\u{4b8}\x07\u{a4}\x02\x02\u{4b8}\u{4ba}\
	\x07\x7c\x02\x02\u{4b9}\u{4b7}\x03\x02\x02\x02\u{4b9}\u{4ba}\x03\x02\x02\
	\x02\u{4ba}\u{4bb}\x03\x02\x02\x02\u{4bb}\u{4bd}\x05\u{a2}\x52\x02\u{4bc}\
	\u{4be}\x07\u{10f}\x02\x02\u{4bd}\u{4bc}\x03\x02\x02\x02\u{4bd}\u{4be}\x03\
	\x02\x02\x02\u{4be}\u{6de}\x03\x02\x02\x02\u{4bf}\u{4c0}\x07\x71\x02\x02\
	\u{4c0}\u{4c3}\x07\u{18a}\x02\x02\u{4c1}\u{4c2}\x07\u{a4}\x02\x02\u{4c2}\
	\u{4c4}\x07\x7c\x02\x02\u{4c3}\u{4c1}\x03\x02\x02\x02\u{4c3}\u{4c4}\x03\
	\x02\x02\x02\u{4c4}\u{4c5}\x03\x02\x02\x02\u{4c5}\u{6de}\x05\u{a2}\x52\x02\
	\u{4c6}\u{4c9}\x07\x49\x02\x02\u{4c7}\u{4c8}\x07\u{f9}\x02\x02\u{4c8}\u{4ca}\
	\x07\u{122}\x02\x02\u{4c9}\u{4c7}\x03\x02\x02\x02\u{4c9}\u{4ca}\x03\x02\
	\x02\x02\u{4ca}\u{4cf}\x03\x02\x02\x02\u{4cb}\u{4cd}\x07\u{99}\x02\x02\u{4cc}\
	\u{4cb}\x03\x02\x02\x02\u{4cc}\u{4cd}\x03\x02\x02\x02\u{4cd}\u{4ce}\x03\
	\x02\x02\x02\u{4ce}\u{4d0}\x07\u{15e}\x02\x02\u{4cf}\u{4cc}\x03\x02\x02\
	\x02\u{4cf}\u{4d0}\x03\x02\x02\x02\u{4d0}\u{4d1}\x03\x02\x02\x02\u{4d1}\
	\u{4d6}\x07\u{18a}\x02\x02\u{4d2}\u{4d3}\x07\u{a4}\x02\x02\u{4d3}\u{4d4}\
	\x05\u{15a}\u{ae}\x02\u{4d4}\u{4d5}\x07\x7c\x02\x02\u{4d5}\u{4d7}\x03\x02\
	\x02\x02\u{4d6}\u{4d2}\x03\x02\x02\x02\u{4d6}\u{4d7}\x03\x02\x02\x02\u{4d7}\
	\u{4d8}\x03\x02\x02\x02\u{4d8}\u{4da}\x05\u{a2}\x52\x02\u{4d9}\u{4db}\x05\
	\u{11c}\u{8f}\x02\u{4da}\u{4d9}\x03\x02\x02\x02\u{4da}\u{4db}\x03\x02\x02\
	\x02\u{4db}\u{4e6}\x03\x02\x02\x02\u{4dc}\u{4e5}\x05\x62\x32\x02\u{4dd}\
	\u{4e5}\x05\x60\x31\x02\u{4de}\u{4e5}\x05\u{18e}\u{c8}\x02\u{4df}\u{4e0}\
	\x07\u{103}\x02\x02\u{4e0}\u{4e1}\x07\u{f5}\x02\x02\u{4e1}\u{4e5}\x05\u{114}\
	\u{8b}\x02\u{4e2}\u{4e3}\x07\u{15d}\x02\x02\u{4e3}\u{4e5}\x05\u{84}\x43\
	\x02\u{4e4}\u{4dc}\x03\x02\x02\x02\u{4e4}\u{4dd}\x03\x02\x02\x02\u{4e4}\
	\u{4de}\x03\x02\x02\x02\u{4e4}\u{4df}\x03\x02\x02\x02\u{4e4}\u{4e2}\x03\
	\x02\x02\x02\u{4e5}\u{4e8}\x03\x02\x02\x02\u{4e6}\u{4e4}\x03\x02\x02\x02\
	\u{4e6}\u{4e7}\x03\x02\x02\x02\u{4e7}\u{4e9}\x03\x02\x02\x02\u{4e8}\u{4e6}\
	\x03\x02\x02\x02\u{4e9}\u{4ea}\x07\x18\x02\x02\u{4ea}\u{4eb}\x05\x66\x34\
	\x02\u{4eb}\u{6de}\x03\x02\x02\x02\u{4ec}\u{4ef}\x07\x49\x02\x02\u{4ed}\
	\u{4ee}\x07\u{f9}\x02\x02\u{4ee}\u{4f0}\x07\u{122}\x02\x02\u{4ef}\u{4ed}\
	\x03\x02\x02\x02\u{4ef}\u{4f0}\x03\x02\x02\x02\u{4f0}\u{4f1}\x03\x02\x02\
	\x02\u{4f1}\u{4f6}\x07\u{18a}\x02\x02\u{4f2}\u{4f3}\x07\u{a4}\x02\x02\u{4f3}\
	\u{4f4}\x05\u{15a}\u{ae}\x02\u{4f4}\u{4f5}\x07\x7c\x02\x02\u{4f5}\u{4f7}\
	\x03\x02\x02\x02\u{4f6}\u{4f2}\x03\x02\x02\x02\u{4f6}\u{4f7}\x03\x02\x02\
	\x02\u{4f7}\u{4f8}\x03\x02\x02\x02\u{4f8}\u{4fa}\x05\u{a2}\x52\x02\u{4f9}\
	\u{4fb}\x05\u{11c}\u{8f}\x02\u{4fa}\u{4f9}\x03\x02\x02\x02\u{4fa}\u{4fb}\
	\x03\x02\x02\x02\u{4fb}\u{504}\x03\x02\x02\x02\u{4fc}\u{4fd}\x07\u{194}\
	\x02\x02\u{4fd}\u{503}\x07\u{db}\x02\x02\u{4fe}\u{503}\x05\u{1c2}\u{e2}\
	\x02\u{4ff}\u{503}\x05\x62\x32\x02\u{500}\u{501}\x07\u{15d}\x02\x02\u{501}\
	\u{503}\x05\u{84}\x43\x02\u{502}\u{4fc}\x03\x02\x02\x02\u{502}\u{4fe}\x03\
	\x02\x02\x02\u{502}\u{4ff}\x03\x02\x02\x02\u{502}\u{500}\x03\x02\x02\x02\
	\u{503}\u{506}\x03\x02\x02\x02\u{504}\u{502}\x03\x02\x02\x02\u{504}\u{505}\
	\x03\x02\x02\x02\u{505}\u{507}\x03\x02\x02\x02\u{506}\u{504}\x03\x02\x02\
	\x02\u{507}\u{508}\x07\x18\x02\x02\u{508}\u{509}\x05\u{1be}\u{e0}\x02\u{509}\
	\u{6de}\x03\x02\x02\x02\u{50a}\u{50d}\x07\x49\x02\x02\u{50b}\u{50c}\x07\
	\u{f9}\x02\x02\u{50c}\u{50e}\x07\u{122}\x02\x02\u{50d}\u{50b}\x03\x02\x02\
	\x02\u{50d}\u{50e}\x03\x02\x02\x02\u{50e}\u{510}\x03\x02\x02\x02\u{50f}\
	\u{511}\x07\u{99}\x02\x02\u{510}\u{50f}\x03\x02\x02\x02\u{510}\u{511}\x03\
	\x02\x02\x02\u{511}\u{512}\x03\x02\x02\x02\u{512}\u{513}\x07\u{15e}\x02\
	\x02\u{513}\u{514}\x07\u{18a}\x02\x02\u{514}\u{519}\x05\u{13e}\u{a0}\x02\
	\u{515}\u{516}\x07\x04\x02\x02\u{516}\u{517}\x05\u{1a4}\u{d3}\x02\u{517}\
	\u{518}\x07\x05\x02\x02\u{518}\u{51a}\x03\x02\x02\x02\u{519}\u{515}\x03\
	\x02\x02\x02\u{519}\u{51a}\x03\x02\x02\x02\u{51a}\u{51b}\x03\x02\x02\x02\
	\u{51b}\u{51e}\x05\u{80}\x41\x02\u{51c}\u{51d}\x07\u{f8}\x02\x02\u{51d}\
	\u{51f}\x05\u{84}\x43\x02\u{51e}\u{51c}\x03\x02\x02\x02\u{51e}\u{51f}\x03\
	\x02\x02\x02\u{51f}\u{6de}\x03\x02\x02\x02\u{520}\u{521}\x07\x0f\x02\x02\
	\u{521}\u{522}\x07\u{18a}\x02\x02\u{522}\u{524}\x05\u{a2}\x52\x02\u{523}\
	\u{525}\x07\x18\x02\x02\u{524}\u{523}\x03\x02\x02\x02\u{524}\u{525}\x03\
	\x02\x02\x02\u{525}\u{526}\x03\x02\x02\x02\u{526}\u{527}\x05\x66\x34\x02\
	\u{527}\u{6de}\x03\x02\x02\x02\u{528}\u{529}\x07\x0f\x02\x02\u{529}\u{52a}\
	\x07\u{18a}\x02\x02\u{52a}\u{52b}\x05\u{a2}\x52\x02\u{52b}\u{52c}\x05\x60\
	\x31\x02\u{52c}\u{6de}\x03\x02\x02\x02\u{52d}\u{530}\x07\x49\x02\x02\u{52e}\
	\u{52f}\x07\u{f9}\x02\x02\u{52f}\u{531}\x07\u{122}\x02\x02\u{530}\u{52e}\
	\x03\x02\x02\x02\u{530}\u{531}\x03\x02\x02\x02\u{531}\u{533}\x03\x02\x02\
	\x02\u{532}\u{534}\x07\u{15e}\x02\x02\u{533}\u{532}\x03\x02\x02\x02\u{533}\
	\u{534}\x03\x02\x02\x02\u{534}\u{535}\x03\x02\x02\x02\u{535}\u{53a}\x07\
	\u{94}\x02\x02\u{536}\u{537}\x07\u{a4}\x02\x02\u{537}\u{538}\x05\u{15a}\
	\u{ae}\x02\u{538}\u{539}\x07\x7c\x02\x02\u{539}\u{53b}\x03\x02\x02\x02\u{53a}\
	\u{536}\x03\x02\x02\x02\u{53a}\u{53b}\x03\x02\x02\x02\u{53b}\u{53c}\x03\
	\x02\x02\x02\u{53c}\u{53d}\x05\u{a2}\x52\x02\u{53d}\u{53e}\x07\x18\x02\x02\
	\u{53e}\u{548}\x05\u{218}\u{10d}\x02\u{53f}\u{540}\x07\u{182}\x02\x02\u{540}\
	\u{545}\x05\u{9e}\x50\x02\u{541}\u{542}\x07\x06\x02\x02\u{542}\u{544}\x05\
	\u{9e}\x50\x02\u{543}\u{541}\x03\x02\x02\x02\u{544}\u{547}\x03\x02\x02\x02\
	\u{545}\u{543}\x03\x02\x02\x02\u{545}\u{546}\x03\x02\x02\x02\u{546}\u{549}\
	\x03\x02\x02\x02\u{547}\u{545}\x03\x02\x02\x02\u{548}\u{53f}\x03\x02\x02\
	\x02\u{548}\u{549}\x03\x02\x02\x02\u{549}\u{6de}\x03\x02\x02\x02\u{54a}\
	\u{54d}\x07\x49\x02\x02\u{54b}\u{54c}\x07\u{f9}\x02\x02\u{54c}\u{54e}\x07\
	\u{122}\x02\x02\u{54d}\u{54b}\x03\x02\x02\x02\u{54d}\u{54e}\x03\x02\x02\
	\x02\u{54e}\u{550}\x03\x02\x02\x02\u{54f}\u{551}\x07\u{15e}\x02\x02\u{550}\
	\u{54f}\x03\x02\x02\x02\u{550}\u{551}\x03\x02\x02\x02\u{551}\u{552}\x03\
	\x02\x02\x02\u{552}\u{557}\x07\u{94}\x02\x02\u{553}\u{554}\x07\u{a4}\x02\
	\x02\u{554}\u{555}\x05\u{15a}\u{ae}\x02\u{555}\u{556}\x07\x7c\x02\x02\u{556}\
	\u{558}\x03\x02\x02\x02\u{557}\u{553}\x03\x02\x02\x02\u{557}\u{558}\x03\
	\x02\x02\x02\u{558}\u{559}\x03\x02\x02\x02\u{559}\u{55a}\x05\u{a2}\x52\x02\
	\u{55a}\u{55c}\x07\x04\x02\x02\u{55b}\u{55d}\x05\u{1ac}\u{d7}\x02\u{55c}\
	\u{55b}\x03\x02\x02\x02\u{55c}\u{55d}\x03\x02\x02\x02\u{55d}\u{55e}\x03\
	\x02\x02\x02\u{55e}\u{568}\x07\x05\x02\x02\u{55f}\u{566}\x07\u{127}\x02\
	\x02\u{560}\u{567}\x05\u{198}\u{cd}\x02\u{561}\u{562}\x07\u{159}\x02\x02\
	\u{562}\u{563}\x07\x04\x02\x02\u{563}\u{564}\x05\u{1a4}\u{d3}\x02\u{564}\
	\u{565}\x07\x05\x02\x02\u{565}\u{567}\x03\x02\x02\x02\u{566}\u{560}\x03\
	\x02\x02\x02\u{566}\u{561}\x03\x02\x02\x02\u{567}\u{569}\x03\x02\x02\x02\
	\u{568}\u{55f}\x03\x02\x02\x02\u{568}\u{569}\x03\x02\x02\x02\u{569}\u{56a}\
	\x03\x02\x02\x02\u{56a}\u{56b}\x05\u{1c0}\u{e1}\x02\u{56b}\u{56e}\x07\u{126}\
	\x02\x02\u{56c}\u{56f}\x05\x66\x34\x02\u{56d}\u{56f}\x05\u{14e}\u{a8}\x02\
	\u{56e}\u{56c}\x03\x02\x02\x02\u{56e}\u{56d}\x03\x02\x02\x02\u{56f}\u{6de}\
	\x03\x02\x02\x02\u{570}\u{572}\x07\x71\x02\x02\u{571}\u{573}\x07\u{15e}\
	\x02\x02\u{572}\u{571}\x03\x02\x02\x02\u{572}\u{573}\x03\x02\x02\x02\u{573}\
	\u{574}\x03\x02\x02\x02\u{574}\u{577}\x07\u{94}\x02\x02\u{575}\u{576}\x07\
	\u{a4}\x02\x02\u{576}\u{578}\x07\x7c\x02\x02\u{577}\u{575}\x03\x02\x02\x02\
	\u{577}\u{578}\x03\x02\x02\x02\u{578}\u{579}\x03\x02\x02\x02\u{579}\u{6de}\
	\x05\u{a2}\x52\x02\u{57a}\u{57d}\x07\x5f\x02\x02\u{57b}\u{57c}\x07\u{f9}\
	\x02\x02\u{57c}\u{57e}\x07\u{122}\x02\x02\u{57d}\u{57b}\x03\x02\x02\x02\
	\u{57d}\u{57e}\x03\x02\x02\x02\u{57e}\u{580}\x03\x02\x02\x02\u{57f}\u{581}\
	\x05\x76\x3c\x02\u{580}\u{57f}\x03\x02\x02\x02\u{580}\u{581}\x03\x02\x02\
	\x02\u{581}\u{582}\x03\x02\x02\x02\u{582}\u{587}\x05\u{a2}\x52\x02\u{583}\
	\u{584}\x07\x06\x02\x02\u{584}\u{586}\x05\u{a2}\x52\x02\u{585}\u{583}\x03\
	\x02\x02\x02\u{586}\u{589}\x03\x02\x02\x02\u{587}\u{585}\x03\x02\x02\x02\
	\u{587}\u{588}\x03\x02\x02\x02\u{588}\u{58b}\x03\x02\x02\x02\u{589}\u{587}\
	\x03\x02\x02\x02\u{58a}\u{58c}\x05\u{198}\u{cd}\x02\u{58b}\u{58a}\x03\x02\
	\x02\x02\u{58b}\u{58c}\x03\x02\x02\x02\u{58c}\u{58e}\x03\x02\x02\x02\u{58d}\
	\u{58f}\x05\u{1a2}\u{d2}\x02\u{58e}\u{58d}\x03\x02\x02\x02\u{58e}\u{58f}\
	\x03\x02\x02\x02\u{58f}\u{6de}\x03\x02\x02\x02\u{590}\u{591}\x07\x71\x02\
	\x02\u{591}\u{592}\x07\u{15e}\x02\x02\u{592}\u{595}\x05\x76\x3c\x02\u{593}\
	\u{594}\x07\u{a4}\x02\x02\u{594}\u{596}\x07\x7c\x02\x02\u{595}\u{593}\x03\
	\x02\x02\x02\u{595}\u{596}\x03\x02\x02\x02\u{596}\u{597}\x03\x02\x02\x02\
	\u{597}\u{598}\x05\u{a2}\x52\x02\u{598}\u{6de}\x03\x02\x02\x02\u{599}\u{59b}\
	\x07\x7e\x02\x02\u{59a}\u{59c}\x09\x09\x02\x02\u{59b}\u{59a}\x03\x02\x02\
	\x02\u{59b}\u{59c}\x03\x02\x02\x02\u{59c}\u{59f}\x03\x02\x02\x02\u{59d}\
	\u{5a0}\x05\x3c\x1f\x02\u{59e}\u{5a0}\x05\x46\x24\x02\u{59f}\u{59d}\x03\
	\x02\x02\x02\u{59f}\u{59e}\x03\x02\x02\x02\u{5a0}\u{6de}\x03\x02\x02\x02\
	\u{5a1}\u{5a2}\x07\u{140}\x02\x02\u{5a2}\u{5a5}\x07\u{15a}\x02\x02\u{5a3}\
	\u{5a4}\x09\x05\x02\x02\u{5a4}\u{5a6}\x05\u{a2}\x52\x02\u{5a5}\u{5a3}\x03\
	\x02\x02\x02\u{5a5}\u{5a6}\x03\x02\x02\x02\u{5a6}\u{5ab}\x03\x02\x02\x02\
	\u{5a7}\u{5a9}\x07\u{c7}\x02\x02\u{5a8}\u{5a7}\x03\x02\x02\x02\u{5a8}\u{5a9}\
	\x03\x02\x02\x02\u{5a9}\u{5aa}\x03\x02\x02\x02\u{5aa}\u{5ac}\x05\u{218}\
	\u{10d}\x02\u{5ab}\u{5a8}\x03\x02\x02\x02\u{5ab}\u{5ac}\x03\x02\x02\x02\
	\u{5ac}\u{6de}\x03\x02\x02\x02\u{5ad}\u{5ae}\x07\u{140}\x02\x02\u{5ae}\u{5af}\
	\x07\u{159}\x02\x02\u{5af}\u{5b2}\x07\u{81}\x02\x02\u{5b0}\u{5b1}\x09\x05\
	\x02\x02\u{5b1}\u{5b3}\x05\u{a2}\x52\x02\u{5b2}\u{5b0}\x03\x02\x02\x02\u{5b2}\
	\u{5b3}\x03\x02\x02\x02\u{5b3}\u{5b4}\x03\x02\x02\x02\u{5b4}\u{5b5}\x07\
	\u{c7}\x02\x02\u{5b5}\u{5b7}\x05\u{218}\u{10d}\x02\u{5b6}\u{5b8}\x05\x6c\
	\x37\x02\u{5b7}\u{5b6}\x03\x02\x02\x02\u{5b7}\u{5b8}\x03\x02\x02\x02\u{5b8}\
	\u{6de}\x03\x02\x02\x02\u{5b9}\u{5ba}\x07\u{140}\x02\x02\u{5ba}\u{5bb}\x07\
	\u{15d}\x02\x02\u{5bb}\u{5c0}\x05\u{a2}\x52\x02\u{5bc}\u{5bd}\x07\x04\x02\
	\x02\u{5bd}\u{5be}\x05\u{8a}\x46\x02\u{5be}\u{5bf}\x07\x05\x02\x02\u{5bf}\
	\u{5c1}\x03\x02\x02\x02\u{5c0}\u{5bc}\x03\x02\x02\x02\u{5c0}\u{5c1}\x03\
	\x02\x02\x02\u{5c1}\u{6de}\x03\x02\x02\x02\u{5c2}\u{5c3}\x07\u{140}\x02\
	\x02\u{5c3}\u{5c4}\x07\x3c\x02\x02\u{5c4}\u{5c5}\x09\x05\x02\x02\u{5c5}\
	\u{5c8}\x05\u{a2}\x52\x02\u{5c6}\u{5c7}\x09\x05\x02\x02\u{5c7}\u{5c9}\x05\
	\u{138}\u{9d}\x02\u{5c8}\u{5c6}\x03\x02\x02\x02\u{5c8}\u{5c9}\x03\x02\x02\
	\x02\u{5c9}\u{6de}\x03\x02\x02\x02\u{5ca}\u{5cb}\x07\u{140}\x02\x02\u{5cb}\
	\u{5ce}\x07\u{18b}\x02\x02\u{5cc}\u{5cd}\x09\x05\x02\x02\u{5cd}\u{5cf}\x05\
	\u{a2}\x52\x02\u{5ce}\u{5cc}\x03\x02\x02\x02\u{5ce}\u{5cf}\x03\x02\x02\x02\
	\u{5cf}\u{5d4}\x03\x02\x02\x02\u{5d0}\u{5d2}\x07\u{c7}\x02\x02\u{5d1}\u{5d0}\
	\x03\x02\x02\x02\u{5d1}\u{5d2}\x03\x02\x02\x02\u{5d2}\u{5d3}\x03\x02\x02\
	\x02\u{5d3}\u{5d5}\x05\u{218}\u{10d}\x02\u{5d4}\u{5d1}\x03\x02\x02\x02\u{5d4}\
	\u{5d5}\x03\x02\x02\x02\u{5d5}\u{6de}\x03\x02\x02\x02\u{5d6}\u{5d7}\x07\
	\u{140}\x02\x02\u{5d7}\u{5d8}\x07\u{104}\x02\x02\u{5d8}\u{5da}\x05\u{a2}\
	\x52\x02\u{5d9}\u{5db}\x05\x6c\x37\x02\u{5da}\u{5d9}\x03\x02\x02\x02\u{5da}\
	\u{5db}\x03\x02\x02\x02\u{5db}\u{6de}\x03\x02\x02\x02\u{5dc}\u{5de}\x07\
	\u{140}\x02\x02\u{5dd}\u{5df}\x05\u{1e6}\u{f4}\x02\u{5de}\u{5dd}\x03\x02\
	\x02\x02\u{5de}\u{5df}\x03\x02\x02\x02\u{5df}\u{5e0}\x03\x02\x02\x02\u{5e0}\
	\u{5e3}\x07\u{95}\x02\x02\u{5e1}\u{5e2}\x09\x05\x02\x02\u{5e2}\u{5e4}\x05\
	\u{a2}\x52\x02\u{5e3}\u{5e1}\x03\x02\x02\x02\u{5e3}\u{5e4}\x03\x02\x02\x02\
	\u{5e4}\u{5ec}\x03\x02\x02\x02\u{5e5}\u{5e7}\x07\u{c7}\x02\x02\u{5e6}\u{5e5}\
	\x03\x02\x02\x02\u{5e6}\u{5e7}\x03\x02\x02\x02\u{5e7}\u{5ea}\x03\x02\x02\
	\x02\u{5e8}\u{5eb}\x05\u{138}\u{9d}\x02\u{5e9}\u{5eb}\x05\u{218}\u{10d}\
	\x02\u{5ea}\u{5e8}\x03\x02\x02\x02\u{5ea}\u{5e9}\x03\x02\x02\x02\u{5eb}\
	\u{5ed}\x03\x02\x02\x02\u{5ec}\u{5e6}\x03\x02\x02\x02\u{5ec}\u{5ed}\x03\
	\x02\x02\x02\u{5ed}\u{6de}\x03\x02\x02\x02\u{5ee}\u{5ef}\x07\u{140}\x02\
	\x02\u{5ef}\u{5f2}\x07\u{10d}\x02\x02\u{5f0}\u{5f1}\x09\x05\x02\x02\u{5f1}\
	\u{5f3}\x05\u{a2}\x52\x02\u{5f2}\u{5f0}\x03\x02\x02\x02\u{5f2}\u{5f3}\x03\
	\x02\x02\x02\u{5f3}\u{6de}\x03\x02\x02\x02\u{5f4}\u{5f5}\x07\u{140}\x02\
	\x02\u{5f5}\u{5f6}\x07\x49\x02\x02\u{5f6}\u{5f7}\x07\u{159}\x02\x02\u{5f7}\
	\u{5fa}\x05\u{a2}\x52\x02\u{5f8}\u{5f9}\x07\x18\x02\x02\u{5f9}\u{5fb}\x07\
	\u{139}\x02\x02\u{5fa}\u{5f8}\x03\x02\x02\x02\u{5fa}\u{5fb}\x03\x02\x02\
	\x02\u{5fb}\u{6de}\x03\x02\x02\x02\u{5fc}\u{5fd}\x07\u{140}\x02\x02\u{5fd}\
	\u{5fe}\x07\x4c\x02\x02\u{5fe}\u{6de}\x05\x72\x3a\x02\u{5ff}\u{600}\x07\
	\u{140}\x02\x02\u{600}\u{605}\x07\x2f\x02\x02\u{601}\u{603}\x07\u{c7}\x02\
	\x02\u{602}\u{601}\x03\x02\x02\x02\u{602}\u{603}\x03\x02\x02\x02\u{603}\
	\u{604}\x03\x02\x02\x02\u{604}\u{606}\x05\u{218}\u{10d}\x02\u{605}\u{602}\
	\x03\x02\x02\x02\u{605}\u{606}\x03\x02\x02\x02\u{606}\u{6de}\x03\x02\x02\
	\x02\u{607}\u{608}\x09\x0a\x02\x02\u{608}\u{60a}\x07\u{94}\x02\x02\u{609}\
	\u{60b}\x07\u{81}\x02\x02\u{60a}\u{609}\x03\x02\x02\x02\u{60a}\u{60b}\x03\
	\x02\x02\x02\u{60b}\u{60c}\x03\x02\x02\x02\u{60c}\u{6de}\x05\x78\x3d\x02\
	\u{60d}\u{60e}\x09\x0a\x02\x02\u{60e}\u{60f}\x07\u{10c}\x02\x02\u{60f}\u{6de}\
	\x05\u{a2}\x52\x02\u{610}\u{611}\x09\x0a\x02\x02\u{611}\u{613}\x05\x72\x3a\
	\x02\u{612}\u{614}\x07\u{81}\x02\x02\u{613}\u{612}\x03\x02\x02\x02\u{613}\
	\u{614}\x03\x02\x02\x02\u{614}\u{615}\x03\x02\x02\x02\u{615}\u{616}\x05\
	\u{a2}\x52\x02\u{616}\u{6de}\x03\x02\x02\x02\u{617}\u{619}\x09\x0a\x02\x02\
	\u{618}\u{61a}\x07\u{159}\x02\x02\u{619}\u{618}\x03\x02\x02\x02\u{619}\u{61a}\
	\x03\x02\x02\x02\u{61a}\u{61c}\x03\x02\x02\x02\u{61b}\u{61d}\x09\x0b\x02\
	\x02\u{61c}\u{61b}\x03\x02\x02\x02\u{61c}\u{61d}\x03\x02\x02\x02\u{61d}\
	\u{61e}\x03\x02\x02\x02\u{61e}\u{620}\x05\u{a2}\x52\x02\u{61f}\u{621}\x05\
	\x6c\x37\x02\u{620}\u{61f}\x03\x02\x02\x02\u{620}\u{621}\x03\x02\x02\x02\
	\u{621}\u{623}\x03\x02\x02\x02\u{622}\u{624}\x05\x7a\x3e\x02\u{623}\u{622}\
	\x03\x02\x02\x02\u{623}\u{624}\x03\x02\x02\x02\u{624}\u{627}\x03\x02\x02\
	\x02\u{625}\u{626}\x07\x18\x02\x02\u{626}\u{628}\x07\u{bc}\x02\x02\u{627}\
	\u{625}\x03\x02\x02\x02\u{627}\u{628}\x03\x02\x02\x02\u{628}\u{6de}\x03\
	\x02\x02\x02\u{629}\u{62b}\x09\x0a\x02\x02\u{62a}\u{62c}\x07\u{111}\x02\
	\x02\u{62b}\u{62a}\x03\x02\x02\x02\u{62b}\u{62c}\x03\x02\x02\x02\u{62c}\
	\u{62d}\x03\x02\x02\x02\u{62d}\u{6de}\x05\x66\x34\x02\u{62e}\u{62f}\x07\
	\x3d\x02\x02\u{62f}\u{630}\x07\u{f5}\x02\x02\u{630}\u{631}\x05\x72\x3a\x02\
	\u{631}\u{632}\x05\u{a2}\x52\x02\u{632}\u{633}\x07\u{b8}\x02\x02\u{633}\
	\u{634}\x05\u{21a}\u{10e}\x02\u{634}\u{6de}\x03\x02\x02\x02\u{635}\u{636}\
	\x07\x3d\x02\x02\u{636}\u{637}\x07\u{f5}\x02\x02\u{637}\u{638}\x07\u{159}\
	\x02\x02\u{638}\u{639}\x05\u{a2}\x52\x02\u{639}\u{63a}\x07\u{b8}\x02\x02\
	\u{63a}\u{63b}\x05\u{21a}\u{10e}\x02\u{63b}\u{6de}\x03\x02\x02\x02\u{63c}\
	\u{63d}\x07\u{11c}\x02\x02\u{63d}\u{63e}\x07\u{159}\x02\x02\u{63e}\u{6de}\
	\x05\u{a2}\x52\x02\u{63f}\u{640}\x07\u{11c}\x02\x02\u{640}\u{641}\x07\u{94}\
	\x02\x02\u{641}\u{6de}\x05\u{a2}\x52\x02\u{642}\u{64a}\x07\u{11c}\x02\x02\
	\u{643}\u{64b}\x05\u{218}\u{10d}\x02\u{644}\u{646}\x0b\x02\x02\x02\u{645}\
	\u{644}\x03\x02\x02\x02\u{646}\u{649}\x03\x02\x02\x02\u{647}\u{648}\x03\
	\x02\x02\x02\u{647}\u{645}\x03\x02\x02\x02\u{648}\u{64b}\x03\x02\x02\x02\
	\u{649}\u{647}\x03\x02\x02\x02\u{64a}\u{643}\x03\x02\x02\x02\u{64a}\u{647}\
	\x03\x02\x02\x02\u{64b}\u{6de}\x03\x02\x02\x02\u{64c}\u{64e}\x07\x28\x02\
	\x02\u{64d}\u{64f}\x07\u{c2}\x02\x02\u{64e}\u{64d}\x03\x02\x02\x02\u{64e}\
	\u{64f}\x03\x02\x02\x02\u{64f}\u{650}\x03\x02\x02\x02\u{650}\u{651}\x07\
	\u{159}\x02\x02\u{651}\u{654}\x05\u{a2}\x52\x02\u{652}\u{653}\x07\u{f8}\
	\x02\x02\u{653}\u{655}\x05\u{84}\x43\x02\u{654}\u{652}\x03\x02\x02\x02\u{654}\
	\u{655}\x03\x02\x02\x02\u{655}\u{65a}\x03\x02\x02\x02\u{656}\u{658}\x07\
	\x18\x02\x02\u{657}\u{656}\x03\x02\x02\x02\u{657}\u{658}\x03\x02\x02\x02\
	\u{658}\u{659}\x03\x02\x02\x02\u{659}\u{65b}\x05\x66\x34\x02\u{65a}\u{657}\
	\x03\x02\x02\x02\u{65a}\u{65b}\x03\x02\x02\x02\u{65b}\u{6de}\x03\x02\x02\
	\x02\u{65c}\u{65d}\x07\u{177}\x02\x02\u{65d}\u{660}\x07\u{159}\x02\x02\u{65e}\
	\u{65f}\x07\u{a4}\x02\x02\u{65f}\u{661}\x07\x7c\x02\x02\u{660}\u{65e}\x03\
	\x02\x02\x02\u{660}\u{661}\x03\x02\x02\x02\u{661}\u{662}\x03\x02\x02\x02\
	\u{662}\u{6de}\x05\u{a2}\x52\x02\u{663}\u{664}\x07\x34\x02\x02\u{664}\u{6de}\
	\x07\x28\x02\x02\u{665}\u{666}\x07\u{cc}\x02\x02\u{666}\u{668}\x07\x54\x02\
	\x02\u{667}\u{669}\x07\u{cd}\x02\x02\u{668}\u{667}\x03\x02\x02\x02\u{668}\
	\u{669}\x03\x02\x02\x02\u{669}\u{66a}\x03\x02\x02\x02\u{66a}\u{66b}\x07\
	\u{ae}\x02\x02\u{66b}\u{66d}\x05\u{218}\u{10d}\x02\u{66c}\u{66e}\x07\u{101}\
	\x02\x02\u{66d}\u{66c}\x03\x02\x02\x02\u{66d}\u{66e}\x03\x02\x02\x02\u{66e}\
	\u{66f}\x03\x02\x02\x02\u{66f}\u{670}\x07\u{b6}\x02\x02\u{670}\u{671}\x07\
	\u{159}\x02\x02\u{671}\u{673}\x05\u{a2}\x52\x02\u{672}\u{674}\x05\x6c\x37\
	\x02\u{673}\u{672}\x03\x02\x02\x02\u{673}\u{674}\x03\x02\x02\x02\u{674}\
	\u{6de}\x03\x02\x02\x02\u{675}\u{676}\x07\u{172}\x02\x02\u{676}\u{677}\x07\
	\u{159}\x02\x02\u{677}\u{679}\x05\u{a2}\x52\x02\u{678}\u{67a}\x05\x6c\x37\
	\x02\u{679}\u{678}\x03\x02\x02\x02\u{679}\u{67a}\x03\x02\x02\x02\u{67a}\
	\u{6de}\x03\x02\x02\x02\u{67b}\u{67d}\x07\u{e5}\x02\x02\u{67c}\u{67b}\x03\
	\x02\x02\x02\u{67c}\u{67d}\x03\x02\x02\x02\u{67d}\u{67e}\x03\x02\x02\x02\
	\u{67e}\u{67f}\x07\u{11f}\x02\x02\u{67f}\u{680}\x07\u{159}\x02\x02\u{680}\
	\u{683}\x05\u{a2}\x52\x02\u{681}\u{682}\x09\x0c\x02\x02\u{682}\u{684}\x07\
	\u{104}\x02\x02\u{683}\u{681}\x03\x02\x02\x02\u{683}\u{684}\x03\x02\x02\
	\x02\u{684}\u{6de}\x03\x02\x02\x02\u{685}\u{686}\x09\x0d\x02\x02\u{686}\
	\u{68a}\x05\u{1e6}\u{f4}\x02\u{687}\u{689}\x0b\x02\x02\x02\u{688}\u{687}\
	\x03\x02\x02\x02\u{689}\u{68c}\x03\x02\x02\x02\u{68a}\u{68b}\x03\x02\x02\
	\x02\u{68a}\u{688}\x03\x02\x02\x02\u{68b}\u{6de}\x03\x02\x02\x02\u{68c}\
	\u{68a}\x03\x02\x02\x02\u{68d}\u{68e}\x07\x49\x02\x02\u{68e}\u{693}\x07\
	\u{ab}\x02\x02\u{68f}\u{690}\x07\u{a4}\x02\x02\u{690}\u{691}\x05\u{15a}\
	\u{ae}\x02\u{691}\u{692}\x07\x7c\x02\x02\u{692}\u{694}\x03\x02\x02\x02\u{693}\
	\u{68f}\x03\x02\x02\x02\u{693}\u{694}\x03\x02\x02\x02\u{694}\u{695}\x03\
	\x02\x02\x02\u{695}\u{696}\x05\u{1e4}\u{f3}\x02\u{696}\u{698}\x07\u{f5}\
	\x02\x02\u{697}\u{699}\x07\u{159}\x02\x02\u{698}\u{697}\x03\x02\x02\x02\
	\u{698}\u{699}\x03\x02\x02\x02\u{699}\u{69a}\x03\x02\x02\x02\u{69a}\u{69d}\
	\x05\u{a2}\x52\x02\u{69b}\u{69c}\x07\u{182}\x02\x02\u{69c}\u{69e}\x05\u{1e4}\
	\u{f3}\x02\u{69d}\u{69b}\x03\x02\x02\x02\u{69d}\u{69e}\x03\x02\x02\x02\u{69e}\
	\u{69f}\x03\x02\x02\x02\u{69f}\u{6a0}\x07\x04\x02\x02\u{6a0}\u{6a1}\x05\
	\u{13a}\u{9e}\x02\u{6a1}\u{6a4}\x07\x05\x02\x02\u{6a2}\u{6a3}\x07\u{f8}\
	\x02\x02\u{6a3}\u{6a5}\x05\u{84}\x43\x02\u{6a4}\u{6a2}\x03\x02\x02\x02\u{6a4}\
	\u{6a5}\x03\x02\x02\x02\u{6a5}\u{6de}\x03\x02\x02\x02\u{6a6}\u{6a7}\x07\
	\x71\x02\x02\u{6a7}\u{6aa}\x07\u{ab}\x02\x02\u{6a8}\u{6a9}\x07\u{a4}\x02\
	\x02\u{6a9}\u{6ab}\x07\x7c\x02\x02\u{6aa}\u{6a8}\x03\x02\x02\x02\u{6aa}\
	\u{6ab}\x03\x02\x02\x02\u{6ab}\u{6ac}\x03\x02\x02\x02\u{6ac}\u{6ad}\x05\
	\u{1e4}\u{f3}\x02\u{6ad}\u{6af}\x07\u{f5}\x02\x02\u{6ae}\u{6b0}\x07\u{159}\
	\x02\x02\u{6af}\u{6ae}\x03\x02\x02\x02\u{6af}\u{6b0}\x03\x02\x02\x02\u{6b0}\
	\u{6b1}\x03\x02\x02\x02\u{6b1}\u{6b2}\x05\u{a2}\x52\x02\u{6b2}\u{6de}\x03\
	\x02\x02\x02\u{6b3}\u{6b4}\x07\x29\x02\x02\u{6b4}\u{6b5}\x05\u{a2}\x52\x02\
	\u{6b5}\u{6be}\x07\x04\x02\x02\u{6b6}\u{6bb}\x05\u{152}\u{aa}\x02\u{6b7}\
	\u{6b8}\x07\x06\x02\x02\u{6b8}\u{6ba}\x05\u{152}\u{aa}\x02\u{6b9}\u{6b7}\
	\x03\x02\x02\x02\u{6ba}\u{6bd}\x03\x02\x02\x02\u{6bb}\u{6b9}\x03\x02\x02\
	\x02\u{6bb}\u{6bc}\x03\x02\x02\x02\u{6bc}\u{6bf}\x03\x02\x02\x02\u{6bd}\
	\u{6bb}\x03\x02\x02\x02\u{6be}\u{6b6}\x03\x02\x02\x02\u{6be}\u{6bf}\x03\
	\x02\x02\x02\u{6bf}\u{6c0}\x03\x02\x02\x02\u{6c0}\u{6c1}\x07\x05\x02\x02\
	\u{6c1}\u{6de}\x03\x02\x02\x02\u{6c2}\u{6c6}\x05\x52\x2a\x02\u{6c3}\u{6c5}\
	\x0b\x02\x02\x02\u{6c4}\u{6c3}\x03\x02\x02\x02\u{6c5}\u{6c8}\x03\x02\x02\
	\x02\u{6c6}\u{6c7}\x03\x02\x02\x02\u{6c6}\u{6c4}\x03\x02\x02\x02\u{6c7}\
	\u{6de}\x03\x02\x02\x02\u{6c8}\u{6c6}\x03\x02\x02\x02\u{6c9}\u{6cf}\x05\
	\x42\x22\x02\u{6ca}\u{6cc}\x07\x04\x02\x02\u{6cb}\u{6cd}\x05\u{1a8}\u{d5}\
	\x02\u{6cc}\u{6cb}\x03\x02\x02\x02\u{6cc}\u{6cd}\x03\x02\x02\x02\u{6cd}\
	\u{6ce}\x03\x02\x02\x02\u{6ce}\u{6d0}\x07\x05\x02\x02\u{6cf}\u{6ca}\x03\
	\x02\x02\x02\u{6cf}\u{6d0}\x03\x02\x02\x02\u{6d0}\u{6d2}\x03\x02\x02\x02\
	\u{6d1}\u{6d3}\x05\u{80}\x41\x02\u{6d2}\u{6d1}\x03\x02\x02\x02\u{6d2}\u{6d3}\
	\x03\x02\x02\x02\u{6d3}\u{6d4}\x03\x02\x02\x02\u{6d4}\u{6d7}\x05\u{82}\x42\
	\x02\u{6d5}\u{6d6}\x07\x18\x02\x02\u{6d6}\u{6d8}\x05\x66\x34\x02\u{6d7}\
	\u{6d5}\x03\x02\x02\x02\u{6d7}\u{6d8}\x03\x02\x02\x02\u{6d8}\u{6de}\x03\
	\x02\x02\x02\u{6d9}\u{6da}\x05\x70\x39\x02\u{6da}\u{6db}\x05\x68\x35\x02\
	\u{6db}\u{6dc}\x05\x66\x34\x02\u{6dc}\u{6de}\x03\x02\x02\x02\u{6dd}\u{32f}\
	\x03\x02\x02\x02\u{6dd}\u{330}\x03\x02\x02\x02\u{6dd}\u{332}\x03\x02\x02\
	\x02\u{6dd}\u{335}\x03\x02\x02\x02\u{6dd}\u{337}\x03\x02\x02\x02\u{6dd}\
	\u{33b}\x03\x02\x02\x02\u{6dd}\u{33e}\x03\x02\x02\x02\u{6dd}\u{352}\x03\
	\x02\x02\x02\u{6dd}\u{359}\x03\x02\x02\x02\u{6dd}\u{360}\x03\x02\x02\x02\
	\u{6dd}\u{365}\x03\x02\x02\x02\u{6dd}\u{36b}\x03\x02\x02\x02\u{6dd}\u{375}\
	\x03\x02\x02\x02\u{6dd}\u{381}\x03\x02\x02\x02\u{6dd}\u{392}\x03\x02\x02\
	\x02\u{6dd}\u{3a8}\x03\x02\x02\x02\u{6dd}\u{3b9}\x03\x02\x02\x02\u{6dd}\
	\u{3ca}\x03\x02\x02\x02\u{6dd}\u{3d5}\x03\x02\x02\x02\u{6dd}\u{3dc}\x03\
	\x02\x02\x02\u{6dd}\u{3e5}\x03\x02\x02\x02\u{6dd}\u{3ee}\x03\x02\x02\x02\
	\u{6dd}\u{3fb}\x03\x02\x02\x02\u{6dd}\u{406}\x03\x02\x02\x02\u{6dd}\u{40d}\
	\x03\x02\x02\x02\u{6dd}\u{414}\x03\x02\x02\x02\u{6dd}\u{41f}\x03\x02\x02\
	\x02\u{6dd}\u{428}\x03\x02\x02\x02\u{6dd}\u{437}\x03\x02\x02\x02\u{6dd}\
	\u{443}\x03\x02\x02\x02\u{6dd}\u{451}\x03\x02\x02\x02\u{6dd}\u{45b}\x03\
	\x02\x02\x02\u{6dd}\u{46a}\x03\x02\x02\x02\u{6dd}\u{472}\x03\x02\x02\x02\
	\u{6dd}\u{485}\x03\x02\x02\x02\u{6dd}\u{48e}\x03\x02\x02\x02\u{6dd}\u{494}\
	\x03\x02\x02\x02\u{6dd}\u{49d}\x03\x02\x02\x02\u{6dd}\u{4a2}\x03\x02\x02\
	\x02\u{6dd}\u{4a8}\x03\x02\x02\x02\u{6dd}\u{4b5}\x03\x02\x02\x02\u{6dd}\
	\u{4bf}\x03\x02\x02\x02\u{6dd}\u{4c6}\x03\x02\x02\x02\u{6dd}\u{4ec}\x03\
	\x02\x02\x02\u{6dd}\u{50a}\x03\x02\x02\x02\u{6dd}\u{520}\x03\x02\x02\x02\
	\u{6dd}\u{528}\x03\x02\x02\x02\u{6dd}\u{52d}\x03\x02\x02\x02\u{6dd}\u{54a}\
	\x03\x02\x02\x02\u{6dd}\u{570}\x03\x02\x02\x02\u{6dd}\u{57a}\x03\x02\x02\
	\x02\u{6dd}\u{590}\x03\x02\x02\x02\u{6dd}\u{599}\x03\x02\x02\x02\u{6dd}\
	\u{5a1}\x03\x02\x02\x02\u{6dd}\u{5ad}\x03\x02\x02\x02\u{6dd}\u{5b9}\x03\
	\x02\x02\x02\u{6dd}\u{5c2}\x03\x02\x02\x02\u{6dd}\u{5ca}\x03\x02\x02\x02\
	\u{6dd}\u{5d6}\x03\x02\x02\x02\u{6dd}\u{5dc}\x03\x02\x02\x02\u{6dd}\u{5ee}\
	\x03\x02\x02\x02\u{6dd}\u{5f4}\x03\x02\x02\x02\u{6dd}\u{5fc}\x03\x02\x02\
	\x02\u{6dd}\u{5ff}\x03\x02\x02\x02\u{6dd}\u{607}\x03\x02\x02\x02\u{6dd}\
	\u{60d}\x03\x02\x02\x02\u{6dd}\u{610}\x03\x02\x02\x02\u{6dd}\u{617}\x03\
	\x02\x02\x02\u{6dd}\u{629}\x03\x02\x02\x02\u{6dd}\u{62e}\x03\x02\x02\x02\
	\u{6dd}\u{635}\x03\x02\x02\x02\u{6dd}\u{63c}\x03\x02\x02\x02\u{6dd}\u{63f}\
	\x03\x02\x02\x02\u{6dd}\u{642}\x03\x02\x02\x02\u{6dd}\u{64c}\x03\x02\x02\
	\x02\u{6dd}\u{65c}\x03\x02\x02\x02\u{6dd}\u{663}\x03\x02\x02\x02\u{6dd}\
	\u{665}\x03\x02\x02\x02\u{6dd}\u{675}\x03\x02\x02\x02\u{6dd}\u{67c}\x03\
	\x02\x02\x02\u{6dd}\u{685}\x03\x02\x02\x02\u{6dd}\u{68d}\x03\x02\x02\x02\
	\u{6dd}\u{6a6}\x03\x02\x02\x02\u{6dd}\u{6b3}\x03\x02\x02\x02\u{6dd}\u{6c2}\
	\x03\x02\x02\x02\u{6dd}\u{6c9}\x03\x02\x02\x02\u{6dd}\u{6d9}\x03\x02\x02\
	\x02\u{6de}\x3d\x03\x02\x02\x02\u{6df}\u{6e0}\x07\u{d7}\x02\x02\u{6e0}\u{6e1}\
	\x07\u{18a}\x02\x02\u{6e1}\x3f\x03\x02\x02\x02\u{6e2}\u{6e3}\x07\u{151}\
	\x02\x02\u{6e3}\u{6e4}\x07\u{159}\x02\x02\u{6e4}\x41\x03\x02\x02\x02\u{6e5}\
	\u{6e8}\x07\x49\x02\x02\u{6e6}\u{6e9}\x05\x3e\x20\x02\u{6e7}\u{6e9}\x05\
	\x40\x21\x02\u{6e8}\u{6e6}\x03\x02\x02\x02\u{6e8}\u{6e7}\x03\x02\x02\x02\
	\u{6e9}\u{6ee}\x03\x02\x02\x02\u{6ea}\u{6eb}\x07\u{a4}\x02\x02\u{6eb}\u{6ec}\
	\x05\u{15a}\u{ae}\x02\u{6ec}\u{6ed}\x07\x7c\x02\x02\u{6ed}\u{6ef}\x03\x02\
	\x02\x02\u{6ee}\u{6ea}\x03\x02\x02\x02\u{6ee}\u{6ef}\x03\x02\x02\x02\u{6ef}\
	\u{6f0}\x03\x02\x02\x02\u{6f0}\u{6f1}\x05\u{a2}\x52\x02\u{6f1}\x43\x03\x02\
	\x02\x02\u{6f2}\u{6f3}\x07\u{150}\x02\x02\u{6f3}\u{6f5}\x05\u{138}\u{9d}\
	\x02\u{6f4}\u{6f6}\x05\u{122}\u{92}\x02\u{6f5}\u{6f4}\x03\x02\x02\x02\u{6f5}\
	\u{6f6}\x03\x02\x02\x02\u{6f6}\u{6f8}\x03\x02\x02\x02\u{6f7}\u{6f9}\x05\
	\u{102}\u{82}\x02\u{6f8}\u{6f7}\x03\x02\x02\x02\u{6f8}\u{6f9}\x03\x02\x02\
	\x02\u{6f9}\u{6fa}\x03\x02\x02\x02\u{6fa}\u{6fb}\x05\u{132}\u{9a}\x02\u{6fb}\
	\u{709}\x03\x02\x02\x02\u{6fc}\u{6fd}\x07\u{150}\x02\x02\u{6fd}\u{6fe}\x07\
	\x04\x02\x02\u{6fe}\u{6ff}\x05\u{138}\u{9d}\x02\u{6ff}\u{701}\x07\x05\x02\
	\x02\u{700}\u{702}\x05\u{122}\u{92}\x02\u{701}\u{700}\x03\x02\x02\x02\u{701}\
	\u{702}\x03\x02\x02\x02\u{702}\u{704}\x03\x02\x02\x02\u{703}\u{705}\x05\
	\u{102}\u{82}\x02\u{704}\u{703}\x03\x02\x02\x02\u{704}\u{705}\x03\x02\x02\
	\x02\u{705}\u{706}\x03\x02\x02\x02\u{706}\u{707}\x05\u{132}\u{9a}\x02\u{707}\
	\u{709}\x03\x02\x02\x02\u{708}\u{6f2}\x03\x02\x02\x02\u{708}\u{6fc}\x03\
	\x02\x02\x02\u{709}\x45\x03\x02\x02\x02\u{70a}\u{70b}\x07\u{13c}\x02\x02\
	\u{70b}\u{70f}\x07\u{12b}\x02\x02\u{70c}\u{70e}\x0b\x02\x02\x02\u{70d}\u{70c}\
	\x03\x02\x02\x02\u{70e}\u{711}\x03\x02\x02\x02\u{70f}\u{710}\x03\x02\x02\
	\x02\u{70f}\u{70d}\x03\x02\x02\x02\u{710}\u{75b}\x03\x02\x02\x02\u{711}\
	\u{70f}\x03\x02\x02\x02\u{712}\u{713}\x07\u{13c}\x02\x02\u{713}\u{714}\x07\
	\u{161}\x02\x02\u{714}\u{715}\x07\u{199}\x02\x02\u{715}\u{75b}\x05\u{17c}\
	\u{bf}\x02\u{716}\u{717}\x07\u{13c}\x02\x02\u{717}\u{718}\x07\u{161}\x02\
	\x02\u{718}\u{719}\x07\u{199}\x02\x02\u{719}\u{75b}\x05\x4c\x27\x02\u{71a}\
	\u{71b}\x07\u{13c}\x02\x02\u{71b}\u{71c}\x07\u{161}\x02\x02\u{71c}\u{720}\
	\x07\u{199}\x02\x02\u{71d}\u{71f}\x0b\x02\x02\x02\u{71e}\u{71d}\x03\x02\
	\x02\x02\u{71f}\u{722}\x03\x02\x02\x02\u{720}\u{721}\x03\x02\x02\x02\u{720}\
	\u{71e}\x03\x02\x02\x02\u{721}\u{75b}\x03\x02\x02\x02\u{722}\u{720}\x03\
	\x02\x02\x02\u{723}\u{724}\x07\u{13c}\x02\x02\u{724}\u{725}\x05\x76\x3c\
	\x02\u{725}\u{726}\x05\u{ca}\x66\x02\u{726}\u{75b}\x03\x02\x02\x02\u{727}\
	\u{728}\x07\u{13c}\x02\x02\u{728}\u{729}\x05\x76\x3c\x02\u{729}\u{72a}\x07\
	\x04\x02\x02\u{72a}\u{72b}\x05\u{136}\u{9c}\x02\u{72b}\u{72c}\x07\x05\x02\
	\x02\u{72c}\u{72d}\x07\u{19a}\x02\x02\u{72d}\u{72e}\x07\x04\x02\x02\u{72e}\
	\u{72f}\x05\x66\x34\x02\u{72f}\u{730}\x07\x05\x02\x02\u{730}\u{75b}\x03\
	\x02\x02\x02\u{731}\u{732}\x07\u{13c}\x02\x02\u{732}\u{733}\x05\x4e\x28\
	\x02\u{733}\u{734}\x07\u{19a}\x02\x02\u{734}\u{735}\x05\x50\x29\x02\u{735}\
	\u{75b}\x03\x02\x02\x02\u{736}\u{737}\x07\u{13c}\x02\x02\u{737}\u{73f}\x05\
	\x4e\x28\x02\u{738}\u{73c}\x07\u{19a}\x02\x02\u{739}\u{73b}\x0b\x02\x02\
	\x02\u{73a}\u{739}\x03\x02\x02\x02\u{73b}\u{73e}\x03\x02\x02\x02\u{73c}\
	\u{73d}\x03\x02\x02\x02\u{73c}\u{73a}\x03\x02\x02\x02\u{73d}\u{740}\x03\
	\x02\x02\x02\u{73e}\u{73c}\x03\x02\x02\x02\u{73f}\u{738}\x03\x02\x02\x02\
	\u{73f}\u{740}\x03\x02\x02\x02\u{740}\u{75b}\x03\x02\x02\x02\u{741}\u{745}\
	\x07\u{13c}\x02\x02\u{742}\u{744}\x0b\x02\x02\x02\u{743}\u{742}\x03\x02\
	\x02\x02\u{744}\u{747}\x03\x02\x02\x02\u{745}\u{746}\x03\x02\x02\x02\u{745}\
	\u{743}\x03\x02\x02\x02\u{746}\u{748}\x03\x02\x02\x02\u{747}\u{745}\x03\
	\x02\x02\x02\u{748}\u{749}\x07\u{19a}\x02\x02\u{749}\u{75b}\x05\x50\x29\
	\x02\u{74a}\u{74e}\x07\u{13c}\x02\x02\u{74b}\u{74d}\x0b\x02\x02\x02\u{74c}\
	\u{74b}\x03\x02\x02\x02\u{74d}\u{750}\x03\x02\x02\x02\u{74e}\u{74f}\x03\
	\x02\x02\x02\u{74e}\u{74c}\x03\x02\x02\x02\u{74f}\u{75b}\x03\x02\x02\x02\
	\u{750}\u{74e}\x03\x02\x02\x02\u{751}\u{752}\x07\u{123}\x02\x02\u{752}\u{75b}\
	\x05\x4e\x28\x02\u{753}\u{757}\x07\u{123}\x02\x02\u{754}\u{756}\x0b\x02\
	\x02\x02\u{755}\u{754}\x03\x02\x02\x02\u{756}\u{759}\x03\x02\x02\x02\u{757}\
	\u{758}\x03\x02\x02\x02\u{757}\u{755}\x03\x02\x02\x02\u{758}\u{75b}\x03\
	\x02\x02\x02\u{759}\u{757}\x03\x02\x02\x02\u{75a}\u{70a}\x03\x02\x02\x02\
	\u{75a}\u{712}\x03\x02\x02\x02\u{75a}\u{716}\x03\x02\x02\x02\u{75a}\u{71a}\
	\x03\x02\x02\x02\u{75a}\u{723}\x03\x02\x02\x02\u{75a}\u{727}\x03\x02\x02\
	\x02\u{75a}\u{731}\x03\x02\x02\x02\u{75a}\u{736}\x03\x02\x02\x02\u{75a}\
	\u{741}\x03\x02\x02\x02\u{75a}\u{74a}\x03\x02\x02\x02\u{75a}\u{751}\x03\
	\x02\x02\x02\u{75a}\u{753}\x03\x02\x02\x02\u{75b}\x47\x03\x02\x02\x02\u{75c}\
	\u{75d}\x07\u{16a}\x02\x02\u{75d}\u{75e}\x07\u{a6}\x02\x02\u{75e}\u{761}\
	\x05\u{14e}\u{a8}\x02\u{75f}\u{760}\x07\u{b6}\x02\x02\u{760}\u{762}\x05\
	\u{136}\u{9c}\x02\u{761}\u{75f}\x03\x02\x02\x02\u{761}\u{762}\x03\x02\x02\
	\x02\u{762}\u{764}\x03\x02\x02\x02\u{763}\u{765}\x05\x4a\x26\x02\u{764}\
	\u{763}\x03\x02\x02\x02\u{764}\u{765}\x03\x02\x02\x02\u{765}\x49\x03\x02\
	\x02\x02\u{766}\u{767}\x07\u{182}\x02\x02\u{767}\u{768}\x07\x04\x02\x02\
	\u{768}\u{769}\x05\u{144}\u{a3}\x02\u{769}\u{76a}\x07\x05\x02\x02\u{76a}\
	\u{76e}\x03\x02\x02\x02\u{76b}\u{76c}\x07\u{182}\x02\x02\u{76c}\u{76e}\x05\
	\u{144}\u{a3}\x02\u{76d}\u{766}\x03\x02\x02\x02\u{76d}\u{76b}\x03\x02\x02\
	\x02\u{76e}\x4b\x03\x02\x02\x02\u{76f}\u{772}\x05\u{218}\u{10d}\x02\u{770}\
	\u{772}\x07\u{cd}\x02\x02\u{771}\u{76f}\x03\x02\x02\x02\u{771}\u{770}\x03\
	\x02\x02\x02\u{772}\x4d\x03\x02\x02\x02\u{773}\u{774}\x05\u{1ec}\u{f7}\x02\
	\u{774}\x4f\x03\x02\x02\x02\u{775}\u{776}\x05\u{1ee}\u{f8}\x02\u{776}\x51\
	\x03\x02\x02\x02\u{777}\u{778}\x07\x49\x02\x02\u{778}\u{820}\x07\u{12b}\
	\x02\x02\u{779}\u{77a}\x07\x71\x02\x02\u{77a}\u{820}\x07\u{12b}\x02\x02\
	\u{77b}\u{77d}\x07\u{9a}\x02\x02\u{77c}\u{77e}\x07\u{12b}\x02\x02\u{77d}\
	\u{77c}\x03\x02\x02\x02\u{77d}\u{77e}\x03\x02\x02\x02\u{77e}\u{820}\x03\
	\x02\x02\x02\u{77f}\u{781}\x07\u{128}\x02\x02\u{780}\u{782}\x07\u{12b}\x02\
	\x02\u{781}\u{780}\x03\x02\x02\x02\u{781}\u{782}\x03\x02\x02\x02\u{782}\
	\u{820}\x03\x02\x02\x02\u{783}\u{784}\x07\u{140}\x02\x02\u{784}\u{820}\x07\
	\u{9a}\x02\x02\u{785}\u{786}\x07\u{140}\x02\x02\u{786}\u{788}\x07\u{12b}\
	\x02\x02\u{787}\u{789}\x07\u{9a}\x02\x02\u{788}\u{787}\x03\x02\x02\x02\u{788}\
	\u{789}\x03\x02\x02\x02\u{789}\u{820}\x03\x02\x02\x02\u{78a}\u{78b}\x07\
	\u{140}\x02\x02\u{78b}\u{820}\x07\u{10b}\x02\x02\u{78c}\u{78d}\x07\u{140}\
	\x02\x02\u{78d}\u{820}\x07\u{12c}\x02\x02\u{78e}\u{78f}\x07\u{140}\x02\x02\
	\u{78f}\u{790}\x07\x4c\x02\x02\u{790}\u{820}\x07\u{12c}\x02\x02\u{791}\u{792}\
	\x07\x7f\x02\x02\u{792}\u{820}\x07\u{159}\x02\x02\u{793}\u{794}\x07\u{a7}\
	\x02\x02\u{794}\u{820}\x07\u{159}\x02\x02\u{795}\u{796}\x07\u{140}\x02\x02\
	\u{796}\u{820}\x07\x40\x02\x02\u{797}\u{798}\x07\u{140}\x02\x02\u{798}\u{799}\
	\x07\x49\x02\x02\u{799}\u{820}\x07\u{159}\x02\x02\u{79a}\u{79b}\x07\u{140}\
	\x02\x02\u{79b}\u{820}\x07\u{16e}\x02\x02\u{79c}\u{79d}\x07\u{140}\x02\x02\
	\u{79d}\u{820}\x07\u{ac}\x02\x02\u{79e}\u{79f}\x07\u{140}\x02\x02\u{79f}\
	\u{820}\x07\u{d0}\x02\x02\u{7a0}\u{7a1}\x07\x49\x02\x02\u{7a1}\u{820}\x07\
	\u{ab}\x02\x02\u{7a2}\u{7a3}\x07\x71\x02\x02\u{7a3}\u{820}\x07\u{ab}\x02\
	\x02\u{7a4}\u{7a5}\x07\x0f\x02\x02\u{7a5}\u{820}\x07\u{ab}\x02\x02\u{7a6}\
	\u{7a7}\x07\u{cf}\x02\x02\u{7a7}\u{820}\x07\u{159}\x02\x02\u{7a8}\u{7a9}\
	\x07\u{cf}\x02\x02\u{7a9}\u{820}\x07\x56\x02\x02\u{7aa}\u{7ab}\x07\u{17b}\
	\x02\x02\u{7ab}\u{820}\x07\u{159}\x02\x02\u{7ac}\u{7ad}\x07\u{17b}\x02\x02\
	\u{7ad}\u{820}\x07\x56\x02\x02\u{7ae}\u{7af}\x07\x49\x02\x02\u{7af}\u{7b0}\
	\x07\u{15e}\x02\x02\u{7b0}\u{820}\x07\u{d4}\x02\x02\u{7b1}\u{7b2}\x07\x71\
	\x02\x02\u{7b2}\u{7b3}\x07\u{15e}\x02\x02\u{7b3}\u{820}\x07\u{d4}\x02\x02\
	\u{7b4}\u{7b5}\x07\x0f\x02\x02\u{7b5}\u{7b6}\x07\u{159}\x02\x02\u{7b6}\u{7b7}\
	\x05\u{13e}\u{a0}\x02\u{7b7}\u{7b8}\x07\u{ee}\x02\x02\u{7b8}\u{7b9}\x07\
	\x36\x02\x02\u{7b9}\u{820}\x03\x02\x02\x02\u{7ba}\u{7bb}\x07\x0f\x02\x02\
	\u{7bb}\u{7bc}\x07\u{159}\x02\x02\u{7bc}\u{7bd}\x05\u{13e}\u{a0}\x02\u{7bd}\
	\u{7be}\x07\x36\x02\x02\u{7be}\u{7bf}\x07\x26\x02\x02\u{7bf}\u{820}\x03\
	\x02\x02\x02\u{7c0}\u{7c1}\x07\x0f\x02\x02\u{7c1}\u{7c2}\x07\u{159}\x02\
	\x02\u{7c2}\u{7c3}\x05\u{13e}\u{a0}\x02\u{7c3}\u{7c4}\x07\u{ee}\x02\x02\
	\u{7c4}\u{7c5}\x07\u{146}\x02\x02\u{7c5}\u{820}\x03\x02\x02\x02\u{7c6}\u{7c7}\
	\x07\x0f\x02\x02\u{7c7}\u{7c8}\x07\u{159}\x02\x02\u{7c8}\u{7c9}\x05\u{13e}\
	\u{a0}\x02\u{7c9}\u{7ca}\x07\u{142}\x02\x02\u{7ca}\u{7cb}\x07\x26\x02\x02\
	\u{7cb}\u{820}\x03\x02\x02\x02\u{7cc}\u{7cd}\x07\x0f\x02\x02\u{7cd}\u{7ce}\
	\x07\u{159}\x02\x02\u{7ce}\u{7cf}\x05\u{13e}\u{a0}\x02\u{7cf}\u{7d0}\x07\
	\u{ee}\x02\x02\u{7d0}\u{7d1}\x07\u{142}\x02\x02\u{7d1}\u{820}\x03\x02\x02\
	\x02\u{7d2}\u{7d3}\x07\x0f\x02\x02\u{7d3}\u{7d4}\x07\u{159}\x02\x02\u{7d4}\
	\u{7d5}\x05\u{13e}\u{a0}\x02\u{7d5}\u{7d6}\x07\u{ee}\x02\x02\u{7d6}\u{7d7}\
	\x07\u{14e}\x02\x02\u{7d7}\u{7d8}\x07\x18\x02\x02\u{7d8}\u{7d9}\x07\x6a\
	\x02\x02\u{7d9}\u{820}\x03\x02\x02\x02\u{7da}\u{7db}\x07\x0f\x02\x02\u{7db}\
	\u{7dc}\x07\u{159}\x02\x02\u{7dc}\u{7dd}\x05\u{13e}\u{a0}\x02\u{7dd}\u{7de}\
	\x07\u{13c}\x02\x02\u{7de}\u{7df}\x07\u{142}\x02\x02\u{7df}\u{7e0}\x07\u{ce}\
	\x02\x02\u{7e0}\u{820}\x03\x02\x02\x02\u{7e1}\u{7e2}\x07\x0f\x02\x02\u{7e2}\
	\u{7e3}\x07\u{159}\x02\x02\u{7e3}\u{7e4}\x05\u{13e}\u{a0}\x02\u{7e4}\u{7e5}\
	\x07\x7a\x02\x02\u{7e5}\u{7e6}\x07\u{102}\x02\x02\u{7e6}\u{820}\x03\x02\
	\x02\x02\u{7e7}\u{7e8}\x07\x0f\x02\x02\u{7e8}\u{7e9}\x07\u{159}\x02\x02\
	\u{7e9}\u{7ea}\x05\u{13e}\u{a0}\x02\u{7ea}\u{7eb}\x07\x16\x02\x02\u{7eb}\
	\u{7ec}\x07\u{102}\x02\x02\u{7ec}\u{820}\x03\x02\x02\x02\u{7ed}\u{7ee}\x07\
	\x0f\x02\x02\u{7ee}\u{7ef}\x07\u{159}\x02\x02\u{7ef}\u{7f0}\x05\u{13e}\u{a0}\
	\x02\u{7f0}\u{7f1}\x07\u{175}\x02\x02\u{7f1}\u{7f2}\x07\u{102}\x02\x02\u{7f2}\
	\u{820}\x03\x02\x02\x02\u{7f3}\u{7f4}\x07\x0f\x02\x02\u{7f4}\u{7f5}\x07\
	\u{159}\x02\x02\u{7f5}\u{7f6}\x05\u{13e}\u{a0}\x02\u{7f6}\u{7f7}\x07\u{16b}\
	\x02\x02\u{7f7}\u{820}\x03\x02\x02\x02\u{7f8}\u{7f9}\x07\x0f\x02\x02\u{7f9}\
	\u{7fa}\x07\u{159}\x02\x02\u{7fa}\u{7fc}\x05\u{13e}\u{a0}\x02\u{7fb}\u{7fd}\
	\x05\x6c\x37\x02\u{7fc}\u{7fb}\x03\x02\x02\x02\u{7fc}\u{7fd}\x03\x02\x02\
	\x02\u{7fd}\u{7fe}\x03\x02\x02\x02\u{7fe}\u{7ff}\x07\x3f\x02\x02\u{7ff}\
	\u{820}\x03\x02\x02\x02\u{800}\u{801}\x07\x0f\x02\x02\u{801}\u{802}\x07\
	\u{159}\x02\x02\u{802}\u{804}\x05\u{13e}\u{a0}\x02\u{803}\u{805}\x05\x6c\
	\x37\x02\u{804}\u{803}\x03\x02\x02\x02\u{804}\u{805}\x03\x02\x02\x02\u{805}\
	\u{806}\x03\x02\x02\x02\u{806}\u{807}\x07\x43\x02\x02\u{807}\u{820}\x03\
	\x02\x02\x02\u{808}\u{809}\x07\x0f\x02\x02\u{809}\u{80a}\x07\u{159}\x02\
	\x02\u{80a}\u{80c}\x05\u{13e}\u{a0}\x02\u{80b}\u{80d}\x05\x6c\x37\x02\u{80c}\
	\u{80b}\x03\x02\x02\x02\u{80c}\u{80d}\x03\x02\x02\x02\u{80d}\u{80e}\x03\
	\x02\x02\x02\u{80e}\u{80f}\x07\u{13c}\x02\x02\u{80f}\u{810}\x07\u{88}\x02\
	\x02\u{810}\u{820}\x03\x02\x02\x02\u{811}\u{812}\x07\x0f\x02\x02\u{812}\
	\u{813}\x07\u{159}\x02\x02\u{813}\u{815}\x05\u{13e}\u{a0}\x02\u{814}\u{816}\
	\x05\x6c\x37\x02\u{815}\u{814}\x03\x02\x02\x02\u{815}\u{816}\x03\x02\x02\
	\x02\u{816}\u{817}\x03\x02\x02\x02\u{817}\u{818}\x07\u{122}\x02\x02\u{818}\
	\u{819}\x07\x3c\x02\x02\u{819}\u{820}\x03\x02\x02\x02\u{81a}\u{81b}\x07\
	\u{14c}\x02\x02\u{81b}\u{820}\x07\u{16d}\x02\x02\u{81c}\u{820}\x07\x3e\x02\
	\x02\u{81d}\u{820}\x07\u{12d}\x02\x02\u{81e}\u{820}\x07\x69\x02\x02\u{81f}\
	\u{777}\x03\x02\x02\x02\u{81f}\u{779}\x03\x02\x02\x02\u{81f}\u{77b}\x03\
	\x02\x02\x02\u{81f}\u{77f}\x03\x02\x02\x02\u{81f}\u{783}\x03\x02\x02\x02\
	\u{81f}\u{785}\x03\x02\x02\x02\u{81f}\u{78a}\x03\x02\x02\x02\u{81f}\u{78c}\
	\x03\x02\x02\x02\u{81f}\u{78e}\x03\x02\x02\x02\u{81f}\u{791}\x03\x02\x02\
	\x02\u{81f}\u{793}\x03\x02\x02\x02\u{81f}\u{795}\x03\x02\x02\x02\u{81f}\
	\u{797}\x03\x02\x02\x02\u{81f}\u{79a}\x03\x02\x02\x02\u{81f}\u{79c}\x03\
	\x02\x02\x02\u{81f}\u{79e}\x03\x02\x02\x02\u{81f}\u{7a0}\x03\x02\x02\x02\
	\u{81f}\u{7a2}\x03\x02\x02\x02\u{81f}\u{7a4}\x03\x02\x02\x02\u{81f}\u{7a6}\
	\x03\x02\x02\x02\u{81f}\u{7a8}\x03\x02\x02\x02\u{81f}\u{7aa}\x03\x02\x02\
	\x02\u{81f}\u{7ac}\x03\x02\x02\x02\u{81f}\u{7ae}\x03\x02\x02\x02\u{81f}\
	\u{7b1}\x03\x02\x02\x02\u{81f}\u{7b4}\x03\x02\x02\x02\u{81f}\u{7ba}\x03\
	\x02\x02\x02\u{81f}\u{7c0}\x03\x02\x02\x02\u{81f}\u{7c6}\x03\x02\x02\x02\
	\u{81f}\u{7cc}\x03\x02\x02\x02\u{81f}\u{7d2}\x03\x02\x02\x02\u{81f}\u{7da}\
	\x03\x02\x02\x02\u{81f}\u{7e1}\x03\x02\x02\x02\u{81f}\u{7e7}\x03\x02\x02\
	\x02\u{81f}\u{7ed}\x03\x02\x02\x02\u{81f}\u{7f3}\x03\x02\x02\x02\u{81f}\
	\u{7f8}\x03\x02\x02\x02\u{81f}\u{800}\x03\x02\x02\x02\u{81f}\u{808}\x03\
	\x02\x02\x02\u{81f}\u{811}\x03\x02\x02\x02\u{81f}\u{81a}\x03\x02\x02\x02\
	\u{81f}\u{81c}\x03\x02\x02\x02\u{81f}\u{81d}\x03\x02\x02\x02\u{81f}\u{81e}\
	\x03\x02\x02\x02\u{820}\x53\x03\x02\x02\x02\u{821}\u{823}\x07\x49\x02\x02\
	\u{822}\u{824}\x07\u{15e}\x02\x02\u{823}\u{822}\x03\x02\x02\x02\u{823}\u{824}\
	\x03\x02\x02\x02\u{824}\u{826}\x03\x02\x02\x02\u{825}\u{827}\x07\u{82}\x02\
	\x02\u{826}\u{825}\x03\x02\x02\x02\u{826}\u{827}\x03\x02\x02\x02\u{827}\
	\u{828}\x03\x02\x02\x02\u{828}\u{82d}\x07\u{159}\x02\x02\u{829}\u{82a}\x07\
	\u{a4}\x02\x02\u{82a}\u{82b}\x05\u{15a}\u{ae}\x02\u{82b}\u{82c}\x07\x7c\
	\x02\x02\u{82c}\u{82e}\x03\x02\x02\x02\u{82d}\u{829}\x03\x02\x02\x02\u{82d}\
	\u{82e}\x03\x02\x02\x02\u{82e}\u{82f}\x03\x02\x02\x02\u{82f}\u{830}\x05\
	\u{a2}\x52\x02\u{830}\x55\x03\x02\x02\x02\u{831}\u{832}\x07\x49\x02\x02\
	\u{832}\u{834}\x07\u{f9}\x02\x02\u{833}\u{831}\x03\x02\x02\x02\u{833}\u{834}\
	\x03\x02\x02\x02\u{834}\u{835}\x03\x02\x02\x02\u{835}\u{836}\x07\u{122}\
	\x02\x02\u{836}\u{837}\x07\u{159}\x02\x02\u{837}\u{838}\x05\u{a2}\x52\x02\
	\u{838}\x57\x03\x02\x02\x02\u{839}\u{83a}\x07\x35\x02\x02\u{83a}\u{83b}\
	\x07\x26\x02\x02\u{83b}\u{83c}\x07\x04\x02\x02\u{83c}\u{83d}\x05\u{136}\
	\u{9c}\x02\u{83d}\u{83e}\x07\x05\x02\x02\u{83e}\x59\x03\x02\x02\x02\u{83f}\
	\u{840}\x07\x36\x02\x02\u{840}\u{841}\x07\x26\x02\x02\u{841}\u{845}\x05\
	\u{114}\u{8b}\x02\u{842}\u{843}\x07\u{146}\x02\x02\u{843}\u{844}\x07\x26\
	\x02\x02\u{844}\u{846}\x05\u{118}\u{8d}\x02\u{845}\u{842}\x03\x02\x02\x02\
	\u{845}\u{846}\x03\x02\x02\x02\u{846}\u{847}\x03\x02\x02\x02\u{847}\u{848}\
	\x07\u{b6}\x02\x02\u{848}\u{849}\x05\u{1f2}\u{fa}\x02\u{849}\u{84a}\x07\
	\x25\x02\x02\u{84a}\x5b\x03\x02\x02\x02\u{84b}\u{84c}\x07\u{142}\x02\x02\
	\u{84c}\u{84d}\x07\x26\x02\x02\u{84d}\u{84e}\x05\u{114}\u{8b}\x02\u{84e}\
	\u{851}\x07\u{f5}\x02\x02\u{84f}\u{852}\x05\u{94}\x4b\x02\u{850}\u{852}\
	\x05\u{96}\x4c\x02\u{851}\u{84f}\x03\x02\x02\x02\u{851}\u{850}\x03\x02\x02\
	\x02\u{852}\u{856}\x03\x02\x02\x02\u{853}\u{854}\x07\u{14e}\x02\x02\u{854}\
	\u{855}\x07\x18\x02\x02\u{855}\u{857}\x07\x6a\x02\x02\u{856}\u{853}\x03\
	\x02\x02\x02\u{856}\u{857}\x03\x02\x02\x02\u{857}\x5d\x03\x02\x02\x02\u{858}\
	\u{859}\x07\u{ce}\x02\x02\u{859}\u{85a}\x05\u{218}\u{10d}\x02\u{85a}\x5f\
	\x03\x02\x02\x02\u{85b}\u{85c}\x07\u{194}\x02\x02\u{85c}\u{862}\x07\u{133}\
	\x02\x02\u{85d}\u{863}\x07\x21\x02\x02\u{85e}\u{863}\x07\x41\x02\x02\u{85f}\
	\u{863}\x07\x78\x02\x02\u{860}\u{861}\x07\u{174}\x02\x02\u{861}\u{863}\x07\
	\x78\x02\x02\u{862}\u{85d}\x03\x02\x02\x02\u{862}\u{85e}\x03\x02\x02\x02\
	\u{862}\u{85f}\x03\x02\x02\x02\u{862}\u{860}\x03\x02\x02\x02\u{863}\x61\
	\x03\x02\x02\x02\u{864}\u{865}\x07\x3d\x02\x02\u{865}\u{866}\x05\u{218}\
	\u{10d}\x02\u{866}\x63\x03\x02\x02\x02\u{867}\u{868}\x05\x66\x34\x02\u{868}\
	\u{869}\x07\x02\x02\x03\u{869}\x65\x03\x02\x02\x02\u{86a}\u{86c}\x05\x7c\
	\x3f\x02\u{86b}\u{86a}\x03\x02\x02\x02\u{86b}\u{86c}\x03\x02\x02\x02\u{86c}\
	\u{86d}\x03\x02\x02\x02\u{86d}\u{86e}\x05\u{aa}\x56\x02\u{86e}\u{86f}\x05\
	\u{a6}\x54\x02\u{86f}\x67\x03\x02\x02\x02\u{870}\u{871}\x07\u{b1}\x02\x02\
	\u{871}\u{873}\x07\u{101}\x02\x02\u{872}\u{874}\x07\u{159}\x02\x02\u{873}\
	\u{872}\x03\x02\x02\x02\u{873}\u{874}\x03\x02\x02\x02\u{874}\u{875}\x03\
	\x02\x02\x02\u{875}\u{877}\x05\u{a2}\x52\x02\u{876}\u{878}\x05\u{122}\u{92}\
	\x02\u{877}\u{876}\x03\x02\x02\x02\u{877}\u{878}\x03\x02\x02\x02\u{878}\
	\u{880}\x03\x02\x02\x02\u{879}\u{87e}\x05\x6c\x37\x02\u{87a}\u{87b}\x07\
	\u{a4}\x02\x02\u{87b}\u{87c}\x05\u{15a}\u{ae}\x02\u{87c}\u{87d}\x07\x7c\
	\x02\x02\u{87d}\u{87f}\x03\x02\x02\x02\u{87e}\u{87a}\x03\x02\x02\x02\u{87e}\
	\u{87f}\x03\x02\x02\x02\u{87f}\u{881}\x03\x02\x02\x02\u{880}\u{879}\x03\
	\x02\x02\x02\u{880}\u{881}\x03\x02\x02\x02\u{881}\u{885}\x03\x02\x02\x02\
	\u{882}\u{883}\x07\x26\x02\x02\u{883}\u{886}\x07\u{e6}\x02\x02\u{884}\u{886}\
	\x05\u{114}\u{8b}\x02\u{885}\u{882}\x03\x02\x02\x02\u{885}\u{884}\x03\x02\
	\x02\x02\u{885}\u{886}\x03\x02\x02\x02\u{886}\u{8c6}\x03\x02\x02\x02\u{887}\
	\u{888}\x07\u{b1}\x02\x02\u{888}\u{88a}\x07\u{b6}\x02\x02\u{889}\u{88b}\
	\x07\u{159}\x02\x02\u{88a}\u{889}\x03\x02\x02\x02\u{88a}\u{88b}\x03\x02\
	\x02\x02\u{88b}\u{88c}\x03\x02\x02\x02\u{88c}\u{88e}\x05\u{a2}\x52\x02\u{88d}\
	\u{88f}\x05\u{122}\u{92}\x02\u{88e}\u{88d}\x03\x02\x02\x02\u{88e}\u{88f}\
	\x03\x02\x02\x02\u{88f}\u{891}\x03\x02\x02\x02\u{890}\u{892}\x05\x6c\x37\
	\x02\u{891}\u{890}\x03\x02\x02\x02\u{891}\u{892}\x03\x02\x02\x02\u{892}\
	\u{897}\x03\x02\x02\x02\u{893}\u{894}\x07\u{a4}\x02\x02\u{894}\u{895}\x05\
	\u{15a}\u{ae}\x02\u{895}\u{896}\x07\x7c\x02\x02\u{896}\u{898}\x03\x02\x02\
	\x02\u{897}\u{893}\x03\x02\x02\x02\u{897}\u{898}\x03\x02\x02\x02\u{898}\
	\u{89c}\x03\x02\x02\x02\u{899}\u{89a}\x07\x26\x02\x02\u{89a}\u{89d}\x07\
	\u{e6}\x02\x02\u{89b}\u{89d}\x05\u{114}\u{8b}\x02\u{89c}\u{899}\x03\x02\
	\x02\x02\u{89c}\u{89b}\x03\x02\x02\x02\u{89c}\u{89d}\x03\x02\x02\x02\u{89d}\
	\u{8c6}\x03\x02\x02\x02\u{89e}\u{89f}\x07\u{b1}\x02\x02\u{89f}\u{8a1}\x07\
	\u{b6}\x02\x02\u{8a0}\u{8a2}\x07\u{159}\x02\x02\u{8a1}\u{8a0}\x03\x02\x02\
	\x02\u{8a1}\u{8a2}\x03\x02\x02\x02\u{8a2}\u{8a3}\x03\x02\x02\x02\u{8a3}\
	\u{8a5}\x05\u{a2}\x52\x02\u{8a4}\u{8a6}\x05\u{122}\u{92}\x02\u{8a5}\u{8a4}\
	\x03\x02\x02\x02\u{8a5}\u{8a6}\x03\x02\x02\x02\u{8a6}\u{8a7}\x03\x02\x02\
	\x02\u{8a7}\u{8a8}\x07\u{122}\x02\x02\u{8a8}\u{8a9}\x05\u{ce}\x68\x02\u{8a9}\
	\u{8c6}\x03\x02\x02\x02\u{8aa}\u{8ab}\x07\u{b1}\x02\x02\u{8ab}\u{8ad}\x07\
	\u{101}\x02\x02\u{8ac}\u{8ae}\x07\u{cd}\x02\x02\u{8ad}\u{8ac}\x03\x02\x02\
	\x02\u{8ad}\u{8ae}\x03\x02\x02\x02\u{8ae}\u{8af}\x03\x02\x02\x02\u{8af}\
	\u{8b0}\x07\x6b\x02\x02\u{8b0}\u{8b2}\x05\u{218}\u{10d}\x02\u{8b1}\u{8b3}\
	\x05\u{134}\u{9b}\x02\u{8b2}\u{8b1}\x03\x02\x02\x02\u{8b2}\u{8b3}\x03\x02\
	\x02\x02\u{8b3}\u{8b5}\x03\x02\x02\x02\u{8b4}\u{8b6}\x05\u{98}\x4d\x02\u{8b5}\
	\u{8b4}\x03\x02\x02\x02\u{8b5}\u{8b6}\x03\x02\x02\x02\u{8b6}\u{8c6}\x03\
	\x02\x02\x02\u{8b7}\u{8b8}\x07\u{b1}\x02\x02\u{8b8}\u{8ba}\x07\u{101}\x02\
	\x02\u{8b9}\u{8bb}\x07\u{cd}\x02\x02\u{8ba}\u{8b9}\x03\x02\x02\x02\u{8ba}\
	\u{8bb}\x03\x02\x02\x02\u{8bb}\u{8bc}\x03\x02\x02\x02\u{8bc}\u{8be}\x07\
	\x6b\x02\x02\u{8bd}\u{8bf}\x05\u{218}\u{10d}\x02\u{8be}\u{8bd}\x03\x02\x02\
	\x02\u{8be}\u{8bf}\x03\x02\x02\x02\u{8bf}\u{8c0}\x03\x02\x02\x02\u{8c0}\
	\u{8c3}\x05\u{80}\x41\x02\u{8c1}\u{8c2}\x07\u{f8}\x02\x02\u{8c2}\u{8c4}\
	\x05\u{84}\x43\x02\u{8c3}\u{8c1}\x03\x02\x02\x02\u{8c3}\u{8c4}\x03\x02\x02\
	\x02\u{8c4}\u{8c6}\x03\x02\x02\x02\u{8c5}\u{870}\x03\x02\x02\x02\u{8c5}\
	\u{887}\x03\x02\x02\x02\u{8c5}\u{89e}\x03\x02\x02\x02\u{8c5}\u{8aa}\x03\
	\x02\x02\x02\u{8c5}\u{8b7}\x03\x02\x02\x02\u{8c6}\x69\x03\x02\x02\x02\u{8c7}\
	\u{8c9}\x05\x6c\x37\x02\u{8c8}\u{8ca}\x05\x5e\x30\x02\u{8c9}\u{8c8}\x03\
	\x02\x02\x02\u{8c9}\u{8ca}\x03\x02\x02\x02\u{8ca}\x6b\x03\x02\x02\x02\u{8cb}\
	\u{8cc}\x07\u{102}\x02\x02\u{8cc}\u{8cd}\x07\x04\x02\x02\u{8cd}\u{8d2}\x05\
	\x6e\x38\x02\u{8ce}\u{8cf}\x07\x06\x02\x02\u{8cf}\u{8d1}\x05\x6e\x38\x02\
	\u{8d0}\u{8ce}\x03\x02\x02\x02\u{8d1}\u{8d4}\x03\x02\x02\x02\u{8d2}\u{8d0}\
	\x03\x02\x02\x02\u{8d2}\u{8d3}\x03\x02\x02\x02\u{8d3}\u{8d5}\x03\x02\x02\
	\x02\u{8d4}\u{8d2}\x03\x02\x02\x02\u{8d5}\u{8d6}\x07\x05\x02\x02\u{8d6}\
	\x6d\x03\x02\x02\x02\u{8d7}\u{8da}\x05\u{1e4}\u{f3}\x02\u{8d8}\u{8d9}\x07\
	\u{19a}\x02\x02\u{8d9}\u{8db}\x05\u{170}\u{b9}\x02\u{8da}\u{8d8}\x03\x02\
	\x02\x02\u{8da}\u{8db}\x03\x02\x02\x02\u{8db}\u{8e1}\x03\x02\x02\x02\u{8dc}\
	\u{8dd}\x05\u{1e4}\u{f3}\x02\u{8dd}\u{8de}\x07\u{19a}\x02\x02\u{8de}\u{8df}\
	\x07\x60\x02\x02\u{8df}\u{8e1}\x03\x02\x02\x02\u{8e0}\u{8d7}\x03\x02\x02\
	\x02\u{8e0}\u{8dc}\x03\x02\x02\x02\u{8e1}\x6f\x03\x02\x02\x02\u{8e2}\u{8e3}\
	\x07\x49\x02\x02\u{8e3}\u{8e4}\x07\u{8b}\x02\x02\u{8e4}\u{8e6}\x05\u{a2}\
	\x52\x02\u{8e5}\u{8e7}\x05\x62\x32\x02\u{8e6}\u{8e5}\x03\x02\x02\x02\u{8e6}\
	\u{8e7}\x03\x02\x02\x02\u{8e7}\u{8e8}\x03\x02\x02\x02\u{8e8}\u{8e9}\x07\
	\x18\x02\x02\u{8e9}\x71\x03\x02\x02\x02\u{8ea}\u{8eb}\x09\x0e\x02\x02\u{8eb}\
	\x73\x03\x02\x02\x02\u{8ec}\u{8ed}\x09\x0f\x02\x02\u{8ed}\x75\x03\x02\x02\
	\x02\u{8ee}\u{8ef}\x09\x10\x02\x02\u{8ef}\x77\x03\x02\x02\x02\u{8f0}\u{8f8}\
	\x05\u{a2}\x52\x02\u{8f1}\u{8f8}\x05\u{218}\u{10d}\x02\u{8f2}\u{8f8}\x05\
	\u{174}\u{bb}\x02\u{8f3}\u{8f8}\x05\u{176}\u{bc}\x02\u{8f4}\u{8f8}\x05\u{178}\
	\u{bd}\x02\u{8f5}\u{8f8}\x05\u{15e}\u{b0}\x02\u{8f6}\u{8f8}\x07\x0a\x02\
	\x02\u{8f7}\u{8f0}\x03\x02\x02\x02\u{8f7}\u{8f1}\x03\x02\x02\x02\u{8f7}\
	\u{8f2}\x03\x02\x02\x02\u{8f7}\u{8f3}\x03\x02\x02\x02\u{8f7}\u{8f4}\x03\
	\x02\x02\x02\u{8f7}\u{8f5}\x03\x02\x02\x02\u{8f7}\u{8f6}\x03\x02\x02\x02\
	\u{8f8}\x79\x03\x02\x02\x02\u{8f9}\u{8fe}\x05\u{1e0}\u{f1}\x02\u{8fa}\u{8fb}\
	\x07\x07\x02\x02\u{8fb}\u{8fd}\x05\u{1e0}\u{f1}\x02\u{8fc}\u{8fa}\x03\x02\
	\x02\x02\u{8fd}\u{900}\x03\x02\x02\x02\u{8fe}\u{8fc}\x03\x02\x02\x02\u{8fe}\
	\u{8ff}\x03\x02\x02\x02\u{8ff}\x7b\x03\x02\x02\x02\u{900}\u{8fe}\x03\x02\
	\x02\x02\u{901}\u{903}\x07\u{194}\x02\x02\u{902}\u{904}\x07\u{119}\x02\x02\
	\u{903}\u{902}\x03\x02\x02\x02\u{903}\u{904}\x03\x02\x02\x02\u{904}\u{905}\
	\x03\x02\x02\x02\u{905}\u{90a}\x05\x7e\x40\x02\u{906}\u{907}\x07\x06\x02\
	\x02\u{907}\u{909}\x05\x7e\x40\x02\u{908}\u{906}\x03\x02\x02\x02\u{909}\
	\u{90c}\x03\x02\x02\x02\u{90a}\u{908}\x03\x02\x02\x02\u{90a}\u{90b}\x03\
	\x02\x02\x02\u{90b}\x7d\x03\x02\x02\x02\u{90c}\u{90a}\x03\x02\x02\x02\u{90d}\
	\u{90f}\x05\u{1e0}\u{f1}\x02\u{90e}\u{910}\x05\u{114}\u{8b}\x02\u{90f}\u{90e}\
	\x03\x02\x02\x02\u{90f}\u{910}\x03\x02\x02\x02\u{910}\u{915}\x03\x02\x02\
	\x02\u{911}\u{912}\x07\u{d8}\x02\x02\u{912}\u{913}\x07\u{118}\x02\x02\u{913}\
	\u{914}\x07\u{c6}\x02\x02\u{914}\u{916}\x05\u{1f2}\u{fa}\x02\u{915}\u{911}\
	\x03\x02\x02\x02\u{915}\u{916}\x03\x02\x02\x02\u{916}\u{918}\x03\x02\x02\
	\x02\u{917}\u{919}\x07\x18\x02\x02\u{918}\u{917}\x03\x02\x02\x02\u{918}\
	\u{919}\x03\x02\x02\x02\u{919}\u{91a}\x03\x02\x02\x02\u{91a}\u{91b}\x07\
	\x04\x02\x02\u{91b}\u{91c}\x05\x66\x34\x02\u{91c}\u{91d}\x07\x05\x02\x02\
	\u{91d}\x7f\x03\x02\x02\x02\u{91e}\u{91f}\x07\u{182}\x02\x02\u{91f}\u{920}\
	\x05\u{138}\u{9d}\x02\u{920}\u{81}\x03\x02\x02\x02\u{921}\u{922}\x07\u{f8}\
	\x02\x02\u{922}\u{931}\x05\u{90}\x49\x02\u{923}\u{924}\x07\u{103}\x02\x02\
	\u{924}\u{925}\x07\x26\x02\x02\u{925}\u{931}\x05\u{146}\u{a4}\x02\u{926}\
	\u{931}\x05\x5c\x2f\x02\u{927}\u{931}\x05\x58\x2d\x02\u{928}\u{931}\x05\
	\x5a\x2e\x02\u{929}\u{931}\x05\u{134}\u{9b}\x02\u{92a}\u{931}\x05\u{98}\
	\x4d\x02\u{92b}\u{931}\x05\x5e\x30\x02\u{92c}\u{931}\x05\x62\x32\x02\u{92d}\
	\u{931}\x05\u{18e}\u{c8}\x02\u{92e}\u{92f}\x07\u{15d}\x02\x02\u{92f}\u{931}\
	\x05\u{84}\x43\x02\u{930}\u{921}\x03\x02\x02\x02\u{930}\u{923}\x03\x02\x02\
	\x02\u{930}\u{926}\x03\x02\x02\x02\u{930}\u{927}\x03\x02\x02\x02\u{930}\
	\u{928}\x03\x02\x02\x02\u{930}\u{929}\x03\x02\x02\x02\u{930}\u{92a}\x03\
	\x02\x02\x02\u{930}\u{92b}\x03\x02\x02\x02\u{930}\u{92c}\x03\x02\x02\x02\
	\u{930}\u{92d}\x03\x02\x02\x02\u{930}\u{92e}\x03\x02\x02\x02\u{931}\u{934}\
	\x03\x02\x02\x02\u{932}\u{930}\x03\x02\x02\x02\u{932}\u{933}\x03\x02\x02\
	\x02\u{933}\u{83}\x03\x02\x02\x02\u{934}\u{932}\x03\x02\x02\x02\u{935}\u{936}\
	\x07\x04\x02\x02\u{936}\u{93b}\x05\u{86}\x44\x02\u{937}\u{938}\x07\x06\x02\
	\x02\u{938}\u{93a}\x05\u{86}\x44\x02\u{939}\u{937}\x03\x02\x02\x02\u{93a}\
	\u{93d}\x03\x02\x02\x02\u{93b}\u{939}\x03\x02\x02\x02\u{93b}\u{93c}\x03\
	\x02\x02\x02\u{93c}\u{93e}\x03\x02\x02\x02\u{93d}\u{93b}\x03\x02\x02\x02\
	\u{93e}\u{93f}\x07\x05\x02\x02\u{93f}\u{85}\x03\x02\x02\x02\u{940}\u{941}\
	\x05\u{8a}\x46\x02\u{941}\u{942}\x07\u{19a}\x02\x02\u{942}\u{943}\x05\u{8e}\
	\x48\x02\u{943}\u{949}\x03\x02\x02\x02\u{944}\u{946}\x05\u{8c}\x47\x02\u{945}\
	\u{947}\x05\u{8e}\x48\x02\u{946}\u{945}\x03\x02\x02\x02\u{946}\u{947}\x03\
	\x02\x02\x02\u{947}\u{949}\x03\x02\x02\x02\u{948}\u{940}\x03\x02\x02\x02\
	\u{948}\u{944}\x03\x02\x02\x02\u{949}\u{87}\x03\x02\x02\x02\u{94a}\u{94f}\
	\x05\u{1e0}\u{f1}\x02\u{94b}\u{94c}\x07\x07\x02\x02\u{94c}\u{94e}\x05\u{1e0}\
	\u{f1}\x02\u{94d}\u{94b}\x03\x02\x02\x02\u{94e}\u{951}\x03\x02\x02\x02\u{94f}\
	\u{94d}\x03\x02\x02\x02\u{94f}\u{950}\x03\x02\x02\x02\u{950}\u{89}\x03\x02\
	\x02\x02\u{951}\u{94f}\x03\x02\x02\x02\u{952}\u{955}\x05\u{88}\x45\x02\u{953}\
	\u{955}\x05\u{218}\u{10d}\x02\u{954}\u{952}\x03\x02\x02\x02\u{954}\u{953}\
	\x03\x02\x02\x02\u{955}\u{8b}\x03\x02\x02\x02\u{956}\u{959}\x05\u{88}\x45\
	\x02\u{957}\u{959}\x05\u{214}\u{10b}\x02\u{958}\u{956}\x03\x02\x02\x02\u{958}\
	\u{957}\x03\x02\x02\x02\u{959}\u{8d}\x03\x02\x02\x02\u{95a}\u{95f}\x07\u{1bd}\
	\x02\x02\u{95b}\u{95f}\x07\u{1bf}\x02\x02\u{95c}\u{95f}\x05\u{17a}\u{be}\
	\x02\u{95d}\u{95f}\x05\u{218}\u{10d}\x02\u{95e}\u{95a}\x03\x02\x02\x02\u{95e}\
	\u{95b}\x03\x02\x02\x02\u{95e}\u{95c}\x03\x02\x02\x02\u{95e}\u{95d}\x03\
	\x02\x02\x02\u{95f}\u{8f}\x03\x02\x02\x02\u{960}\u{961}\x07\x04\x02\x02\
	\u{961}\u{966}\x05\u{92}\x4a\x02\u{962}\u{963}\x07\x06\x02\x02\u{963}\u{965}\
	\x05\u{92}\x4a\x02\u{964}\u{962}\x03\x02\x02\x02\u{965}\u{968}\x03\x02\x02\
	\x02\u{966}\u{964}\x03\x02\x02\x02\u{966}\u{967}\x03\x02\x02\x02\u{967}\
	\u{969}\x03\x02\x02\x02\u{968}\u{966}\x03\x02\x02\x02\u{969}\u{96a}\x07\
	\x05\x02\x02\u{96a}\u{91}\x03\x02\x02\x02\u{96b}\u{96c}\x05\u{8a}\x46\x02\
	\u{96c}\u{96d}\x07\u{19a}\x02\x02\u{96d}\u{96e}\x05\u{14e}\u{a8}\x02\u{96e}\
	\u{974}\x03\x02\x02\x02\u{96f}\u{971}\x05\u{8c}\x47\x02\u{970}\u{972}\x05\
	\u{14e}\u{a8}\x02\u{971}\u{970}\x03\x02\x02\x02\u{971}\u{972}\x03\x02\x02\
	\x02\u{972}\u{974}\x03\x02\x02\x02\u{973}\u{96b}\x03\x02\x02\x02\u{973}\
	\u{96f}\x03\x02\x02\x02\u{974}\u{93}\x03\x02\x02\x02\u{975}\u{976}\x07\x04\
	\x02\x02\u{976}\u{97b}\x05\u{170}\u{b9}\x02\u{977}\u{978}\x07\x06\x02\x02\
	\u{978}\u{97a}\x05\u{170}\u{b9}\x02\u{979}\u{977}\x03\x02\x02\x02\u{97a}\
	\u{97d}\x03\x02\x02\x02\u{97b}\u{979}\x03\x02\x02\x02\u{97b}\u{97c}\x03\
	\x02\x02\x02\u{97c}\u{97e}\x03\x02\x02\x02\u{97d}\u{97b}\x03\x02\x02\x02\
	\u{97e}\u{97f}\x07\x05\x02\x02\u{97f}\u{95}\x03\x02\x02\x02\u{980}\u{981}\
	\x07\x04\x02\x02\u{981}\u{986}\x05\u{94}\x4b\x02\u{982}\u{983}\x07\x06\x02\
	\x02\u{983}\u{985}\x05\u{94}\x4b\x02\u{984}\u{982}\x03\x02\x02\x02\u{985}\
	\u{988}\x03\x02\x02\x02\u{986}\u{984}\x03\x02\x02\x02\u{986}\u{987}\x03\
	\x02\x02\x02\u{987}\u{989}\x03\x02\x02\x02\u{988}\u{986}\x03\x02\x02\x02\
	\u{989}\u{98a}\x07\x05\x02\x02\u{98a}\u{97}\x03\x02\x02\x02\u{98b}\u{98c}\
	\x07\u{14e}\x02\x02\u{98c}\u{98d}\x07\x18\x02\x02\u{98d}\u{992}\x05\u{9a}\
	\x4e\x02\u{98e}\u{98f}\x07\u{14e}\x02\x02\u{98f}\u{990}\x07\x26\x02\x02\
	\u{990}\u{992}\x05\u{9c}\x4f\x02\u{991}\u{98b}\x03\x02\x02\x02\u{991}\u{98e}\
	\x03\x02\x02\x02\u{992}\u{99}\x03\x02\x02\x02\u{993}\u{994}\x07\u{b0}\x02\
	\x02\u{994}\u{995}\x05\u{218}\u{10d}\x02\u{995}\u{996}\x07\u{fd}\x02\x02\
	\u{996}\u{997}\x05\u{218}\u{10d}\x02\u{997}\u{99a}\x03\x02\x02\x02\u{998}\
	\u{99a}\x05\u{1e6}\u{f4}\x02\u{999}\u{993}\x03\x02\x02\x02\u{999}\u{998}\
	\x03\x02\x02\x02\u{99a}\u{9b}\x03\x02\x02\x02\u{99b}\u{99f}\x05\u{218}\u{10d}\
	\x02\u{99c}\u{99d}\x07\u{194}\x02\x02\u{99d}\u{99e}\x07\u{13a}\x02\x02\u{99e}\
	\u{9a0}\x05\u{84}\x43\x02\u{99f}\u{99c}\x03\x02\x02\x02\u{99f}\u{9a0}\x03\
	\x02\x02\x02\u{9a0}\u{9d}\x03\x02\x02\x02\u{9a1}\u{9a2}\x05\u{1e6}\u{f4}\
	\x02\u{9a2}\u{9a3}\x05\u{218}\u{10d}\x02\u{9a3}\u{9f}\x03\x02\x02\x02\u{9a4}\
	\u{9a5}\x05\x68\x35\x02\u{9a5}\u{9a6}\x05\x66\x34\x02\u{9a6}\u{9e2}\x03\
	\x02\x02\x02\u{9a7}\u{9a9}\x05\u{d6}\x6c\x02\u{9a8}\u{9aa}\x05\u{a8}\x55\
	\x02\u{9a9}\u{9a8}\x03\x02\x02\x02\u{9aa}\u{9ab}\x03\x02\x02\x02\u{9ab}\
	\u{9a9}\x03\x02\x02\x02\u{9ab}\u{9ac}\x03\x02\x02\x02\u{9ac}\u{9e2}\x03\
	\x02\x02\x02\u{9ad}\u{9ae}\x07\x64\x02\x02\u{9ae}\u{9af}\x07\u{92}\x02\x02\
	\u{9af}\u{9b0}\x05\u{a2}\x52\x02\u{9b0}\u{9b2}\x05\u{132}\u{9a}\x02\u{9b1}\
	\u{9b3}\x05\u{ce}\x68\x02\u{9b2}\u{9b1}\x03\x02\x02\x02\u{9b2}\u{9b3}\x03\
	\x02\x02\x02\u{9b3}\u{9e2}\x03\x02\x02\x02\u{9b4}\u{9b5}\x07\u{17f}\x02\
	\x02\u{9b5}\u{9b6}\x05\u{a2}\x52\x02\u{9b6}\u{9b7}\x05\u{132}\u{9a}\x02\
	\u{9b7}\u{9b9}\x05\u{ba}\x5e\x02\u{9b8}\u{9ba}\x05\u{ce}\x68\x02\u{9b9}\
	\u{9b8}\x03\x02\x02\x02\u{9b9}\u{9ba}\x03\x02\x02\x02\u{9ba}\u{9e2}\x03\
	\x02\x02\x02\u{9bb}\u{9bf}\x07\u{da}\x02\x02\u{9bc}\u{9bd}\x07\u{194}\x02\
	\x02\u{9bd}\u{9be}\x07\u{133}\x02\x02\u{9be}\u{9c0}\x07\x78\x02\x02\u{9bf}\
	\u{9bc}\x03\x02\x02\x02\u{9bf}\u{9c0}\x03\x02\x02\x02\u{9c0}\u{9c1}\x03\
	\x02\x02\x02\u{9c1}\u{9c2}\x07\u{b6}\x02\x02\u{9c2}\u{9c3}\x05\u{a2}\x52\
	\x02\u{9c3}\u{9c4}\x05\u{132}\u{9a}\x02\u{9c4}\u{9ca}\x07\u{182}\x02\x02\
	\u{9c5}\u{9cb}\x05\u{a2}\x52\x02\u{9c6}\u{9c7}\x07\x04\x02\x02\u{9c7}\u{9c8}\
	\x05\x66\x34\x02\u{9c8}\u{9c9}\x07\x05\x02\x02\u{9c9}\u{9cb}\x03\x02\x02\
	\x02\u{9ca}\u{9c5}\x03\x02\x02\x02\u{9ca}\u{9c6}\x03\x02\x02\x02\u{9cb}\
	\u{9cc}\x03\x02\x02\x02\u{9cc}\u{9cd}\x05\u{132}\u{9a}\x02\u{9cd}\u{9ce}\
	\x07\u{f5}\x02\x02\u{9ce}\u{9d2}\x05\u{156}\u{ac}\x02\u{9cf}\u{9d1}\x05\
	\u{bc}\x5f\x02\u{9d0}\u{9cf}\x03\x02\x02\x02\u{9d1}\u{9d4}\x03\x02\x02\x02\
	\u{9d2}\u{9d0}\x03\x02\x02\x02\u{9d2}\u{9d3}\x03\x02\x02\x02\u{9d3}\u{9d8}\
	\x03\x02\x02\x02\u{9d4}\u{9d2}\x03\x02\x02\x02\u{9d5}\u{9d7}\x05\u{be}\x60\
	\x02\u{9d6}\u{9d5}\x03\x02\x02\x02\u{9d7}\u{9da}\x03\x02\x02\x02\u{9d8}\
	\u{9d6}\x03\x02\x02\x02\u{9d8}\u{9d9}\x03\x02\x02\x02\u{9d9}\u{9de}\x03\
	\x02\x02\x02\u{9da}\u{9d8}\x03\x02\x02\x02\u{9db}\u{9dd}\x05\u{c0}\x61\x02\
	\u{9dc}\u{9db}\x03\x02\x02\x02\u{9dd}\u{9e0}\x03\x02\x02\x02\u{9de}\u{9dc}\
	\x03\x02\x02\x02\u{9de}\u{9df}\x03\x02\x02\x02\u{9df}\u{9e2}\x03\x02\x02\
	\x02\u{9e0}\u{9de}\x03\x02\x02\x02\u{9e1}\u{9a4}\x03\x02\x02\x02\u{9e1}\
	\u{9a7}\x03\x02\x02\x02\u{9e1}\u{9ad}\x03\x02\x02\x02\u{9e1}\u{9b4}\x03\
	\x02\x02\x02\u{9e1}\u{9bb}\x03\x02\x02\x02\u{9e2}\u{a1}\x03\x02\x02\x02\
	\u{9e3}\u{9e4}\x07\u{a2}\x02\x02\u{9e4}\u{9e5}\x07\x04\x02\x02\u{9e5}\u{9e6}\
	\x05\u{14e}\u{a8}\x02\u{9e6}\u{9e7}\x07\x05\x02\x02\u{9e7}\u{9ea}\x03\x02\
	\x02\x02\u{9e8}\u{9ea}\x05\u{138}\u{9d}\x02\u{9e9}\u{9e3}\x03\x02\x02\x02\
	\u{9e9}\u{9e8}\x03\x02\x02\x02\u{9ea}\u{a3}\x03\x02\x02\x02\u{9eb}\u{9ec}\
	\x07\u{a2}\x02\x02\u{9ec}\u{9ed}\x07\x04\x02\x02\u{9ed}\u{9ee}\x05\u{14e}\
	\u{a8}\x02\u{9ee}\u{9ef}\x07\x05\x02\x02\u{9ef}\u{9f3}\x03\x02\x02\x02\u{9f0}\
	\u{9f3}\x05\u{1e0}\u{f1}\x02\u{9f1}\u{9f3}\x05\u{218}\u{10d}\x02\u{9f2}\
	\u{9eb}\x03\x02\x02\x02\u{9f2}\u{9f0}\x03\x02\x02\x02\u{9f2}\u{9f1}\x03\
	\x02\x02\x02\u{9f3}\u{a5}\x03\x02\x02\x02\u{9f4}\u{9f5}\x07\u{fa}\x02\x02\
	\u{9f5}\u{9f6}\x07\x26\x02\x02\u{9f6}\u{9fb}\x05\u{ae}\x58\x02\u{9f7}\u{9f8}\
	\x07\x06\x02\x02\u{9f8}\u{9fa}\x05\u{ae}\x58\x02\u{9f9}\u{9f7}\x03\x02\x02\
	\x02\u{9fa}\u{9fd}\x03\x02\x02\x02\u{9fb}\u{9f9}\x03\x02\x02\x02\u{9fb}\
	\u{9fc}\x03\x02\x02\x02\u{9fc}\u{9ff}\x03\x02\x02\x02\u{9fd}\u{9fb}\x03\
	\x02\x02\x02\u{9fe}\u{9f4}\x03\x02\x02\x02\u{9fe}\u{9ff}\x03\x02\x02\x02\
	\u{9ff}\u{a0a}\x03\x02\x02\x02\u{a00}\u{a01}\x07\x35\x02\x02\u{a01}\u{a02}\
	\x07\x26\x02\x02\u{a02}\u{a07}\x05\u{14e}\u{a8}\x02\u{a03}\u{a04}\x07\x06\
	\x02\x02\u{a04}\u{a06}\x05\u{14e}\u{a8}\x02\u{a05}\u{a03}\x03\x02\x02\x02\
	\u{a06}\u{a09}\x03\x02\x02\x02\u{a07}\u{a05}\x03\x02\x02\x02\u{a07}\u{a08}\
	\x03\x02\x02\x02\u{a08}\u{a0b}\x03\x02\x02\x02\u{a09}\u{a07}\x03\x02\x02\
	\x02\u{a0a}\u{a00}\x03\x02\x02\x02\u{a0a}\u{a0b}\x03\x02\x02\x02\u{a0b}\
	\u{a16}\x03\x02\x02\x02\u{a0c}\u{a0d}\x07\x6d\x02\x02\u{a0d}\u{a0e}\x07\
	\x26\x02\x02\u{a0e}\u{a13}\x05\u{14e}\u{a8}\x02\u{a0f}\u{a10}\x07\x06\x02\
	\x02\u{a10}\u{a12}\x05\u{14e}\u{a8}\x02\u{a11}\u{a0f}\x03\x02\x02\x02\u{a12}\
	\u{a15}\x03\x02\x02\x02\u{a13}\u{a11}\x03\x02\x02\x02\u{a13}\u{a14}\x03\
	\x02\x02\x02\u{a14}\u{a17}\x03\x02\x02\x02\u{a15}\u{a13}\x03\x02\x02\x02\
	\u{a16}\u{a0c}\x03\x02\x02\x02\u{a16}\u{a17}\x03\x02\x02\x02\u{a17}\u{a22}\
	\x03\x02\x02\x02\u{a18}\u{a19}\x07\u{145}\x02\x02\u{a19}\u{a1a}\x07\x26\
	\x02\x02\u{a1a}\u{a1f}\x05\u{ae}\x58\x02\u{a1b}\u{a1c}\x07\x06\x02\x02\u{a1c}\
	\u{a1e}\x05\u{ae}\x58\x02\u{a1d}\u{a1b}\x03\x02\x02\x02\u{a1e}\u{a21}\x03\
	\x02\x02\x02\u{a1f}\u{a1d}\x03\x02\x02\x02\u{a1f}\u{a20}\x03\x02\x02\x02\
	\u{a20}\u{a23}\x03\x02\x02\x02\u{a21}\u{a1f}\x03\x02\x02\x02\u{a22}\u{a18}\
	\x03\x02\x02\x02\u{a22}\u{a23}\x03\x02\x02\x02\u{a23}\u{a25}\x03\x02\x02\
	\x02\u{a24}\u{a26}\x05\u{1d0}\u{e9}\x02\u{a25}\u{a24}\x03\x02\x02\x02\u{a25}\
	\u{a26}\x03\x02\x02\x02\u{a26}\u{a2c}\x03\x02\x02\x02\u{a27}\u{a2a}\x07\
	\u{c9}\x02\x02\u{a28}\u{a2b}\x07\x0e\x02\x02\u{a29}\u{a2b}\x05\u{14e}\u{a8}\
	\x02\u{a2a}\u{a28}\x03\x02\x02\x02\u{a2a}\u{a29}\x03\x02\x02\x02\u{a2b}\
	\u{a2d}\x03\x02\x02\x02\u{a2c}\u{a27}\x03\x02\x02\x02\u{a2c}\u{a2d}\x03\
	\x02\x02\x02\u{a2d}\u{a30}\x03\x02\x02\x02\u{a2e}\u{a2f}\x07\u{f4}\x02\x02\
	\u{a2f}\u{a31}\x05\u{14e}\u{a8}\x02\u{a30}\u{a2e}\x03\x02\x02\x02\u{a30}\
	\u{a31}\x03\x02\x02\x02\u{a31}\u{a7}\x03\x02\x02\x02\u{a32}\u{a33}\x05\x68\
	\x35\x02\u{a33}\u{a34}\x05\u{b2}\x5a\x02\u{a34}\u{a9}\x03\x02\x02\x02\u{a35}\
	\u{a36}\x08\x56\x01\x02\u{a36}\u{a37}\x05\u{ac}\x57\x02\u{a37}\u{a56}\x03\
	\x02\x02\x02\u{a38}\u{a39}\x0c\x07\x02\x02\u{a39}\u{a3a}\x06\x56\x03\x02\
	\u{a3a}\u{a3c}\x09\x11\x02\x02\u{a3b}\u{a3d}\x05\u{104}\u{83}\x02\u{a3c}\
	\u{a3b}\x03\x02\x02\x02\u{a3c}\u{a3d}\x03\x02\x02\x02\u{a3d}\u{a3e}\x03\
	\x02\x02\x02\u{a3e}\u{a55}\x05\u{aa}\x56\x08\u{a3f}\u{a40}\x0c\x06\x02\x02\
	\u{a40}\u{a41}\x06\x56\x05\x02\u{a41}\u{a43}\x07\u{b2}\x02\x02\u{a42}\u{a44}\
	\x05\u{104}\u{83}\x02\u{a43}\u{a42}\x03\x02\x02\x02\u{a43}\u{a44}\x03\x02\
	\x02\x02\u{a44}\u{a45}\x03\x02\x02\x02\u{a45}\u{a55}\x05\u{aa}\x56\x07\u{a46}\
	\u{a47}\x0c\x05\x02\x02\u{a47}\u{a48}\x06\x56\x07\x02\u{a48}\u{a4a}\x09\
	\x12\x02\x02\u{a49}\u{a4b}\x05\u{104}\u{83}\x02\u{a4a}\u{a49}\x03\x02\x02\
	\x02\u{a4a}\u{a4b}\x03\x02\x02\x02\u{a4b}\u{a4c}\x03\x02\x02\x02\u{a4c}\
	\u{a55}\x05\u{aa}\x56\x06\u{a4d}\u{a4e}\x0c\x04\x02\x02\u{a4e}\u{a4f}\x07\
	\u{1ae}\x02\x02\u{a4f}\u{a55}\x05\u{21e}\u{110}\x02\u{a50}\u{a51}\x0c\x03\
	\x02\x02\u{a51}\u{a52}\x06\x56\x0a\x02\u{a52}\u{a53}\x07\u{1ac}\x02\x02\
	\u{a53}\u{a55}\x05\u{21e}\u{110}\x02\u{a54}\u{a38}\x03\x02\x02\x02\u{a54}\
	\u{a3f}\x03\x02\x02\x02\u{a54}\u{a46}\x03\x02\x02\x02\u{a54}\u{a4d}\x03\
	\x02\x02\x02\u{a54}\u{a50}\x03\x02\x02\x02\u{a55}\u{a58}\x03\x02\x02\x02\
	\u{a56}\u{a54}\x03\x02\x02\x02\u{a56}\u{a57}\x03\x02\x02\x02\u{a57}\u{ab}\
	\x03\x02\x02\x02\u{a58}\u{a56}\x03\x02\x02\x02\u{a59}\u{a63}\x05\u{b4}\x5b\
	\x02\u{a5a}\u{a63}\x05\u{b0}\x59\x02\u{a5b}\u{a5c}\x07\u{159}\x02\x02\u{a5c}\
	\u{a63}\x05\u{a2}\x52\x02\u{a5d}\u{a63}\x05\u{124}\u{93}\x02\u{a5e}\u{a5f}\
	\x07\x04\x02\x02\u{a5f}\u{a60}\x05\x66\x34\x02\u{a60}\u{a61}\x07\x05\x02\
	\x02\u{a61}\u{a63}\x03\x02\x02\x02\u{a62}\u{a59}\x03\x02\x02\x02\u{a62}\
	\u{a5a}\x03\x02\x02\x02\u{a62}\u{a5b}\x03\x02\x02\x02\u{a62}\u{a5d}\x03\
	\x02\x02\x02\u{a62}\u{a5e}\x03\x02\x02\x02\u{a63}\u{ad}\x03\x02\x02\x02\
	\u{a64}\u{a66}\x05\u{14e}\u{a8}\x02\u{a65}\u{a67}\x09\x13\x02\x02\u{a66}\
	\u{a65}\x03\x02\x02\x02\u{a66}\u{a67}\x03\x02\x02\x02\u{a67}\u{a6a}\x03\
	\x02\x02\x02\u{a68}\u{a69}\x07\u{f0}\x02\x02\u{a69}\u{a6b}\x09\x14\x02\x02\
	\u{a6a}\u{a68}\x03\x02\x02\x02\u{a6a}\u{a6b}\x03\x02\x02\x02\u{a6b}\u{af}\
	\x03\x02\x02\x02\u{a6c}\u{a70}\x05\u{d6}\x6c\x02\u{a6d}\u{a6f}\x05\u{b2}\
	\x5a\x02\u{a6e}\u{a6d}\x03\x02\x02\x02\u{a6f}\u{a72}\x03\x02\x02\x02\u{a70}\
	\u{a6e}\x03\x02\x02\x02\u{a70}\u{a71}\x03\x02\x02\x02\u{a71}\u{b1}\x03\x02\
	\x02\x02\u{a72}\u{a70}\x03\x02\x02\x02\u{a73}\u{a75}\x05\u{b6}\x5c\x02\u{a74}\
	\u{a76}\x05\u{ce}\x68\x02\u{a75}\u{a74}\x03\x02\x02\x02\u{a75}\u{a76}\x03\
	\x02\x02\x02\u{a76}\u{a77}\x03\x02\x02\x02\u{a77}\u{a78}\x05\u{a6}\x54\x02\
	\u{a78}\u{a8f}\x03\x02\x02\x02\u{a79}\u{a7d}\x05\u{b8}\x5d\x02\u{a7a}\u{a7c}\
	\x05\u{100}\u{81}\x02\u{a7b}\u{a7a}\x03\x02\x02\x02\u{a7c}\u{a7f}\x03\x02\
	\x02\x02\u{a7d}\u{a7b}\x03\x02\x02\x02\u{a7d}\u{a7e}\x03\x02\x02\x02\u{a7e}\
	\u{a81}\x03\x02\x02\x02\u{a7f}\u{a7d}\x03\x02\x02\x02\u{a80}\u{a82}\x05\
	\u{ce}\x68\x02\u{a81}\u{a80}\x03\x02\x02\x02\u{a81}\u{a82}\x03\x02\x02\x02\
	\u{a82}\u{a84}\x03\x02\x02\x02\u{a83}\u{a85}\x05\u{da}\x6e\x02\u{a84}\u{a83}\
	\x03\x02\x02\x02\u{a84}\u{a85}\x03\x02\x02\x02\u{a85}\u{a87}\x03\x02\x02\
	\x02\u{a86}\u{a88}\x05\u{d0}\x69\x02\u{a87}\u{a86}\x03\x02\x02\x02\u{a87}\
	\u{a88}\x03\x02\x02\x02\u{a88}\u{a8a}\x03\x02\x02\x02\u{a89}\u{a8b}\x05\
	\u{1d0}\u{e9}\x02\u{a8a}\u{a89}\x03\x02\x02\x02\u{a8a}\u{a8b}\x03\x02\x02\
	\x02\u{a8b}\u{a8c}\x03\x02\x02\x02\u{a8c}\u{a8d}\x05\u{a6}\x54\x02\u{a8d}\
	\u{a8f}\x03\x02\x02\x02\u{a8e}\u{a73}\x03\x02\x02\x02\u{a8e}\u{a79}\x03\
	\x02\x02\x02\u{a8f}\u{b3}\x03\x02\x02\x02\u{a90}\u{a92}\x05\u{b6}\x5c\x02\
	\u{a91}\u{a93}\x05\u{d6}\x6c\x02\u{a92}\u{a91}\x03\x02\x02\x02\u{a92}\u{a93}\
	\x03\x02\x02\x02\u{a93}\u{a97}\x03\x02\x02\x02\u{a94}\u{a96}\x05\u{100}\
	\u{81}\x02\u{a95}\u{a94}\x03\x02\x02\x02\u{a96}\u{a99}\x03\x02\x02\x02\u{a97}\
	\u{a95}\x03\x02\x02\x02\u{a97}\u{a98}\x03\x02\x02\x02\u{a98}\u{a9b}\x03\
	\x02\x02\x02\u{a99}\u{a97}\x03\x02\x02\x02\u{a9a}\u{a9c}\x05\u{ce}\x68\x02\
	\u{a9b}\u{a9a}\x03\x02\x02\x02\u{a9b}\u{a9c}\x03\x02\x02\x02\u{a9c}\u{a9e}\
	\x03\x02\x02\x02\u{a9d}\u{a9f}\x05\u{da}\x6e\x02\u{a9e}\u{a9d}\x03\x02\x02\
	\x02\u{a9e}\u{a9f}\x03\x02\x02\x02\u{a9f}\u{aa1}\x03\x02\x02\x02\u{aa0}\
	\u{aa2}\x05\u{d0}\x69\x02\u{aa1}\u{aa0}\x03\x02\x02\x02\u{aa1}\u{aa2}\x03\
	\x02\x02\x02\u{aa2}\u{aa4}\x03\x02\x02\x02\u{aa3}\u{aa5}\x05\u{1d0}\u{e9}\
	\x02\u{aa4}\u{aa3}\x03\x02\x02\x02\u{aa4}\u{aa5}\x03\x02\x02\x02\u{aa5}\
	\u{abd}\x03\x02\x02\x02\u{aa6}\u{aa8}\x05\u{b8}\x5d\x02\u{aa7}\u{aa9}\x05\
	\u{d6}\x6c\x02\u{aa8}\u{aa7}\x03\x02\x02\x02\u{aa8}\u{aa9}\x03\x02\x02\x02\
	\u{aa9}\u{aad}\x03\x02\x02\x02\u{aaa}\u{aac}\x05\u{100}\u{81}\x02\u{aab}\
	\u{aaa}\x03\x02\x02\x02\u{aac}\u{aaf}\x03\x02\x02\x02\u{aad}\u{aab}\x03\
	\x02\x02\x02\u{aad}\u{aae}\x03\x02\x02\x02\u{aae}\u{ab1}\x03\x02\x02\x02\
	\u{aaf}\u{aad}\x03\x02\x02\x02\u{ab0}\u{ab2}\x05\u{ce}\x68\x02\u{ab1}\u{ab0}\
	\x03\x02\x02\x02\u{ab1}\u{ab2}\x03\x02\x02\x02\u{ab2}\u{ab4}\x03\x02\x02\
	\x02\u{ab3}\u{ab5}\x05\u{da}\x6e\x02\u{ab4}\u{ab3}\x03\x02\x02\x02\u{ab4}\
	\u{ab5}\x03\x02\x02\x02\u{ab5}\u{ab7}\x03\x02\x02\x02\u{ab6}\u{ab8}\x05\
	\u{d0}\x69\x02\u{ab7}\u{ab6}\x03\x02\x02\x02\u{ab7}\u{ab8}\x03\x02\x02\x02\
	\u{ab8}\u{aba}\x03\x02\x02\x02\u{ab9}\u{abb}\x05\u{1d0}\u{e9}\x02\u{aba}\
	\u{ab9}\x03\x02\x02\x02\u{aba}\u{abb}\x03\x02\x02\x02\u{abb}\u{abd}\x03\
	\x02\x02\x02\u{abc}\u{a90}\x03\x02\x02\x02\u{abc}\u{aa6}\x03\x02\x02\x02\
	\u{abd}\u{b5}\x03\x02\x02\x02\u{abe}\u{abf}\x07\u{136}\x02\x02\u{abf}\u{ac0}\
	\x07\u{16f}\x02\x02\u{ac0}\u{ac2}\x07\x04\x02\x02\u{ac1}\u{ac3}\x05\u{104}\
	\u{83}\x02\u{ac2}\u{ac1}\x03\x02\x02\x02\u{ac2}\u{ac3}\x03\x02\x02\x02\u{ac3}\
	\u{ac4}\x03\x02\x02\x02\u{ac4}\u{ac5}\x05\u{154}\u{ab}\x02\u{ac5}\u{ac6}\
	\x07\x05\x02\x02\u{ac6}\u{ad2}\x03\x02\x02\x02\u{ac7}\u{ac9}\x07\u{d5}\x02\
	\x02\u{ac8}\u{aca}\x05\u{104}\u{83}\x02\u{ac9}\u{ac8}\x03\x02\x02\x02\u{ac9}\
	\u{aca}\x03\x02\x02\x02\u{aca}\u{acb}\x03\x02\x02\x02\u{acb}\u{ad2}\x05\
	\u{154}\u{ab}\x02\u{acc}\u{ace}\x07\u{11a}\x02\x02\u{acd}\u{acf}\x05\u{104}\
	\u{83}\x02\u{ace}\u{acd}\x03\x02\x02\x02\u{ace}\u{acf}\x03\x02\x02\x02\u{acf}\
	\u{ad0}\x03\x02\x02\x02\u{ad0}\u{ad2}\x05\u{154}\u{ab}\x02\u{ad1}\u{abe}\
	\x03\x02\x02\x02\u{ad1}\u{ac7}\x03\x02\x02\x02\u{ad1}\u{acc}\x03\x02\x02\
	\x02\u{ad2}\u{ad4}\x03\x02\x02\x02\u{ad3}\u{ad5}\x05\u{134}\u{9b}\x02\u{ad4}\
	\u{ad3}\x03\x02\x02\x02\u{ad4}\u{ad5}\x03\x02\x02\x02\u{ad5}\u{ad8}\x03\
	\x02\x02\x02\u{ad6}\u{ad7}\x07\u{116}\x02\x02\u{ad7}\u{ad9}\x05\u{218}\u{10d}\
	\x02\u{ad8}\u{ad6}\x03\x02\x02\x02\u{ad8}\u{ad9}\x03\x02\x02\x02\u{ad9}\
	\u{ada}\x03\x02\x02\x02\u{ada}\u{adb}\x07\u{182}\x02\x02\u{adb}\u{ae8}\x05\
	\u{218}\u{10d}\x02\u{adc}\u{ae6}\x07\x18\x02\x02\u{add}\u{ae7}\x05\u{116}\
	\u{8c}\x02\u{ade}\u{ae7}\x05\u{1a4}\u{d3}\x02\u{adf}\u{ae2}\x07\x04\x02\
	\x02\u{ae0}\u{ae3}\x05\u{116}\u{8c}\x02\u{ae1}\u{ae3}\x05\u{1a4}\u{d3}\x02\
	\u{ae2}\u{ae0}\x03\x02\x02\x02\u{ae2}\u{ae1}\x03\x02\x02\x02\u{ae3}\u{ae4}\
	\x03\x02\x02\x02\u{ae4}\u{ae5}\x07\x05\x02\x02\u{ae5}\u{ae7}\x03\x02\x02\
	\x02\u{ae6}\u{add}\x03\x02\x02\x02\u{ae6}\u{ade}\x03\x02\x02\x02\u{ae6}\
	\u{adf}\x03\x02\x02\x02\u{ae7}\u{ae9}\x03\x02\x02\x02\u{ae8}\u{adc}\x03\
	\x02\x02\x02\u{ae8}\u{ae9}\x03\x02\x02\x02\u{ae9}\u{aeb}\x03\x02\x02\x02\
	\u{aea}\u{aec}\x05\u{134}\u{9b}\x02\u{aeb}\u{aea}\x03\x02\x02\x02\u{aeb}\
	\u{aec}\x03\x02\x02\x02\u{aec}\u{aef}\x03\x02\x02\x02\u{aed}\u{aee}\x07\
	\u{115}\x02\x02\u{aee}\u{af0}\x05\u{218}\u{10d}\x02\u{aef}\u{aed}\x03\x02\
	\x02\x02\u{aef}\u{af0}\x03\x02\x02\x02\u{af0}\u{b7}\x03\x02\x02\x02\u{af1}\
	\u{af5}\x07\u{136}\x02\x02\u{af2}\u{af4}\x05\u{d2}\x6a\x02\u{af3}\u{af2}\
	\x03\x02\x02\x02\u{af4}\u{af7}\x03\x02\x02\x02\u{af5}\u{af3}\x03\x02\x02\
	\x02\u{af5}\u{af6}\x03\x02\x02\x02\u{af6}\u{af9}\x03\x02\x02\x02\u{af7}\
	\u{af5}\x03\x02\x02\x02\u{af8}\u{afa}\x05\u{104}\u{83}\x02\u{af9}\u{af8}\
	\x03\x02\x02\x02\u{af9}\u{afa}\x03\x02\x02\x02\u{afa}\u{afb}\x03\x02\x02\
	\x02\u{afb}\u{afc}\x05\u{144}\u{a3}\x02\u{afc}\u{b9}\x03\x02\x02\x02\u{afd}\
	\u{afe}\x07\u{13c}\x02\x02\u{afe}\u{aff}\x05\u{ca}\x66\x02\u{aff}\u{bb}\
	\x03\x02\x02\x02\u{b00}\u{b01}\x07\u{190}\x02\x02\u{b01}\u{b04}\x07\u{d6}\
	\x02\x02\u{b02}\u{b03}\x07\x12\x02\x02\u{b03}\u{b05}\x05\u{156}\u{ac}\x02\
	\u{b04}\u{b02}\x03\x02\x02\x02\u{b04}\u{b05}\x03\x02\x02\x02\u{b05}\u{b06}\
	\x03\x02\x02\x02\u{b06}\u{b07}\x07\u{160}\x02\x02\u{b07}\u{b08}\x05\u{c2}\
	\x62\x02\u{b08}\u{bd}\x03\x02\x02\x02\u{b09}\u{b0a}\x07\u{190}\x02\x02\u{b0a}\
	\u{b0b}\x05\u{15a}\u{ae}\x02\u{b0b}\u{b0e}\x07\u{d6}\x02\x02\u{b0c}\u{b0d}\
	\x07\x26\x02\x02\u{b0d}\u{b0f}\x07\u{15c}\x02\x02\u{b0e}\u{b0c}\x03\x02\
	\x02\x02\u{b0e}\u{b0f}\x03\x02\x02\x02\u{b0f}\u{b12}\x03\x02\x02\x02\u{b10}\
	\u{b11}\x07\x12\x02\x02\u{b11}\u{b13}\x05\u{156}\u{ac}\x02\u{b12}\u{b10}\
	\x03\x02\x02\x02\u{b12}\u{b13}\x03\x02\x02\x02\u{b13}\u{b14}\x03\x02\x02\
	\x02\u{b14}\u{b15}\x07\u{160}\x02\x02\u{b15}\u{b16}\x05\u{c4}\x63\x02\u{b16}\
	\u{bf}\x03\x02\x02\x02\u{b17}\u{b18}\x07\u{190}\x02\x02\u{b18}\u{b19}\x05\
	\u{15a}\u{ae}\x02\u{b19}\u{b1a}\x07\u{d6}\x02\x02\u{b1a}\u{b1b}\x07\x26\
	\x02\x02\u{b1b}\u{b1e}\x07\u{147}\x02\x02\u{b1c}\u{b1d}\x07\x12\x02\x02\
	\u{b1d}\u{b1f}\x05\u{156}\u{ac}\x02\u{b1e}\u{b1c}\x03\x02\x02\x02\u{b1e}\
	\u{b1f}\x03\x02\x02\x02\u{b1f}\u{b20}\x03\x02\x02\x02\u{b20}\u{b21}\x07\
	\u{160}\x02\x02\u{b21}\u{b22}\x05\u{c6}\x64\x02\u{b22}\u{c1}\x03\x02\x02\
	\x02\u{b23}\u{b2b}\x07\x64\x02\x02\u{b24}\u{b25}\x07\u{17f}\x02\x02\u{b25}\
	\u{b26}\x07\u{13c}\x02\x02\u{b26}\u{b2b}\x07\u{1a7}\x02\x02\u{b27}\u{b28}\
	\x07\u{17f}\x02\x02\u{b28}\u{b29}\x07\u{13c}\x02\x02\u{b29}\u{b2b}\x05\u{ca}\
	\x66\x02\u{b2a}\u{b23}\x03\x02\x02\x02\u{b2a}\u{b24}\x03\x02\x02\x02\u{b2a}\
	\u{b27}\x03\x02\x02\x02\u{b2b}\u{c3}\x03\x02\x02\x02\u{b2c}\u{b2d}\x07\u{b1}\
	\x02\x02\u{b2d}\u{b3f}\x07\u{1a7}\x02\x02\u{b2e}\u{b2f}\x07\u{b1}\x02\x02\
	\u{b2f}\u{b30}\x07\x04\x02\x02\u{b30}\u{b31}\x05\u{136}\u{9c}\x02\u{b31}\
	\u{b32}\x07\x05\x02\x02\u{b32}\u{b33}\x07\u{184}\x02\x02\u{b33}\u{b34}\x07\
	\x04\x02\x02\u{b34}\u{b39}\x05\u{14e}\u{a8}\x02\u{b35}\u{b36}\x07\x06\x02\
	\x02\u{b36}\u{b38}\x05\u{14e}\u{a8}\x02\u{b37}\u{b35}\x03\x02\x02\x02\u{b38}\
	\u{b3b}\x03\x02\x02\x02\u{b39}\u{b37}\x03\x02\x02\x02\u{b39}\u{b3a}\x03\
	\x02\x02\x02\u{b3a}\u{b3c}\x03\x02\x02\x02\u{b3b}\u{b39}\x03\x02\x02\x02\
	\u{b3c}\u{b3d}\x07\x05\x02\x02\u{b3d}\u{b3f}\x03\x02\x02\x02\u{b3e}\u{b2c}\
	\x03\x02\x02\x02\u{b3e}\u{b2e}\x03\x02\x02\x02\u{b3f}\u{c5}\x03\x02\x02\
	\x02\u{b40}\u{b45}\x07\x64\x02\x02\u{b41}\u{b42}\x07\u{17f}\x02\x02\u{b42}\
	\u{b43}\x07\u{13c}\x02\x02\u{b43}\u{b45}\x05\u{ca}\x66\x02\u{b44}\u{b40}\
	\x03\x02\x02\x02\u{b44}\u{b41}\x03\x02\x02\x02\u{b45}\u{c7}\x03\x02\x02\
	\x02\u{b46}\u{b47}\x07\x79\x02\x02\u{b47}\u{b48}\x07\x04\x02\x02\u{b48}\
	\u{b49}\x05\u{136}\u{9c}\x02\u{b49}\u{b4a}\x07\x05\x02\x02\u{b4a}\u{c9}\
	\x03\x02\x02\x02\u{b4b}\u{b50}\x05\u{cc}\x67\x02\u{b4c}\u{b4d}\x07\x06\x02\
	\x02\u{b4d}\u{b4f}\x05\u{cc}\x67\x02\u{b4e}\u{b4c}\x03\x02\x02\x02\u{b4f}\
	\u{b52}\x03\x02\x02\x02\u{b50}\u{b4e}\x03\x02\x02\x02\u{b50}\u{b51}\x03\
	\x02\x02\x02\u{b51}\u{cb}\x03\x02\x02\x02\u{b52}\u{b50}\x03\x02\x02\x02\
	\u{b53}\u{b54}\x05\u{138}\u{9d}\x02\u{b54}\u{b55}\x07\u{19a}\x02\x02\u{b55}\
	\u{b56}\x05\u{14e}\u{a8}\x02\u{b56}\u{cd}\x03\x02\x02\x02\u{b57}\u{b58}\
	\x07\u{191}\x02\x02\u{b58}\u{b59}\x05\u{156}\u{ac}\x02\u{b59}\u{cf}\x03\
	\x02\x02\x02\u{b5a}\u{b5b}\x07\u{9e}\x02\x02\u{b5b}\u{b5c}\x05\u{156}\u{ac}\
	\x02\u{b5c}\u{d1}\x03\x02\x02\x02\u{b5d}\u{b5e}\x07\u{1b4}\x02\x02\u{b5e}\
	\u{b65}\x05\u{d4}\x6b\x02\u{b5f}\u{b61}\x07\x06\x02\x02\u{b60}\u{b5f}\x03\
	\x02\x02\x02\u{b60}\u{b61}\x03\x02\x02\x02\u{b61}\u{b62}\x03\x02\x02\x02\
	\u{b62}\u{b64}\x05\u{d4}\x6b\x02\u{b63}\u{b60}\x03\x02\x02\x02\u{b64}\u{b67}\
	\x03\x02\x02\x02\u{b65}\u{b63}\x03\x02\x02\x02\u{b65}\u{b66}\x03\x02\x02\
	\x02\u{b66}\u{b68}\x03\x02\x02\x02\u{b67}\u{b65}\x03\x02\x02\x02\u{b68}\
	\u{b69}\x07\u{1b5}\x02\x02\u{b69}\u{d3}\x03\x02\x02\x02\u{b6a}\u{b78}\x05\
	\u{1e6}\u{f4}\x02\u{b6b}\u{b6c}\x05\u{1e6}\u{f4}\x02\u{b6c}\u{b6d}\x07\x04\
	\x02\x02\u{b6d}\u{b72}\x05\u{162}\u{b2}\x02\u{b6e}\u{b6f}\x07\x06\x02\x02\
	\u{b6f}\u{b71}\x05\u{162}\u{b2}\x02\u{b70}\u{b6e}\x03\x02\x02\x02\u{b71}\
	\u{b74}\x03\x02\x02\x02\u{b72}\u{b70}\x03\x02\x02\x02\u{b72}\u{b73}\x03\
	\x02\x02\x02\u{b73}\u{b75}\x03\x02\x02\x02\u{b74}\u{b72}\x03\x02\x02\x02\
	\u{b75}\u{b76}\x07\x05\x02\x02\u{b76}\u{b78}\x03\x02\x02\x02\u{b77}\u{b6a}\
	\x03\x02\x02\x02\u{b77}\u{b6b}\x03\x02\x02\x02\u{b78}\u{d5}\x03\x02\x02\
	\x02\u{b79}\u{b7a}\x07\u{92}\x02\x02\u{b7a}\u{b7f}\x05\u{106}\u{84}\x02\
	\u{b7b}\u{b7c}\x07\x06\x02\x02\u{b7c}\u{b7e}\x05\u{106}\u{84}\x02\u{b7d}\
	\u{b7b}\x03\x02\x02\x02\u{b7e}\u{b81}\x03\x02\x02\x02\u{b7f}\u{b7d}\x03\
	\x02\x02\x02\u{b7f}\u{b80}\x03\x02\x02\x02\u{b80}\u{b85}\x03\x02\x02\x02\
	\u{b81}\u{b7f}\x03\x02\x02\x02\u{b82}\u{b84}\x05\u{100}\u{81}\x02\u{b83}\
	\u{b82}\x03\x02\x02\x02\u{b84}\u{b87}\x03\x02\x02\x02\u{b85}\u{b83}\x03\
	\x02\x02\x02\u{b85}\u{b86}\x03\x02\x02\x02\u{b86}\u{b89}\x03\x02\x02\x02\
	\u{b87}\u{b85}\x03\x02\x02\x02\u{b88}\u{b8a}\x05\u{e4}\x73\x02\u{b89}\u{b88}\
	\x03\x02\x02\x02\u{b89}\u{b8a}\x03\x02\x02\x02\u{b8a}\u{b8c}\x03\x02\x02\
	\x02\u{b8b}\u{b8d}\x05\u{ea}\x76\x02\u{b8c}\u{b8b}\x03\x02\x02\x02\u{b8c}\
	\u{b8d}\x03\x02\x02\x02\u{b8d}\u{d7}\x03\x02\x02\x02\u{b8e}\u{b90}\x07\u{8d}\
	\x02\x02\u{b8f}\u{b8e}\x03\x02\x02\x02\u{b8f}\u{b90}\x03\x02\x02\x02\u{b90}\
	\u{b91}\x03\x02\x02\x02\u{b91}\u{b92}\x09\x15\x02\x02\u{b92}\u{b93}\x07\
	\x18\x02\x02\u{b93}\u{b94}\x07\u{f3}\x02\x02\u{b94}\u{b9d}\x05\u{21c}\u{10f}\
	\x02\u{b95}\u{b97}\x07\u{8d}\x02\x02\u{b96}\u{b95}\x03\x02\x02\x02\u{b96}\
	\u{b97}\x03\x02\x02\x02\u{b97}\u{b98}\x03\x02\x02\x02\u{b98}\u{b99}\x09\
	\x16\x02\x02\u{b99}\u{b9a}\x07\x18\x02\x02\u{b9a}\u{b9b}\x07\u{f3}\x02\x02\
	\u{b9b}\u{b9d}\x05\u{15c}\u{af}\x02\u{b9c}\u{b8f}\x03\x02\x02\x02\u{b9c}\
	\u{b96}\x03\x02\x02\x02\u{b9d}\u{d9}\x03\x02\x02\x02\u{b9e}\u{b9f}\x07\u{9b}\
	\x02\x02\u{b9f}\u{ba0}\x07\x26\x02\x02\u{ba0}\u{ba5}\x05\u{dc}\x6f\x02\u{ba1}\
	\u{ba2}\x07\x06\x02\x02\u{ba2}\u{ba4}\x05\u{dc}\x6f\x02\u{ba3}\u{ba1}\x03\
	\x02\x02\x02\u{ba4}\u{ba7}\x03\x02\x02\x02\u{ba5}\u{ba3}\x03\x02\x02\x02\
	\u{ba5}\u{ba6}\x03\x02\x02\x02\u{ba6}\u{bc6}\x03\x02\x02\x02\u{ba7}\u{ba5}\
	\x03\x02\x02\x02\u{ba8}\u{ba9}\x07\u{9b}\x02\x02\u{ba9}\u{baa}\x07\x26\x02\
	\x02\u{baa}\u{baf}\x05\u{142}\u{a2}\x02\u{bab}\u{bac}\x07\x06\x02\x02\u{bac}\
	\u{bae}\x05\u{142}\u{a2}\x02\u{bad}\u{bab}\x03\x02\x02\x02\u{bae}\u{bb1}\
	\x03\x02\x02\x02\u{baf}\u{bad}\x03\x02\x02\x02\u{baf}\u{bb0}\x03\x02\x02\
	\x02\u{bb0}\u{bc3}\x03\x02\x02\x02\u{bb1}\u{baf}\x03\x02\x02\x02\u{bb2}\
	\u{bb3}\x07\u{194}\x02\x02\u{bb3}\u{bc4}\x07\u{12e}\x02\x02\u{bb4}\u{bb5}\
	\x07\u{194}\x02\x02\u{bb5}\u{bc4}\x07\x4b\x02\x02\u{bb6}\u{bb7}\x07\u{9c}\
	\x02\x02\u{bb7}\u{bb8}\x07\u{13e}\x02\x02\u{bb8}\u{bb9}\x07\x04\x02\x02\
	\u{bb9}\u{bbe}\x05\u{e2}\x72\x02\u{bba}\u{bbb}\x07\x06\x02\x02\u{bbb}\u{bbd}\
	\x05\u{e2}\x72\x02\u{bbc}\u{bba}\x03\x02\x02\x02\u{bbd}\u{bc0}\x03\x02\x02\
	\x02\u{bbe}\u{bbc}\x03\x02\x02\x02\u{bbe}\u{bbf}\x03\x02\x02\x02\u{bbf}\
	\u{bc1}\x03\x02\x02\x02\u{bc0}\u{bbe}\x03\x02\x02\x02\u{bc1}\u{bc2}\x07\
	\x05\x02\x02\u{bc2}\u{bc4}\x03\x02\x02\x02\u{bc3}\u{bb2}\x03\x02\x02\x02\
	\u{bc3}\u{bb4}\x03\x02\x02\x02\u{bc3}\u{bb6}\x03\x02\x02\x02\u{bc3}\u{bc4}\
	\x03\x02\x02\x02\u{bc4}\u{bc6}\x03\x02\x02\x02\u{bc5}\u{b9e}\x03\x02\x02\
	\x02\u{bc5}\u{ba8}\x03\x02\x02\x02\u{bc6}\u{db}\x03\x02\x02\x02\u{bc7}\u{bca}\
	\x05\u{de}\x70\x02\u{bc8}\u{bca}\x05\u{14e}\u{a8}\x02\u{bc9}\u{bc7}\x03\
	\x02\x02\x02\u{bc9}\u{bc8}\x03\x02\x02\x02\u{bca}\u{dd}\x03\x02\x02\x02\
	\u{bcb}\u{bcc}\x09\x17\x02\x02\u{bcc}\u{bcd}\x07\x04\x02\x02\u{bcd}\u{bd2}\
	\x05\u{e2}\x72\x02\u{bce}\u{bcf}\x07\x06\x02\x02\u{bcf}\u{bd1}\x05\u{e2}\
	\x72\x02\u{bd0}\u{bce}\x03\x02\x02\x02\u{bd1}\u{bd4}\x03\x02\x02\x02\u{bd2}\
	\u{bd0}\x03\x02\x02\x02\u{bd2}\u{bd3}\x03\x02\x02\x02\u{bd3}\u{bd5}\x03\
	\x02\x02\x02\u{bd4}\u{bd2}\x03\x02\x02\x02\u{bd5}\u{bd6}\x07\x05\x02\x02\
	\u{bd6}\u{be5}\x03\x02\x02\x02\u{bd7}\u{bd8}\x07\u{9c}\x02\x02\u{bd8}\u{bd9}\
	\x07\u{13e}\x02\x02\u{bd9}\u{bda}\x07\x04\x02\x02\u{bda}\u{bdf}\x05\u{e0}\
	\x71\x02\u{bdb}\u{bdc}\x07\x06\x02\x02\u{bdc}\u{bde}\x05\u{e0}\x71\x02\u{bdd}\
	\u{bdb}\x03\x02\x02\x02\u{bde}\u{be1}\x03\x02\x02\x02\u{bdf}\u{bdd}\x03\
	\x02\x02\x02\u{bdf}\u{be0}\x03\x02\x02\x02\u{be0}\u{be2}\x03\x02\x02\x02\
	\u{be1}\u{bdf}\x03\x02\x02\x02\u{be2}\u{be3}\x07\x05\x02\x02\u{be3}\u{be5}\
	\x03\x02\x02\x02\u{be4}\u{bcb}\x03\x02\x02\x02\u{be4}\u{bd7}\x03\x02\x02\
	\x02\u{be5}\u{df}\x03\x02\x02\x02\u{be6}\u{be9}\x05\u{de}\x70\x02\u{be7}\
	\u{be9}\x05\u{e2}\x72\x02\u{be8}\u{be6}\x03\x02\x02\x02\u{be8}\u{be7}\x03\
	\x02\x02\x02\u{be9}\u{e1}\x03\x02\x02\x02\u{bea}\u{bf3}\x07\x04\x02\x02\
	\u{beb}\u{bf0}\x05\u{14e}\u{a8}\x02\u{bec}\u{bed}\x07\x06\x02\x02\u{bed}\
	\u{bef}\x05\u{14e}\u{a8}\x02\u{bee}\u{bec}\x03\x02\x02\x02\u{bef}\u{bf2}\
	\x03\x02\x02\x02\u{bf0}\u{bee}\x03\x02\x02\x02\u{bf0}\u{bf1}\x03\x02\x02\
	\x02\u{bf1}\u{bf4}\x03\x02\x02\x02\u{bf2}\u{bf0}\x03\x02\x02\x02\u{bf3}\
	\u{beb}\x03\x02\x02\x02\u{bf3}\u{bf4}\x03\x02\x02\x02\u{bf4}\u{bf5}\x03\
	\x02\x02\x02\u{bf5}\u{bf8}\x07\x05\x02\x02\u{bf6}\u{bf8}\x05\u{14e}\u{a8}\
	\x02\u{bf7}\u{bea}\x03\x02\x02\x02\u{bf7}\u{bf6}\x03\x02\x02\x02\u{bf8}\
	\u{e3}\x03\x02\x02\x02\u{bf9}\u{bfa}\x07\u{106}\x02\x02\u{bfa}\u{bfb}\x07\
	\x04\x02\x02\u{bfb}\u{bfc}\x05\u{144}\u{a3}\x02\u{bfc}\u{bfd}\x07\u{8d}\
	\x02\x02\u{bfd}\u{bfe}\x05\u{e6}\x74\x02\u{bfe}\u{bff}\x07\u{a8}\x02\x02\
	\u{bff}\u{c00}\x07\x04\x02\x02\u{c00}\u{c05}\x05\u{e8}\x75\x02\u{c01}\u{c02}\
	\x07\x06\x02\x02\u{c02}\u{c04}\x05\u{e8}\x75\x02\u{c03}\u{c01}\x03\x02\x02\
	\x02\u{c04}\u{c07}\x03\x02\x02\x02\u{c05}\u{c03}\x03\x02\x02\x02\u{c05}\
	\u{c06}\x03\x02\x02\x02\u{c06}\u{c08}\x03\x02\x02\x02\u{c07}\u{c05}\x03\
	\x02\x02\x02\u{c08}\u{c09}\x07\x05\x02\x02\u{c09}\u{c0a}\x07\x05\x02\x02\
	\u{c0a}\u{e5}\x03\x02\x02\x02\u{c0b}\u{c18}\x05\u{1e0}\u{f1}\x02\u{c0c}\
	\u{c0d}\x07\x04\x02\x02\u{c0d}\u{c12}\x05\u{1e0}\u{f1}\x02\u{c0e}\u{c0f}\
	\x07\x06\x02\x02\u{c0f}\u{c11}\x05\u{1e0}\u{f1}\x02\u{c10}\u{c0e}\x03\x02\
	\x02\x02\u{c11}\u{c14}\x03\x02\x02\x02\u{c12}\u{c10}\x03\x02\x02\x02\u{c12}\
	\u{c13}\x03\x02\x02\x02\u{c13}\u{c15}\x03\x02\x02\x02\u{c14}\u{c12}\x03\
	\x02\x02\x02\u{c15}\u{c16}\x07\x05\x02\x02\u{c16}\u{c18}\x03\x02\x02\x02\
	\u{c17}\u{c0b}\x03\x02\x02\x02\u{c17}\u{c0c}\x03\x02\x02\x02\u{c18}\u{e7}\
	\x03\x02\x02\x02\u{c19}\u{c1e}\x05\u{14e}\u{a8}\x02\u{c1a}\u{c1c}\x07\x18\
	\x02\x02\u{c1b}\u{c1a}\x03\x02\x02\x02\u{c1b}\u{c1c}\x03\x02\x02\x02\u{c1c}\
	\u{c1d}\x03\x02\x02\x02\u{c1d}\u{c1f}\x05\u{1e0}\u{f1}\x02\u{c1e}\u{c1b}\
	\x03\x02\x02\x02\u{c1e}\u{c1f}\x03\x02\x02\x02\u{c1f}\u{e9}\x03\x02\x02\
	\x02\u{c20}\u{c22}\x07\u{17c}\x02\x02\u{c21}\u{c23}\x05\u{ec}\x77\x02\u{c22}\
	\u{c21}\x03\x02\x02\x02\u{c22}\u{c23}\x03\x02\x02\x02\u{c23}\u{c24}\x03\
	\x02\x02\x02\u{c24}\u{c25}\x07\x04\x02\x02\u{c25}\u{c26}\x05\u{ee}\x78\x02\
	\u{c26}\u{c2b}\x07\x05\x02\x02\u{c27}\u{c29}\x07\x18\x02\x02\u{c28}\u{c27}\
	\x03\x02\x02\x02\u{c28}\u{c29}\x03\x02\x02\x02\u{c29}\u{c2a}\x03\x02\x02\
	\x02\u{c2a}\u{c2c}\x05\u{1e0}\u{f1}\x02\u{c2b}\u{c28}\x03\x02\x02\x02\u{c2b}\
	\u{c2c}\x03\x02\x02\x02\u{c2c}\u{eb}\x03\x02\x02\x02\u{c2d}\u{c2e}\x09\x18\
	\x02\x02\u{c2e}\u{c2f}\x07\u{f0}\x02\x02\u{c2f}\u{ed}\x03\x02\x02\x02\u{c30}\
	\u{c33}\x05\u{f0}\x79\x02\u{c31}\u{c33}\x05\u{f2}\x7a\x02\u{c32}\u{c30}\
	\x03\x02\x02\x02\u{c32}\u{c31}\x03\x02\x02\x02\u{c33}\u{ef}\x03\x02\x02\
	\x02\u{c34}\u{c35}\x05\u{f6}\x7c\x02\u{c35}\u{c36}\x07\u{8d}\x02\x02\u{c36}\
	\u{c37}\x05\u{f8}\x7d\x02\u{c37}\u{c38}\x07\u{a8}\x02\x02\u{c38}\u{c39}\
	\x07\x04\x02\x02\u{c39}\u{c3e}\x05\u{fa}\x7e\x02\u{c3a}\u{c3b}\x07\x06\x02\
	\x02\u{c3b}\u{c3d}\x05\u{fa}\x7e\x02\u{c3c}\u{c3a}\x03\x02\x02\x02\u{c3d}\
	\u{c40}\x03\x02\x02\x02\u{c3e}\u{c3c}\x03\x02\x02\x02\u{c3e}\u{c3f}\x03\
	\x02\x02\x02\u{c3f}\u{c41}\x03\x02\x02\x02\u{c40}\u{c3e}\x03\x02\x02\x02\
	\u{c41}\u{c42}\x07\x05\x02\x02\u{c42}\u{f1}\x03\x02\x02\x02\u{c43}\u{c44}\
	\x07\x04\x02\x02\u{c44}\u{c49}\x05\u{f6}\x7c\x02\u{c45}\u{c46}\x07\x06\x02\
	\x02\u{c46}\u{c48}\x05\u{f6}\x7c\x02\u{c47}\u{c45}\x03\x02\x02\x02\u{c48}\
	\u{c4b}\x03\x02\x02\x02\u{c49}\u{c47}\x03\x02\x02\x02\u{c49}\u{c4a}\x03\
	\x02\x02\x02\u{c4a}\u{c4c}\x03\x02\x02\x02\u{c4b}\u{c49}\x03\x02\x02\x02\
	\u{c4c}\u{c4d}\x07\x05\x02\x02\u{c4d}\u{c4e}\x07\u{8d}\x02\x02\u{c4e}\u{c4f}\
	\x05\u{f8}\x7d\x02\u{c4f}\u{c50}\x07\u{a8}\x02\x02\u{c50}\u{c51}\x07\x04\
	\x02\x02\u{c51}\u{c56}\x05\u{f4}\x7b\x02\u{c52}\u{c53}\x07\x06\x02\x02\u{c53}\
	\u{c55}\x05\u{f4}\x7b\x02\u{c54}\u{c52}\x03\x02\x02\x02\u{c55}\u{c58}\x03\
	\x02\x02\x02\u{c56}\u{c54}\x03\x02\x02\x02\u{c56}\u{c57}\x03\x02\x02\x02\
	\u{c57}\u{c59}\x03\x02\x02\x02\u{c58}\u{c56}\x03\x02\x02\x02\u{c59}\u{c5a}\
	\x07\x05\x02\x02\u{c5a}\u{f3}\x03\x02\x02\x02\u{c5b}\u{c5c}\x07\x04\x02\
	\x02\u{c5c}\u{c61}\x05\u{fc}\x7f\x02\u{c5d}\u{c5e}\x07\x06\x02\x02\u{c5e}\
	\u{c60}\x05\u{fc}\x7f\x02\u{c5f}\u{c5d}\x03\x02\x02\x02\u{c60}\u{c63}\x03\
	\x02\x02\x02\u{c61}\u{c5f}\x03\x02\x02\x02\u{c61}\u{c62}\x03\x02\x02\x02\
	\u{c62}\u{c64}\x03\x02\x02\x02\u{c63}\u{c61}\x03\x02\x02\x02\u{c64}\u{c66}\
	\x07\x05\x02\x02\u{c65}\u{c67}\x05\u{fe}\u{80}\x02\u{c66}\u{c65}\x03\x02\
	\x02\x02\u{c66}\u{c67}\x03\x02\x02\x02\u{c67}\u{f5}\x03\x02\x02\x02\u{c68}\
	\u{c69}\x05\u{1e4}\u{f3}\x02\u{c69}\u{f7}\x03\x02\x02\x02\u{c6a}\u{c6b}\
	\x05\u{1e4}\u{f3}\x02\u{c6b}\u{f9}\x03\x02\x02\x02\u{c6c}\u{c6e}\x05\u{fc}\
	\x7f\x02\u{c6d}\u{c6f}\x05\u{fe}\u{80}\x02\u{c6e}\u{c6d}\x03\x02\x02\x02\
	\u{c6e}\u{c6f}\x03\x02\x02\x02\u{c6f}\u{fb}\x03\x02\x02\x02\u{c70}\u{c71}\
	\x05\u{138}\u{9d}\x02\u{c71}\u{fd}\x03\x02\x02\x02\u{c72}\u{c74}\x07\x18\
	\x02\x02\u{c73}\u{c72}\x03\x02\x02\x02\u{c73}\u{c74}\x03\x02\x02\x02\u{c74}\
	\u{c75}\x03\x02\x02\x02\u{c75}\u{c76}\x05\u{1e0}\u{f1}\x02\u{c76}\u{ff}\
	\x03\x02\x02\x02\u{c77}\u{c78}\x07\u{c1}\x02\x02\u{c78}\u{c7a}\x07\u{18a}\
	\x02\x02\u{c79}\u{c7b}\x07\u{fc}\x02\x02\u{c7a}\u{c79}\x03\x02\x02\x02\u{c7a}\
	\u{c7b}\x03\x02\x02\x02\u{c7b}\u{c7c}\x03\x02\x02\x02\u{c7c}\u{c7d}\x05\
	\u{1de}\u{f0}\x02\u{c7d}\u{c86}\x07\x04\x02\x02\u{c7e}\u{c83}\x05\u{14e}\
	\u{a8}\x02\u{c7f}\u{c80}\x07\x06\x02\x02\u{c80}\u{c82}\x05\u{14e}\u{a8}\
	\x02\u{c81}\u{c7f}\x03\x02\x02\x02\u{c82}\u{c85}\x03\x02\x02\x02\u{c83}\
	\u{c81}\x03\x02\x02\x02\u{c83}\u{c84}\x03\x02\x02\x02\u{c84}\u{c87}\x03\
	\x02\x02\x02\u{c85}\u{c83}\x03\x02\x02\x02\u{c86}\u{c7e}\x03\x02\x02\x02\
	\u{c86}\u{c87}\x03\x02\x02\x02\u{c87}\u{c88}\x03\x02\x02\x02\u{c88}\u{c89}\
	\x07\x05\x02\x02\u{c89}\u{c95}\x05\u{1e4}\u{f3}\x02\u{c8a}\u{c8c}\x07\x18\
	\x02\x02\u{c8b}\u{c8a}\x03\x02\x02\x02\u{c8b}\u{c8c}\x03\x02\x02\x02\u{c8c}\
	\u{c8d}\x03\x02\x02\x02\u{c8d}\u{c92}\x05\u{1e4}\u{f3}\x02\u{c8e}\u{c8f}\
	\x07\x06\x02\x02\u{c8f}\u{c91}\x05\u{1e4}\u{f3}\x02\u{c90}\u{c8e}\x03\x02\
	\x02\x02\u{c91}\u{c94}\x03\x02\x02\x02\u{c92}\u{c90}\x03\x02\x02\x02\u{c92}\
	\u{c93}\x03\x02\x02\x02\u{c93}\u{c96}\x03\x02\x02\x02\u{c94}\u{c92}\x03\
	\x02\x02\x02\u{c95}\u{c8b}\x03\x02\x02\x02\u{c95}\u{c96}\x03\x02\x02\x02\
	\u{c96}\u{101}\x03\x02\x02\x02\u{c97}\u{c98}\x07\u{18d}\x02\x02\u{c98}\u{c99}\
	\x05\u{142}\u{a2}\x02\u{c99}\u{c9a}\x07\x63\x02\x02\u{c9a}\u{c9b}\x07\u{f3}\
	\x02\x02\u{c9b}\u{c9c}\x05\u{17c}\u{bf}\x02\u{c9c}\u{103}\x03\x02\x02\x02\
	\u{c9d}\u{c9e}\x09\x19\x02\x02\u{c9e}\u{105}\x03\x02\x02\x02\u{c9f}\u{ca1}\
	\x07\u{c1}\x02\x02\u{ca0}\u{c9f}\x03\x02\x02\x02\u{ca0}\u{ca1}\x03\x02\x02\
	\x02\u{ca1}\u{ca2}\x03\x02\x02\x02\u{ca2}\u{ca6}\x05\u{120}\u{91}\x02\u{ca3}\
	\u{ca5}\x05\u{108}\u{85}\x02\u{ca4}\u{ca3}\x03\x02\x02\x02\u{ca5}\u{ca8}\
	\x03\x02\x02\x02\u{ca6}\u{ca4}\x03\x02\x02\x02\u{ca6}\u{ca7}\x03\x02\x02\
	\x02\u{ca7}\u{107}\x03\x02\x02\x02\u{ca8}\u{ca6}\x03\x02\x02\x02\u{ca9}\
	\u{cad}\x05\u{10a}\u{86}\x02\u{caa}\u{cad}\x05\u{e4}\x73\x02\u{cab}\u{cad}\
	\x05\u{ea}\x76\x02\u{cac}\u{ca9}\x03\x02\x02\x02\u{cac}\u{caa}\x03\x02\x02\
	\x02\u{cac}\u{cab}\x03\x02\x02\x02\u{cad}\u{109}\x03\x02\x02\x02\u{cae}\
	\u{caf}\x05\u{10c}\u{87}\x02\u{caf}\u{cb1}\x07\u{bb}\x02\x02\u{cb0}\u{cb2}\
	\x07\u{c1}\x02\x02\u{cb1}\u{cb0}\x03\x02\x02\x02\u{cb1}\u{cb2}\x03\x02\x02\
	\x02\u{cb2}\u{cb3}\x03\x02\x02\x02\u{cb3}\u{cb5}\x05\u{120}\u{91}\x02\u{cb4}\
	\u{cb6}\x05\u{10e}\u{88}\x02\u{cb5}\u{cb4}\x03\x02\x02\x02\u{cb5}\u{cb6}\
	\x03\x02\x02\x02\u{cb6}\u{cc0}\x03\x02\x02\x02\u{cb7}\u{cb8}\x07\u{eb}\x02\
	\x02\u{cb8}\u{cb9}\x05\u{10c}\u{87}\x02\u{cb9}\u{cbb}\x07\u{bb}\x02\x02\
	\u{cba}\u{cbc}\x07\u{c1}\x02\x02\u{cbb}\u{cba}\x03\x02\x02\x02\u{cbb}\u{cbc}\
	\x03\x02\x02\x02\u{cbc}\u{cbd}\x03\x02\x02\x02\u{cbd}\u{cbe}\x05\u{120}\
	\u{91}\x02\u{cbe}\u{cc0}\x03\x02\x02\x02\u{cbf}\u{cae}\x03\x02\x02\x02\u{cbf}\
	\u{cb7}\x03\x02\x02\x02\u{cc0}\u{10b}\x03\x02\x02\x02\u{cc1}\u{cc3}\x07\
	\u{ad}\x02\x02\u{cc2}\u{cc1}\x03\x02\x02\x02\u{cc2}\u{cc3}\x03\x02\x02\x02\
	\u{cc3}\u{cda}\x03\x02\x02\x02\u{cc4}\u{cda}\x07\x4a\x02\x02\u{cc5}\u{cc7}\
	\x07\u{c5}\x02\x02\u{cc6}\u{cc8}\x07\u{fc}\x02\x02\u{cc7}\u{cc6}\x03\x02\
	\x02\x02\u{cc7}\u{cc8}\x03\x02\x02\x02\u{cc8}\u{cda}\x03\x02\x02\x02\u{cc9}\
	\u{ccb}\x07\u{c5}\x02\x02\u{cca}\u{cc9}\x03\x02\x02\x02\u{cca}\u{ccb}\x03\
	\x02\x02\x02\u{ccb}\u{ccc}\x03\x02\x02\x02\u{ccc}\u{cda}\x07\u{137}\x02\
	\x02\u{ccd}\u{ccf}\x07\u{129}\x02\x02\u{cce}\u{cd0}\x07\u{fc}\x02\x02\u{ccf}\
	\u{cce}\x03\x02\x02\x02\u{ccf}\u{cd0}\x03\x02\x02\x02\u{cd0}\u{cda}\x03\
	\x02\x02\x02\u{cd1}\u{cd3}\x07\u{93}\x02\x02\u{cd2}\u{cd4}\x07\u{fc}\x02\
	\x02\u{cd3}\u{cd2}\x03\x02\x02\x02\u{cd3}\u{cd4}\x03\x02\x02\x02\u{cd4}\
	\u{cda}\x03\x02\x02\x02\u{cd5}\u{cd7}\x07\u{c5}\x02\x02\u{cd6}\u{cd5}\x03\
	\x02\x02\x02\u{cd6}\u{cd7}\x03\x02\x02\x02\u{cd7}\u{cd8}\x03\x02\x02\x02\
	\u{cd8}\u{cda}\x07\x13\x02\x02\u{cd9}\u{cc2}\x03\x02\x02\x02\u{cd9}\u{cc4}\
	\x03\x02\x02\x02\u{cd9}\u{cc5}\x03\x02\x02\x02\u{cd9}\u{cca}\x03\x02\x02\
	\x02\u{cd9}\u{ccd}\x03\x02\x02\x02\u{cd9}\u{cd1}\x03\x02\x02\x02\u{cd9}\
	\u{cd6}\x03\x02\x02\x02\u{cda}\u{10d}\x03\x02\x02\x02\u{cdb}\u{cdc}\x07\
	\u{f5}\x02\x02\u{cdc}\u{ce0}\x05\u{156}\u{ac}\x02\u{cdd}\u{cde}\x07\u{182}\
	\x02\x02\u{cde}\u{ce0}\x05\u{114}\u{8b}\x02\u{cdf}\u{cdb}\x03\x02\x02\x02\
	\u{cdf}\u{cdd}\x03\x02\x02\x02\u{ce0}\u{10f}\x03\x02\x02\x02\u{ce1}\u{ce2}\
	\x07\u{15b}\x02\x02\u{ce2}\u{ce4}\x07\x04\x02\x02\u{ce3}\u{ce5}\x05\u{112}\
	\u{8a}\x02\u{ce4}\u{ce3}\x03\x02\x02\x02\u{ce4}\u{ce5}\x03\x02\x02\x02\u{ce5}\
	\u{ce6}\x03\x02\x02\x02\u{ce6}\u{cec}\x07\x05\x02\x02\u{ce7}\u{ce8}\x07\
	\u{121}\x02\x02\u{ce8}\u{ce9}\x07\x04\x02\x02\u{ce9}\u{cea}\x05\u{1f2}\u{fa}\
	\x02\u{cea}\u{ceb}\x07\x05\x02\x02\u{ceb}\u{ced}\x03\x02\x02\x02\u{cec}\
	\u{ce7}\x03\x02\x02\x02\u{cec}\u{ced}\x03\x02\x02\x02\u{ced}\u{111}\x03\
	\x02\x02\x02\u{cee}\u{cf0}\x07\u{1a6}\x02\x02\u{cef}\u{cee}\x03\x02\x02\
	\x02\u{cef}\u{cf0}\x03\x02\x02\x02\u{cf0}\u{cf3}\x03\x02\x02\x02\u{cf1}\
	\u{cf4}\x05\u{1f2}\u{fa}\x02\u{cf2}\u{cf4}\x07\u{1bf}\x02\x02\u{cf3}\u{cf1}\
	\x03\x02\x02\x02\u{cf3}\u{cf2}\x03\x02\x02\x02\u{cf4}\u{cf5}\x03\x02\x02\
	\x02\u{cf5}\u{d0a}\x07\u{105}\x02\x02\u{cf6}\u{cf7}\x05\u{14e}\u{a8}\x02\
	\u{cf7}\u{cf8}\x07\u{130}\x02\x02\u{cf8}\u{d0a}\x03\x02\x02\x02\u{cf9}\u{cfa}\
	\x07\x24\x02\x02\u{cfa}\u{cfb}\x05\u{1f2}\u{fa}\x02\u{cfb}\u{cfc}\x07\u{fb}\
	\x02\x02\u{cfc}\u{cfd}\x07\u{f3}\x02\x02\u{cfd}\u{d06}\x05\u{1f2}\u{fa}\
	\x02\u{cfe}\u{d04}\x07\u{f5}\x02\x02\u{cff}\u{d05}\x05\u{1e4}\u{f3}\x02\
	\u{d00}\u{d01}\x05\u{1de}\u{f0}\x02\u{d01}\u{d02}\x07\x04\x02\x02\u{d02}\
	\u{d03}\x07\x05\x02\x02\u{d03}\u{d05}\x03\x02\x02\x02\u{d04}\u{cff}\x03\
	\x02\x02\x02\u{d04}\u{d00}\x03\x02\x02\x02\u{d05}\u{d07}\x03\x02\x02\x02\
	\u{d06}\u{cfe}\x03\x02\x02\x02\u{d06}\u{d07}\x03\x02\x02\x02\u{d07}\u{d0a}\
	\x03\x02\x02\x02\u{d08}\u{d0a}\x05\u{14e}\u{a8}\x02\u{d09}\u{cef}\x03\x02\
	\x02\x02\u{d09}\u{cf6}\x03\x02\x02\x02\u{d09}\u{cf9}\x03\x02\x02\x02\u{d09}\
	\u{d08}\x03\x02\x02\x02\u{d0a}\u{113}\x03\x02\x02\x02\u{d0b}\u{d0c}\x07\
	\x04\x02\x02\u{d0c}\u{d0d}\x05\u{116}\u{8c}\x02\u{d0d}\u{d0e}\x07\x05\x02\
	\x02\u{d0e}\u{115}\x03\x02\x02\x02\u{d0f}\u{d14}\x05\u{1e0}\u{f1}\x02\u{d10}\
	\u{d11}\x07\x06\x02\x02\u{d11}\u{d13}\x05\u{1e0}\u{f1}\x02\u{d12}\u{d10}\
	\x03\x02\x02\x02\u{d13}\u{d16}\x03\x02\x02\x02\u{d14}\u{d12}\x03\x02\x02\
	\x02\u{d14}\u{d15}\x03\x02\x02\x02\u{d15}\u{117}\x03\x02\x02\x02\u{d16}\
	\u{d14}\x03\x02\x02\x02\u{d17}\u{d18}\x07\x04\x02\x02\u{d18}\u{d1d}\x05\
	\u{11a}\u{8e}\x02\u{d19}\u{d1a}\x07\x06\x02\x02\u{d1a}\u{d1c}\x05\u{11a}\
	\u{8e}\x02\u{d1b}\u{d19}\x03\x02\x02\x02\u{d1c}\u{d1f}\x03\x02\x02\x02\u{d1d}\
	\u{d1b}\x03\x02\x02\x02\u{d1d}\u{d1e}\x03\x02\x02\x02\u{d1e}\u{d20}\x03\
	\x02\x02\x02\u{d1f}\u{d1d}\x03\x02\x02\x02\u{d20}\u{d21}\x07\x05\x02\x02\
	\u{d21}\u{119}\x03\x02\x02\x02\u{d22}\u{d24}\x05\u{1e0}\u{f1}\x02\u{d23}\
	\u{d25}\x09\x13\x02\x02\u{d24}\u{d23}\x03\x02\x02\x02\u{d24}\u{d25}\x03\
	\x02\x02\x02\u{d25}\u{11b}\x03\x02\x02\x02\u{d26}\u{d27}\x07\x04\x02\x02\
	\u{d27}\u{d2c}\x05\u{11e}\u{90}\x02\u{d28}\u{d29}\x07\x06\x02\x02\u{d29}\
	\u{d2b}\x05\u{11e}\u{90}\x02\u{d2a}\u{d28}\x03\x02\x02\x02\u{d2b}\u{d2e}\
	\x03\x02\x02\x02\u{d2c}\u{d2a}\x03\x02\x02\x02\u{d2c}\u{d2d}\x03\x02\x02\
	\x02\u{d2d}\u{d2f}\x03\x02\x02\x02\u{d2e}\u{d2c}\x03\x02\x02\x02\u{d2f}\
	\u{d30}\x07\x05\x02\x02\u{d30}\u{11d}\x03\x02\x02\x02\u{d31}\u{d33}\x05\
	\u{1e4}\u{f3}\x02\u{d32}\u{d34}\x05\x62\x32\x02\u{d33}\u{d32}\x03\x02\x02\
	\x02\u{d33}\u{d34}\x03\x02\x02\x02\u{d34}\u{11f}\x03\x02\x02\x02\u{d35}\
	\u{d5e}\x05\x44\x23\x02\u{d36}\u{d38}\x05\u{a2}\x52\x02\u{d37}\u{d39}\x05\
	\u{d8}\x6d\x02\u{d38}\u{d37}\x03\x02\x02\x02\u{d38}\u{d39}\x03\x02\x02\x02\
	\u{d39}\u{d3b}\x03\x02\x02\x02\u{d3a}\u{d3c}\x05\u{122}\u{92}\x02\u{d3b}\
	\u{d3a}\x03\x02\x02\x02\u{d3b}\u{d3c}\x03\x02\x02\x02\u{d3c}\u{d3e}\x03\
	\x02\x02\x02\u{d3d}\u{d3f}\x05\u{110}\u{89}\x02\u{d3e}\u{d3d}\x03\x02\x02\
	\x02\u{d3e}\u{d3f}\x03\x02\x02\x02\u{d3f}\u{d41}\x03\x02\x02\x02\u{d40}\
	\u{d42}\x05\u{102}\u{82}\x02\u{d41}\u{d40}\x03\x02\x02\x02\u{d41}\u{d42}\
	\x03\x02\x02\x02\u{d42}\u{d43}\x03\x02\x02\x02\u{d43}\u{d44}\x05\u{132}\
	\u{9a}\x02\u{d44}\u{d5e}\x03\x02\x02\x02\u{d45}\u{d46}\x07\x04\x02\x02\u{d46}\
	\u{d47}\x05\x66\x34\x02\u{d47}\u{d49}\x07\x05\x02\x02\u{d48}\u{d4a}\x05\
	\u{110}\u{89}\x02\u{d49}\u{d48}\x03\x02\x02\x02\u{d49}\u{d4a}\x03\x02\x02\
	\x02\u{d4a}\u{d4c}\x03\x02\x02\x02\u{d4b}\u{d4d}\x05\u{102}\u{82}\x02\u{d4c}\
	\u{d4b}\x03\x02\x02\x02\u{d4c}\u{d4d}\x03\x02\x02\x02\u{d4d}\u{d4e}\x03\
	\x02\x02\x02\u{d4e}\u{d4f}\x05\u{132}\u{9a}\x02\u{d4f}\u{d5e}\x03\x02\x02\
	\x02\u{d50}\u{d51}\x07\x04\x02\x02\u{d51}\u{d52}\x05\u{106}\u{84}\x02\u{d52}\
	\u{d54}\x07\x05\x02\x02\u{d53}\u{d55}\x05\u{110}\u{89}\x02\u{d54}\u{d53}\
	\x03\x02\x02\x02\u{d54}\u{d55}\x03\x02\x02\x02\u{d55}\u{d57}\x03\x02\x02\
	\x02\u{d56}\u{d58}\x05\u{102}\u{82}\x02\u{d57}\u{d56}\x03\x02\x02\x02\u{d57}\
	\u{d58}\x03\x02\x02\x02\u{d58}\u{d59}\x03\x02\x02\x02\u{d59}\u{d5a}\x05\
	\u{132}\u{9a}\x02\u{d5a}\u{d5e}\x03\x02\x02\x02\u{d5b}\u{d5e}\x05\u{124}\
	\u{93}\x02\u{d5c}\u{d5e}\x05\u{130}\u{99}\x02\u{d5d}\u{d35}\x03\x02\x02\
	\x02\u{d5d}\u{d36}\x03\x02\x02\x02\u{d5d}\u{d45}\x03\x02\x02\x02\u{d5d}\
	\u{d50}\x03\x02\x02\x02\u{d5d}\u{d5b}\x03\x02\x02\x02\u{d5d}\u{d5c}\x03\
	\x02\x02\x02\u{d5e}\u{121}\x03\x02\x02\x02\u{d5f}\u{d60}\x07\u{194}\x02\
	\x02\u{d60}\u{d61}\x05\u{84}\x43\x02\u{d61}\u{123}\x03\x02\x02\x02\u{d62}\
	\u{d63}\x07\u{184}\x02\x02\u{d63}\u{d68}\x05\u{14e}\u{a8}\x02\u{d64}\u{d65}\
	\x07\x06\x02\x02\u{d65}\u{d67}\x05\u{14e}\u{a8}\x02\u{d66}\u{d64}\x03\x02\
	\x02\x02\u{d67}\u{d6a}\x03\x02\x02\x02\u{d68}\u{d66}\x03\x02\x02\x02\u{d68}\
	\u{d69}\x03\x02\x02\x02\u{d69}\u{d6b}\x03\x02\x02\x02\u{d6a}\u{d68}\x03\
	\x02\x02\x02\u{d6b}\u{d6c}\x05\u{132}\u{9a}\x02\u{d6c}\u{125}\x03\x02\x02\
	\x02\u{d6d}\u{d6e}\x07\u{159}\x02\x02\u{d6e}\u{d70}\x05\u{a2}\x52\x02\u{d6f}\
	\u{d71}\x05\u{128}\u{95}\x02\u{d70}\u{d6f}\x03\x02\x02\x02\u{d70}\u{d71}\
	\x03\x02\x02\x02\u{d71}\u{d81}\x03\x02\x02\x02\u{d72}\u{d73}\x07\u{159}\
	\x02\x02\u{d73}\u{d74}\x07\x04\x02\x02\u{d74}\u{d75}\x05\u{a2}\x52\x02\u{d75}\
	\u{d77}\x07\x05\x02\x02\u{d76}\u{d78}\x05\u{128}\u{95}\x02\u{d77}\u{d76}\
	\x03\x02\x02\x02\u{d77}\u{d78}\x03\x02\x02\x02\u{d78}\u{d81}\x03\x02\x02\
	\x02\u{d79}\u{d7a}\x07\u{159}\x02\x02\u{d7a}\u{d7b}\x07\x04\x02\x02\u{d7b}\
	\u{d7c}\x05\x66\x34\x02\u{d7c}\u{d7e}\x07\x05\x02\x02\u{d7d}\u{d7f}\x05\
	\u{128}\u{95}\x02\u{d7e}\u{d7d}\x03\x02\x02\x02\u{d7e}\u{d7f}\x03\x02\x02\
	\x02\u{d7f}\u{d81}\x03\x02\x02\x02\u{d80}\u{d6d}\x03\x02\x02\x02\u{d80}\
	\u{d72}\x03\x02\x02\x02\u{d80}\u{d79}\x03\x02\x02\x02\u{d81}\u{127}\x03\
	\x02\x02\x02\u{d82}\u{d83}\x07\u{194}\x02\x02\u{d83}\u{d84}\x07\u{141}\x02\
	\x02\u{d84}\u{d9d}\x07\u{102}\x02\x02\u{d85}\u{d86}\x09\x1a\x02\x02\u{d86}\
	\u{d9a}\x07\x26\x02\x02\u{d87}\u{d88}\x07\x04\x02\x02\u{d88}\u{d8d}\x05\
	\u{14e}\u{a8}\x02\u{d89}\u{d8a}\x07\x06\x02\x02\u{d8a}\u{d8c}\x05\u{14e}\
	\u{a8}\x02\u{d8b}\u{d89}\x03\x02\x02\x02\u{d8c}\u{d8f}\x03\x02\x02\x02\u{d8d}\
	\u{d8b}\x03\x02\x02\x02\u{d8d}\u{d8e}\x03\x02\x02\x02\u{d8e}\u{d90}\x03\
	\x02\x02\x02\u{d8f}\u{d8d}\x03\x02\x02\x02\u{d90}\u{d91}\x07\x05\x02\x02\
	\u{d91}\u{d9b}\x03\x02\x02\x02\u{d92}\u{d95}\x05\u{14e}\u{a8}\x02\u{d93}\
	\u{d94}\x07\x06\x02\x02\u{d94}\u{d96}\x05\u{14e}\u{a8}\x02\u{d95}\u{d93}\
	\x03\x02\x02\x02\u{d96}\u{d97}\x03\x02\x02\x02\u{d97}\u{d95}\x03\x02\x02\
	\x02\u{d97}\u{d98}\x03\x02\x02\x02\u{d98}\u{d9b}\x03\x02\x02\x02\u{d99}\
	\u{d9b}\x05\u{14e}\u{a8}\x02\u{d9a}\u{d87}\x03\x02\x02\x02\u{d9a}\u{d92}\
	\x03\x02\x02\x02\u{d9a}\u{d99}\x03\x02\x02\x02\u{d9b}\u{d9d}\x03\x02\x02\
	\x02\u{d9c}\u{d82}\x03\x02\x02\x02\u{d9c}\u{d85}\x03\x02\x02\x02\u{d9d}\
	\u{db5}\x03\x02\x02\x02\u{d9e}\u{d9f}\x09\x1b\x02\x02\u{d9f}\u{db3}\x07\
	\x26\x02\x02\u{da0}\u{da1}\x07\x04\x02\x02\u{da1}\u{da6}\x05\u{ae}\x58\x02\
	\u{da2}\u{da3}\x07\x06\x02\x02\u{da3}\u{da5}\x05\u{ae}\x58\x02\u{da4}\u{da2}\
	\x03\x02\x02\x02\u{da5}\u{da8}\x03\x02\x02\x02\u{da6}\u{da4}\x03\x02\x02\
	\x02\u{da6}\u{da7}\x03\x02\x02\x02\u{da7}\u{da9}\x03\x02\x02\x02\u{da8}\
	\u{da6}\x03\x02\x02\x02\u{da9}\u{daa}\x07\x05\x02\x02\u{daa}\u{db4}\x03\
	\x02\x02\x02\u{dab}\u{dae}\x05\u{ae}\x58\x02\u{dac}\u{dad}\x07\x06\x02\x02\
	\u{dad}\u{daf}\x05\u{ae}\x58\x02\u{dae}\u{dac}\x03\x02\x02\x02\u{daf}\u{db0}\
	\x03\x02\x02\x02\u{db0}\u{dae}\x03\x02\x02\x02\u{db0}\u{db1}\x03\x02\x02\
	\x02\u{db1}\u{db4}\x03\x02\x02\x02\u{db2}\u{db4}\x05\u{ae}\x58\x02\u{db3}\
	\u{da0}\x03\x02\x02\x02\u{db3}\u{dab}\x03\x02\x02\x02\u{db3}\u{db2}\x03\
	\x02\x02\x02\u{db4}\u{db6}\x03\x02\x02\x02\u{db5}\u{d9e}\x03\x02\x02\x02\
	\u{db5}\u{db6}\x03\x02\x02\x02\u{db6}\u{129}\x03\x02\x02\x02\u{db7}\u{db8}\
	\x05\u{1e4}\u{f3}\x02\u{db8}\u{db9}\x07\u{1b3}\x02\x02\u{db9}\u{dba}\x05\
	\u{126}\u{94}\x02\u{dba}\u{12b}\x03\x02\x02\x02\u{dbb}\u{dbe}\x05\u{126}\
	\u{94}\x02\u{dbc}\u{dbe}\x05\u{12a}\u{96}\x02\u{dbd}\u{dbb}\x03\x02\x02\
	\x02\u{dbd}\u{dbc}\x03\x02\x02\x02\u{dbe}\u{12d}\x03\x02\x02\x02\u{dbf}\
	\u{dc2}\x05\u{12c}\u{97}\x02\u{dc0}\u{dc2}\x05\u{152}\u{aa}\x02\u{dc1}\u{dbf}\
	\x03\x02\x02\x02\u{dc1}\u{dc0}\x03\x02\x02\x02\u{dc2}\u{12f}\x03\x02\x02\
	\x02\u{dc3}\u{dc4}\x05\u{1dc}\u{ef}\x02\u{dc4}\u{dcd}\x07\x04\x02\x02\u{dc5}\
	\u{dca}\x05\u{12e}\u{98}\x02\u{dc6}\u{dc7}\x07\x06\x02\x02\u{dc7}\u{dc9}\
	\x05\u{12e}\u{98}\x02\u{dc8}\u{dc6}\x03\x02\x02\x02\u{dc9}\u{dcc}\x03\x02\
	\x02\x02\u{dca}\u{dc8}\x03\x02\x02\x02\u{dca}\u{dcb}\x03\x02\x02\x02\u{dcb}\
	\u{dce}\x03\x02\x02\x02\u{dcc}\u{dca}\x03\x02\x02\x02\u{dcd}\u{dc5}\x03\
	\x02\x02\x02\u{dcd}\u{dce}\x03\x02\x02\x02\u{dce}\u{dcf}\x03\x02\x02\x02\
	\u{dcf}\u{dd1}\x07\x05\x02\x02\u{dd0}\u{dd2}\x05\u{102}\u{82}\x02\u{dd1}\
	\u{dd0}\x03\x02\x02\x02\u{dd1}\u{dd2}\x03\x02\x02\x02\u{dd2}\u{dd3}\x03\
	\x02\x02\x02\u{dd3}\u{dd4}\x05\u{132}\u{9a}\x02\u{dd4}\u{131}\x03\x02\x02\
	\x02\u{dd5}\u{dd7}\x07\x18\x02\x02\u{dd6}\u{dd5}\x03\x02\x02\x02\u{dd6}\
	\u{dd7}\x03\x02\x02\x02\u{dd7}\u{dd8}\x03\x02\x02\x02\u{dd8}\u{dda}\x05\
	\u{1e8}\u{f5}\x02\u{dd9}\u{ddb}\x05\u{114}\u{8b}\x02\u{dda}\u{dd9}\x03\x02\
	\x02\x02\u{dda}\u{ddb}\x03\x02\x02\x02\u{ddb}\u{ddd}\x03\x02\x02\x02\u{ddc}\
	\u{dd6}\x03\x02\x02\x02\u{ddc}\u{ddd}\x03\x02\x02\x02\u{ddd}\u{133}\x03\
	\x02\x02\x02\u{dde}\u{ddf}\x07\u{12f}\x02\x02\u{ddf}\u{de0}\x07\u{8f}\x02\
	\x02\u{de0}\u{de1}\x07\u{139}\x02\x02\u{de1}\u{de5}\x05\u{218}\u{10d}\x02\
	\u{de2}\u{de3}\x07\u{194}\x02\x02\u{de3}\u{de4}\x07\u{13a}\x02\x02\u{de4}\
	\u{de6}\x05\u{84}\x43\x02\u{de5}\u{de2}\x03\x02\x02\x02\u{de5}\u{de6}\x03\
	\x02\x02\x02\u{de6}\u{e10}\x03\x02\x02\x02\u{de7}\u{de8}\x07\u{12f}\x02\
	\x02\u{de8}\u{de9}\x07\u{8f}\x02\x02\u{de9}\u{df3}\x07\x65\x02\x02\u{dea}\
	\u{deb}\x07\u{86}\x02\x02\u{deb}\u{dec}\x07\u{15f}\x02\x02\u{dec}\u{ded}\
	\x07\x26\x02\x02\u{ded}\u{df1}\x05\u{218}\u{10d}\x02\u{dee}\u{def}\x07\x77\
	\x02\x02\u{def}\u{df0}\x07\x26\x02\x02\u{df0}\u{df2}\x05\u{218}\u{10d}\x02\
	\u{df1}\u{dee}\x03\x02\x02\x02\u{df1}\u{df2}\x03\x02\x02\x02\u{df2}\u{df4}\
	\x03\x02\x02\x02\u{df3}\u{dea}\x03\x02\x02\x02\u{df3}\u{df4}\x03\x02\x02\
	\x02\u{df4}\u{dfa}\x03\x02\x02\x02\u{df5}\u{df6}\x07\x3a\x02\x02\u{df6}\
	\u{df7}\x07\u{b9}\x02\x02\u{df7}\u{df8}\x07\u{15f}\x02\x02\u{df8}\u{df9}\
	\x07\x26\x02\x02\u{df9}\u{dfb}\x05\u{218}\u{10d}\x02\u{dfa}\u{df5}\x03\x02\
	\x02\x02\u{dfa}\u{dfb}\x03\x02\x02\x02\u{dfb}\u{e01}\x03\x02\x02\x02\u{dfc}\
	\u{dfd}\x07\u{d5}\x02\x02\u{dfd}\u{dfe}\x07\u{be}\x02\x02\u{dfe}\u{dff}\
	\x07\u{15f}\x02\x02\u{dff}\u{e00}\x07\x26\x02\x02\u{e00}\u{e02}\x05\u{218}\
	\u{10d}\x02\u{e01}\u{dfc}\x03\x02\x02\x02\u{e01}\u{e02}\x03\x02\x02\x02\
	\u{e02}\u{e07}\x03\x02\x02\x02\u{e03}\u{e04}\x07\u{ca}\x02\x02\u{e04}\u{e05}\
	\x07\u{15f}\x02\x02\u{e05}\u{e06}\x07\x26\x02\x02\u{e06}\u{e08}\x05\u{218}\
	\u{10d}\x02\u{e07}\u{e03}\x03\x02\x02\x02\u{e07}\u{e08}\x03\x02\x02\x02\
	\u{e08}\u{e0d}\x03\x02\x02\x02\u{e09}\u{e0a}\x07\u{ef}\x02\x02\u{e0a}\u{e0b}\
	\x07\x61\x02\x02\u{e0b}\u{e0c}\x07\x18\x02\x02\u{e0c}\u{e0e}\x05\u{218}\
	\u{10d}\x02\u{e0d}\u{e09}\x03\x02\x02\x02\u{e0d}\u{e0e}\x03\x02\x02\x02\
	\u{e0e}\u{e10}\x03\x02\x02\x02\u{e0f}\u{dde}\x03\x02\x02\x02\u{e0f}\u{de7}\
	\x03\x02\x02\x02\u{e10}\u{135}\x03\x02\x02\x02\u{e11}\u{e16}\x05\u{138}\
	\u{9d}\x02\u{e12}\u{e13}\x07\x06\x02\x02\u{e13}\u{e15}\x05\u{138}\u{9d}\
	\x02\u{e14}\u{e12}\x03\x02\x02\x02\u{e15}\u{e18}\x03\x02\x02\x02\u{e16}\
	\u{e14}\x03\x02\x02\x02\u{e16}\u{e17}\x03\x02\x02\x02\u{e17}\u{137}\x03\
	\x02\x02\x02\u{e18}\u{e16}\x03\x02\x02\x02\u{e19}\u{e1e}\x05\u{1e0}\u{f1}\
	\x02\u{e1a}\u{e1b}\x07\x07\x02\x02\u{e1b}\u{e1d}\x05\u{1e0}\u{f1}\x02\u{e1c}\
	\u{e1a}\x03\x02\x02\x02\u{e1d}\u{e20}\x03\x02\x02\x02\u{e1e}\u{e1c}\x03\
	\x02\x02\x02\u{e1e}\u{e1f}\x03\x02\x02\x02\u{e1f}\u{139}\x03\x02\x02\x02\
	\u{e20}\u{e1e}\x03\x02\x02\x02\u{e21}\u{e26}\x05\u{13c}\u{9f}\x02\u{e22}\
	\u{e23}\x07\x06\x02\x02\u{e23}\u{e25}\x05\u{13c}\u{9f}\x02\u{e24}\u{e22}\
	\x03\x02\x02\x02\u{e25}\u{e28}\x03\x02\x02\x02\u{e26}\u{e24}\x03\x02\x02\
	\x02\u{e26}\u{e27}\x03\x02\x02\x02\u{e27}\u{13b}\x03\x02\x02\x02\u{e28}\
	\u{e26}\x03\x02\x02\x02\u{e29}\u{e2c}\x05\u{138}\u{9d}\x02\u{e2a}\u{e2b}\
	\x07\u{f8}\x02\x02\u{e2b}\u{e2d}\x05\u{84}\x43\x02\u{e2c}\u{e2a}\x03\x02\
	\x02\x02\u{e2c}\u{e2d}\x03\x02\x02\x02\u{e2d}\u{13d}\x03\x02\x02\x02\u{e2e}\
	\u{e2f}\x05\u{1e0}\u{f1}\x02\u{e2f}\u{e30}\x07\x07\x02\x02\u{e30}\u{e32}\
	\x03\x02\x02\x02\u{e31}\u{e2e}\x03\x02\x02\x02\u{e31}\u{e32}\x03\x02\x02\
	\x02\u{e32}\u{e33}\x03\x02\x02\x02\u{e33}\u{e34}\x05\u{1e0}\u{f1}\x02\u{e34}\
	\u{13f}\x03\x02\x02\x02\u{e35}\u{e36}\x05\u{1e0}\u{f1}\x02\u{e36}\u{e37}\
	\x07\x07\x02\x02\u{e37}\u{e39}\x03\x02\x02\x02\u{e38}\u{e35}\x03\x02\x02\
	\x02\u{e38}\u{e39}\x03\x02\x02\x02\u{e39}\u{e3a}\x03\x02\x02\x02\u{e3a}\
	\u{e3b}\x05\u{1e0}\u{f1}\x02\u{e3b}\u{141}\x03\x02\x02\x02\u{e3c}\u{e44}\
	\x05\u{14e}\u{a8}\x02\u{e3d}\u{e3f}\x07\x18\x02\x02\u{e3e}\u{e3d}\x03\x02\
	\x02\x02\u{e3e}\u{e3f}\x03\x02\x02\x02\u{e3f}\u{e42}\x03\x02\x02\x02\u{e40}\
	\u{e43}\x05\u{1e0}\u{f1}\x02\u{e41}\u{e43}\x05\u{114}\u{8b}\x02\u{e42}\u{e40}\
	\x03\x02\x02\x02\u{e42}\u{e41}\x03\x02\x02\x02\u{e43}\u{e45}\x03\x02\x02\
	\x02\u{e44}\u{e3e}\x03\x02\x02\x02\u{e44}\u{e45}\x03\x02\x02\x02\u{e45}\
	\u{143}\x03\x02\x02\x02\u{e46}\u{e4b}\x05\u{142}\u{a2}\x02\u{e47}\u{e48}\
	\x07\x06\x02\x02\u{e48}\u{e4a}\x05\u{142}\u{a2}\x02\u{e49}\u{e47}\x03\x02\
	\x02\x02\u{e4a}\u{e4d}\x03\x02\x02\x02\u{e4b}\u{e49}\x03\x02\x02\x02\u{e4b}\
	\u{e4c}\x03\x02\x02\x02\u{e4c}\u{145}\x03\x02\x02\x02\u{e4d}\u{e4b}\x03\
	\x02\x02\x02\u{e4e}\u{e4f}\x07\x04\x02\x02\u{e4f}\u{e54}\x05\u{148}\u{a5}\
	\x02\u{e50}\u{e51}\x07\x06\x02\x02\u{e51}\u{e53}\x05\u{148}\u{a5}\x02\u{e52}\
	\u{e50}\x03\x02\x02\x02\u{e53}\u{e56}\x03\x02\x02\x02\u{e54}\u{e52}\x03\
	\x02\x02\x02\u{e54}\u{e55}\x03\x02\x02\x02\u{e55}\u{e57}\x03\x02\x02\x02\
	\u{e56}\u{e54}\x03\x02\x02\x02\u{e57}\u{e58}\x07\x05\x02\x02\u{e58}\u{147}\
	\x03\x02\x02\x02\u{e59}\u{e5c}\x05\u{14a}\u{a6}\x02\u{e5a}\u{e5c}\x05\u{1a6}\
	\u{d4}\x02\u{e5b}\u{e59}\x03\x02\x02\x02\u{e5b}\u{e5a}\x03\x02\x02\x02\u{e5c}\
	\u{149}\x03\x02\x02\x02\u{e5d}\u{e6b}\x05\u{1de}\u{f0}\x02\u{e5e}\u{e5f}\
	\x05\u{1e4}\u{f3}\x02\u{e5f}\u{e60}\x07\x04\x02\x02\u{e60}\u{e65}\x05\u{14c}\
	\u{a7}\x02\u{e61}\u{e62}\x07\x06\x02\x02\u{e62}\u{e64}\x05\u{14c}\u{a7}\
	\x02\u{e63}\u{e61}\x03\x02\x02\x02\u{e64}\u{e67}\x03\x02\x02\x02\u{e65}\
	\u{e63}\x03\x02\x02\x02\u{e65}\u{e66}\x03\x02\x02\x02\u{e66}\u{e68}\x03\
	\x02\x02\x02\u{e67}\u{e65}\x03\x02\x02\x02\u{e68}\u{e69}\x07\x05\x02\x02\
	\u{e69}\u{e6b}\x03\x02\x02\x02\u{e6a}\u{e5d}\x03\x02\x02\x02\u{e6a}\u{e5e}\
	\x03\x02\x02\x02\u{e6b}\u{14b}\x03\x02\x02\x02\u{e6c}\u{e6f}\x05\u{1de}\
	\u{f0}\x02\u{e6d}\u{e6f}\x05\u{170}\u{b9}\x02\u{e6e}\u{e6c}\x03\x02\x02\
	\x02\u{e6e}\u{e6d}\x03\x02\x02\x02\u{e6f}\u{14d}\x03\x02\x02\x02\u{e70}\
	\u{e71}\x05\u{156}\u{ac}\x02\u{e71}\u{14f}\x03\x02\x02\x02\u{e72}\u{e73}\
	\x05\u{1e4}\u{f3}\x02\u{e73}\u{e74}\x07\u{1b3}\x02\x02\u{e74}\u{e75}\x05\
	\u{14e}\u{a8}\x02\u{e75}\u{151}\x03\x02\x02\x02\u{e76}\u{e79}\x05\u{14e}\
	\u{a8}\x02\u{e77}\u{e79}\x05\u{150}\u{a9}\x02\u{e78}\u{e76}\x03\x02\x02\
	\x02\u{e78}\u{e77}\x03\x02\x02\x02\u{e79}\u{153}\x03\x02\x02\x02\u{e7a}\
	\u{e7f}\x05\u{14e}\u{a8}\x02\u{e7b}\u{e7c}\x07\x06\x02\x02\u{e7c}\u{e7e}\
	\x05\u{14e}\u{a8}\x02\u{e7d}\u{e7b}\x03\x02\x02\x02\u{e7e}\u{e81}\x03\x02\
	\x02\x02\u{e7f}\u{e7d}\x03\x02\x02\x02\u{e7f}\u{e80}\x03\x02\x02\x02\u{e80}\
	\u{155}\x03\x02\x02\x02\u{e81}\u{e7f}\x03\x02\x02\x02\u{e82}\u{e83}\x08\
	\u{ac}\x01\x02\u{e83}\u{e84}\x09\x1c\x02\x02\u{e84}\u{e8f}\x05\u{156}\u{ac}\
	\x07\u{e85}\u{e86}\x07\x7c\x02\x02\u{e86}\u{e87}\x07\x04\x02\x02\u{e87}\
	\u{e88}\x05\x66\x34\x02\u{e88}\u{e89}\x07\x05\x02\x02\u{e89}\u{e8f}\x03\
	\x02\x02\x02\u{e8a}\u{e8c}\x05\u{15c}\u{af}\x02\u{e8b}\u{e8d}\x05\u{158}\
	\u{ad}\x02\u{e8c}\u{e8b}\x03\x02\x02\x02\u{e8c}\u{e8d}\x03\x02\x02\x02\u{e8d}\
	\u{e8f}\x03\x02\x02\x02\u{e8e}\u{e82}\x03\x02\x02\x02\u{e8e}\u{e85}\x03\
	\x02\x02\x02\u{e8e}\u{e8a}\x03\x02\x02\x02\u{e8f}\u{e98}\x03\x02\x02\x02\
	\u{e90}\u{e91}\x0c\x04\x02\x02\u{e91}\u{e92}\x07\x12\x02\x02\u{e92}\u{e97}\
	\x05\u{156}\u{ac}\x05\u{e93}\u{e94}\x0c\x03\x02\x02\u{e94}\u{e95}\x07\u{f9}\
	\x02\x02\u{e95}\u{e97}\x05\u{156}\u{ac}\x04\u{e96}\u{e90}\x03\x02\x02\x02\
	\u{e96}\u{e93}\x03\x02\x02\x02\u{e97}\u{e9a}\x03\x02\x02\x02\u{e98}\u{e96}\
	\x03\x02\x02\x02\u{e98}\u{e99}\x03\x02\x02\x02\u{e99}\u{157}\x03\x02\x02\
	\x02\u{e9a}\u{e98}\x03\x02\x02\x02\u{e9b}\u{e9d}\x05\u{15a}\u{ae}\x02\u{e9c}\
	\u{e9b}\x03\x02\x02\x02\u{e9c}\u{e9d}\x03\x02\x02\x02\u{e9d}\u{e9e}\x03\
	\x02\x02\x02\u{e9e}\u{e9f}\x07\x1e\x02\x02\u{e9f}\u{ea0}\x05\u{15c}\u{af}\
	\x02\u{ea0}\u{ea1}\x07\x12\x02\x02\u{ea1}\u{ea2}\x05\u{15c}\u{af}\x02\u{ea2}\
	\u{eee}\x03\x02\x02\x02\u{ea3}\u{ea5}\x05\u{15a}\u{ae}\x02\u{ea4}\u{ea3}\
	\x03\x02\x02\x02\u{ea4}\u{ea5}\x03\x02\x02\x02\u{ea5}\u{ea6}\x03\x02\x02\
	\x02\u{ea6}\u{ea7}\x07\u{a8}\x02\x02\u{ea7}\u{ea8}\x07\x04\x02\x02\u{ea8}\
	\u{ead}\x05\u{14e}\u{a8}\x02\u{ea9}\u{eaa}\x07\x06\x02\x02\u{eaa}\u{eac}\
	\x05\u{14e}\u{a8}\x02\u{eab}\u{ea9}\x03\x02\x02\x02\u{eac}\u{eaf}\x03\x02\
	\x02\x02\u{ead}\u{eab}\x03\x02\x02\x02\u{ead}\u{eae}\x03\x02\x02\x02\u{eae}\
	\u{eb0}\x03\x02\x02\x02\u{eaf}\u{ead}\x03\x02\x02\x02\u{eb0}\u{eb1}\x07\
	\x05\x02\x02\u{eb1}\u{eee}\x03\x02\x02\x02\u{eb2}\u{eb4}\x05\u{15a}\u{ae}\
	\x02\u{eb3}\u{eb2}\x03\x02\x02\x02\u{eb3}\u{eb4}\x03\x02\x02\x02\u{eb4}\
	\u{eb5}\x03\x02\x02\x02\u{eb5}\u{eb6}\x07\u{a8}\x02\x02\u{eb6}\u{eb7}\x07\
	\x04\x02\x02\u{eb7}\u{eb8}\x05\x66\x34\x02\u{eb8}\u{eb9}\x07\x05\x02\x02\
	\u{eb9}\u{eee}\x03\x02\x02\x02\u{eba}\u{ebc}\x05\u{15a}\u{ae}\x02\u{ebb}\
	\u{eba}\x03\x02\x02\x02\u{ebb}\u{ebc}\x03\x02\x02\x02\u{ebc}\u{ebd}\x03\
	\x02\x02\x02\u{ebd}\u{ebe}\x07\u{12a}\x02\x02\u{ebe}\u{eee}\x05\u{15c}\u{af}\
	\x02\u{ebf}\u{ec1}\x05\u{15a}\u{ae}\x02\u{ec0}\u{ebf}\x03\x02\x02\x02\u{ec0}\
	\u{ec1}\x03\x02\x02\x02\u{ec1}\u{ec2}\x03\x02\x02\x02\u{ec2}\u{ec3}\x09\
	\x1d\x02\x02\u{ec3}\u{ed1}\x09\x1e\x02\x02\u{ec4}\u{ec5}\x07\x04\x02\x02\
	\u{ec5}\u{ed2}\x07\x05\x02\x02\u{ec6}\u{ec7}\x07\x04\x02\x02\u{ec7}\u{ecc}\
	\x05\u{14e}\u{a8}\x02\u{ec8}\u{ec9}\x07\x06\x02\x02\u{ec9}\u{ecb}\x05\u{14e}\
	\u{a8}\x02\u{eca}\u{ec8}\x03\x02\x02\x02\u{ecb}\u{ece}\x03\x02\x02\x02\u{ecc}\
	\u{eca}\x03\x02\x02\x02\u{ecc}\u{ecd}\x03\x02\x02\x02\u{ecd}\u{ecf}\x03\
	\x02\x02\x02\u{ece}\u{ecc}\x03\x02\x02\x02\u{ecf}\u{ed0}\x07\x05\x02\x02\
	\u{ed0}\u{ed2}\x03\x02\x02\x02\u{ed1}\u{ec4}\x03\x02\x02\x02\u{ed1}\u{ec6}\
	\x03\x02\x02\x02\u{ed2}\u{eee}\x03\x02\x02\x02\u{ed3}\u{ed5}\x05\u{15a}\
	\u{ae}\x02\u{ed4}\u{ed3}\x03\x02\x02\x02\u{ed4}\u{ed5}\x03\x02\x02\x02\u{ed5}\
	\u{ed6}\x03\x02\x02\x02\u{ed6}\u{ed7}\x09\x1d\x02\x02\u{ed7}\u{eda}\x05\
	\u{15c}\u{af}\x02\u{ed8}\u{ed9}\x07\x76\x02\x02\u{ed9}\u{edb}\x05\u{218}\
	\u{10d}\x02\u{eda}\u{ed8}\x03\x02\x02\x02\u{eda}\u{edb}\x03\x02\x02\x02\
	\u{edb}\u{eee}\x03\x02\x02\x02\u{edc}\u{ede}\x07\u{b8}\x02\x02\u{edd}\u{edf}\
	\x05\u{15a}\u{ae}\x02\u{ede}\u{edd}\x03\x02\x02\x02\u{ede}\u{edf}\x03\x02\
	\x02\x02\u{edf}\u{ee0}\x03\x02\x02\x02\u{ee0}\u{eee}\x07\u{ef}\x02\x02\u{ee1}\
	\u{ee3}\x07\u{b8}\x02\x02\u{ee2}\u{ee4}\x05\u{15a}\u{ae}\x02\u{ee3}\u{ee2}\
	\x03\x02\x02\x02\u{ee3}\u{ee4}\x03\x02\x02\x02\u{ee4}\u{ee5}\x03\x02\x02\
	\x02\u{ee5}\u{eee}\x09\x1f\x02\x02\u{ee6}\u{ee8}\x07\u{b8}\x02\x02\u{ee7}\
	\u{ee9}\x05\u{15a}\u{ae}\x02\u{ee8}\u{ee7}\x03\x02\x02\x02\u{ee8}\u{ee9}\
	\x03\x02\x02\x02\u{ee9}\u{eea}\x03\x02\x02\x02\u{eea}\u{eeb}\x07\x6c\x02\
	\x02\u{eeb}\u{eec}\x07\u{92}\x02\x02\u{eec}\u{eee}\x05\u{15c}\u{af}\x02\
	\u{eed}\u{e9c}\x03\x02\x02\x02\u{eed}\u{ea4}\x03\x02\x02\x02\u{eed}\u{eb3}\
	\x03\x02\x02\x02\u{eed}\u{ebb}\x03\x02\x02\x02\u{eed}\u{ec0}\x03\x02\x02\
	\x02\u{eed}\u{ed4}\x03\x02\x02\x02\u{eed}\u{edc}\x03\x02\x02\x02\u{eed}\
	\u{ee1}\x03\x02\x02\x02\u{eed}\u{ee6}\x03\x02\x02\x02\u{eee}\u{159}\x03\
	\x02\x02\x02\u{eef}\u{ef0}\x09\x1c\x02\x02\u{ef0}\u{15b}\x03\x02\x02\x02\
	\u{ef1}\u{ef2}\x08\u{af}\x01\x02\u{ef2}\u{ef6}\x05\u{162}\u{b2}\x02\u{ef3}\
	\u{ef4}\x09\x20\x02\x02\u{ef4}\u{ef6}\x05\u{15c}\u{af}\x0a\u{ef5}\u{ef1}\
	\x03\x02\x02\x02\u{ef5}\u{ef3}\x03\x02\x02\x02\u{ef6}\u{f11}\x03\x02\x02\
	\x02\u{ef7}\u{ef8}\x0c\x09\x02\x02\u{ef8}\u{ef9}\x09\x21\x02\x02\u{ef9}\
	\u{f10}\x05\u{15c}\u{af}\x0a\u{efa}\u{efb}\x0c\x08\x02\x02\u{efb}\u{efc}\
	\x09\x22\x02\x02\u{efc}\u{f10}\x05\u{15c}\u{af}\x09\u{efd}\u{efe}\x0c\x07\
	\x02\x02\u{efe}\u{eff}\x05\u{15e}\u{b0}\x02\u{eff}\u{f00}\x05\u{15c}\u{af}\
	\x08\u{f00}\u{f10}\x03\x02\x02\x02\u{f01}\u{f02}\x0c\x06\x02\x02\u{f02}\
	\u{f03}\x07\u{1ab}\x02\x02\u{f03}\u{f10}\x05\u{15c}\u{af}\x07\u{f04}\u{f05}\
	\x0c\x05\x02\x02\u{f05}\u{f06}\x07\u{1af}\x02\x02\u{f06}\u{f10}\x05\u{15c}\
	\u{af}\x06\u{f07}\u{f08}\x0c\x04\x02\x02\u{f08}\u{f09}\x06\u{af}\x13\x02\
	\u{f09}\u{f0a}\x07\u{1ac}\x02\x02\u{f0a}\u{f10}\x05\u{15c}\u{af}\x05\u{f0b}\
	\u{f0c}\x0c\x03\x02\x02\u{f0c}\u{f0d}\x05\u{174}\u{bb}\x02\u{f0d}\u{f0e}\
	\x05\u{15c}\u{af}\x04\u{f0e}\u{f10}\x03\x02\x02\x02\u{f0f}\u{ef7}\x03\x02\
	\x02\x02\u{f0f}\u{efa}\x03\x02\x02\x02\u{f0f}\u{efd}\x03\x02\x02\x02\u{f0f}\
	\u{f01}\x03\x02\x02\x02\u{f0f}\u{f04}\x03\x02\x02\x02\u{f0f}\u{f07}\x03\
	\x02\x02\x02\u{f0f}\u{f0b}\x03\x02\x02\x02\u{f10}\u{f13}\x03\x02\x02\x02\
	\u{f11}\u{f0f}\x03\x02\x02\x02\u{f11}\u{f12}\x03\x02\x02\x02\u{f12}\u{15d}\
	\x03\x02\x02\x02\u{f13}\u{f11}\x03\x02\x02\x02\u{f14}\u{f15}\x09\x23\x02\
	\x02\u{f15}\u{15f}\x03\x02\x02\x02\u{f16}\u{f17}\x09\x24\x02\x02\u{f17}\
	\u{161}\x03\x02\x02\x02\u{f18}\u{f19}\x08\u{b2}\x01\x02\u{f19}\u{100c}\x09\
	\x25\x02\x02\u{f1a}\u{f1b}\x09\x26\x02\x02\u{f1b}\u{f1e}\x07\x04\x02\x02\
	\u{f1c}\u{f1f}\x05\u{160}\u{b1}\x02\u{f1d}\u{f1f}\x05\u{218}\u{10d}\x02\
	\u{f1e}\u{f1c}\x03\x02\x02\x02\u{f1e}\u{f1d}\x03\x02\x02\x02\u{f1f}\u{f20}\
	\x03\x02\x02\x02\u{f20}\u{f21}\x07\x06\x02\x02\u{f21}\u{f22}\x05\u{15c}\
	\u{af}\x02\u{f22}\u{f23}\x07\x06\x02\x02\u{f23}\u{f24}\x05\u{15c}\u{af}\
	\x02\u{f24}\u{f25}\x07\x05\x02\x02\u{f25}\u{100c}\x03\x02\x02\x02\u{f26}\
	\u{f27}\x09\x27\x02\x02\u{f27}\u{f2a}\x07\x04\x02\x02\u{f28}\u{f2b}\x05\
	\u{160}\u{b1}\x02\u{f29}\u{f2b}\x05\u{218}\u{10d}\x02\u{f2a}\u{f28}\x03\
	\x02\x02\x02\u{f2a}\u{f29}\x03\x02\x02\x02\u{f2b}\u{f2c}\x03\x02\x02\x02\
	\u{f2c}\u{f2d}\x07\x06\x02\x02\u{f2d}\u{f2e}\x05\u{15c}\u{af}\x02\u{f2e}\
	\u{f2f}\x07\x06\x02\x02\u{f2f}\u{f30}\x05\u{15c}\u{af}\x02\u{f30}\u{f31}\
	\x07\x05\x02\x02\u{f31}\u{100c}\x03\x02\x02\x02\u{f32}\u{f34}\x07\x2c\x02\
	\x02\u{f33}\u{f35}\x05\u{1ce}\u{e8}\x02\u{f34}\u{f33}\x03\x02\x02\x02\u{f35}\
	\u{f36}\x03\x02\x02\x02\u{f36}\u{f34}\x03\x02\x02\x02\u{f36}\u{f37}\x03\
	\x02\x02\x02\u{f37}\u{f3a}\x03\x02\x02\x02\u{f38}\u{f39}\x07\x72\x02\x02\
	\u{f39}\u{f3b}\x05\u{14e}\u{a8}\x02\u{f3a}\u{f38}\x03\x02\x02\x02\u{f3a}\
	\u{f3b}\x03\x02\x02\x02\u{f3b}\u{f3c}\x03\x02\x02\x02\u{f3c}\u{f3d}\x07\
	\x74\x02\x02\u{f3d}\u{100c}\x03\x02\x02\x02\u{f3e}\u{f3f}\x07\x2c\x02\x02\
	\u{f3f}\u{f41}\x05\u{14e}\u{a8}\x02\u{f40}\u{f42}\x05\u{1ce}\u{e8}\x02\u{f41}\
	\u{f40}\x03\x02\x02\x02\u{f42}\u{f43}\x03\x02\x02\x02\u{f43}\u{f41}\x03\
	\x02\x02\x02\u{f43}\u{f44}\x03\x02\x02\x02\u{f44}\u{f47}\x03\x02\x02\x02\
	\u{f45}\u{f46}\x07\x72\x02\x02\u{f46}\u{f48}\x05\u{14e}\u{a8}\x02\u{f47}\
	\u{f45}\x03\x02\x02\x02\u{f47}\u{f48}\x03\x02\x02\x02\u{f48}\u{f49}\x03\
	\x02\x02\x02\u{f49}\u{f4a}\x07\x74\x02\x02\u{f4a}\u{100c}\x03\x02\x02\x02\
	\u{f4b}\u{f4c}\x09\x28\x02\x02\u{f4c}\u{f4d}\x07\x04\x02\x02\u{f4d}\u{f4e}\
	\x05\u{14e}\u{a8}\x02\u{f4e}\u{f4f}\x07\x18\x02\x02\u{f4f}\u{f50}\x05\u{198}\
	\u{cd}\x02\u{f50}\u{f51}\x07\x05\x02\x02\u{f51}\u{100c}\x03\x02\x02\x02\
	\u{f52}\u{f53}\x07\u{153}\x02\x02\u{f53}\u{f5c}\x07\x04\x02\x02\u{f54}\u{f59}\
	\x05\u{142}\u{a2}\x02\u{f55}\u{f56}\x07\x06\x02\x02\u{f56}\u{f58}\x05\u{142}\
	\u{a2}\x02\u{f57}\u{f55}\x03\x02\x02\x02\u{f58}\u{f5b}\x03\x02\x02\x02\u{f59}\
	\u{f57}\x03\x02\x02\x02\u{f59}\u{f5a}\x03\x02\x02\x02\u{f5a}\u{f5d}\x03\
	\x02\x02\x02\u{f5b}\u{f59}\x03\x02\x02\x02\u{f5c}\u{f54}\x03\x02\x02\x02\
	\u{f5c}\u{f5d}\x03\x02\x02\x02\u{f5d}\u{f5e}\x03\x02\x02\x02\u{f5e}\u{100c}\
	\x07\x05\x02\x02\u{f5f}\u{f60}\x07\u{89}\x02\x02\u{f60}\u{f61}\x07\x04\x02\
	\x02\u{f61}\u{f64}\x05\u{14e}\u{a8}\x02\u{f62}\u{f63}\x07\u{a5}\x02\x02\
	\u{f63}\u{f65}\x07\u{f0}\x02\x02\u{f64}\u{f62}\x03\x02\x02\x02\u{f64}\u{f65}\
	\x03\x02\x02\x02\u{f65}\u{f66}\x03\x02\x02\x02\u{f66}\u{f67}\x07\x05\x02\
	\x02\u{f67}\u{100c}\x03\x02\x02\x02\u{f68}\u{f69}\x07\x15\x02\x02\u{f69}\
	\u{f6a}\x07\x04\x02\x02\u{f6a}\u{f6d}\x05\u{14e}\u{a8}\x02\u{f6b}\u{f6c}\
	\x07\u{a5}\x02\x02\u{f6c}\u{f6e}\x07\u{f0}\x02\x02\u{f6d}\u{f6b}\x03\x02\
	\x02\x02\u{f6d}\u{f6e}\x03\x02\x02\x02\u{f6e}\u{f6f}\x03\x02\x02\x02\u{f6f}\
	\u{f70}\x07\x05\x02\x02\u{f70}\u{100c}\x03\x02\x02\x02\u{f71}\u{f72}\x07\
	\u{c0}\x02\x02\u{f72}\u{f73}\x07\x04\x02\x02\u{f73}\u{f76}\x05\u{14e}\u{a8}\
	\x02\u{f74}\u{f75}\x07\u{a5}\x02\x02\u{f75}\u{f77}\x07\u{f0}\x02\x02\u{f76}\
	\u{f74}\x03\x02\x02\x02\u{f76}\u{f77}\x03\x02\x02\x02\u{f77}\u{f78}\x03\
	\x02\x02\x02\u{f78}\u{f79}\x07\x05\x02\x02\u{f79}\u{100c}\x03\x02\x02\x02\
	\u{f7a}\u{f7b}\x07\u{108}\x02\x02\u{f7b}\u{f7c}\x07\x04\x02\x02\u{f7c}\u{f7d}\
	\x05\u{15c}\u{af}\x02\u{f7d}\u{f7e}\x07\u{a8}\x02\x02\u{f7e}\u{f7f}\x05\
	\u{15c}\u{af}\x02\u{f7f}\u{f80}\x07\x05\x02\x02\u{f80}\u{100c}\x03\x02\x02\
	\x02\u{f81}\u{100c}\x05\u{170}\u{b9}\x02\u{f82}\u{f84}\x07\u{1a7}\x02\x02\
	\u{f83}\u{f85}\x05\u{c8}\x65\x02\u{f84}\u{f83}\x03\x02\x02\x02\u{f84}\u{f85}\
	\x03\x02\x02\x02\u{f85}\u{100c}\x03\x02\x02\x02\u{f86}\u{f87}\x05\u{1de}\
	\u{f0}\x02\u{f87}\u{f88}\x07\x07\x02\x02\u{f88}\u{f8a}\x07\u{1a7}\x02\x02\
	\u{f89}\u{f8b}\x05\u{c8}\x65\x02\u{f8a}\u{f89}\x03\x02\x02\x02\u{f8a}\u{f8b}\
	\x03\x02\x02\x02\u{f8b}\u{100c}\x03\x02\x02\x02\u{f8c}\u{f8d}\x07\x04\x02\
	\x02\u{f8d}\u{f90}\x05\u{142}\u{a2}\x02\u{f8e}\u{f8f}\x07\x06\x02\x02\u{f8f}\
	\u{f91}\x05\u{142}\u{a2}\x02\u{f90}\u{f8e}\x03\x02\x02\x02\u{f91}\u{f92}\
	\x03\x02\x02\x02\u{f92}\u{f90}\x03\x02\x02\x02\u{f92}\u{f93}\x03\x02\x02\
	\x02\u{f93}\u{f94}\x03\x02\x02\x02\u{f94}\u{f95}\x07\x05\x02\x02\u{f95}\
	\u{100c}\x03\x02\x02\x02\u{f96}\u{f97}\x07\x04\x02\x02\u{f97}\u{f98}\x05\
	\x66\x34\x02\u{f98}\u{f99}\x07\x05\x02\x02\u{f99}\u{100c}\x03\x02\x02\x02\
	\u{f9a}\u{f9b}\x05\u{1dc}\u{ef}\x02\u{f9b}\u{fa7}\x07\x04\x02\x02\u{f9c}\
	\u{f9e}\x05\u{104}\u{83}\x02\u{f9d}\u{f9c}\x03\x02\x02\x02\u{f9d}\u{f9e}\
	\x03\x02\x02\x02\u{f9e}\u{f9f}\x03\x02\x02\x02\u{f9f}\u{fa4}\x05\u{152}\
	\u{aa}\x02\u{fa0}\u{fa1}\x07\x06\x02\x02\u{fa1}\u{fa3}\x05\u{152}\u{aa}\
	\x02\u{fa2}\u{fa0}\x03\x02\x02\x02\u{fa3}\u{fa6}\x03\x02\x02\x02\u{fa4}\
	\u{fa2}\x03\x02\x02\x02\u{fa4}\u{fa5}\x03\x02\x02\x02\u{fa5}\u{fa8}\x03\
	\x02\x02\x02\u{fa6}\u{fa4}\x03\x02\x02\x02\u{fa7}\u{f9d}\x03\x02\x02\x02\
	\u{fa7}\u{fa8}\x03\x02\x02\x02\u{fa8}\u{fa9}\x03\x02\x02\x02\u{fa9}\u{fb9}\
	\x07\x05\x02\x02\u{faa}\u{fab}\x07\u{195}\x02\x02\u{fab}\u{fac}\x07\u{9b}\
	\x02\x02\u{fac}\u{fad}\x07\x04\x02\x02\u{fad}\u{fae}\x07\u{fa}\x02\x02\u{fae}\
	\u{faf}\x07\x26\x02\x02\u{faf}\u{fb4}\x05\u{ae}\x58\x02\u{fb0}\u{fb1}\x07\
	\x06\x02\x02\u{fb1}\u{fb3}\x05\u{ae}\x58\x02\u{fb2}\u{fb0}\x03\x02\x02\x02\
	\u{fb3}\u{fb6}\x03\x02\x02\x02\u{fb4}\u{fb2}\x03\x02\x02\x02\u{fb4}\u{fb5}\
	\x03\x02\x02\x02\u{fb5}\u{fb7}\x03\x02\x02\x02\u{fb6}\u{fb4}\x03\x02\x02\
	\x02\u{fb7}\u{fb8}\x07\x05\x02\x02\u{fb8}\u{fba}\x03\x02\x02\x02\u{fb9}\
	\u{faa}\x03\x02\x02\x02\u{fb9}\u{fba}\x03\x02\x02\x02\u{fba}\u{fc1}\x03\
	\x02\x02\x02\u{fbb}\u{fbc}\x07\u{87}\x02\x02\u{fbc}\u{fbd}\x07\x04\x02\x02\
	\u{fbd}\u{fbe}\x07\u{191}\x02\x02\u{fbe}\u{fbf}\x05\u{156}\u{ac}\x02\u{fbf}\
	\u{fc0}\x07\x05\x02\x02\u{fc0}\u{fc2}\x03\x02\x02\x02\u{fc1}\u{fbb}\x03\
	\x02\x02\x02\u{fc1}\u{fc2}\x03\x02\x02\x02\u{fc2}\u{fc5}\x03\x02\x02\x02\
	\u{fc3}\u{fc4}\x09\x29\x02\x02\u{fc4}\u{fc6}\x07\u{f0}\x02\x02\u{fc5}\u{fc3}\
	\x03\x02\x02\x02\u{fc5}\u{fc6}\x03\x02\x02\x02\u{fc6}\u{fc9}\x03\x02\x02\
	\x02\u{fc7}\u{fc8}\x07\u{fe}\x02\x02\u{fc8}\u{fca}\x05\u{1d4}\u{eb}\x02\
	\u{fc9}\u{fc7}\x03\x02\x02\x02\u{fc9}\u{fca}\x03\x02\x02\x02\u{fca}\u{100c}\
	\x03\x02\x02\x02\u{fcb}\u{fcc}\x05\u{1e4}\u{f3}\x02\u{fcc}\u{fcd}\x07\u{1b2}\
	\x02\x02\u{fcd}\u{fce}\x05\u{14e}\u{a8}\x02\u{fce}\u{100c}\x03\x02\x02\x02\
	\u{fcf}\u{fd0}\x07\x04\x02\x02\u{fd0}\u{fd3}\x05\u{1e4}\u{f3}\x02\u{fd1}\
	\u{fd2}\x07\x06\x02\x02\u{fd2}\u{fd4}\x05\u{1e4}\u{f3}\x02\u{fd3}\u{fd1}\
	\x03\x02\x02\x02\u{fd4}\u{fd5}\x03\x02\x02\x02\u{fd5}\u{fd3}\x03\x02\x02\
	\x02\u{fd5}\u{fd6}\x03\x02\x02\x02\u{fd6}\u{fd7}\x03\x02\x02\x02\u{fd7}\
	\u{fd8}\x07\x05\x02\x02\u{fd8}\u{fd9}\x07\u{1b2}\x02\x02\u{fd9}\u{fda}\x05\
	\u{14e}\u{a8}\x02\u{fda}\u{100c}\x03\x02\x02\x02\u{fdb}\u{100c}\x05\u{1e4}\
	\u{f3}\x02\u{fdc}\u{fdd}\x07\x04\x02\x02\u{fdd}\u{fde}\x05\u{14e}\u{a8}\
	\x02\u{fde}\u{fdf}\x07\x05\x02\x02\u{fdf}\u{100c}\x03\x02\x02\x02\u{fe0}\
	\u{fe1}\x07\u{83}\x02\x02\u{fe1}\u{fe2}\x07\x04\x02\x02\u{fe2}\u{fe3}\x05\
	\u{1e6}\u{f4}\x02\u{fe3}\u{fe4}\x07\u{92}\x02\x02\u{fe4}\u{fe5}\x05\u{15c}\
	\u{af}\x02\u{fe5}\u{fe6}\x07\x05\x02\x02\u{fe6}\u{100c}\x03\x02\x02\x02\
	\u{fe7}\u{fe8}\x09\x2a\x02\x02\u{fe8}\u{fe9}\x07\x04\x02\x02\u{fe9}\u{fea}\
	\x05\u{15c}\u{af}\x02\u{fea}\u{feb}\x09\x2b\x02\x02\u{feb}\u{fee}\x05\u{15c}\
	\u{af}\x02\u{fec}\u{fed}\x09\x2c\x02\x02\u{fed}\u{fef}\x05\u{15c}\u{af}\
	\x02\u{fee}\u{fec}\x03\x02\x02\x02\u{fee}\u{fef}\x03\x02\x02\x02\u{fef}\
	\u{ff0}\x03\x02\x02\x02\u{ff0}\u{ff1}\x07\x05\x02\x02\u{ff1}\u{100c}\x03\
	\x02\x02\x02\u{ff2}\u{ff3}\x07\u{170}\x02\x02\u{ff3}\u{ff5}\x07\x04\x02\
	\x02\u{ff4}\u{ff6}\x09\x2d\x02\x02\u{ff5}\u{ff4}\x03\x02\x02\x02\u{ff5}\
	\u{ff6}\x03\x02\x02\x02\u{ff6}\u{ff8}\x03\x02\x02\x02\u{ff7}\u{ff9}\x05\
	\u{15c}\u{af}\x02\u{ff8}\u{ff7}\x03\x02\x02\x02\u{ff8}\u{ff9}\x03\x02\x02\
	\x02\u{ff9}\u{ffa}\x03\x02\x02\x02\u{ffa}\u{ffb}\x07\u{92}\x02\x02\u{ffb}\
	\u{ffc}\x05\u{15c}\u{af}\x02\u{ffc}\u{ffd}\x07\x05\x02\x02\u{ffd}\u{100c}\
	\x03\x02\x02\x02\u{ffe}\u{fff}\x07\u{100}\x02\x02\u{fff}\u{1000}\x07\x04\
	\x02\x02\u{1000}\u{1001}\x05\u{15c}\u{af}\x02\u{1001}\u{1002}\x07\u{107}\
	\x02\x02\u{1002}\u{1003}\x05\u{15c}\u{af}\x02\u{1003}\u{1004}\x07\u{92}\
	\x02\x02\u{1004}\u{1007}\x05\u{15c}\u{af}\x02\u{1005}\u{1006}\x07\u{8d}\
	\x02\x02\u{1006}\u{1008}\x05\u{15c}\u{af}\x02\u{1007}\u{1005}\x03\x02\x02\
	\x02\u{1007}\u{1008}\x03\x02\x02\x02\u{1008}\u{1009}\x03\x02\x02\x02\u{1009}\
	\u{100a}\x07\x05\x02\x02\u{100a}\u{100c}\x03\x02\x02\x02\u{100b}\u{f18}\
	\x03\x02\x02\x02\u{100b}\u{f1a}\x03\x02\x02\x02\u{100b}\u{f26}\x03\x02\x02\
	\x02\u{100b}\u{f32}\x03\x02\x02\x02\u{100b}\u{f3e}\x03\x02\x02\x02\u{100b}\
	\u{f4b}\x03\x02\x02\x02\u{100b}\u{f52}\x03\x02\x02\x02\u{100b}\u{f5f}\x03\
	\x02\x02\x02\u{100b}\u{f68}\x03\x02\x02\x02\u{100b}\u{f71}\x03\x02\x02\x02\
	\u{100b}\u{f7a}\x03\x02\x02\x02\u{100b}\u{f81}\x03\x02\x02\x02\u{100b}\u{f82}\
	\x03\x02\x02\x02\u{100b}\u{f86}\x03\x02\x02\x02\u{100b}\u{f8c}\x03\x02\x02\
	\x02\u{100b}\u{f96}\x03\x02\x02\x02\u{100b}\u{f9a}\x03\x02\x02\x02\u{100b}\
	\u{fcb}\x03\x02\x02\x02\u{100b}\u{fcf}\x03\x02\x02\x02\u{100b}\u{fdb}\x03\
	\x02\x02\x02\u{100b}\u{fdc}\x03\x02\x02\x02\u{100b}\u{fe0}\x03\x02\x02\x02\
	\u{100b}\u{fe7}\x03\x02\x02\x02\u{100b}\u{ff2}\x03\x02\x02\x02\u{100b}\u{ffe}\
	\x03\x02\x02\x02\u{100c}\u{101f}\x03\x02\x02\x02\u{100d}\u{100e}\x0c\x1a\
	\x02\x02\u{100e}\u{101e}\x05\u{190}\u{c9}\x02\u{100f}\u{1010}\x0c\x19\x02\
	\x02\u{1010}\u{1011}\x07\u{1b1}\x02\x02\u{1011}\u{101e}\x05\u{198}\u{cd}\
	\x02\u{1012}\u{1013}\x0c\x10\x02\x02\u{1013}\u{1014}\x07\u{1b0}\x02\x02\
	\u{1014}\u{101e}\x05\u{164}\u{b3}\x02\u{1015}\u{1016}\x0c\x0a\x02\x02\u{1016}\
	\u{1017}\x07\x08\x02\x02\u{1017}\u{1018}\x05\u{15c}\u{af}\x02\u{1018}\u{1019}\
	\x07\x09\x02\x02\u{1019}\u{101e}\x03\x02\x02\x02\u{101a}\u{101b}\x0c\x08\
	\x02\x02\u{101b}\u{101c}\x07\x07\x02\x02\u{101c}\u{101e}\x05\u{1e4}\u{f3}\
	\x02\u{101d}\u{100d}\x03\x02\x02\x02\u{101d}\u{100f}\x03\x02\x02\x02\u{101d}\
	\u{1012}\x03\x02\x02\x02\u{101d}\u{1015}\x03\x02\x02\x02\u{101d}\u{101a}\
	\x03\x02\x02\x02\u{101e}\u{1021}\x03\x02\x02\x02\u{101f}\u{101d}\x03\x02\
	\x02\x02\u{101f}\u{1020}\x03\x02\x02\x02\u{1020}\u{163}\x03\x02\x02\x02\
	\u{1021}\u{101f}\x03\x02\x02\x02\u{1022}\u{1026}\x05\u{16a}\u{b6}\x02\u{1023}\
	\u{1025}\x05\u{16c}\u{b7}\x02\u{1024}\u{1023}\x03\x02\x02\x02\u{1025}\u{1028}\
	\x03\x02\x02\x02\u{1026}\u{1024}\x03\x02\x02\x02\u{1026}\u{1027}\x03\x02\
	\x02\x02\u{1027}\u{165}\x03\x02\x02\x02\u{1028}\u{1026}\x03\x02\x02\x02\
	\u{1029}\u{102c}\x05\u{1e4}\u{f3}\x02\u{102a}\u{102c}\x07\u{1c4}\x02\x02\
	\u{102b}\u{1029}\x03\x02\x02\x02\u{102b}\u{102a}\x03\x02\x02\x02\u{102c}\
	\u{167}\x03\x02\x02\x02\u{102d}\u{102e}\x07\x08\x02\x02\u{102e}\u{102f}\
	\x05\u{218}\u{10d}\x02\u{102f}\u{1030}\x07\x09\x02\x02\u{1030}\u{169}\x03\
	\x02\x02\x02\u{1031}\u{1038}\x05\u{166}\u{b4}\x02\u{1032}\u{1038}\x05\u{168}\
	\u{b5}\x02\u{1033}\u{1034}\x07\x08\x02\x02\u{1034}\u{1035}\x05\u{1f2}\u{fa}\
	\x02\u{1035}\u{1036}\x07\x09\x02\x02\u{1036}\u{1038}\x03\x02\x02\x02\u{1037}\
	\u{1031}\x03\x02\x02\x02\u{1037}\u{1032}\x03\x02\x02\x02\u{1037}\u{1033}\
	\x03\x02\x02\x02\u{1038}\u{16b}\x03\x02\x02\x02\u{1039}\u{103a}\x07\x07\
	\x02\x02\u{103a}\u{1045}\x05\u{166}\u{b4}\x02\u{103b}\u{1045}\x05\u{168}\
	\u{b5}\x02\u{103c}\u{103d}\x07\x08\x02\x02\u{103d}\u{103e}\x05\u{1f2}\u{fa}\
	\x02\u{103e}\u{103f}\x07\x09\x02\x02\u{103f}\u{1045}\x03\x02\x02\x02\u{1040}\
	\u{1041}\x07\x08\x02\x02\u{1041}\u{1042}\x05\u{1e4}\u{f3}\x02\u{1042}\u{1043}\
	\x07\x09\x02\x02\u{1043}\u{1045}\x03\x02\x02\x02\u{1044}\u{1039}\x03\x02\
	\x02\x02\u{1044}\u{103b}\x03\x02\x02\x02\u{1044}\u{103c}\x03\x02\x02\x02\
	\u{1044}\u{1040}\x03\x02\x02\x02\u{1045}\u{16d}\x03\x02\x02\x02\u{1046}\
	\u{104f}\x07\x55\x02\x02\u{1047}\u{104f}\x07\u{161}\x02\x02\u{1048}\u{104f}\
	\x07\u{163}\x02\x02\u{1049}\u{104f}\x07\u{164}\x02\x02\u{104a}\u{104f}\x07\
	\u{165}\x02\x02\u{104b}\u{104f}\x07\u{b3}\x02\x02\u{104c}\u{104f}\x07\u{9f}\
	\x02\x02\u{104d}\u{104f}\x05\u{1e4}\u{f3}\x02\u{104e}\u{1046}\x03\x02\x02\
	\x02\u{104e}\u{1047}\x03\x02\x02\x02\u{104e}\u{1048}\x03\x02\x02\x02\u{104e}\
	\u{1049}\x03\x02\x02\x02\u{104e}\u{104a}\x03\x02\x02\x02\u{104e}\u{104b}\
	\x03\x02\x02\x02\u{104e}\u{104c}\x03\x02\x02\x02\u{104e}\u{104d}\x03\x02\
	\x02\x02\u{104f}\u{16f}\x03\x02\x02\x02\u{1050}\u{105b}\x07\u{ef}\x02\x02\
	\u{1051}\u{105b}\x07\u{1b6}\x02\x02\u{1052}\u{105b}\x05\u{172}\u{ba}\x02\
	\u{1053}\u{105b}\x05\u{17c}\u{bf}\x02\u{1054}\u{1055}\x05\u{16e}\u{b8}\x02\
	\u{1055}\u{1056}\x05\u{212}\u{10a}\x02\u{1056}\u{105b}\x03\x02\x02\x02\u{1057}\
	\u{105b}\x05\u{1f0}\u{f9}\x02\u{1058}\u{105b}\x05\u{17a}\u{be}\x02\u{1059}\
	\u{105b}\x05\u{218}\u{10d}\x02\u{105a}\u{1050}\x03\x02\x02\x02\u{105a}\u{1051}\
	\x03\x02\x02\x02\u{105a}\u{1052}\x03\x02\x02\x02\u{105a}\u{1053}\x03\x02\
	\x02\x02\u{105a}\u{1054}\x03\x02\x02\x02\u{105a}\u{1057}\x03\x02\x02\x02\
	\u{105a}\u{1058}\x03\x02\x02\x02\u{105a}\u{1059}\x03\x02\x02\x02\u{105b}\
	\u{171}\x03\x02\x02\x02\u{105c}\u{105d}\x07\u{1b0}\x02\x02\u{105d}\u{105e}\
	\x05\u{1e6}\u{f4}\x02\u{105e}\u{173}\x03\x02\x02\x02\u{105f}\u{1060}\x09\
	\x2e\x02\x02\u{1060}\u{175}\x03\x02\x02\x02\u{1061}\u{1062}\x09\x2f\x02\
	\x02\u{1062}\u{177}\x03\x02\x02\x02\u{1063}\u{1064}\x09\x30\x02\x02\u{1064}\
	\u{179}\x03\x02\x02\x02\u{1065}\u{1066}\x09\x31\x02\x02\u{1066}\u{17b}\x03\
	\x02\x02\x02\u{1067}\u{106a}\x07\u{b3}\x02\x02\u{1068}\u{106b}\x05\u{17e}\
	\u{c0}\x02\u{1069}\u{106b}\x05\u{182}\u{c2}\x02\u{106a}\u{1068}\x03\x02\
	\x02\x02\u{106a}\u{1069}\x03\x02\x02\x02\u{106b}\u{17d}\x03\x02\x02\x02\
	\u{106c}\u{106e}\x05\u{180}\u{c1}\x02\u{106d}\u{106f}\x05\u{184}\u{c3}\x02\
	\u{106e}\u{106d}\x03\x02\x02\x02\u{106e}\u{106f}\x03\x02\x02\x02\u{106f}\
	\u{17f}\x03\x02\x02\x02\u{1070}\u{1071}\x05\u{186}\u{c4}\x02\u{1071}\u{1072}\
	\x05\u{188}\u{c5}\x02\u{1072}\u{1074}\x03\x02\x02\x02\u{1073}\u{1070}\x03\
	\x02\x02\x02\u{1074}\u{1075}\x03\x02\x02\x02\u{1075}\u{1073}\x03\x02\x02\
	\x02\u{1075}\u{1076}\x03\x02\x02\x02\u{1076}\u{181}\x03\x02\x02\x02\u{1077}\
	\u{107a}\x05\u{184}\u{c3}\x02\u{1078}\u{107b}\x05\u{180}\u{c1}\x02\u{1079}\
	\u{107b}\x05\u{184}\u{c3}\x02\u{107a}\u{1078}\x03\x02\x02\x02\u{107a}\u{1079}\
	\x03\x02\x02\x02\u{107a}\u{107b}\x03\x02\x02\x02\u{107b}\u{183}\x03\x02\
	\x02\x02\u{107c}\u{107d}\x05\u{186}\u{c4}\x02\u{107d}\u{107e}\x05\u{18a}\
	\u{c6}\x02\u{107e}\u{107f}\x07\u{169}\x02\x02\u{107f}\u{1080}\x05\u{18a}\
	\u{c6}\x02\u{1080}\u{185}\x03\x02\x02\x02\u{1081}\u{1083}\x09\x32\x02\x02\
	\u{1082}\u{1081}\x03\x02\x02\x02\u{1082}\u{1083}\x03\x02\x02\x02\u{1083}\
	\u{1087}\x03\x02\x02\x02\u{1084}\u{1088}\x07\u{1bd}\x02\x02\u{1085}\u{1088}\
	\x07\u{1bf}\x02\x02\u{1086}\u{1088}\x05\u{218}\u{10d}\x02\u{1087}\u{1084}\
	\x03\x02\x02\x02\u{1087}\u{1085}\x03\x02\x02\x02\u{1087}\u{1086}\x03\x02\
	\x02\x02\u{1088}\u{187}\x03\x02\x02\x02\u{1089}\u{108a}\x09\x33\x02\x02\
	\u{108a}\u{189}\x03\x02\x02\x02\u{108b}\u{108c}\x09\x34\x02\x02\u{108c}\
	\u{18b}\x03\x02\x02\x02\u{108d}\u{1091}\x07\u{89}\x02\x02\u{108e}\u{108f}\
	\x07\x0c\x02\x02\u{108f}\u{1091}\x05\u{1e0}\u{f1}\x02\u{1090}\u{108d}\x03\
	\x02\x02\x02\u{1090}\u{108e}\x03\x02\x02\x02\u{1091}\u{18d}\x03\x02\x02\
	\x02\u{1092}\u{1093}\x07\x60\x02\x02\u{1093}\u{1094}\x07\x39\x02\x02\u{1094}\
	\u{1095}\x05\u{1e4}\u{f3}\x02\u{1095}\u{18f}\x03\x02\x02\x02\u{1096}\u{1097}\
	\x07\x38\x02\x02\u{1097}\u{1098}\x05\u{138}\u{9d}\x02\u{1098}\u{191}\x03\
	\x02\x02\x02\u{1099}\u{109b}\x07\u{152}\x02\x02\u{109a}\u{109c}\x05\u{190}\
	\u{c9}\x02\u{109b}\u{109a}\x03\x02\x02\x02\u{109b}\u{109c}\x03\x02\x02\x02\
	\u{109c}\u{10e4}\x03\x02\x02\x02\u{109d}\u{10a2}\x09\x35\x02\x02\u{109e}\
	\u{109f}\x07\x04\x02\x02\u{109f}\u{10a0}\x05\u{1f2}\u{fa}\x02\u{10a0}\u{10a1}\
	\x07\x05\x02\x02\u{10a1}\u{10a3}\x03\x02\x02\x02\u{10a2}\u{109e}\x03\x02\
	\x02\x02\u{10a2}\u{10a3}\x03\x02\x02\x02\u{10a3}\u{10e4}\x03\x02\x02\x02\
	\u{10a4}\u{10a9}\x07\u{185}\x02\x02\u{10a5}\u{10a6}\x07\x04\x02\x02\u{10a6}\
	\u{10a7}\x05\u{1f2}\u{fa}\x02\u{10a7}\u{10a8}\x07\x05\x02\x02\u{10a8}\u{10aa}\
	\x03\x02\x02\x02\u{10a9}\u{10a5}\x03\x02\x02\x02\u{10a9}\u{10aa}\x03\x02\
	\x02\x02\u{10aa}\u{10e4}\x03\x02\x02\x02\u{10ab}\u{10b4}\x09\x36\x02\x02\
	\u{10ac}\u{10ad}\x07\x04\x02\x02\u{10ad}\u{10b0}\x05\u{1f2}\u{fa}\x02\u{10ae}\
	\u{10af}\x07\x06\x02\x02\u{10af}\u{10b1}\x05\u{1f2}\u{fa}\x02\u{10b0}\u{10ae}\
	\x03\x02\x02\x02\u{10b0}\u{10b1}\x03\x02\x02\x02\u{10b1}\u{10b2}\x03\x02\
	\x02\x02\u{10b2}\u{10b3}\x07\x05\x02\x02\u{10b3}\u{10b5}\x03\x02\x02\x02\
	\u{10b4}\u{10ac}\x03\x02\x02\x02\u{10b4}\u{10b5}\x03\x02\x02\x02\u{10b5}\
	\u{10e4}\x03\x02\x02\x02\u{10b6}\u{10c1}\x07\u{b3}\x02\x02\u{10b7}\u{10ba}\
	\x09\x37\x02\x02\u{10b8}\u{10b9}\x07\u{169}\x02\x02\u{10b9}\u{10bb}\x07\
	\u{e3}\x02\x02\u{10ba}\u{10b8}\x03\x02\x02\x02\u{10ba}\u{10bb}\x03\x02\x02\
	\x02\u{10bb}\u{10c2}\x03\x02\x02\x02\u{10bc}\u{10bf}\x09\x38\x02\x02\u{10bd}\
	\u{10be}\x07\u{169}\x02\x02\u{10be}\u{10c0}\x09\x39\x02\x02\u{10bf}\u{10bd}\
	\x03\x02\x02\x02\u{10bf}\u{10c0}\x03\x02\x02\x02\u{10c0}\u{10c2}\x03\x02\
	\x02\x02\u{10c1}\u{10b7}\x03\x02\x02\x02\u{10c1}\u{10bc}\x03\x02\x02\x02\
	\u{10c1}\u{10c2}\x03\x02\x02\x02\u{10c2}\u{10e4}\x03\x02\x02\x02\u{10c3}\
	\u{10c7}\x07\u{163}\x02\x02\u{10c4}\u{10c5}\x07\u{196}\x02\x02\u{10c5}\u{10c6}\
	\x07\u{161}\x02\x02\u{10c6}\u{10c8}\x07\u{199}\x02\x02\u{10c7}\u{10c4}\x03\
	\x02\x02\x02\u{10c7}\u{10c8}\x03\x02\x02\x02\u{10c8}\u{10e4}\x03\x02\x02\
	\x02\u{10c9}\u{10ce}\x07\u{161}\x02\x02\u{10ca}\u{10cb}\x07\x04\x02\x02\
	\u{10cb}\u{10cc}\x05\u{1f2}\u{fa}\x02\u{10cc}\u{10cd}\x07\x05\x02\x02\u{10cd}\
	\u{10cf}\x03\x02\x02\x02\u{10ce}\u{10ca}\x03\x02\x02\x02\u{10ce}\u{10cf}\
	\x03\x02\x02\x02\u{10cf}\u{10d3}\x03\x02\x02\x02\u{10d0}\u{10d1}\x07\u{196}\
	\x02\x02\u{10d1}\u{10d2}\x07\u{161}\x02\x02\u{10d2}\u{10d4}\x07\u{199}\x02\
	\x02\u{10d3}\u{10d0}\x03\x02\x02\x02\u{10d3}\u{10d4}\x03\x02\x02\x02\u{10d4}\
	\u{10e4}\x03\x02\x02\x02\u{10d5}\u{10d6}\x07\u{97}\x02\x02\u{10d6}\u{10d9}\
	\x07\x04\x02\x02\u{10d7}\u{10da}\x05\u{1f2}\u{fa}\x02\u{10d8}\u{10da}\x07\
	\x14\x02\x02\u{10d9}\u{10d7}\x03\x02\x02\x02\u{10d9}\u{10d8}\x03\x02\x02\
	\x02\u{10da}\u{10db}\x03\x02\x02\x02\u{10db}\u{10e4}\x07\x05\x02\x02\u{10dc}\
	\u{10dd}\x07\u{98}\x02\x02\u{10dd}\u{10e0}\x07\x04\x02\x02\u{10de}\u{10e1}\
	\x05\u{1f2}\u{fa}\x02\u{10df}\u{10e1}\x07\x14\x02\x02\u{10e0}\u{10de}\x03\
	\x02\x02\x02\u{10e0}\u{10df}\x03\x02\x02\x02\u{10e1}\u{10e2}\x03\x02\x02\
	\x02\u{10e2}\u{10e4}\x07\x05\x02\x02\u{10e3}\u{1099}\x03\x02\x02\x02\u{10e3}\
	\u{109d}\x03\x02\x02\x02\u{10e3}\u{10a4}\x03\x02\x02\x02\u{10e3}\u{10ab}\
	\x03\x02\x02\x02\u{10e3}\u{10b6}\x03\x02\x02\x02\u{10e3}\u{10c3}\x03\x02\
	\x02\x02\u{10e3}\u{10c9}\x03\x02\x02\x02\u{10e3}\u{10d5}\x03\x02\x02\x02\
	\u{10e3}\u{10dc}\x03\x02\x02\x02\u{10e4}\u{193}\x03\x02\x02\x02\u{10e5}\
	\u{10e6}\x09\x3a\x02\x02\u{10e6}\u{195}\x03\x02\x02\x02\u{10e7}\u{10f8}\
	\x05\u{192}\u{ca}\x02\u{10e8}\u{10f8}\x05\u{194}\u{cb}\x02\u{10e9}\u{10f5}\
	\x05\u{1e4}\u{f3}\x02\u{10ea}\u{10eb}\x07\x04\x02\x02\u{10eb}\u{10f0}\x05\
	\u{1f2}\u{fa}\x02\u{10ec}\u{10ed}\x07\x06\x02\x02\u{10ed}\u{10ef}\x05\u{1f2}\
	\u{fa}\x02\u{10ee}\u{10ec}\x03\x02\x02\x02\u{10ef}\u{10f2}\x03\x02\x02\x02\
	\u{10f0}\u{10ee}\x03\x02\x02\x02\u{10f0}\u{10f1}\x03\x02\x02\x02\u{10f1}\
	\u{10f3}\x03\x02\x02\x02\u{10f2}\u{10f0}\x03\x02\x02\x02\u{10f3}\u{10f4}\
	\x07\x05\x02\x02\u{10f4}\u{10f6}\x03\x02\x02\x02\u{10f5}\u{10ea}\x03\x02\
	\x02\x02\u{10f5}\u{10f6}\x03\x02\x02\x02\u{10f6}\u{10f8}\x03\x02\x02\x02\
	\u{10f7}\u{10e7}\x03\x02\x02\x02\u{10f7}\u{10e8}\x03\x02\x02\x02\u{10f7}\
	\u{10e9}\x03\x02\x02\x02\u{10f8}\u{197}\x03\x02\x02\x02\u{10f9}\u{10fe}\
	\x07\x17\x02\x02\u{10fa}\u{10fb}\x07\u{19e}\x02\x02\u{10fb}\u{10fc}\x05\
	\u{198}\u{cd}\x02\u{10fc}\u{10fd}\x07\u{1a0}\x02\x02\u{10fd}\u{10ff}\x03\
	\x02\x02\x02\u{10fe}\u{10fa}\x03\x02\x02\x02\u{10fe}\u{10ff}\x03\x02\x02\
	\x02\u{10ff}\u{1114}\x03\x02\x02\x02\u{1100}\u{1107}\x07\u{d5}\x02\x02\u{1101}\
	\u{1102}\x07\u{19e}\x02\x02\u{1102}\u{1103}\x05\u{198}\u{cd}\x02\u{1103}\
	\u{1104}\x07\x06\x02\x02\u{1104}\u{1105}\x05\u{198}\u{cd}\x02\u{1105}\u{1106}\
	\x07\u{1a0}\x02\x02\u{1106}\u{1108}\x03\x02\x02\x02\u{1107}\u{1101}\x03\
	\x02\x02\x02\u{1107}\u{1108}\x03\x02\x02\x02\u{1108}\u{1114}\x03\x02\x02\
	\x02\u{1109}\u{1110}\x07\u{153}\x02\x02\u{110a}\u{110c}\x07\u{19e}\x02\x02\
	\u{110b}\u{110d}\x05\u{1ba}\u{de}\x02\u{110c}\u{110b}\x03\x02\x02\x02\u{110c}\
	\u{110d}\x03\x02\x02\x02\u{110d}\u{110e}\x03\x02\x02\x02\u{110e}\u{1111}\
	\x07\u{1a0}\x02\x02\u{110f}\u{1111}\x07\u{19c}\x02\x02\u{1110}\u{110a}\x03\
	\x02\x02\x02\u{1110}\u{110f}\x03\x02\x02\x02\u{1110}\u{1111}\x03\x02\x02\
	\x02\u{1111}\u{1114}\x03\x02\x02\x02\u{1112}\u{1114}\x05\u{196}\u{cc}\x02\
	\u{1113}\u{10f9}\x03\x02\x02\x02\u{1113}\u{1100}\x03\x02\x02\x02\u{1113}\
	\u{1109}\x03\x02\x02\x02\u{1113}\u{1112}\x03\x02\x02\x02\u{1114}\u{199}\
	\x03\x02\x02\x02\u{1115}\u{111a}\x05\u{19c}\u{cf}\x02\u{1116}\u{1117}\x07\
	\x06\x02\x02\u{1117}\u{1119}\x05\u{19c}\u{cf}\x02\u{1118}\u{1116}\x03\x02\
	\x02\x02\u{1119}\u{111c}\x03\x02\x02\x02\u{111a}\u{1118}\x03\x02\x02\x02\
	\u{111a}\u{111b}\x03\x02\x02\x02\u{111b}\u{19b}\x03\x02\x02\x02\u{111c}\
	\u{111a}\x03\x02\x02\x02\u{111d}\u{111e}\x05\u{138}\u{9d}\x02\u{111e}\u{1122}\
	\x05\u{198}\u{cd}\x02\u{111f}\u{1121}\x05\u{19e}\u{d0}\x02\u{1120}\u{111f}\
	\x03\x02\x02\x02\u{1121}\u{1124}\x03\x02\x02\x02\u{1122}\u{1120}\x03\x02\
	\x02\x02\u{1122}\u{1123}\x03\x02\x02\x02\u{1123}\u{19d}\x03\x02\x02\x02\
	\u{1124}\u{1122}\x03\x02\x02\x02\u{1125}\u{1126}\x05\u{15a}\u{ae}\x02\u{1126}\
	\u{1127}\x07\u{ef}\x02\x02\u{1127}\u{112c}\x03\x02\x02\x02\u{1128}\u{112c}\
	\x05\u{1a0}\u{d1}\x02\u{1129}\u{112c}\x05\x62\x32\x02\u{112a}\u{112c}\x05\
	\u{18c}\u{c7}\x02\u{112b}\u{1125}\x03\x02\x02\x02\u{112b}\u{1128}\x03\x02\
	\x02\x02\u{112b}\u{1129}\x03\x02\x02\x02\u{112b}\u{112a}\x03\x02\x02\x02\
	\u{112c}\u{19f}\x03\x02\x02\x02\u{112d}\u{112e}\x07\x60\x02\x02\u{112e}\
	\u{112f}\x05\u{14e}\u{a8}\x02\u{112f}\u{1a1}\x03\x02\x02\x02\u{1130}\u{1131}\
	\x09\x3b\x02\x02\u{1131}\u{1132}\x05\u{14e}\u{a8}\x02\u{1132}\u{1a3}\x03\
	\x02\x02\x02\u{1133}\u{1138}\x05\u{1a6}\u{d4}\x02\u{1134}\u{1135}\x07\x06\
	\x02\x02\u{1135}\u{1137}\x05\u{1a6}\u{d4}\x02\u{1136}\u{1134}\x03\x02\x02\
	\x02\u{1137}\u{113a}\x03\x02\x02\x02\u{1138}\u{1136}\x03\x02\x02\x02\u{1138}\
	\u{1139}\x03\x02\x02\x02\u{1139}\u{1a5}\x03\x02\x02\x02\u{113a}\u{1138}\
	\x03\x02\x02\x02\u{113b}\u{113c}\x05\u{1e0}\u{f1}\x02\u{113c}\u{1140}\x05\
	\u{198}\u{cd}\x02\u{113d}\u{113e}\x05\u{15a}\u{ae}\x02\u{113e}\u{113f}\x07\
	\u{ef}\x02\x02\u{113f}\u{1141}\x03\x02\x02\x02\u{1140}\u{113d}\x03\x02\x02\
	\x02\u{1140}\u{1141}\x03\x02\x02\x02\u{1141}\u{1143}\x03\x02\x02\x02\u{1142}\
	\u{1144}\x05\x62\x32\x02\u{1143}\u{1142}\x03\x02\x02\x02\u{1143}\u{1144}\
	\x03\x02\x02\x02\u{1144}\u{1a7}\x03\x02\x02\x02\u{1145}\u{114a}\x05\u{1aa}\
	\u{d6}\x02\u{1146}\u{1147}\x07\x06\x02\x02\u{1147}\u{1149}\x05\u{1aa}\u{d6}\
	\x02\u{1148}\u{1146}\x03\x02\x02\x02\u{1149}\u{114c}\x03\x02\x02\x02\u{114a}\
	\u{1148}\x03\x02\x02\x02\u{114a}\u{114b}\x03\x02\x02\x02\u{114b}\u{1a9}\
	\x03\x02\x02\x02\u{114c}\u{114a}\x03\x02\x02\x02\u{114d}\u{1150}\x05\u{1f8}\
	\u{fd}\x02\u{114e}\u{1150}\x05\u{1ae}\u{d8}\x02\u{114f}\u{114d}\x03\x02\
	\x02\x02\u{114f}\u{114e}\x03\x02\x02\x02\u{1150}\u{1ab}\x03\x02\x02\x02\
	\u{1151}\u{1156}\x05\u{1ae}\u{d8}\x02\u{1152}\u{1153}\x07\x06\x02\x02\u{1153}\
	\u{1155}\x05\u{1ae}\u{d8}\x02\u{1154}\u{1152}\x03\x02\x02\x02\u{1155}\u{1158}\
	\x03\x02\x02\x02\u{1156}\u{1154}\x03\x02\x02\x02\u{1156}\u{1157}\x03\x02\
	\x02\x02\u{1157}\u{1ad}\x03\x02\x02\x02\u{1158}\u{1156}\x03\x02\x02\x02\
	\u{1159}\u{115a}\x05\u{1e0}\u{f1}\x02\u{115a}\u{115e}\x05\u{198}\u{cd}\x02\
	\u{115b}\u{115d}\x05\u{1b0}\u{d9}\x02\u{115c}\u{115b}\x03\x02\x02\x02\u{115d}\
	\u{1160}\x03\x02\x02\x02\u{115e}\u{115c}\x03\x02\x02\x02\u{115e}\u{115f}\
	\x03\x02\x02\x02\u{115f}\u{1af}\x03\x02\x02\x02\u{1160}\u{115e}\x03\x02\
	\x02\x02\u{1161}\u{1162}\x05\u{15a}\u{ae}\x02\u{1162}\u{1163}\x07\u{ef}\
	\x02\x02\u{1163}\u{1169}\x03\x02\x02\x02\u{1164}\u{1169}\x05\u{1a0}\u{d1}\
	\x02\u{1165}\u{1169}\x05\u{1b2}\u{da}\x02\u{1166}\u{1169}\x05\x62\x32\x02\
	\u{1167}\u{1169}\x05\u{1f4}\u{fb}\x02\u{1168}\u{1161}\x03\x02\x02\x02\u{1168}\
	\u{1164}\x03\x02\x02\x02\u{1168}\u{1165}\x03\x02\x02\x02\u{1168}\u{1166}\
	\x03\x02\x02\x02\u{1168}\u{1167}\x03\x02\x02\x02\u{1169}\u{1b1}\x03\x02\
	\x02\x02\u{116a}\u{116b}\x07\u{96}\x02\x02\u{116b}\u{116c}\x07\x10\x02\x02\
	\u{116c}\u{116d}\x07\x18\x02\x02\u{116d}\u{116e}\x07\x04\x02\x02\u{116e}\
	\u{116f}\x05\u{14e}\u{a8}\x02\u{116f}\u{1170}\x07\x05\x02\x02\u{1170}\u{117d}\
	\x03\x02\x02\x02\u{1171}\u{1175}\x07\u{96}\x02\x02\u{1172}\u{1176}\x07\x10\
	\x02\x02\u{1173}\u{1174}\x07\x26\x02\x02\u{1174}\u{1176}\x07\x60\x02\x02\
	\u{1175}\u{1172}\x03\x02\x02\x02\u{1175}\u{1173}\x03\x02\x02\x02\u{1176}\
	\u{1177}\x03\x02\x02\x02\u{1177}\u{1178}\x07\x18\x02\x02\u{1178}\u{117a}\
	\x07\u{a3}\x02\x02\u{1179}\u{117b}\x05\u{1b4}\u{db}\x02\u{117a}\u{1179}\
	\x03\x02\x02\x02\u{117a}\u{117b}\x03\x02\x02\x02\u{117b}\u{117d}\x03\x02\
	\x02\x02\u{117c}\u{116a}\x03\x02\x02\x02\u{117c}\u{1171}\x03\x02\x02\x02\
	\u{117d}\u{1b3}\x03\x02\x02\x02\u{117e}\u{1182}\x07\x04\x02\x02\u{117f}\
	\u{1181}\x05\u{1b6}\u{dc}\x02\u{1180}\u{117f}\x03\x02\x02\x02\u{1181}\u{1184}\
	\x03\x02\x02\x02\u{1182}\u{1180}\x03\x02\x02\x02\u{1182}\u{1183}\x03\x02\
	\x02\x02\u{1183}\u{1185}\x03\x02\x02\x02\u{1184}\u{1182}\x03\x02\x02\x02\
	\u{1185}\u{1186}\x07\x05\x02\x02\u{1186}\u{1b5}\x03\x02\x02\x02\u{1187}\
	\u{1188}\x07\u{14c}\x02\x02\u{1188}\u{1189}\x07\u{194}\x02\x02\u{1189}\u{118e}\
	\x05\u{1b8}\u{dd}\x02\u{118a}\u{118b}\x07\u{aa}\x02\x02\u{118b}\u{118c}\
	\x07\x26\x02\x02\u{118c}\u{118e}\x05\u{1b8}\u{dd}\x02\u{118d}\u{1187}\x03\
	\x02\x02\x02\u{118d}\u{118a}\x03\x02\x02\x02\u{118e}\u{1b7}\x03\x02\x02\
	\x02\u{118f}\u{1191}\x07\u{1a6}\x02\x02\u{1190}\u{118f}\x03\x02\x02\x02\
	\u{1190}\u{1191}\x03\x02\x02\x02\u{1191}\u{1192}\x03\x02\x02\x02\u{1192}\
	\u{1198}\x05\u{1f2}\u{fa}\x02\u{1193}\u{1195}\x07\u{1a6}\x02\x02\u{1194}\
	\u{1193}\x03\x02\x02\x02\u{1194}\u{1195}\x03\x02\x02\x02\u{1195}\u{1196}\
	\x03\x02\x02\x02\u{1196}\u{1198}\x07\u{1ba}\x02\x02\u{1197}\u{1190}\x03\
	\x02\x02\x02\u{1197}\u{1194}\x03\x02\x02\x02\u{1198}\u{1b9}\x03\x02\x02\
	\x02\u{1199}\u{119e}\x05\u{1bc}\u{df}\x02\u{119a}\u{119b}\x07\x06\x02\x02\
	\u{119b}\u{119d}\x05\u{1bc}\u{df}\x02\u{119c}\u{119a}\x03\x02\x02\x02\u{119d}\
	\u{11a0}\x03\x02\x02\x02\u{119e}\u{119c}\x03\x02\x02\x02\u{119e}\u{119f}\
	\x03\x02\x02\x02\u{119f}\u{1bb}\x03\x02\x02\x02\u{11a0}\u{119e}\x03\x02\
	\x02\x02\u{11a1}\u{11a3}\x05\u{1e0}\u{f1}\x02\u{11a2}\u{11a4}\x07\u{1b0}\
	\x02\x02\u{11a3}\u{11a2}\x03\x02\x02\x02\u{11a3}\u{11a4}\x03\x02\x02\x02\
	\u{11a4}\u{11a5}\x03\x02\x02\x02\u{11a5}\u{11a9}\x05\u{198}\u{cd}\x02\u{11a6}\
	\u{11a7}\x05\u{15a}\u{ae}\x02\u{11a7}\u{11a8}\x07\u{ef}\x02\x02\u{11a8}\
	\u{11aa}\x03\x02\x02\x02\u{11a9}\u{11a6}\x03\x02\x02\x02\u{11a9}\u{11aa}\
	\x03\x02\x02\x02\u{11aa}\u{11ac}\x03\x02\x02\x02\u{11ab}\u{11ad}\x05\x62\
	\x32\x02\u{11ac}\u{11ab}\x03\x02\x02\x02\u{11ac}\u{11ad}\x03\x02\x02\x02\
	\u{11ad}\u{1bd}\x03\x02\x02\x02\u{11ae}\u{11b0}\x07\u{1b8}\x02\x02\u{11af}\
	\u{11b1}\x07\u{1c9}\x02\x02\u{11b0}\u{11af}\x03\x02\x02\x02\u{11b1}\u{11b2}\
	\x03\x02\x02\x02\u{11b2}\u{11b0}\x03\x02\x02\x02\u{11b2}\u{11b3}\x03\x02\
	\x02\x02\u{11b3}\u{11b4}\x03\x02\x02\x02\u{11b4}\u{11b5}\x07\u{1ca}\x02\
	\x02\u{11b5}\u{1bf}\x03\x02\x02\x02\u{11b6}\u{11be}\x05\u{1c2}\u{e2}\x02\
	\u{11b7}\u{11be}\x05\u{1c4}\u{e3}\x02\u{11b8}\u{11be}\x05\u{1c6}\u{e4}\x02\
	\u{11b9}\u{11be}\x05\u{1c8}\u{e5}\x02\u{11ba}\u{11be}\x05\u{1ca}\u{e6}\x02\
	\u{11bb}\u{11be}\x05\x62\x32\x02\u{11bc}\u{11be}\x05\u{1cc}\u{e7}\x02\u{11bd}\
	\u{11b6}\x03\x02\x02\x02\u{11bd}\u{11b7}\x03\x02\x02\x02\u{11bd}\u{11b8}\
	\x03\x02\x02\x02\u{11bd}\u{11b9}\x03\x02\x02\x02\u{11bd}\u{11ba}\x03\x02\
	\x02\x02\u{11bd}\u{11bb}\x03\x02\x02\x02\u{11bd}\u{11bc}\x03\x02\x02\x02\
	\u{11be}\u{11c1}\x03\x02\x02\x02\u{11bf}\u{11bd}\x03\x02\x02\x02\u{11bf}\
	\u{11c0}\x03\x02\x02\x02\u{11c0}\u{1c1}\x03\x02\x02\x02\u{11c1}\u{11bf}\
	\x03\x02\x02\x02\u{11c2}\u{11c3}\x07\u{bf}\x02\x02\u{11c3}\u{11c4}\x09\x3c\
	\x02\x02\u{11c4}\u{1c3}\x03\x02\x02\x02\u{11c5}\u{11c6}\x07\u{148}\x02\x02\
	\u{11c6}\u{11c7}\x05\u{1e0}\u{f1}\x02\u{11c7}\u{1c5}\x03\x02\x02\x02\u{11c8}\
	\u{11cd}\x07\x68\x02\x02\u{11c9}\u{11ca}\x05\u{15a}\u{ae}\x02\u{11ca}\u{11cb}\
	\x07\x68\x02\x02\u{11cb}\u{11cd}\x03\x02\x02\x02\u{11cc}\u{11c8}\x03\x02\
	\x02\x02\u{11cc}\u{11c9}\x03\x02\x02\x02\u{11cd}\u{1c7}\x03\x02\x02\x02\
	\u{11ce}\u{11cf}\x07\u{ec}\x02\x02\u{11cf}\u{11d9}\x07\u{149}\x02\x02\u{11d0}\
	\u{11d1}\x07\x46\x02\x02\u{11d1}\u{11d9}\x07\u{149}\x02\x02\u{11d2}\u{11d3}\
	\x07\u{113}\x02\x02\u{11d3}\u{11d4}\x07\u{149}\x02\x02\u{11d4}\u{11d9}\x07\
	\x54\x02\x02\u{11d5}\u{11d6}\x07\u{e2}\x02\x02\u{11d6}\u{11d7}\x07\u{149}\
	\x02\x02\u{11d7}\u{11d9}\x07\x54\x02\x02\u{11d8}\u{11ce}\x03\x02\x02\x02\
	\u{11d8}\u{11d0}\x03\x02\x02\x02\u{11d8}\u{11d2}\x03\x02\x02\x02\u{11d8}\
	\u{11d5}\x03\x02\x02\x02\u{11d9}\u{1c9}\x03\x02\x02\x02\u{11da}\u{11db}\
	\x07\u{127}\x02\x02\u{11db}\u{11dc}\x07\u{ef}\x02\x02\u{11dc}\u{11dd}\x07\
	\u{f5}\x02\x02\u{11dd}\u{11de}\x07\u{ef}\x02\x02\u{11de}\u{11e4}\x07\u{af}\
	\x02\x02\u{11df}\u{11e0}\x07\x2a\x02\x02\u{11e0}\u{11e1}\x07\u{f5}\x02\x02\
	\u{11e1}\u{11e2}\x07\u{ef}\x02\x02\u{11e2}\u{11e4}\x07\u{af}\x02\x02\u{11e3}\
	\u{11da}\x03\x02\x02\x02\u{11e3}\u{11df}\x03\x02\x02\x02\u{11e4}\u{1cb}\
	\x03\x02\x02\x02\u{11e5}\u{11e6}\x07\u{149}\x02\x02\u{11e6}\u{11e7}\x07\
	\u{135}\x02\x02\u{11e7}\u{11ec}\x07\u{b7}\x02\x02\u{11e8}\u{11e9}\x07\u{149}\
	\x02\x02\u{11e9}\u{11ea}\x07\u{135}\x02\x02\u{11ea}\u{11ec}\x07\x62\x02\
	\x02\u{11eb}\u{11e5}\x03\x02\x02\x02\u{11eb}\u{11e8}\x03\x02\x02\x02\u{11ec}\
	\u{1cd}\x03\x02\x02\x02\u{11ed}\u{11ee}\x07\u{190}\x02\x02\u{11ee}\u{11ef}\
	\x05\u{14e}\u{a8}\x02\u{11ef}\u{11f0}\x07\u{160}\x02\x02\u{11f0}\u{11f1}\
	\x05\u{14e}\u{a8}\x02\u{11f1}\u{1cf}\x03\x02\x02\x02\u{11f2}\u{11f3}\x07\
	\u{193}\x02\x02\u{11f3}\u{11f8}\x05\u{1d2}\u{ea}\x02\u{11f4}\u{11f5}\x07\
	\x06\x02\x02\u{11f5}\u{11f7}\x05\u{1d2}\u{ea}\x02\u{11f6}\u{11f4}\x03\x02\
	\x02\x02\u{11f7}\u{11fa}\x03\x02\x02\x02\u{11f8}\u{11f6}\x03\x02\x02\x02\
	\u{11f8}\u{11f9}\x03\x02\x02\x02\u{11f9}\u{1d1}\x03\x02\x02\x02\u{11fa}\
	\u{11f8}\x03\x02\x02\x02\u{11fb}\u{11fc}\x05\u{1e0}\u{f1}\x02\u{11fc}\u{11fd}\
	\x07\x18\x02\x02\u{11fd}\u{11fe}\x05\u{1d4}\u{eb}\x02\u{11fe}\u{1d3}\x03\
	\x02\x02\x02\u{11ff}\u{122e}\x05\u{1e0}\u{f1}\x02\u{1200}\u{1201}\x07\x04\
	\x02\x02\u{1201}\u{1202}\x05\u{1e0}\u{f1}\x02\u{1202}\u{1203}\x07\x05\x02\
	\x02\u{1203}\u{122e}\x03\x02\x02\x02\u{1204}\u{1227}\x07\x04\x02\x02\u{1205}\
	\u{1206}\x07\x35\x02\x02\u{1206}\u{1207}\x07\x26\x02\x02\u{1207}\u{120c}\
	\x05\u{14e}\u{a8}\x02\u{1208}\u{1209}\x07\x06\x02\x02\u{1209}\u{120b}\x05\
	\u{14e}\u{a8}\x02\u{120a}\u{1208}\x03\x02\x02\x02\u{120b}\u{120e}\x03\x02\
	\x02\x02\u{120c}\u{120a}\x03\x02\x02\x02\u{120c}\u{120d}\x03\x02\x02\x02\
	\u{120d}\u{1228}\x03\x02\x02\x02\u{120e}\u{120c}\x03\x02\x02\x02\u{120f}\
	\u{1210}\x09\x1a\x02\x02\u{1210}\u{1211}\x07\x26\x02\x02\u{1211}\u{1216}\
	\x05\u{14e}\u{a8}\x02\u{1212}\u{1213}\x07\x06\x02\x02\u{1213}\u{1215}\x05\
	\u{14e}\u{a8}\x02\u{1214}\u{1212}\x03\x02\x02\x02\u{1215}\u{1218}\x03\x02\
	\x02\x02\u{1216}\u{1214}\x03\x02\x02\x02\u{1216}\u{1217}\x03\x02\x02\x02\
	\u{1217}\u{121a}\x03\x02\x02\x02\u{1218}\u{1216}\x03\x02\x02\x02\u{1219}\
	\u{120f}\x03\x02\x02\x02\u{1219}\u{121a}\x03\x02\x02\x02\u{121a}\u{1225}\
	\x03\x02\x02\x02\u{121b}\u{121c}\x09\x1b\x02\x02\u{121c}\u{121d}\x07\x26\
	\x02\x02\u{121d}\u{1222}\x05\u{ae}\x58\x02\u{121e}\u{121f}\x07\x06\x02\x02\
	\u{121f}\u{1221}\x05\u{ae}\x58\x02\u{1220}\u{121e}\x03\x02\x02\x02\u{1221}\
	\u{1224}\x03\x02\x02\x02\u{1222}\u{1220}\x03\x02\x02\x02\u{1222}\u{1223}\
	\x03\x02\x02\x02\u{1223}\u{1226}\x03\x02\x02\x02\u{1224}\u{1222}\x03\x02\
	\x02\x02\u{1225}\u{121b}\x03\x02\x02\x02\u{1225}\u{1226}\x03\x02\x02\x02\
	\u{1226}\u{1228}\x03\x02\x02\x02\u{1227}\u{1205}\x03\x02\x02\x02\u{1227}\
	\u{1219}\x03\x02\x02\x02\u{1228}\u{122a}\x03\x02\x02\x02\u{1229}\u{122b}\
	\x05\u{1d6}\u{ec}\x02\u{122a}\u{1229}\x03\x02\x02\x02\u{122a}\u{122b}\x03\
	\x02\x02\x02\u{122b}\u{122c}\x03\x02\x02\x02\u{122c}\u{122e}\x07\x05\x02\
	\x02\u{122d}\u{11ff}\x03\x02\x02\x02\u{122d}\u{1200}\x03\x02\x02\x02\u{122d}\
	\u{1204}\x03\x02\x02\x02\u{122e}\u{1d5}\x03\x02\x02\x02\u{122f}\u{1230}\
	\x07\u{112}\x02\x02\u{1230}\u{1240}\x05\u{1d8}\u{ed}\x02\u{1231}\u{1232}\
	\x07\u{130}\x02\x02\u{1232}\u{1240}\x05\u{1d8}\u{ed}\x02\u{1233}\u{1234}\
	\x07\u{112}\x02\x02\u{1234}\u{1235}\x07\x1e\x02\x02\u{1235}\u{1236}\x05\
	\u{1d8}\u{ed}\x02\u{1236}\u{1237}\x07\x12\x02\x02\u{1237}\u{1238}\x05\u{1d8}\
	\u{ed}\x02\u{1238}\u{1240}\x03\x02\x02\x02\u{1239}\u{123a}\x07\u{130}\x02\
	\x02\u{123a}\u{123b}\x07\x1e\x02\x02\u{123b}\u{123c}\x05\u{1d8}\u{ed}\x02\
	\u{123c}\u{123d}\x07\x12\x02\x02\u{123d}\u{123e}\x05\u{1d8}\u{ed}\x02\u{123e}\
	\u{1240}\x03\x02\x02\x02\u{123f}\u{122f}\x03\x02\x02\x02\u{123f}\u{1231}\
	\x03\x02\x02\x02\u{123f}\u{1233}\x03\x02\x02\x02\u{123f}\u{1239}\x03\x02\
	\x02\x02\u{1240}\u{1d7}\x03\x02\x02\x02\u{1241}\u{1242}\x07\u{176}\x02\x02\
	\u{1242}\u{1249}\x09\x3d\x02\x02\u{1243}\u{1244}\x07\x4c\x02\x02\u{1244}\
	\u{1249}\x07\u{12f}\x02\x02\u{1245}\u{1246}\x05\u{14e}\u{a8}\x02\u{1246}\
	\u{1247}\x09\x3d\x02\x02\u{1247}\u{1249}\x03\x02\x02\x02\u{1248}\u{1241}\
	\x03\x02\x02\x02\u{1248}\u{1243}\x03\x02\x02\x02\u{1248}\u{1245}\x03\x02\
	\x02\x02\u{1249}\u{1d9}\x03\x02\x02\x02\u{124a}\u{124f}\x05\u{1de}\u{f0}\
	\x02\u{124b}\u{124c}\x07\x06\x02\x02\u{124c}\u{124e}\x05\u{1de}\u{f0}\x02\
	\u{124d}\u{124b}\x03\x02\x02\x02\u{124e}\u{1251}\x03\x02\x02\x02\u{124f}\
	\u{124d}\x03\x02\x02\x02\u{124f}\u{1250}\x03\x02\x02\x02\u{1250}\u{1db}\
	\x03\x02\x02\x02\u{1251}\u{124f}\x03\x02\x02\x02\u{1252}\u{1253}\x07\u{a2}\
	\x02\x02\u{1253}\u{1254}\x07\x04\x02\x02\u{1254}\u{1255}\x05\u{14e}\u{a8}\
	\x02\u{1255}\u{1256}\x07\x05\x02\x02\u{1256}\u{125d}\x03\x02\x02\x02\u{1257}\
	\u{125d}\x07\u{a2}\x02\x02\u{1258}\u{125d}\x05\u{1de}\u{f0}\x02\u{1259}\
	\u{125d}\x07\u{87}\x02\x02\u{125a}\u{125d}\x07\u{c5}\x02\x02\u{125b}\u{125d}\
	\x07\u{129}\x02\x02\u{125c}\u{1252}\x03\x02\x02\x02\u{125c}\u{1257}\x03\
	\x02\x02\x02\u{125c}\u{1258}\x03\x02\x02\x02\u{125c}\u{1259}\x03\x02\x02\
	\x02\u{125c}\u{125a}\x03\x02\x02\x02\u{125c}\u{125b}\x03\x02\x02\x02\u{125d}\
	\u{1dd}\x03\x02\x02\x02\u{125e}\u{1263}\x05\u{1e4}\u{f3}\x02\u{125f}\u{1260}\
	\x07\x07\x02\x02\u{1260}\u{1262}\x05\u{1e4}\u{f3}\x02\u{1261}\u{125f}\x03\
	\x02\x02\x02\u{1262}\u{1265}\x03\x02\x02\x02\u{1263}\u{1261}\x03\x02\x02\
	\x02\u{1263}\u{1264}\x03\x02\x02\x02\u{1264}\u{1df}\x03\x02\x02\x02\u{1265}\
	\u{1263}\x03\x02\x02\x02\u{1266}\u{1267}\x05\u{1e4}\u{f3}\x02\u{1267}\u{1268}\
	\x05\u{1e2}\u{f2}\x02\u{1268}\u{1e1}\x03\x02\x02\x02\u{1269}\u{126a}\x07\
	\u{1a6}\x02\x02\u{126a}\u{126c}\x05\u{1e4}\u{f3}\x02\u{126b}\u{1269}\x03\
	\x02\x02\x02\u{126c}\u{126d}\x03\x02\x02\x02\u{126d}\u{126b}\x03\x02\x02\
	\x02\u{126d}\u{126e}\x03\x02\x02\x02\u{126e}\u{1271}\x03\x02\x02\x02\u{126f}\
	\u{1271}\x03\x02\x02\x02\u{1270}\u{126b}\x03\x02\x02\x02\u{1270}\u{126f}\
	\x03\x02\x02\x02\u{1271}\u{1e3}\x03\x02\x02\x02\u{1272}\u{1276}\x05\u{1e8}\
	\u{f5}\x02\u{1273}\u{1274}\x06\u{f3}\x1a\x02\u{1274}\u{1276}\x05\u{224}\
	\u{113}\x02\u{1275}\u{1272}\x03\x02\x02\x02\u{1275}\u{1273}\x03\x02\x02\
	\x02\u{1276}\u{1e5}\x03\x02\x02\x02\u{1277}\u{127b}\x05\u{1ea}\u{f6}\x02\
	\u{1278}\u{1279}\x06\u{f4}\x1b\x02\u{1279}\u{127b}\x05\u{224}\u{113}\x02\
	\u{127a}\u{1277}\x03\x02\x02\x02\u{127a}\u{1278}\x03\x02\x02\x02\u{127b}\
	\u{1e7}\x03\x02\x02\x02\u{127c}\u{1289}\x07\u{1c3}\x02\x02\u{127d}\u{1289}\
	\x05\u{1ec}\u{f7}\x02\u{127e}\u{127f}\x06\u{f5}\x1c\x02\u{127f}\u{1280}\
	\x07\u{a2}\x02\x02\u{1280}\u{1281}\x07\x04\x02\x02\u{1281}\u{1282}\x05\u{218}\
	\u{10d}\x02\u{1282}\u{1283}\x07\x05\x02\x02\u{1283}\u{1289}\x03\x02\x02\
	\x02\u{1284}\u{1285}\x06\u{f5}\x1d\x02\u{1285}\u{1289}\x05\u{222}\u{112}\
	\x02\u{1286}\u{1287}\x06\u{f5}\x1e\x02\u{1287}\u{1289}\x05\u{226}\u{114}\
	\x02\u{1288}\u{127c}\x03\x02\x02\x02\u{1288}\u{127d}\x03\x02\x02\x02\u{1288}\
	\u{127e}\x03\x02\x02\x02\u{1288}\u{1284}\x03\x02\x02\x02\u{1288}\u{1286}\
	\x03\x02\x02\x02\u{1289}\u{1e9}\x03\x02\x02\x02\u{128a}\u{1291}\x07\u{1c3}\
	\x02\x02\u{128b}\u{1291}\x05\u{1ec}\u{f7}\x02\u{128c}\u{128d}\x06\u{f6}\
	\x1f\x02\u{128d}\u{1291}\x05\u{222}\u{112}\x02\u{128e}\u{128f}\x06\u{f6}\
	\x20\x02\u{128f}\u{1291}\x05\u{226}\u{114}\x02\u{1290}\u{128a}\x03\x02\x02\
	\x02\u{1290}\u{128b}\x03\x02\x02\x02\u{1290}\u{128c}\x03\x02\x02\x02\u{1290}\
	\u{128e}\x03\x02\x02\x02\u{1291}\u{1eb}\x03\x02\x02\x02\u{1292}\u{1296}\
	\x07\u{1c4}\x02\x02\u{1293}\u{1294}\x06\u{f7}\x21\x02\u{1294}\u{1296}\x07\
	\u{1b9}\x02\x02\u{1295}\u{1292}\x03\x02\x02\x02\u{1295}\u{1293}\x03\x02\
	\x02\x02\u{1296}\u{1ed}\x03\x02\x02\x02\u{1297}\u{1298}\x07\u{1c4}\x02\x02\
	\u{1298}\u{1ef}\x03\x02\x02\x02\u{1299}\u{129b}\x06\u{f9}\x22\x02\u{129a}\
	\u{129c}\x07\u{1a6}\x02\x02\u{129b}\u{129a}\x03\x02\x02\x02\u{129b}\u{129c}\
	\x03\x02\x02\x02\u{129c}\u{129d}\x03\x02\x02\x02\u{129d}\u{12c5}\x07\u{1be}\
	\x02\x02\u{129e}\u{12a0}\x06\u{f9}\x23\x02\u{129f}\u{12a1}\x07\u{1a6}\x02\
	\x02\u{12a0}\u{129f}\x03\x02\x02\x02\u{12a0}\u{12a1}\x03\x02\x02\x02\u{12a1}\
	\u{12a2}\x03\x02\x02\x02\u{12a2}\u{12c5}\x07\u{1bf}\x02\x02\u{12a3}\u{12a5}\
	\x06\u{f9}\x24\x02\u{12a4}\u{12a6}\x07\u{1a6}\x02\x02\u{12a5}\u{12a4}\x03\
	\x02\x02\x02\u{12a5}\u{12a6}\x03\x02\x02\x02\u{12a6}\u{12a7}\x03\x02\x02\
	\x02\u{12a7}\u{12c5}\x09\x3e\x02\x02\u{12a8}\u{12aa}\x07\u{1a6}\x02\x02\
	\u{12a9}\u{12a8}\x03\x02\x02\x02\u{12a9}\u{12aa}\x03\x02\x02\x02\u{12aa}\
	\u{12ab}\x03\x02\x02\x02\u{12ab}\u{12c5}\x07\u{1bd}\x02\x02\u{12ac}\u{12ae}\
	\x07\u{1a6}\x02\x02\u{12ad}\u{12ac}\x03\x02\x02\x02\u{12ad}\u{12ae}\x03\
	\x02\x02\x02\u{12ae}\u{12af}\x03\x02\x02\x02\u{12af}\u{12c5}\x07\u{1ba}\
	\x02\x02\u{12b0}\u{12b2}\x07\u{1a6}\x02\x02\u{12b1}\u{12b0}\x03\x02\x02\
	\x02\u{12b1}\u{12b2}\x03\x02\x02\x02\u{12b2}\u{12b3}\x03\x02\x02\x02\u{12b3}\
	\u{12c5}\x07\u{1bb}\x02\x02\u{12b4}\u{12b6}\x07\u{1a6}\x02\x02\u{12b5}\u{12b4}\
	\x03\x02\x02\x02\u{12b5}\u{12b6}\x03\x02\x02\x02\u{12b6}\u{12b7}\x03\x02\
	\x02\x02\u{12b7}\u{12c5}\x07\u{1bc}\x02\x02\u{12b8}\u{12ba}\x07\u{1a6}\x02\
	\x02\u{12b9}\u{12b8}\x03\x02\x02\x02\u{12b9}\u{12ba}\x03\x02\x02\x02\u{12ba}\
	\u{12bb}\x03\x02\x02\x02\u{12bb}\u{12c5}\x07\u{1c1}\x02\x02\u{12bc}\u{12be}\
	\x07\u{1a6}\x02\x02\u{12bd}\u{12bc}\x03\x02\x02\x02\u{12bd}\u{12be}\x03\
	\x02\x02\x02\u{12be}\u{12bf}\x03\x02\x02\x02\u{12bf}\u{12c5}\x07\u{1c0}\
	\x02\x02\u{12c0}\u{12c2}\x07\u{1a6}\x02\x02\u{12c1}\u{12c0}\x03\x02\x02\
	\x02\u{12c1}\u{12c2}\x03\x02\x02\x02\u{12c2}\u{12c3}\x03\x02\x02\x02\u{12c3}\
	\u{12c5}\x07\u{1c2}\x02\x02\u{12c4}\u{1299}\x03\x02\x02\x02\u{12c4}\u{129e}\
	\x03\x02\x02\x02\u{12c4}\u{12a3}\x03\x02\x02\x02\u{12c4}\u{12a9}\x03\x02\
	\x02\x02\u{12c4}\u{12ad}\x03\x02\x02\x02\u{12c4}\u{12b1}\x03\x02\x02\x02\
	\u{12c4}\u{12b5}\x03\x02\x02\x02\u{12c4}\u{12b9}\x03\x02\x02\x02\u{12c4}\
	\u{12bd}\x03\x02\x02\x02\u{12c4}\u{12c1}\x03\x02\x02\x02\u{12c5}\u{1f1}\
	\x03\x02\x02\x02\u{12c6}\u{12c9}\x07\u{1bd}\x02\x02\u{12c7}\u{12c9}\x05\
	\u{216}\u{10c}\x02\u{12c8}\u{12c6}\x03\x02\x02\x02\u{12c8}\u{12c7}\x03\x02\
	\x02\x02\u{12c9}\u{1f3}\x03\x02\x02\x02\u{12ca}\u{12cb}\x07\x45\x02\x02\
	\u{12cb}\u{12cd}\x05\u{1e0}\u{f1}\x02\u{12cc}\u{12ca}\x03\x02\x02\x02\u{12cc}\
	\u{12cd}\x03\x02\x02\x02\u{12cd}\u{12ce}\x03\x02\x02\x02\u{12ce}\u{12d2}\
	\x05\u{1f6}\u{fc}\x02\u{12cf}\u{12d1}\x05\u{206}\u{104}\x02\u{12d0}\u{12cf}\
	\x03\x02\x02\x02\u{12d1}\u{12d4}\x03\x02\x02\x02\u{12d2}\u{12d0}\x03\x02\
	\x02\x02\u{12d2}\u{12d3}\x03\x02\x02\x02\u{12d3}\u{1f5}\x03\x02\x02\x02\
	\u{12d4}\u{12d2}\x03\x02\x02\x02\u{12d5}\u{12d9}\x05\u{1fc}\u{ff}\x02\u{12d6}\
	\u{12d9}\x05\u{1fe}\u{100}\x02\u{12d7}\u{12d9}\x05\u{202}\u{102}\x02\u{12d8}\
	\u{12d5}\x03\x02\x02\x02\u{12d8}\u{12d6}\x03\x02\x02\x02\u{12d8}\u{12d7}\
	\x03\x02\x02\x02\u{12d9}\u{1f7}\x03\x02\x02\x02\u{12da}\u{12db}\x07\x45\
	\x02\x02\u{12db}\u{12dd}\x05\u{1e0}\u{f1}\x02\u{12dc}\u{12da}\x03\x02\x02\
	\x02\u{12dc}\u{12dd}\x03\x02\x02\x02\u{12dd}\u{12de}\x03\x02\x02\x02\u{12de}\
	\u{12e2}\x05\u{1fa}\u{fe}\x02\u{12df}\u{12e1}\x05\u{206}\u{104}\x02\u{12e0}\
	\u{12df}\x03\x02\x02\x02\u{12e1}\u{12e4}\x03\x02\x02\x02\u{12e2}\u{12e0}\
	\x03\x02\x02\x02\u{12e2}\u{12e3}\x03\x02\x02\x02\u{12e3}\u{1f9}\x03\x02\
	\x02\x02\u{12e4}\u{12e2}\x03\x02\x02\x02\u{12e5}\u{12e9}\x05\u{1fc}\u{ff}\
	\x02\u{12e6}\u{12e9}\x05\u{200}\u{101}\x02\u{12e7}\u{12e9}\x05\u{204}\u{103}\
	\x02\u{12e8}\u{12e5}\x03\x02\x02\x02\u{12e8}\u{12e6}\x03\x02\x02\x02\u{12e8}\
	\u{12e7}\x03\x02\x02\x02\u{12e9}\u{1fb}\x03\x02\x02\x02\u{12ea}\u{12eb}\
	\x07\x33\x02\x02\u{12eb}\u{12ec}\x07\x04\x02\x02\u{12ec}\u{12ed}\x05\u{156}\
	\u{ac}\x02\u{12ed}\u{12ee}\x07\x05\x02\x02\u{12ee}\u{1fd}\x03\x02\x02\x02\
	\u{12ef}\u{12f3}\x07\u{179}\x02\x02\u{12f0}\u{12f1}\x07\u{10a}\x02\x02\u{12f1}\
	\u{12f3}\x07\u{bd}\x02\x02\u{12f2}\u{12ef}\x03\x02\x02\x02\u{12f2}\u{12f0}\
	\x03\x02\x02\x02\u{12f3}\u{1ff}\x03\x02\x02\x02\u{12f4}\u{12f5}\x05\u{1fe}\
	\u{100}\x02\u{12f5}\u{12f6}\x05\u{114}\u{8b}\x02\u{12f6}\u{201}\x03\x02\
	\x02\x02\u{12f7}\u{12f8}\x07\u{11b}\x02\x02\u{12f8}\u{12fa}\x05\u{138}\u{9d}\
	\x02\u{12f9}\u{12fb}\x05\u{114}\u{8b}\x02\u{12fa}\u{12f9}\x03\x02\x02\x02\
	\u{12fa}\u{12fb}\x03\x02\x02\x02\u{12fb}\u{203}\x03\x02\x02\x02\u{12fc}\
	\u{12fd}\x07\u{8e}\x02\x02\u{12fd}\u{12fe}\x07\u{bd}\x02\x02\u{12fe}\u{12ff}\
	\x05\u{114}\u{8b}\x02\u{12ff}\u{1300}\x05\u{202}\u{102}\x02\u{1300}\u{205}\
	\x03\x02\x02\x02\u{1301}\u{1304}\x05\u{208}\u{105}\x02\u{1302}\u{1304}\x05\
	\u{20a}\u{106}\x02\u{1303}\u{1301}\x03\x02\x02\x02\u{1303}\u{1302}\x03\x02\
	\x02\x02\u{1304}\u{207}\x03\x02\x02\x02\u{1305}\u{1309}\x07\x75\x02\x02\
	\u{1306}\u{1307}\x07\u{ee}\x02\x02\u{1307}\u{1309}\x07\x75\x02\x02\u{1308}\
	\u{1305}\x03\x02\x02\x02\u{1308}\u{1306}\x03\x02\x02\x02\u{1309}\u{209}\
	\x03\x02\x02\x02\u{130a}\u{130b}\x09\x3f\x02\x02\u{130b}\u{20b}\x03\x02\
	\x02\x02\u{130c}\u{1311}\x05\u{20e}\u{108}\x02\u{130d}\u{130e}\x07\x06\x02\
	\x02\u{130e}\u{1310}\x05\u{20e}\u{108}\x02\u{130f}\u{130d}\x03\x02\x02\x02\
	\u{1310}\u{1313}\x03\x02\x02\x02\u{1311}\u{130f}\x03\x02\x02\x02\u{1311}\
	\u{1312}\x03\x02\x02\x02\u{1312}\u{20d}\x03\x02\x02\x02\u{1313}\u{1311}\
	\x03\x02\x02\x02\u{1314}\u{1316}\x05\u{138}\u{9d}\x02\u{1315}\u{1317}\x05\
	\u{210}\u{109}\x02\u{1316}\u{1315}\x03\x02\x02\x02\u{1316}\u{1317}\x03\x02\
	\x02\x02\u{1317}\u{20f}\x03\x02\x02\x02\u{1318}\u{1319}\x07\u{174}\x02\x02\
	\u{1319}\u{1325}\x05\u{198}\u{cd}\x02\u{131a}\u{1325}\x05\x62\x32\x02\u{131b}\
	\u{1325}\x05\u{18c}\u{c7}\x02\u{131c}\u{131d}\x09\x40\x02\x02\u{131d}\u{131e}\
	\x05\u{15a}\u{ae}\x02\u{131e}\u{131f}\x07\u{ef}\x02\x02\u{131f}\u{1325}\
	\x03\x02\x02\x02\u{1320}\u{1321}\x07\u{13c}\x02\x02\u{1321}\u{1325}\x05\
	\u{1a0}\u{d1}\x02\u{1322}\u{1323}\x07\x71\x02\x02\u{1323}\u{1325}\x07\x60\
	\x02\x02\u{1324}\u{1318}\x03\x02\x02\x02\u{1324}\u{131a}\x03\x02\x02\x02\
	\u{1324}\u{131b}\x03\x02\x02\x02\u{1324}\u{131c}\x03\x02\x02\x02\u{1324}\
	\u{1320}\x03\x02\x02\x02\u{1324}\u{1322}\x03\x02\x02\x02\u{1325}\u{211}\
	\x03\x02\x02\x02\u{1326}\u{132a}\x07\u{1b7}\x02\x02\u{1327}\u{1328}\x06\
	\u{10a}\x25\x02\u{1328}\u{132a}\x07\u{1b9}\x02\x02\u{1329}\u{1326}\x03\x02\
	\x02\x02\u{1329}\u{1327}\x03\x02\x02\x02\u{132a}\u{213}\x03\x02\x02\x02\
	\u{132b}\u{132e}\x05\u{212}\u{10a}\x02\u{132c}\u{132e}\x05\u{216}\u{10c}\
	\x02\u{132d}\u{132b}\x03\x02\x02\x02\u{132d}\u{132c}\x03\x02\x02\x02\u{132e}\
	\u{215}\x03\x02\x02\x02\u{132f}\u{1330}\x06\u{10c}\x26\x02\u{1330}\u{1334}\
	\x05\u{172}\u{ba}\x02\u{1331}\u{1332}\x06\u{10c}\x27\x02\u{1332}\u{1334}\
	\x07\u{1b6}\x02\x02\u{1333}\u{132f}\x03\x02\x02\x02\u{1333}\u{1331}\x03\
	\x02\x02\x02\u{1334}\u{217}\x03\x02\x02\x02\u{1335}\u{1337}\x05\u{214}\u{10b}\
	\x02\u{1336}\u{1335}\x03\x02\x02\x02\u{1337}\u{1338}\x03\x02\x02\x02\u{1338}\
	\u{1336}\x03\x02\x02\x02\u{1338}\u{1339}\x03\x02\x02\x02\u{1339}\u{219}\
	\x03\x02\x02\x02\u{133a}\u{133d}\x05\u{218}\u{10d}\x02\u{133b}\u{133d}\x07\
	\u{ef}\x02\x02\u{133c}\u{133a}\x03\x02\x02\x02\u{133c}\u{133b}\x03\x02\x02\
	\x02\u{133d}\u{21b}\x03\x02\x02\x02\u{133e}\u{1341}\x07\u{1bd}\x02\x02\u{133f}\
	\u{1341}\x05\u{218}\u{10d}\x02\u{1340}\u{133e}\x03\x02\x02\x02\u{1340}\u{133f}\
	\x03\x02\x02\x02\u{1341}\u{21d}\x03\x02\x02\x02\u{1342}\u{1344}\x05\u{b8}\
	\x5d\x02\u{1343}\u{1345}\x05\u{da}\x6e\x02\u{1344}\u{1343}\x03\x02\x02\x02\
	\u{1344}\u{1345}\x03\x02\x02\x02\u{1345}\u{1347}\x03\x02\x02\x02\u{1346}\
	\u{1348}\x05\u{1d0}\u{e9}\x02\u{1347}\u{1346}\x03\x02\x02\x02\u{1347}\u{1348}\
	\x03\x02\x02\x02\u{1348}\u{136d}\x03\x02\x02\x02\u{1349}\u{134a}\x07\u{80}\
	\x02\x02\u{134a}\u{136d}\x05\u{144}\u{a3}\x02\u{134b}\u{134c}\x07\u{13c}\
	\x02\x02\u{134c}\u{136d}\x05\u{220}\u{111}\x02\u{134d}\u{134e}\x07\x71\x02\
	\x02\u{134e}\u{136d}\x05\u{116}\u{8c}\x02\u{134f}\u{1350}\x07\x18\x02\x02\
	\u{1350}\u{136d}\x05\u{1e0}\u{f1}\x02\u{1351}\u{1353}\x05\u{ce}\x68\x02\
	\u{1352}\u{1354}\x05\u{1d0}\u{e9}\x02\u{1353}\u{1352}\x03\x02\x02\x02\u{1353}\
	\u{1354}\x03\x02\x02\x02\u{1354}\u{136d}\x03\x02\x02\x02\u{1355}\u{1357}\
	\x05\u{e4}\x73\x02\u{1356}\u{1358}\x05\u{ea}\x76\x02\u{1357}\u{1356}\x03\
	\x02\x02\x02\u{1357}\u{1358}\x03\x02\x02\x02\u{1358}\u{136d}\x03\x02\x02\
	\x02\u{1359}\u{135b}\x05\u{ea}\x76\x02\u{135a}\u{135c}\x05\u{e4}\x73\x02\
	\u{135b}\u{135a}\x03\x02\x02\x02\u{135b}\u{135c}\x03\x02\x02\x02\u{135c}\
	\u{136d}\x03\x02\x02\x02\u{135d}\u{136d}\x05\u{110}\u{89}\x02\u{135e}\u{136d}\
	\x05\u{10a}\u{86}\x02\u{135f}\u{1361}\x09\x11\x02\x02\u{1360}\u{1362}\x05\
	\u{104}\u{83}\x02\u{1361}\u{1360}\x03\x02\x02\x02\u{1361}\u{1362}\x03\x02\
	\x02\x02\u{1362}\u{1363}\x03\x02\x02\x02\u{1363}\u{136d}\x05\u{ac}\x57\x02\
	\u{1364}\u{136d}\x05\u{a6}\x54\x02\u{1365}\u{1367}\x07\x0d\x02\x02\u{1366}\
	\u{1368}\x05\u{144}\u{a3}\x02\u{1367}\u{1366}\x03\x02\x02\x02\u{1367}\u{1368}\
	\x03\x02\x02\x02\u{1368}\u{136a}\x03\x02\x02\x02\u{1369}\u{136b}\x05\u{da}\
	\x6e\x02\u{136a}\u{1369}\x03\x02\x02\x02\u{136a}\u{136b}\x03\x02\x02\x02\
	\u{136b}\u{136d}\x03\x02\x02\x02\u{136c}\u{1342}\x03\x02\x02\x02\u{136c}\
	\u{1349}\x03\x02\x02\x02\u{136c}\u{134b}\x03\x02\x02\x02\u{136c}\u{134d}\
	\x03\x02\x02\x02\u{136c}\u{134f}\x03\x02\x02\x02\u{136c}\u{1351}\x03\x02\
	\x02\x02\u{136c}\u{1355}\x03\x02\x02\x02\u{136c}\u{1359}\x03\x02\x02\x02\
	\u{136c}\u{135d}\x03\x02\x02\x02\u{136c}\u{135e}\x03\x02\x02\x02\u{136c}\
	\u{135f}\x03\x02\x02\x02\u{136c}\u{1364}\x03\x02\x02\x02\u{136c}\u{1365}\
	\x03\x02\x02\x02\u{136d}\u{21f}\x03\x02\x02\x02\u{136e}\u{1373}\x05\u{1e0}\
	\u{f1}\x02\u{136f}\u{1370}\x07\x07\x02\x02\u{1370}\u{1372}\x05\u{1e0}\u{f1}\
	\x02\u{1371}\u{136f}\x03\x02\x02\x02\u{1372}\u{1375}\x03\x02\x02\x02\u{1373}\
	\u{1371}\x03\x02\x02\x02\u{1373}\u{1374}\x03\x02\x02\x02\u{1374}\u{1376}\
	\x03\x02\x02\x02\u{1375}\u{1373}\x03\x02\x02\x02\u{1376}\u{1377}\x07\u{19a}\
	\x02\x02\u{1377}\u{1386}\x05\u{14e}\u{a8}\x02\u{1378}\u{1379}\x07\x06\x02\
	\x02\u{1379}\u{137e}\x05\u{1e0}\u{f1}\x02\u{137a}\u{137b}\x07\x07\x02\x02\
	\u{137b}\u{137d}\x05\u{1e0}\u{f1}\x02\u{137c}\u{137a}\x03\x02\x02\x02\u{137d}\
	\u{1380}\x03\x02\x02\x02\u{137e}\u{137c}\x03\x02\x02\x02\u{137e}\u{137f}\
	\x03\x02\x02\x02\u{137f}\u{1381}\x03\x02\x02\x02\u{1380}\u{137e}\x03\x02\
	\x02\x02\u{1381}\u{1382}\x07\u{19a}\x02\x02\u{1382}\u{1383}\x05\u{14e}\u{a8}\
	\x02\u{1383}\u{1385}\x03\x02\x02\x02\u{1384}\u{1378}\x03\x02\x02\x02\u{1385}\
	\u{1388}\x03\x02\x02\x02\u{1386}\u{1384}\x03\x02\x02\x02\u{1386}\u{1387}\
	\x03\x02\x02\x02\u{1387}\u{221}\x03\x02\x02\x02\u{1388}\u{1386}\x03\x02\
	\x02\x02\u{1389}\u{138a}\x09\x41\x02\x02\u{138a}\u{223}\x03\x02\x02\x02\
	\u{138b}\u{138c}\x09\x42\x02\x02\u{138c}\u{225}\x03\x02\x02\x02\u{138d}\
	\u{138e}\x09\x43\x02\x02\u{138e}\u{227}\x03\x02\x02\x02\u{285}\u{22a}\u{22f}\
	\u{232}\u{236}\u{23b}\u{240}\u{243}\u{247}\u{24e}\u{25d}\u{26a}\u{274}\u{277}\
	\u{27b}\u{282}\u{289}\u{294}\u{297}\u{2a0}\u{2ad}\u{2b2}\u{2b8}\u{2c1}\u{2d1}\
	\u{2d5}\u{2e3}\u{2e7}\u{2ec}\u{2ef}\u{2f6}\u{2f9}\u{2ff}\u{307}\u{30b}\u{310}\
	\u{332}\u{344}\u{34d}\u{34f}\u{36f}\u{373}\u{379}\u{37c}\u{37f}\u{386}\u{389}\
	\u{38d}\u{390}\u{398}\u{3a3}\u{3a5}\u{3ad}\u{3b0}\u{3b4}\u{3b7}\u{3bd}\u{3c8}\
	\u{3ce}\u{3d3}\u{3f5}\u{402}\u{41b}\u{424}\u{42c}\u{430}\u{435}\u{43b}\u{447}\
	\u{44f}\u{455}\u{463}\u{468}\u{478}\u{47f}\u{483}\u{489}\u{49b}\u{4af}\u{4b3}\
	\u{4b9}\u{4bd}\u{4c3}\u{4c9}\u{4cc}\u{4cf}\u{4d6}\u{4da}\u{4e4}\u{4e6}\u{4ef}\
	\u{4f6}\u{4fa}\u{502}\u{504}\u{50d}\u{510}\u{519}\u{51e}\u{524}\u{530}\u{533}\
	\u{53a}\u{545}\u{548}\u{54d}\u{550}\u{557}\u{55c}\u{566}\u{568}\u{56e}\u{572}\
	\u{577}\u{57d}\u{580}\u{587}\u{58b}\u{58e}\u{595}\u{59b}\u{59f}\u{5a5}\u{5a8}\
	\u{5ab}\u{5b2}\u{5b7}\u{5c0}\u{5c8}\u{5ce}\u{5d1}\u{5d4}\u{5da}\u{5de}\u{5e3}\
	\u{5e6}\u{5ea}\u{5ec}\u{5f2}\u{5fa}\u{602}\u{605}\u{60a}\u{613}\u{619}\u{61c}\
	\u{620}\u{623}\u{627}\u{62b}\u{647}\u{64a}\u{64e}\u{654}\u{657}\u{65a}\u{660}\
	\u{668}\u{66d}\u{673}\u{679}\u{67c}\u{683}\u{68a}\u{693}\u{698}\u{69d}\u{6a4}\
	\u{6aa}\u{6af}\u{6bb}\u{6be}\u{6c6}\u{6cc}\u{6cf}\u{6d2}\u{6d7}\u{6dd}\u{6e8}\
	\u{6ee}\u{6f5}\u{6f8}\u{701}\u{704}\u{708}\u{70f}\u{720}\u{73c}\u{73f}\u{745}\
	\u{74e}\u{757}\u{75a}\u{761}\u{764}\u{76d}\u{771}\u{77d}\u{781}\u{788}\u{7fc}\
	\u{804}\u{80c}\u{815}\u{81f}\u{823}\u{826}\u{82d}\u{833}\u{845}\u{851}\u{856}\
	\u{862}\u{86b}\u{873}\u{877}\u{87e}\u{880}\u{885}\u{88a}\u{88e}\u{891}\u{897}\
	\u{89c}\u{8a1}\u{8a5}\u{8ad}\u{8b2}\u{8b5}\u{8ba}\u{8be}\u{8c3}\u{8c5}\u{8c9}\
	\u{8d2}\u{8da}\u{8e0}\u{8e6}\u{8f7}\u{8fe}\u{903}\u{90a}\u{90f}\u{915}\u{918}\
	\u{930}\u{932}\u{93b}\u{946}\u{948}\u{94f}\u{954}\u{958}\u{95e}\u{966}\u{971}\
	\u{973}\u{97b}\u{986}\u{991}\u{999}\u{99f}\u{9ab}\u{9b2}\u{9b9}\u{9bf}\u{9ca}\
	\u{9d2}\u{9d8}\u{9de}\u{9e1}\u{9e9}\u{9f2}\u{9fb}\u{9fe}\u{a07}\u{a0a}\u{a13}\
	\u{a16}\u{a1f}\u{a22}\u{a25}\u{a2a}\u{a2c}\u{a30}\u{a3c}\u{a43}\u{a4a}\u{a54}\
	\u{a56}\u{a62}\u{a66}\u{a6a}\u{a70}\u{a75}\u{a7d}\u{a81}\u{a84}\u{a87}\u{a8a}\
	\u{a8e}\u{a92}\u{a97}\u{a9b}\u{a9e}\u{aa1}\u{aa4}\u{aa8}\u{aad}\u{ab1}\u{ab4}\
	\u{ab7}\u{aba}\u{abc}\u{ac2}\u{ac9}\u{ace}\u{ad1}\u{ad4}\u{ad8}\u{ae2}\u{ae6}\
	\u{ae8}\u{aeb}\u{aef}\u{af5}\u{af9}\u{b04}\u{b0e}\u{b12}\u{b1e}\u{b2a}\u{b39}\
	\u{b3e}\u{b44}\u{b50}\u{b60}\u{b65}\u{b72}\u{b77}\u{b7f}\u{b85}\u{b89}\u{b8c}\
	\u{b8f}\u{b96}\u{b9c}\u{ba5}\u{baf}\u{bbe}\u{bc3}\u{bc5}\u{bc9}\u{bd2}\u{bdf}\
	\u{be4}\u{be8}\u{bf0}\u{bf3}\u{bf7}\u{c05}\u{c12}\u{c17}\u{c1b}\u{c1e}\u{c22}\
	\u{c28}\u{c2b}\u{c32}\u{c3e}\u{c49}\u{c56}\u{c61}\u{c66}\u{c6e}\u{c73}\u{c7a}\
	\u{c83}\u{c86}\u{c8b}\u{c92}\u{c95}\u{ca0}\u{ca6}\u{cac}\u{cb1}\u{cb5}\u{cbb}\
	\u{cbf}\u{cc2}\u{cc7}\u{cca}\u{ccf}\u{cd3}\u{cd6}\u{cd9}\u{cdf}\u{ce4}\u{cec}\
	\u{cef}\u{cf3}\u{d04}\u{d06}\u{d09}\u{d14}\u{d1d}\u{d24}\u{d2c}\u{d33}\u{d38}\
	\u{d3b}\u{d3e}\u{d41}\u{d49}\u{d4c}\u{d54}\u{d57}\u{d5d}\u{d68}\u{d70}\u{d77}\
	\u{d7e}\u{d80}\u{d8d}\u{d97}\u{d9a}\u{d9c}\u{da6}\u{db0}\u{db3}\u{db5}\u{dbd}\
	\u{dc1}\u{dca}\u{dcd}\u{dd1}\u{dd6}\u{dda}\u{ddc}\u{de5}\u{df1}\u{df3}\u{dfa}\
	\u{e01}\u{e07}\u{e0d}\u{e0f}\u{e16}\u{e1e}\u{e26}\u{e2c}\u{e31}\u{e38}\u{e3e}\
	\u{e42}\u{e44}\u{e4b}\u{e54}\u{e5b}\u{e65}\u{e6a}\u{e6e}\u{e78}\u{e7f}\u{e8c}\
	\u{e8e}\u{e96}\u{e98}\u{e9c}\u{ea4}\u{ead}\u{eb3}\u{ebb}\u{ec0}\u{ecc}\u{ed1}\
	\u{ed4}\u{eda}\u{ede}\u{ee3}\u{ee8}\u{eed}\u{ef5}\u{f0f}\u{f11}\u{f1e}\u{f2a}\
	\u{f36}\u{f3a}\u{f43}\u{f47}\u{f59}\u{f5c}\u{f64}\u{f6d}\u{f76}\u{f84}\u{f8a}\
	\u{f92}\u{f9d}\u{fa4}\u{fa7}\u{fb4}\u{fb9}\u{fc1}\u{fc5}\u{fc9}\u{fd5}\u{fee}\
	\u{ff5}\u{ff8}\u{1007}\u{100b}\u{101d}\u{101f}\u{1026}\u{102b}\u{1037}\u{1044}\
	\u{104e}\u{105a}\u{106a}\u{106e}\u{1075}\u{107a}\u{1082}\u{1087}\u{1090}\
	\u{109b}\u{10a2}\u{10a9}\u{10b0}\u{10b4}\u{10ba}\u{10bf}\u{10c1}\u{10c7}\
	\u{10ce}\u{10d3}\u{10d9}\u{10e0}\u{10e3}\u{10f0}\u{10f5}\u{10f7}\u{10fe}\
	\u{1107}\u{110c}\u{1110}\u{1113}\u{111a}\u{1122}\u{112b}\u{1138}\u{1140}\
	\u{1143}\u{114a}\u{114f}\u{1156}\u{115e}\u{1168}\u{1175}\u{117a}\u{117c}\
	\u{1182}\u{118d}\u{1190}\u{1194}\u{1197}\u{119e}\u{11a3}\u{11a9}\u{11ac}\
	\u{11b2}\u{11bd}\u{11bf}\u{11cc}\u{11d8}\u{11e3}\u{11eb}\u{11f8}\u{120c}\
	\u{1216}\u{1219}\u{1222}\u{1225}\u{1227}\u{122a}\u{122d}\u{123f}\u{1248}\
	\u{124f}\u{125c}\u{1263}\u{126d}\u{1270}\u{1275}\u{127a}\u{1288}\u{1290}\
	\u{1295}\u{129b}\u{12a0}\u{12a5}\u{12a9}\u{12ad}\u{12b1}\u{12b5}\u{12b9}\
	\u{12bd}\u{12c1}\u{12c4}\u{12c8}\u{12cc}\u{12d2}\u{12d8}\u{12dc}\u{12e2}\
	\u{12e8}\u{12f2}\u{12fa}\u{1303}\u{1308}\u{1311}\u{1316}\u{1324}\u{1329}\
	\u{132d}\u{1333}\u{1338}\u{133c}\u{1340}\u{1344}\u{1347}\u{1353}\u{1357}\
	\u{135b}\u{1361}\u{1367}\u{136a}\u{136c}\u{1373}\u{137e}\u{1386}";

